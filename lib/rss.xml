<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Congzhi's Notes Vault]]></title><description><![CDATA[Obsidian digital garden]]></description><link>https://congzhi.wiki/</link><image><url>https://congzhi.wiki/lib/media/favicon.png</url><title>Congzhi&apos;s Notes Vault</title><link>https://congzhi.wiki/</link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Tue, 25 Mar 2025 19:39:52 GMT</lastBuildDate><atom:link href="https://congzhi.wiki/lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Tue, 25 Mar 2025 19:38:12 GMT</pubDate><copyright><![CDATA[Congzhi]]></copyright><ttl>60</ttl><dc:creator>Congzhi</dc:creator><item><title><![CDATA[1. Compilation]]></title><description><![CDATA[ 
 <br><br><br>在本节，我们将讨论 GCC 是如何一步一步地将 C/C++ 语言源代码编译成二进制机器语言的。也就是 C/C++ 代码是如何变成 ELF 的。<br><br>在编译 C/C++ 时，我们常常使用 GCC 作为我们的编译器。GCC 并不是 GNU C Compiler， GCC 是一系列编译器的集合。不仅仅支持 C 语言，还支持 C++ 、 D 、 Objective-C  、 Go 等其他的编程语言。你可以用 gcc -v 来查看你的 GCC 支持哪些语言。<br><br>我们把程序从源代码到可执行文件的过程分为两步——编译和链接。在本节，我们将会学习程序是如何编译的。我们把编译的过程共分为 3 步，分别是预处理、编译和汇编。我们先来从机器的视角观察 C/C++ 源代码是怎么样的。<br><br>这是一个最简单的例子。这是一段源代码，我将其存放到 hello.c 文件中。我们在文件中输入的所有指令都是 human-friendly 的，而计算机是没有办法理解这个文本文件到底写了什么的。<br>#include &lt;stdio.h&gt;
int main(){
	printf("hello, world\n"); // This prints "hello, world\n"
}
<br>这段源代码以文本文件的形式存储在磁盘上，它在计算机眼中就是这样的：<br>#include&lt;stdio.h&gt; int main(){printf("hello, world\n");//This prints "hello, world\n"}

<br>而实际上计算机存储的只有 0 和 1 构成的二进制数，如果将这些 ASCII 字符转换成 16 进制的二进制数，就是这样：<br>23696e636c7564653c737464696f2e683e20696e74206d61696e28297b7072696e7466282268656c6c6f2c20776f726c645c6e22293b2f2f54686973207072696e7473202268656c6c6f2c20776f726c645c6e22227d
<br><br>我们有源程序后，我们需要“翻译”这段程序，让计算机能够理解我们想要表达的意思，这个过程就是编译。而编译的第一步，就是预处理。<br>我们用下面的 shell 指令对程序进行预处理：<br>gcc -E hello.c -o hello.i
<br>完成后，编译器就会生成一个 .i 文件，即中间文件(intermediate file)。那么预处理的作用是什么呢？我们把这一步骤叫做预处理，把预处理完成所得到的文件叫中间文件。不难想到，预处理阶段是程序编译正式进行的临门一脚。预处理阶段的作用是处理源文件中以 # 开头的语句。即：<br>
<br>删除 #define 并展开其所定义的宏。
<br>处理所有条件预编译指令，如 #if、#ifdef、#endif等。
<br>插入头文件到#include处，可以递归方式进行处理（复制粘贴）。
<br>删除注释（可选择保留）。
<br>添加行标记和文件名标识。
<br>保留#pragma编译指令（编译用）。
<br>如果你打开 .i 文件，你会发现一些函数的声明、一些系统信息......各种乱七八糟的东西，但总体上还是可读的。只不过是将文件进行了一些加工。在中间文件中，你仍然会看到：<br>int main(){
	printf("hello, world\n");
}
<br>extern int printf (const char *__restrict __format, ...);
<br>在 hello.c 中，我们有 #include &lt;stdio.h&gt;。实际上，你为什么会看到乱七八糟的东西就是因为我们将头文件加入到预处理后的中间文件去了。此外，我们还观察到了文件中以 # 开头的行标记和文件名标识。如：<br># 0 "hello.c"
<br>预处理 -E 展开所有的头文件/strips comments/展开宏（完成后获得.i文件）<br>预处理-&gt;analysis/code generate-&gt;linking<br>
.cpp-&gt;.i-&gt;.o-&gt;.elf/.exe<br>预处理完成后的 .i 文件就是一个个的翻译单元<br>.o文件是一个个的 object file，在C++20也被叫做 object module<br>
.o文件中包含一系列的01数据和元数据（链接器用与重定义和。。。）元数据指明了当前的object file定义了那些符号声明了那些符号<br>这些01数据以一定的格式（数据段/bss/代码段)存储，这些格式也作为元数据存储在.o文件中<br>
.o文件是机器指令，实际上可以放到机器上运行了，但是我们上节课也看到，有的符号定义可能在其他的翻译单元（external reference)，也就是为什么在Linux中，我们把.o文件成为.elf，链接后的文件格式仍然是.elf。但是视角不同了。链接器的职责就是将符号的外部引用替换到。。。（place the placeholder of external reference to an address）<br>one definition rule(ODR): ambitious, which one to call<br>memory map<br>gcc common flags<br>-E 预处理 include a header twice is causing 重复定义<br>-S <br>-c<br>-l<br>生成可执行文件后：<br>
-ldd prog （查看动态链接库）<br>objdump -g 添加debug信息<br>为什么我不需要链接C的动态链接库来运行程序？我直接用 ./proc？甚至用pthread库我也可以./proc而不是 ./proc -lpthread<br>-L来寻找库路径（默认会在 PATH 中去寻找，PATH 有很多（和环境变量的关系呢？<br>
-I 是干嘛的？如果找不到，那么就在这里找<br>当使用&lt;&gt;时，就会去system path中寻找（include path<br>
echo $PATH]]></description><link>https://congzhi.wiki/building-and-version-control/1.-compilation.html</link><guid isPermaLink="false">Building and Version Control/1. Compilation.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 19:29:48 GMT</pubDate></item><item><title><![CDATA[2. Linking]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/building-and-version-control/2.-linking.html</link><guid isPermaLink="false">Building and Version Control/2. Linking.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 13 Mar 2025 18:59:52 GMT</pubDate></item><item><title><![CDATA[3. A Normal Project Structure]]></title><description><![CDATA[ 
 <br><br>在构建系列的<br>头文件：存放声明和内联化的函数/变量（constexpr/consteval...）declarations<br>因为内联后的符号没有定义<br>These files contain declarations and inline functions/variables. For example, constexpr and consteval declarations are often found in header files. Declarations inform the compiler about the existence and type of functions or variables without providing the full implementation.<br>Source Files (源文件): These files contain definitions. A definition is a specific type of declaration that provides complete information about an entity, including its implementation.<br>foo.h<br>int foo(int n); //A declaration, no function body.
extern int e; // A non-defining declaration.
<br>foo.cpp<br>#include "foo.h"

int foo(int n) // A definition, we have the function body after this.
{
    // Function implementation goes here.
}
int a; // Definition without initialization
int b = 10; // Definition with initialization
static int c = 10; // A file-scope static definition
extern int d = 10;
<br>other.cpp<br>int e = 10; // 
<br>源文件中存放definitions， definition is a specific type of declaration. Definition gives a set of informations about the entity but no verse visa<br>ProjectName/
├── include/              # Header file
│   ├── main.h
│   └── utils.h
├── src/                  # Source file
│   ├── main.cpp
│   └── utils.cpp
├── lib/                  # Libraries
│   └── mylib.a
├── build/                # Object files
│   └── (object files, executables)
├── tests/                # Testing code
│   └── test_main.cpp
├── CMakeLists.txt        # CMake build file
├── Makefile              # Makefile build file
└── README.md             # Intro to the project

<br>这节课用建立 shell 文件构建代码<br>gcc ....
gcc ....

gcc x.o y.o -o bin
<br>用上面的方法的劣势就是每次构建都需要整个的编译，而不是选择性编译<br>下节课用 makefile]]></description><link>https://congzhi.wiki/building-and-version-control/3.-a-normal-project-structure.html</link><guid isPermaLink="false">Building and Version Control/3. A Normal Project Structure.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Mar 2025 18:09:43 GMT</pubDate></item><item><title><![CDATA[4. Makefile and Building System]]></title><description><![CDATA[ 
 <br>Source: <a data-tooltip-position="top" aria-label="https://www.youtube.com/watch?v=DtGrdB8wQ_8&amp;t=14s" rel="noopener nofollow" class="external-link" href="https://www.youtube.com/watch?v=DtGrdB8wQ_8&amp;t=14s" target="_blank">Makefiles: 95% of what you need to know</a><br>what is a building system do?<br>
<br>自动地进行文件的编译和链接，将各个文件变成一个可执行文件。通过构建系统，你可以直观地体会到整个项目是如何编译并链接的，各个文件之间的联系是什么。
<br>应当只完成必要的：也就是说当文件（依赖项）有修改时，重新编译这些修改过的文件并链接。可以省去全部编译所产生的时间。也就是说你不需要重新编译所有的代码，用 shell bash 就需要整个的进行编译。当项目非常大时，你可能需要数个小时进行编译，而用makefile，你只需要编译需要的
<br>同时，build system 应当有一定的规约（一种编程语言，比如用shell script）使得整个构建系统易于上手
<br>一个简单的makefile.   前面的都是变量，直到 all: <br>CC=gcc # complier variable
INCDIRS=-I # 
OPT=-O0 # optimization variable
CFLAGS=-Wall -Wextra -g $(INCDIRS) $(OPT)

CFLAGS=x.c y.c
OBJECTS=x.o y.o

BINARY=bin

all: $(BINARY)

$(BINARY): $(OBJECTS)
		$(CC) -o $@ $^
%.o:%.c # make feature, % is a wildcard (repersenting everything)
		$(CC) $(CFLAGS) -c -o $@ $^
clean:
		rm -rf $(BINARY) $(OBJECTS)
<br>build rule: all: $(BINARY) 就是一个build rule（这里的target和dependencies有何联系？）<br>
all directive, 当你用make all就会转到makefile中的 （默认情况下只用 make 会转到第一个 rule）<br>上面的makefile的意思就是说当你在终端 make all 的时候，你就会转到 $(BINARY): $(OBJECTS)。但是BINARY depends on OBJECTS，也就是你要构建bin你就需要先得到所有的 .o 文件。如果没有，就会执行 %.o:%.c (.o 文件 依赖 .c 文件) @ 表示 LHS (.o) ^表示RHS (.c)<br>target: dependencies 如果所有依赖项都满足就执行 command
		command
<br>即使你有 x.o 如果你修改了源文件，make 一个新的 x.o 将会被编译(build system的第二个事情，只做需要的事情)<br>需要先介绍不用variable会怎么样。<br>用variable之后makefile才会做需要做的事情吗？<br>如果头文件修改，makefile不会察觉到有什么修改了（因为.h没有依赖项<br>第三个例子： featureful makefile---我们将头文件都放在include文件夹中，将库放到lib文件夹中。我们将include作为依赖项，当我们修改.h文件时，makefile就能够察觉到有东西被修改了<br>BINARY=bin
CODEDIR=. lib
INCDIRS=. ./include/ # can be listed

CC=gcc
OPT=-O0
# generate files that encode make rules for the .h dependencies
DEPFLAGS=-MP -MD # let make work with compiler?是这样么
CFLAGS=-Wall -Wextra -g $(foreach D, $(INCDIRS),-I$(D) $(OPT) $(DEPFLAGS))

CFILES=$(foreach D,$(CODEDIRS),$(wildcard $(D)/*.c))

OBJECTS=$(patsubst %.c,%.o,%(CFILES))
DEPFILES=$(patsubst %.c,%.d,%(CFILES))

all: $(BINARY)

$(BINARY): $(OBJECT)
		$(CC) -o $@ $^

%.o:%.c # make feature, % is a wildcard (repersenting everything)
		$(CC) $(CFLAGS) -c -o $@ $&lt; # only want .c dependency here thus $&lt;
clean:
		rm -rf $(BINARY) $(OBJECTS) $(DEPFILES)

distribute: clean
		tar zcvf dist.tgz *

diff
# include the dependency
-include $(DEPFILES)
<br><img alt="Pasted image 20250322033111.png" src="https://congzhi.wiki/lib/media/pasted-image-20250322033111.png"><br>依赖项 (dependencies)<br># GCC flags first
target [targets...]: [components...]
	[ command 1]
	# ...
	[ command n]
<br>special commands<br>-
@
+
<br>macros and variables<br>MACRO1 = 12
COMPILE = gcc *.c

gcc:
	$(COMPILE)
<br>multi line commands<br>
在makefile中，每行命令都默认允许在一个独立的shell终端中，也就是说在 Badlisting 中<br>
如果需要多个命令共享同一个上下文（例如切换目录后运行操作），需要将它们合并到一个 Shell 会话中，通常使用反斜杠 \ 或 &amp;&amp;<br>
分号用于在同一行中分隔多个命令。例如：<br>Badlisting:
	cd dir
	ls
Goodlisting:
	cd dir;\ # same as cd dir &amp;&amp; ls
	ls
<br>makefile 也可以用于 testing<br><br>makefile的好处就是只编译修改了的.c/.cpp文件并生成修改后的.o文件。节省编译时间。一个标准的makefile可能是这样的：<br>CC = gcc
INCDIRS = -I.
OPT = -O0
CFLAGS = -Wall -Wextra -g $(INCDIRS) $(OPT)

CFILES = 
OBJECTS = 
BINARY = 

all: $(BINARY)

clean:


random:
	date
	sl
	mkdir useless
	cd useless ;\
	cd..
<br>all: # all 是干嘛的？

help: #这些是按照顺序执行的么

<br>CC = GCC
all:
	$(CC) file.c -o proj
debug:
debug: CC += -g -DDEBUG
]]></description><link>https://congzhi.wiki/building-and-version-control/4.-makefile-and-building-system.html</link><guid isPermaLink="false">Building and Version Control/4. Makefile and Building System.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 21 Mar 2025 19:31:52 GMT</pubDate><enclosure url="https://congzhi.wiki/lib/media/pasted-image-20250322033111.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/lib/media/pasted-image-20250322033111.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[5. CMake]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/building-and-version-control/5.-cmake.html</link><guid isPermaLink="false">Building and Version Control/5. CMake.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sat, 15 Mar 2025 09:27:52 GMT</pubDate></item><item><title><![CDATA[5. Release Build and Debug Build]]></title><description><![CDATA[ 
 <br>release build and debug build<br>#ifdef DEBUG
printf("Debugging info...\n");
#endif

#ifdef NDEBUG
printf("This version is for releasing\n");
#endif
]]></description><link>https://congzhi.wiki/building-and-version-control/5.-release-build-and-debug-build.html</link><guid isPermaLink="false">Building and Version Control/5. Release Build and Debug Build.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sun, 23 Mar 2025 14:15:13 GMT</pubDate></item><item><title><![CDATA[Building and Version Control]]></title><description><![CDATA[ 
 <br><br><br>一当 <a data-href="Building and Version Control" href="https://congzhi.wiki/building-and-version-control/building-and-version-control.html" class="internal-link" target="_self" rel="noopener nofollow">Building and Version Control</a> 系列完成， <a data-href="进程的一生——从出生到死亡 (Abandoned)" href="https://congzhi.wiki/some-notes/进程的一生——从出生到死亡-(abandoned).html" class="internal-link" target="_self" rel="noopener nofollow">进程的一生——从出生到死亡 (Abandoned)</a> 将被彻底废除。其所有关于进程如何出生的内容将会在本系列中重制，其他内容请参阅操作系统系列。<br>在这个系列中，我想系统地探讨探讨 C/C++ 的代码构建方面的知识。我们会聊到一段文本（高级语言）是如何变成 01序列（机器语言）在 CPU 上运行的。同时，我们牵扯到一些 Git 版本控制的简单知识。本系列不会太深入。<br>系列目录如下：<br>Building and Version Control

<br><a data-href="1. Compilation" href="https://congzhi.wiki/building-and-version-control/1.-compilation.html" class="internal-link" target="_self" rel="noopener nofollow">1. Compilation</a>
<br><a data-href="2. Linking" href="https://congzhi.wiki/building-and-version-control/2.-linking.html" class="internal-link" target="_self" rel="noopener nofollow">2. Linking</a>
<br><a data-href="3. A Normal Project Structure" href="https://congzhi.wiki/building-and-version-control/3.-a-normal-project-structure.html" class="internal-link" target="_self" rel="noopener nofollow">3. A Normal Project Structure</a>
<br><a data-href="4. Makefile and Building System" href="https://congzhi.wiki/building-and-version-control/4.-makefile-and-building-system.html" class="internal-link" target="_self" rel="noopener nofollow">4. Makefile and Building System</a>
<br><a data-href="5. CMake" href="https://congzhi.wiki/building-and-version-control/5.-cmake.html" class="internal-link" target="_self" rel="noopener nofollow">5. CMake</a>
<br><a data-href="5. Release Build and Debug Build" href="https://congzhi.wiki/building-and-version-control/5.-release-build-and-debug-build.html" class="internal-link" target="_self" rel="noopener nofollow">5. Release Build and Debug Build</a>
<br><a data-href="Git and Github (Part I)" href="https://congzhi.wiki/building-and-version-control/git-and-github-(part-i).html" class="internal-link" target="_self" rel="noopener nofollow">Git and Github (Part I)</a>

<br><br><br>任何问题都可以通过 <a data-tooltip-position="top" aria-label="mailto:duzhi_02@qq.com" rel="noopener nofollow" class="external-link" href="https://congzhi.wiki/mailto:duzhi_02@qq.com" target="_blank">duzhi_02@qq.com</a> 联系我。]]></description><link>https://congzhi.wiki/building-and-version-control/building-and-version-control.html</link><guid isPermaLink="false">Building and Version Control/Building and Version Control.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 16:06:12 GMT</pubDate></item><item><title><![CDATA[Git and Github (Part I)]]></title><description><![CDATA[ 
 <br><br>Git 是一种开源的分布式版本控制系统，在学习 Git 之前，我们先来了解<br>提供了对代码（不仅仅）的版本控制。<br><br><br>]]></description><link>https://congzhi.wiki/building-and-version-control/git-and-github-(part-i).html</link><guid isPermaLink="false">Building and Version Control/Git and Github (Part I).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sun, 23 Mar 2025 15:58:31 GMT</pubDate></item><item><title><![CDATA[Alignment in C++ (ENG)]]></title><description><![CDATA[ 
 <br><br>The operating system provides us with an abstract view of how real memory works, giving us a virtual contiguous sequence of bytes to use. When an object is created, the system needs to allocate the object on the stack or heap memory, depending on how it is created, and you get a memory address to manipulate this object. This address is called the memory location.<br>(By the way, if you find a class with no data members in it, would it have zero memory cost? No, because it needs at least one byte to be instantiated in memory. Otherwise, chaos would ensue since you wouldn’t be able to obtain a unique address for that instance.)<br>class no_data_member{
	void printName(){
		std::cout &lt;&lt; "no_data_member" &lt;&lt; std::endl;
	}
};
int main(){
	no_data_member i; // occipies 1 byte of memory
}
<br>At this location, you need some contiguous space to store the object, so every object will have a size property, which you can get through the sizeof operator. And also, every complete object type has an alignment requirement property. This alignment is what we are going to talk about.<br><br>Alignment is an integer value of the size_t type representing the number of bytes between successive addresses at which objects of a type can be allocated. A valid alignment value is a non-negative integer that is a power of two. For example:<br>#include &lt;stdio.h&gt;
struct A{
	char c;  // size: 1, alignment: 1
	long l;  // size: 8, alignment: 8
	short s; // size: 2, alignment: 2
	int i;   // size: 4, alignment: 4
};

int main(){
	printf("sizeof struct A is: %ld\n", sizeof(A));
	// The alignment of a type can be queried with the `alignof` operator.
	printf("alignof struct A is: %ld\n", alignof(A));
}
<br>When we add up the struct size, we might expect the struct size to be 13 bytes, right? Wrong! We got 24 bytes instead. And we have an alignment of struct A being 8. What the heck is that?<br>The alignment requirement of the struct is determined by the member with the strictest (largest) alignment, which is long l with an 8-byte alignment. Therefore, the overall alignment of struct A is 8 bytes.<br>To satisfy the alignment requirement of all members of the struct, the compiler will insert padding after some of its members. The grey area in the picture below represents those inserted padding.<br><img alt="align_ex.png" src="https://congzhi.wiki/c-plus-plus/pics/align_ex.png"><br>In order to optimize the memory layout of the struct, we could:<br>#include &lt;stdio.h&gt;
struct A{
	char c;  // size: 1, alignment: 1
	long l;  // size: 8, alignment: 8
	short s; // size: 2, alignment: 2
	int i;   // size: 4, alignment: 4
};
// same member, but smaller size
struct B{
	char c;  // size: 1, alignment: 1
	short s; // size: 2, alignment: 2
	int i;   // size: 4, alignment: 4
	long l;  // size: 8, alignment: 8	
};

int main(){
	printf("sizeof struct A is: %ld\n", sizeof(A));
	// The alignment of a type can be queried with the `alignof` operator.
	printf("alignof struct A is: %ld\n", alignof(A));
	printf("sizeof struct B is: %ld\n", sizeof(B));
	// The alignment of a type can be queried with the `alignof` operator.
	printf("alignof struct B is: %ld\n", alignof(B));
}
<br>We see the struct B only used 16 bytes of memory. What happened here? We reduced the need for padding by arranging its members in a more efficient order. The padding in this struct is only 1 byte after char c like what I draw fellows:<br><img alt="align_ex2.png" src="https://congzhi.wiki/c-plus-plus/pics/align_ex2.png"><br>By optimizing the member order, we minimized the padding required to satisfy alignment requirements, resulting in a more compact memory layout for the struct.]]></description><link>https://congzhi.wiki/c-plus-plus/alignment-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Alignment in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sat, 22 Mar 2025 16:48:36 GMT</pubDate><enclosure url="https://congzhi.wiki/c-plus-plus/pics/align_ex.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/c-plus-plus/pics/align_ex.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[ASLR for Safety (ENG)]]></title><description><![CDATA[ 
 <br>Inspired by <a data-href="Malloc in C (ENG)" href="https://congzhi.wiki/c-plus-plus/malloc-in-c-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Malloc in C (ENG)</a><br>Actually, I really should put this in operating system section......<br><br>ASLR is a computer security technique. Its primary purpose is to protect against memory corruption vulnerabilities. It is primarily a security feature used to prevent exploitation by making it harder for attackers to predict memory locations. <br>With ASLR, every time you run your program, the memory mapping will differ. We will demonstrate this phenomenon using an example just a second.<br>In this brief note, we will continue using the example from the malloc note. If you compile that code and run it multiple times, you will observe that the heap memory layout varies with each execution. This variability is a direct result of ASLR.<br>du@DVM:~/cpp$ ./proc
Size of struct linked_block is 16 bytes.
The address of first block is: 0x584b0525b6b0
The address of second block is: 0x584b0525b6d0
du@DVM:~/cpp$ ./proc 
Size of struct linked_block is 16 bytes.
The address of first block is: 0x59697921b6b0
The address of second block is: 0x59697921b6d0
du@DVM:~/cpp$ ./proc 
Size of struct linked_block is 16 bytes.
The address of first block is: 0x5659369f46b0
The address of second block is: 0x5659369f46d0
du@DVM:~/cpp$ ./proc 
Size of struct linked_block is 16 bytes.
The address of first block is: 0x61b7291d06b0
The address of second block is: 0x61b7291d06d0
<br>Modern operating systems enable ASLR by default. This is why, each time you run your program, the memory mapping is different. And you can disable ASLR using this:<br>setarch $(uname -m) -R ./proc
<br><br>When running your program in GDB, you will notice that the memory addresses remain consistent across executions. For instance:<br>(gdb) run
Starting program: /home/du/cpp/proc 
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Size of struct linked_block is 16 bytes.
The address of first block is: 0x5555555596b0
The address of second block is: 0x5555555596d0
[Inferior 1 (process 12774) exited normally]
<br>This happens because ASLR is disabled by default in GDB. The reason for this is that GDB is designed for debugging. Consistent memory addresses are very important during debugging to allow for repeatable and predictable analysis of memory-related behaviors. <br>If you wish, you can enable ASLR in GDB using the following command:<br>set disable-randomization off
]]></description><link>https://congzhi.wiki/c-plus-plus/aslr-for-safety-(eng).html</link><guid isPermaLink="false">C Plus Plus/ASLR for Safety (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Mar 2025 16:36:49 GMT</pubDate></item><item><title><![CDATA[Assert in C++ (NC)]]></title><description><![CDATA[ 
 <br>static_assert: a compile-time assert]]></description><link>https://congzhi.wiki/c-plus-plus/assert-in-c++-(nc).html</link><guid isPermaLink="false">C Plus Plus/Assert in C++ (NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 27 Feb 2025 14:41:55 GMT</pubDate></item><item><title><![CDATA[Auto in C++]]></title><description><![CDATA[ 
 <br><br>在 C++ 中，我们有各种各样的数据类型。我们有 int 、 long 、 float 、 double 还有表示字符串的 const char* 等等。我们每次定义一个变量的时候都要带上不同的类型符，好不麻烦。C++ 什么时候能像 python 那样做一些无所谓内置类型的变量定义呢？在 C++11 后，我们有 auto 关键字来帮我们做类似的类型推导。<br>简单来说，我们在定义类型的时候不需要再考虑它是什么类型了，编译器会帮我们做这些。甚至你可以让它帮你推导自定义的类类型。我们用下面的代码举一些例子：<br>class MyClass {
public:
    MyClass(int val) : i(val) {}
    int i;
};
auto func(){ // return type is deduced as int type, since C++14
	return 0;
}
int main() {
    int a = 0;
    auto b = a; // b is deduced as int type
    auto c = 0; // c is deduced as int type
    auto d = 3.14; // d is deduced as double type

    auto obj = MyClass{10}; // obj is deduced as MyClass type
    std::cout &lt;&lt; "obj.i = " &lt;&lt; obj.i &lt;&lt; std::endl; // Outputs: obj.i = 10

    return 0;
}
<br>auto 是一个占位符(placeholder)，在编译时，编译器会自动推导变量的类型或函数的返回类型。<br><br>有人可能会觉得 auto 的滥用可能导致变量类型或函数返回类型的混乱。但事实上，当你使用 auto 后，你不需要太担心什么类型推导错误的问题。相反地，一旦你使用 auto，你就应该使用到底。不然就可能导致你不希望看到的问题。我们用一个例子来说明，假设我们有一个 API，我们可以直接用 auto 来与 API 返回的类型相匹配，而不需要担心 API 返回类型的变化，例如：<br>#include &lt;string&gt;

char* API(int i) {
	char* status;
    if (i == 0) {
	    status = "OKAY";
    } else {
	    status = "false";
    }
	return status;
}

int main() {
    auto status_code = API(1); // status_code is deduced as char*
    std::cout &lt;&lt; status_code &lt;&lt; std::endl; // Outputs: false
}

<br>在上面的例子中，auto 会将 status_code 推导成 char* 类型。但如果 API 的返回类型变成标准库的 std::string，你仍不需要担心，届时 auto 会推导 status_code 为 std::string 类型。如果你没有使用 auto，在这种情况下，你的源代码就需要随着 API 返回类型的改变而改变<br>但另一方面，当你使用 auto 之后，status_code 的类型将对你不可见。为了确定性，你也可以将 auto 去掉。<br>此外，你需要留意 auto 会忽略引用和 const 。如：<br>const int&amp; ref = x;
auto a = ref; // a is deduced as int type
const auto&amp;b = ref; // b has the same type as ref
<br><br>这部分将在 <a data-href="Decltype in C++#`decltype(auto)`" href="https://congzhi.wiki/c-plus-plus/decltype-in-c++.html#`decltype(auto)`" class="internal-link" target="_self" rel="noopener nofollow">Decltype in C++ &gt; `decltype(auto)`</a> 中介绍。]]></description><link>https://congzhi.wiki/c-plus-plus/auto-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Auto in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 08:45:44 GMT</pubDate></item><item><title><![CDATA[C Plus Plus]]></title><description><![CDATA[ 
 <br><br><br>This series will document my C++ learning path from zero to hero. A big part of these notes are inspired by Mr. Mike, all the learning resources are listed below:<br>
这个系列用于记录我学习 C++ 的进化之路。参考资料来源如下：<br>
<br><a data-tooltip-position="top" aria-label="https://en.cppreference.com/w/" rel="noopener nofollow" class="external-link" href="https://en.cppreference.com/w/" target="_blank">cppreference.com</a>
<br><a data-tooltip-position="top" aria-label="https://www.learncpp.com/" rel="noopener nofollow" class="external-link" href="https://www.learncpp.com/" target="_blank">Learn C++</a>
<br><a data-tooltip-position="top" aria-label="https://www.youtube.com/@CppCon" rel="noopener nofollow" class="external-link" href="https://www.youtube.com/@CppCon" target="_blank">CppCon C++ Talks</a>
<br><a data-tooltip-position="top" aria-label="https://www.youtube.com/@MikeShah/playlists" rel="noopener nofollow" class="external-link" href="https://www.youtube.com/@MikeShah/playlists" target="_blank">Mr. Mike Shah's C++ Series</a>
<br><a data-tooltip-position="top" aria-label="https://www.youtube.com/@TheCherno/playlists" rel="noopener nofollow" class="external-link" href="https://www.youtube.com/@TheCherno/playlists" target="_blank">The Cherno's C++ Series</a>
<br>...
<br>一些好用的工具：<br>
<br><a data-tooltip-position="top" aria-label="https://godbolt.org/" rel="noopener nofollow" class="external-link" href="https://godbolt.org/" target="_blank">Compiler Explorer</a>
<br><a data-tooltip-position="top" aria-label="https://cppinsights.io/" rel="noopener nofollow" class="external-link" href="https://cppinsights.io/" target="_blank">C++ Insights</a>
<br><br><br>由于大多数学习资料的源内容都以英文形式呈现，所以部分笔记的撰写将用英文完成。这些英文笔记通常比较简短（我会尝试完成一些英文长笔记），但对于理解这些 C++ 知识应当是足够的。目前，我所有的 C++ 笔记罗列如下：<br>C++ 中文笔记 (NC stands for Not Covered, 37 notes in total)：

<br><a data-href="Assert in C++ (NC)" href="https://congzhi.wiki/c-plus-plus/assert-in-c++-(nc).html" class="internal-link" target="_self" rel="noopener nofollow">Assert in C++ (NC)</a>
<br><a data-href="Auto in C++" href="https://congzhi.wiki/c-plus-plus/auto-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Auto in C++</a>
<br><a data-href="Casting in C++ (NC)" href="https://congzhi.wiki/c-plus-plus/casting-in-c++-(nc).html" class="internal-link" target="_self" rel="noopener nofollow">Casting in C++ (NC)</a>
<br><a data-href="Character Literal &amp; String Literal in C++" href="https://congzhi.wiki/c-plus-plus/character-literal-&amp;-string-literal-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Character Literal &amp; String Literal in C++</a>
<br><a data-href="Concurrency in C++" href="https://congzhi.wiki/c-plus-plus/concurrency-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Concurrency in C++</a>
<br><a data-href="Const in C++" href="https://congzhi.wiki/c-plus-plus/const-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Const in C++</a>
<br><a data-href="Copying and Copy Constructors in C++" href="https://congzhi.wiki/c-plus-plus/copying-and-copy-constructors-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Copying and Copy Constructors in C++</a>
<br><a data-href="Decltype in C++" href="https://congzhi.wiki/c-plus-plus/decltype-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Decltype in C++</a>
<br><a data-href="Exception Control in C++ (NC)" href="https://congzhi.wiki/c-plus-plus/exception-control-in-c++-(nc).html" class="internal-link" target="_self" rel="noopener nofollow">Exception Control in C++ (NC)</a>
<br><a data-href="Extern Keyword in C++" href="https://congzhi.wiki/c-plus-plus/extern-keyword-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Extern Keyword in C++</a>
<br><a data-href="Forwarding in C++" href="https://congzhi.wiki/c-plus-plus/forwarding-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Forwarding in C++</a>
<br><a data-href="Function Pointers in C++ (Examples)" href="https://congzhi.wiki/c-plus-plus/function-pointers-in-c++-(examples).html" class="internal-link" target="_self" rel="noopener nofollow">Function Pointers in C++ (Examples)</a>
<br><a data-href="Functions in Standard Library (Examples)" href="https://congzhi.wiki/c-plus-plus/functions-in-standard-library-(examples).html" class="internal-link" target="_self" rel="noopener nofollow">Functions in Standard Library (Examples)</a>
<br><a data-href="Generics Programming in C++" href="https://congzhi.wiki/c-plus-plus/generics-programming-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Generics Programming in C++</a>
<br><a data-href="Inheritance in C++" href="https://congzhi.wiki/c-plus-plus/inheritance-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Inheritance in C++</a>
<br><a data-href="Integer Literal &amp; Float Literal in C++" href="https://congzhi.wiki/c-plus-plus/integer-literal-&amp;-float-literal-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Integer Literal &amp; Float Literal in C++</a>
<br><a data-href="Lambdas in C++" href="https://congzhi.wiki/c-plus-plus/lambdas-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Lambdas in C++</a>
<br><a data-href="Memory Management in C++ (Abandoned)" href="https://congzhi.wiki/c-plus-plus/memory-management-in-c++-(abandoned).html" class="internal-link" target="_self" rel="noopener nofollow">Memory Management in C++ (Abandoned)</a>
<br><a data-href="Move Semantics in C++" href="https://congzhi.wiki/c-plus-plus/move-semantics-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Move Semantics in C++</a>
<br><a data-href="Networking - CS model" href="https://congzhi.wiki/c-plus-plus/networking-cs-model.html" class="internal-link" target="_self" rel="noopener nofollow">Networking - CS model</a>
<br><a data-href="Object Oriented Programming in C++" href="https://congzhi.wiki/c-plus-plus/object-oriented-programming-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Object Oriented Programming in C++</a>
<br><a data-href="Part1：C++11 (Abandoned)" href="https://congzhi.wiki/c-plus-plus/part1：c++11-(abandoned).html" class="internal-link" target="_self" rel="noopener nofollow">Part1：C++11 (Abandoned)</a>
<br><a data-href="Part2：Class (Abandoned)" href="https://congzhi.wiki/c-plus-plus/part2：class-(abandoned).html" class="internal-link" target="_self" rel="noopener nofollow">Part2：Class (Abandoned)</a>
<br><a data-href="Program Arguments Handling in C++" href="https://congzhi.wiki/c-plus-plus/program-arguments-handling-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Program Arguments Handling in C++</a>
<br><a data-href="RAII and Scope in C++" href="https://congzhi.wiki/c-plus-plus/raii-and-scope-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">RAII and Scope in C++</a>
<br><a data-href="Smart Pointers in C++" href="https://congzhi.wiki/c-plus-plus/smart-pointers-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Smart Pointers in C++</a>
<br><a data-href="Standard Variant in C++" href="https://congzhi.wiki/c-plus-plus/standard-variant-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Standard Variant in C++</a>
<br><a data-href="Static Keyword in C++" href="https://congzhi.wiki/c-plus-plus/static-keyword-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Static Keyword in C++</a>
<br><a data-href="STL in C++ (Pre-Part)" href="https://congzhi.wiki/c-plus-plus/stl-in-c++-(pre-part).html" class="internal-link" target="_self" rel="noopener nofollow">STL in C++ (Pre-Part)</a>
<br><a data-href="STL Container - Standard Array in C++" href="https://congzhi.wiki/c-plus-plus/stl-container-standard-array-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">STL Container - Standard Array in C++</a>
<br><a data-href="STL Container - Standard Vector in C++" href="https://congzhi.wiki/c-plus-plus/stl-container-standard-vector-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">STL Container - Standard Vector in C++</a>
<br><a data-href="STL Container - Standard Span Since C++20" href="https://congzhi.wiki/c-plus-plus/stl-container-standard-span-since-c++20.html" class="internal-link" target="_self" rel="noopener nofollow">STL Container - Standard Span Since C++20</a>
<br><a data-href="String Library in C++" href="https://congzhi.wiki/c-plus-plus/string-library-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">String Library in C++</a>
<br><a data-href="The Rule of Five in C++" href="https://congzhi.wiki/c-plus-plus/the-rule-of-five-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">The Rule of Five in C++</a>
<br><a data-href="Unions in C++" href="https://congzhi.wiki/c-plus-plus/unions-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Unions in C++</a>
<br><a data-href="Virtual Dispatch in C++" href="https://congzhi.wiki/c-plus-plus/virtual-dispatch-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Virtual Dispatch in C++</a>
<br><a data-href="Volatile Specifier in C++ (Questioning)" href="https://congzhi.wiki/c-plus-plus/volatile-specifier-in-c++-(questioning).html" class="internal-link" target="_self" rel="noopener nofollow">Volatile Specifier in C++ (Questioning)</a>

<br>Current existing C++ English notes are listed down below:<br>C++ English Notes: (29 notes in total)

<br><a data-href="Alignment in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/alignment-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Alignment in C++ (ENG)</a>
<br><a data-href="ASLR for Safety (ENG)" href="https://congzhi.wiki/c-plus-plus/aslr-for-safety-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">ASLR for Safety (ENG)</a>
<br><a data-href="Call Stack in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/call-stack-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Call Stack in C++ (ENG)</a>
<br><a data-href="Constexpr in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/constexpr-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Constexpr in C++ (ENG)</a>
<br><a data-href="Consteval in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/consteval-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Consteval in C++ (ENG)</a>
<br><a data-href="Constinit in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/constinit-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Constinit in C++ (ENG)</a>
<br><a data-href="Delegating Constructors in C++ (ENG, NC)" href="https://congzhi.wiki/c-plus-plus/delegating-constructors-in-c++-(eng,-nc).html" class="internal-link" target="_self" rel="noopener nofollow">Delegating Constructors in C++ (ENG, NC)</a>
<br><a data-href="Explicit Specifier in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/explicit-specifier-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Explicit Specifier in C++ (ENG)</a>
<br><a data-href="Friend Keyword in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/friend-keyword-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Friend Keyword in C++ (ENG)</a>
<br><a data-href="Inline in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/inline-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Inline in C++ (ENG)</a>
<br><a data-href="Malloc in C (ENG)" href="https://congzhi.wiki/c-plus-plus/malloc-in-c-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Malloc in C (ENG)</a>
<br><a data-href="Member Initializer List in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/member-initializer-list-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Member Initializer List in C++ (ENG)</a>
<br><a data-href="Mutable and The M&amp;M Rule in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/mutable-and-the-m&amp;m-rule-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Mutable and The M&amp;M Rule in C++ (ENG)</a>
<br><a data-href="Namespaces in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/namespaces-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Namespaces in C++ (ENG)</a>
<br><a data-href="Noexcept in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/noexcept-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Noexcept in C++ (ENG)</a>
<br><a data-href="Operator Overloading in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/operator-overloading-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Operator Overloading in C++ (ENG)</a>
<br><a data-href="Parameter Pack in C++ (ENG, NC)" href="https://congzhi.wiki/c-plus-plus/parameter-pack-in-c++-(eng,-nc).html" class="internal-link" target="_self" rel="noopener nofollow">Parameter Pack in C++ (ENG, NC)</a>
<br><a data-href="Preprocessor in C++ (Part I, NC)" href="https://congzhi.wiki/c-plus-plus/preprocessor-in-c++-(part-i,-nc).html" class="internal-link" target="_self" rel="noopener nofollow">Preprocessor in C++ (Part I, NC)</a>
<br><a data-href="Preprocessor in C++ (Part II, NC)" href="https://congzhi.wiki/c-plus-plus/preprocessor-in-c++-(part-ii,-nc).html" class="internal-link" target="_self" rel="noopener nofollow">Preprocessor in C++ (Part II, NC)</a>
<br><a data-href="Preprocessor in C++ (Part III, NC)" href="https://congzhi.wiki/c-plus-plus/preprocessor-in-c++-(part-iii,-nc).html" class="internal-link" target="_self" rel="noopener nofollow">Preprocessor in C++ (Part III, NC)</a>
<br><a data-href="Preprocessor in C++ (Part IV, NC)" href="https://congzhi.wiki/c-plus-plus/preprocessor-in-c++-(part-iv,-nc).html" class="internal-link" target="_self" rel="noopener nofollow">Preprocessor in C++ (Part IV, NC)</a>
<br><a data-href="Preprocessor in C++ (Part V, NC)" href="https://congzhi.wiki/c-plus-plus/preprocessor-in-c++-(part-v,-nc).html" class="internal-link" target="_self" rel="noopener nofollow">Preprocessor in C++ (Part V, NC)</a>
<br><a data-href="Preprocessor in C++ (Part VI, NC)" href="https://congzhi.wiki/c-plus-plus/preprocessor-in-c++-(part-vi,-nc).html" class="internal-link" target="_self" rel="noopener nofollow">Preprocessor in C++ (Part VI, NC)</a>
<br><a data-href="Standard Array Basics (ENG)" href="https://congzhi.wiki/c-plus-plus/standard-array-basics-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Standard Array Basics (ENG)</a>
<br><a data-href="Static Dispatch in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/static-dispatch-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Static Dispatch in C++ (ENG)</a>
<br><a data-href="The pIMPL Idiom in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/the-pimpl-idiom-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">The pIMPL Idiom in C++ (ENG)</a>
<br><a data-href="This Keyword in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/this-keyword-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">This Keyword in C++ (ENG)</a>
<br><a data-href="Typename Keyword in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/typename-keyword-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Typename Keyword in C++ (ENG)</a>
<br><a data-href="Using Keyword in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/using-keyword-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Using Keyword in C++ (ENG)</a>

<br><br><br>才疏学浅，笔记内容可能不会过于深入，欢迎批评指正、交流学习。如果有发现任何疑问、错误和错别字问题，欢迎在邮箱 <a data-tooltip-position="top" aria-label="mailto:duzhi_02@qq.com" rel="noopener nofollow" class="external-link" href="https://congzhi.wiki/mailto:duzhi_02@qq.com" target="_blank">duzhi_02@qq.com</a> 联系我。]]></description><link>https://congzhi.wiki/c-plus-plus/c-plus-plus.html</link><guid isPermaLink="false">C Plus Plus/C Plus Plus.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 16:06:41 GMT</pubDate></item><item><title><![CDATA[Call Stack in C++ (ENG)]]></title><description><![CDATA[ 
 <br>Learn more at: <a data-tooltip-position="top" aria-label="https://www.icourse163.org/learn/NJU-1001625001?tid=1472100484#/learn/content?type=detail&amp;id=1257458503&amp;cid=1291031865" rel="noopener nofollow" class="external-link" href="https://www.icourse163.org/learn/NJU-1001625001?tid=1472100484#/learn/content?type=detail&amp;id=1257458503&amp;cid=1291031865" target="_blank">计算机系统基础(一)：第七周<em></em>中国大学MOOC(慕课)</a>过程调用概述<br>
<br><a data-tooltip-position="top" aria-label="Call Stack" data-href="#Call Stack" href="https://congzhi.wiki/about:blank#Call_Stack" class="internal-link" target="_self" rel="noopener nofollow">Call Stack</a>
<br><a data-tooltip-position="top" aria-label="An Easy Example" data-href="#An Easy Example" href="https://congzhi.wiki/about:blank#An_Easy_Example" class="internal-link" target="_self" rel="noopener nofollow">An Easy Example</a>
<br><a data-tooltip-position="top" aria-label="Under the Hood" data-href="#Under the Hood" href="https://congzhi.wiki/about:blank#Under_the_Hood" class="internal-link" target="_self" rel="noopener nofollow">Under the Hood</a>
<br><a data-tooltip-position="top" aria-label="Copy and Reference" data-href="#Copy and Reference" href="https://congzhi.wiki/about:blank#Copy_and_Reference" class="internal-link" target="_self" rel="noopener nofollow">Copy and Reference</a>
<br><a data-tooltip-position="top" aria-label="Pass by Value or Pass by Const Reference?" data-href="#Pass by Value or Pass by Const Reference?" href="https://congzhi.wiki/about:blank#Pass_by_Value_or_Pass_by_Const_Reference" class="internal-link" target="_self" rel="noopener nofollow">Pass by Value or Pass by Const Reference?</a>
<br><a data-tooltip-position="top" aria-label="Parameter Passing Rule in 64-Bit Machine (AI Generated)" data-href="#Parameter Passing Rule in 64-Bit Machine (AI Generated)" href="https://congzhi.wiki/about:blank#Parameter_Passing_Rule_in_64-Bit_Machine_(AI_Generated)" class="internal-link" target="_self" rel="noopener nofollow">Parameter Passing Rule in 64-Bit Machine (AI Generated)</a>
<br><br>The call stack, also known as the execution stack or just the stack if you will, is a crucial component for running your program. Before we dive deep, it's important to understand the process memory layout. If you're not familiar with it, check the linked resources above.<br>When you call a function, the system sets aside some space in the stack memory for the function to do its necessary work. These chunks of space or memory are often called "stack frames" or "function frames." The purpose of the call stack is to manage the way procedures or functions call each other and pass parameters.<br>Each thread has its own call stack, also known as stack memory.<br><br>Let's learn how a function stack frame is formed and what's inside a frame using the code below:<br>int add(int x, int y){
	return x + y;
}
int main(){
	int a = 32;
	int b = 64;
	int sum = add(a, b);
}
<br>Here's what happens:<br>
<br>The main() function is called first, and its function frame is created.    
<br>The add() function is called by main(), and its function frame is added to the stack.
<br>After the add() function finishes executing, its function frame is popped off the stack, returning control to main().
<br>The main() finishes executing, the program finishes.
<br><img alt="call_stack.png" src="https://congzhi.wiki/c-plus-plus/pics/call_stack.png"><br><br>We now understand how stack frames are pushed and popped. Next, let's delve into what is inside the stack frame. We'll compile the code above into assembly language to examine the details. For this purpose, I'll use GCC with the -m32 option here, because on a 64-bit machine, parameters are typically passed using registers rather than the stack.<br>Here's the assembly:<br>_Z3addii:
    pushl   %ebp
    movl    %esp, %ebp
    movl    8(%ebp), %edx
    movl    12(%ebp), %eax
    addl    %edx, %eax          ; &lt;&lt;&lt;&lt;&lt; Calling add()
    popl    %ebp
    ret ; Return address -&gt; EIP
main:
    pushl   %ebp
    movl    %esp, %ebp
    subl    $16, %esp
    movl    $32, -12(%ebp)
    movl    $64, -8(%ebp)
    pushl   -8(%ebp)
    pushl   -12(%ebp)
    call    _Z3addii            ; &lt;&lt;&lt;&lt;&lt; Before calling add()
    addl    $8, %esp
    movl    %eax, -4(%ebp) ; &lt;- Next instruction address
    movl    $0, %eax            ; &lt;&lt;&lt;&lt;&lt; After calling add()
    leave
    ret
<br>Okay, in assembly, you would always see the annoying base pointer register (ebp in this case) and stack pointer register (esp in this case). But don't worry, you'll get there.<br>
<img alt="Stack_under_the_hood.png" src="https://congzhi.wiki/c-plus-plus/pics/stack_under_the_hood.png"><br>
Before calling add(), main() forms its stack frame using ebp and esp. It first saves the old base pointer using a pushl instruction, and then sets the new ebp to point to the old ebp, creating the base of the stack frame. After that, space is allocated on the stack for local variables. Then, the passing parameters are pushed, and add() is called.<br>When the call instruction is executed, a return address is automatically pushed into the stack frame. In the add() function, a new stack frame is formed using pushl %ebp and movl %esp, %ebp. After the calculation is done, the return value is passed back via eax. The frame is then cleaned up with popl %ebp.<br>After the frame is cleaned up, the return address is instantly passed to eip, which points to the next instruction address of call _Z3addii. The stack space allocated for passing parameters is then cleaned up. Finally, the return value 0 is set, and the stack is further cleaned up.<br><br>From the above, we have seen that passing parameters involves copying them to the stack (32-bit machine). If the object is large, this copying can be quite costly in terms of CPU time. To mitigate this, we can pass a pointer or a reference to the object instead, making the copy much smaller. You can consider references in C++ as syntactic sugar for pointers, they act the same way.<br>For large objects, it's always recommended to pass it by a reference. You might be concerned that directly operating on the original object could lead to unintended modifications. To avoid this, you can use the const keyword to ensure the object is not altered. This approach is exactly what we use in a copy constructor and copy assignment operator.<br><br>It is generally recommended to pass by const reference. On modern 64-bit machines, a pointer requires 8 bytes to store. Whether you use pass-by-pointer or pass-by-reference, you will always copy an 8-byte pointer to somewhere, typically a register (or the stack when there are many parameters).<br>When you pass a easy type no bigger than 8 bytes (e.g., int, which typically stores 4 bytes on most machines) by value, you only copy 4 bytes. However, if you use a pointer or reference, it would take 8 bytes. In this case, will pass this type no bigger than 8 bytes by value be better?<br>It looks so, because you copy 4 bytes must be two times faster than copy a 8 bytes pointer. But in most cases, these parameters will be passed to a register (the rule is in the next section). Copying a type no larger than 8 bytes to a register doesn't make much of a difference in terms of performance. But it's a good practice to do so.<br>It seems so, because copying 4 bytes must be two-times faster than copying an 8-byte pointer, right? However, in most cases, these parameters will be passed to a register. Copying a type no larger than 8 bytes to a register doesn't make much of a difference in terms of performance. But it's a good practice to do so.<br><br>On 64-bit machines, function parameters are usually passed through specific registers, and only when the number of parameters exceeds the available registers do parameters get passed on the stack. Here are the typical rules for x86-64 (System V ABI):<br>
<br>Integer and Pointer Parameters:

<br>Passed through registers: RDI, RSI, RDX, RCX, R8, R9 (for the first six parameters).
<br>Any additional parameters are passed on the stack.


<br>Floating-point Parameters:

<br>Passed through registers: XMM0, XMM1, XMM2, XMM3, XMM4, XMM5, XMM6, XMM7 (for the first eight parameters).
<br>Any additional parameters are passed on the stack.


<br>For custom complex types:<br>
<br>If passed by value and they do not fit into available registers, they are stored on the stack.
<br>If passed by reference (pointer), the reference itself is passed through a register if there are enough available.
<br>Following these rules ensures efficient and consistent parameter passing, helping to optimize function calls.]]></description><link>https://congzhi.wiki/c-plus-plus/call-stack-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Call Stack in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 04 Mar 2025 18:07:39 GMT</pubDate><enclosure url="https://congzhi.wiki/c-plus-plus/pics/call_stack.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/c-plus-plus/pics/call_stack.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Casting in C++ (NC)]]></title><description><![CDATA[ 
 <br><br><br>我们观察下面的一段代码，思考这两个问题：pi_int 的值是怎么转换成 3 的？直接输出 355/113 为什么是整数 3 ？<br>#include &lt;iostream&gt;
int main(){
	int pi_int = 3.14159;
	std::cout &lt;&lt; pi_int &lt;&lt; std::endl; // 3
	std::cout &lt;&lt; 355/113 &lt;&lt; std::endl;// 3
	return 0;
}
<br>这两个问题都和 implicit narrowing conversion 有关。当我们运行 int pi_int = pi; 时，由于类型不同，这里会发生 narrow conversion（ casting 的一种）。会损失相关的数据和精度，将结果截断到整数个位，损失小数的精度。<br>在执行 std::cout &lt;&lt; 355/113 &lt;&lt; std::endl; 时，编译器会先检查除数和被除数的类型。这两种类型都是 int 类型，所以编译器断定商数应该是 int 类型的，在运行这行代码时也会出现截断。要输出正确的值，我们可以将类型显式地告诉编译器或者显式地使用浮点字面量类型。如：<br>#include &lt;iostream&gt;
int main(){
    std::cout &lt;&lt; (double)355/(double)113 &lt;&lt; std::endl; // 3.14159
    // or, explicitly use the float literals
    std::cout &lt;&lt; 355.0/113.0 &lt;&lt; std::endl; // 3.14159
    return 0;
}
<br>这种将一种类型变成另一种类型的方式就是我们所说的强制类型转换，这是一种 C-style casting。<br>上述的这些类型转换我们喜欢么？可能一般，因为它们不一定保证类型安全。除了可能发生的截断之外，编译器解析不同类型的方式也是不一样的，如果你把一个 int 类型值赋给 char 类型变量，输出 char 后你并不会看到一个整型数，而大概率是一个字符。<br>int val = 65;
char c = val;          // implicit conversion
std::cout &lt;&lt; c;        // prints out 'a'
std::cout &lt;&lt; (int)c;   // prints out 65

int val2 = 256;
char danger = val2; // undefined behavior
<br>为了类型安全，在 C++11 后引入的列表初始化禁止这种 narrowing conversion。<br>int pi = 3.14; // okay
int pi{3.14}; // error
<br><br>]]></description><link>https://congzhi.wiki/c-plus-plus/casting-in-c++-(nc).html</link><guid isPermaLink="false">C Plus Plus/Casting in C++ (NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 04 Mar 2025 14:19:26 GMT</pubDate></item><item><title><![CDATA[Character Literal & String Literal in C++]]></title><description><![CDATA[ 
 <br><br><br>在我们了解了整数型字面量和浮点型字面量之后，这篇文档我们来学习什么是字符字面量和字符串字面量。首先，我们来看一看最常见的字符字面量和字符串字面量。<br><img alt="std_ascii.png" src="https://congzhi.wiki/c-plus-plus/pics/std_ascii.png"><br>普通字符字面量就是我们常用 char 类型来表示的标准 ASCII 字符。 char 类型只占 1 个字节，能表示的数值在 0 - 255 这 256 个数字，而用来表示标准的 ASCII 绰绰有余（不包含 EASCII ）。普通字符字面量在 C++ 中有这几种表示形式：<br>char a1 = 'a';      // basic character, ASCII value of 'a' is 97
char a2 = '\x61';   // using escape sequence, equals to '\141' as in octal
char a3 = 0x61;     // direct hexadecimal value, equals to a3 = 97;
<br>第一种形式适合用于表示那些在 ASCII 中可显示的字符，上图从 0x21(32) 到 0x7E(126) 都是可显示字符。而那些不可显示的字符我们通常用转义字符来表示，比如换行符 \n 和水平制表符 \t，你也可以用转移字符表示可显示的字符。因为每个 ASCII 字符在表中都有一个数字与之对应，你也可以直接使用这些数值来对 char 类型变量赋值。<br><br>"String is an array of characters"，不难理解，普通字符串字面量就是由普通字符字面量构成的字符序列。这些字符序列要在双引号 " " 中进行表示。里面的字符可以是标准 ASCII 字符和转义字符。普通字符串字面量的类型是 const char[N] 或 const char*。为了知道结尾的位置，编译器会在字符串末尾添加一个空字符 \0。<br>const char* str1 = "Hello, world"; // Same as const char[] str1 = "Hello, World!";
const char* str2 = "Line1\nLine2";
const char* str3 = "Hello,\0world"; // only prints "Hello,"
<br>在这个例子中的三个普通字符串字面量在内存中如下图所示：<br>
<img alt="string_literal.png" src="https://congzhi.wiki/c-plus-plus/pics/string_literal.png"><br>
C++11 引入了原始字符串字面量，这也是一种普通字符串字面量。和上面的用双引号表示方法不同的是，原始字符串字面量以 R"()" 的形式表示。允许字符串中包含反斜杠和引号而不用转义。我们接着用上面的例子举例：<br>const char* str1 = R"(Hello, world)";
const char* str2 = R"(Line1
Line2)";
const char* str3 = R"(Hello,\0world)"; // prints Hello,\0world
<br><br>Unicode 是一个字符集，旨在包含全世界上所有的字符和符号，它兼容 ASCII 。UFT(Unicode Transformation Format) 是一系列用于编码 Unicode 字符的标准。<br><br>UFT-8 字符字面量能够表示的字符和普通字符字面量能表示的字符是相同的（0x00 - 0x7F），都只能表示标准 ASCII 字符。所以UFT-8 字符字面量的一个字符只占用 1 字节。<br>UFT-8 表示字面量格式如下：<br>char a = u8'a'; // until C++20
char8_t a = u8'a'; // since C++20
<br>在 C++20 之前，我们用 char 类型来表示 UFT-8 字符字面量，因为 Unicode 兼容 ASCII 嘛。但是在 C++20 之后，我们用 char8_t 类型来表示 UFT-8 的字符字面量。为了保持统一。<br><br>// Until C++20
const char[] c = u8"Hello, world!";
const char[] c2 = u8R"(Hello, world!)";

// Since C++20
const char8_t[] c = u8"Hello, world!";
const char8_t[] c2 = u8R"(Hello, world!)";
<br>普通和 UFT-8 d 字符串字面量统称为narrow string literals.<br><br><br>虽然 char 类型表示的字符还能扩容到 256 个。但是对于世界上这么多字符符号，256 个完全是不够用的。为了表示比普通字符集更大的字符集，在 C++ 中，我们有宽字符或者叫长字符字面量。在不同的平台，宽字符大小的实现可能有所不同，通常是 2 字节（UFT-16）或是 4 字节（UFT-32）。字节数多了，能够表示的字符数量也就指数级别的增多。2 字节宽字符可以表示 65536 个字符，4 字节宽字符可以表示超过 400 万个字符。<br>宽字符用 wchar_t 类型来表示，我们有下面的例子：<br>wchar_t a = L'哈'; // Allocate 2/4 bytes of memory depending on the system
std::wcout &lt;&lt; a &lt;&lt; std::endl;
std::wcout &lt;&lt; L'β' &lt;&lt; std::endl;
<br>奇怪的是宽字符的前缀不为 W 而是 L，令人百思不得其解。<br><br>一切尽在不言中。<br>const wchar_t* c = L"Hello, world!";
const wchar_t* c2 = LR"(Hello, world!)";
<br><br>你现在知道了字符字面量和字符串字面量表示上的联系，我们最后再来看看 C++ 中的最后两种字符字面量：UFT-16 字符字面量和 UFT-32 字符字面量。<br><br>UFT-16 字符用 char16_t 类型表示，单个 char16_t 字符占用 2 字节内存，可以表示 65536 个不同的字符。UFT-32 字符用 char32_t 类型表示，单个 char32_t 字符占用 4 字节内存，可以表示 4,294,967,296 个不同的字符。<br>UFT-16 和 UFT-32 表示字面量的格式如下：<br>char16_t a = u'a';
char32_t a = U'a';
<br><br>// UFT-16 string literals
const char16_t* c = u"Hello, world!";
const char16_t* c2 = uR"(Hello, world!)";
// UFT-32 string literals
const char32_t* c = U"Hello, world!";
const char32_t* c2 = UR"(Hello, world!)";
]]></description><link>https://congzhi.wiki/c-plus-plus/character-literal-&amp;-string-literal-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Character Literal &amp; String Literal in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 28 Feb 2025 19:29:45 GMT</pubDate><enclosure url="https://congzhi.wiki/c-plus-plus/pics/std_ascii.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/c-plus-plus/pics/std_ascii.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Concurrency in C++]]></title><description><![CDATA[ 
 <br><br><br>我们在操作系统课程中了解到过并发和并行的概念，并发和并行都为我们提供了一种多个线程在同时运行的宏观感受。在多核机器上，不同的线程可以并发执行，也可以并行执行。在我们用户的视角上，线程好像都是并行执行的，但微观上它们可能是交替轮流地执行，也就是并发。<br>对于这两个概念，我们可以这样理解：并发是操作系统通过时间片轮转提供的，而并行是硬件平台提供的（多核CPU）。对于开发高并发程序，我们的目标可能是降低使用延迟，充分利用多核心的性能。通过封装，我们可以在C++线程库中使程序并发执行。<br><br>在早期的 C++ 中，标准库中并不包含相关的线程机制，你要是需要创建线程执行流，你就得调用第三方的库函数（pthread, Boost, Thread Building Block）。关于 POSIX Thread，我们在操作系统的系列课程中已经了解了许多。你可以在 <a data-tooltip-position="top" aria-label="7. Thread and Concurrency > 第二课 The POSIX Thread" data-href="7. Thread and Concurrency#第二课 The POSIX Thread" href="https://congzhi.wiki/congzhi's-os-series/7.-thread-and-concurrency.html#第二课_The_POSIX_Thread" class="internal-link" target="_self" rel="noopener nofollow">pthread</a> 进一步了解 pthread 库提供的线程 API 。<br><br>直到 C++11，也就是 pthread API 初次 release 的 16 年后，标准库才在语言层面封装了自己的线程库。现在，你只需要用 std::thread 来创建一个线程对象。标准库中的 std::thread 简化了线程的创建和使用，屏蔽了操作系统平台带来的差异性，我们还能享受 RAII 带来的资源的自动管理。<br>在多线程的程序中，每个运行的进程都需要至少包含一个（主线程）的线程执行流。由于同一进程下的不同线程共享进程资源，所以不恰当的多线程程序就很容易出现竞态条件导致。在本文档中，我们也会覆盖C++中的同步互斥的相关内容（std::mutex和std::atomic&lt;T&gt;）。<br><br><br><br>如下，我们用标准库的 std::thread 很轻易的创建了一个线程执行流。std::thread的构造函数的参数表示你想让线程执行的任务，即任何可调用对象。<br>#include &lt;iostream&gt;
#include &lt;thread&gt;

void new_thread(){
    std::cout &lt;&lt; "Creating a thread\n" &lt;&lt; std::endl;
}
int main(){
	std::cout &lt;&lt; "In main thread." &lt;&lt; std::endl;
    std::thread newThread(&amp;new_thread);
    return 0;
}
<br>由于函数很小，我们还可以用 Lambda 表达式来简化代码：<br>#include &lt;iostream&gt;
#include &lt;thread&gt;

int main(){
	std::cout &lt;&lt; "In main thread." &lt;&lt; std::endl;
    std::thread newThread([](){ std::cout &lt;&lt; "Creating a thread\n"; });
    return 0;
}
<br>运行这段代码，你大概率会得到一个 Abort 。这是因为主线程提前退出而没有等待子线程结束。为什么会得到 abort，你可以参照 <a data-tooltip-position="top" aria-label="7. Thread and Concurrency > 第二课 The POSIX Thread > 2.1.4 Join the Family `pthread_join()`" data-href="7. Thread and Concurrency#第二课 The POSIX Thread#2.1.4 Join the Family `pthread_join()`" href="https://congzhi.wiki/congzhi's-os-series/7.-thread-and-concurrency.html#第二课_The_POSIX_Thread" class="internal-link" target="_self" rel="noopener nofollow">joining</a> 。<br><br>当线程执行结束，线程变得无事可做，我们描述这种执行结束的线程为 joinable。即调用线程和被调用线程两个执行流合并(join) 为一个执行流。这个时候我们就该调用std::thread.join();函数来回收线程的资源（调用其析构函数）。值得注意的是， join 操作会阻塞调用线程，直到被调用的线程完成执行。<br>std::thread new_Thread([](){std::cout &lt;&lt; "Creating a thread\n";});
if (new_Thread.joinable()) {
    new_Thread.join();
}
<br><br>join()方法提供的阻塞调用线程在下面这种简单的例子中是线程安全(thread safe) 的。因为这两个线程实际上是同步的，我们并不需要担心有任何数据竞争(data race) 的问题。<br>int dataVar = 0;
std::thread new_Thread([](){
	std::cout &lt;&lt; "Creating a thread\n";
	dataVar = 15;
});
std::cout &lt;&lt; "Doing my work...\n";
if (new_Thread.joinable()) {
    new_Thread.join();
}
std::cout &lt;&lt; "I have read:" &lt;&lt; dataVar &lt;&lt; std::endl;
<br><br>当你将这行代码std::cout &lt;&lt; "I read:" &lt;&lt; dataVar &lt;&lt; std::endl;放到join()前面就会有这种未定义行为的出现，你会看到输出不确定的dataVar。<br>int dataVar = 0;
std::thread new_Thread([](){
	std::cout &lt;&lt; "Creating a thread\n";
	dataVar = 15;
});
std::cout &lt;&lt; "Doing my work...\n";
std::cout &lt;&lt; "I have read:" &lt;&lt; dataVar &lt;&lt; std::endl;
if (new_Thread.joinable()) {
    new_Thread.join();
}
<br><br><br><br>if&nbsp;*this&nbsp;has an associated thread (joinable()&nbsp;==&nbsp;true), calls&nbsp;request_stop()&nbsp;and then&nbsp;join().<br><br><br>如果你对数据竞争的概念还不够明晰，下面这个经典的例子能帮助你理解数据竞争及其危害。这段代码逻辑上看起来没问题，但实际操作每次&nbsp;counter++;&nbsp;时，都会将&nbsp;counter&nbsp;从内存读取到寄存器，对寄存器中的值进行操作，然后将结果写回内存。乍看之下似乎没问题，但麻烦就出在这里。<br>运行第一个例子时，你会发现&nbsp;counter&nbsp;的输出值远远小于&nbsp;20000000，而不是期望的&nbsp;20000000。原因可能是：线程&nbsp;A&nbsp;将&nbsp;counter&nbsp;的值取到寄存器中，线程&nbsp;B&nbsp;也将值取到另一个寄存器，两个线程分别操作后各自将结果写回内存。我们期望的是取值到写回之间的操作不间断，但实际上，两次加法操作的结果只写回了一次。<br>#include &lt;stdio.h&gt;
#include &lt;thread&gt;
#include &lt;atomic&gt;

int counter = 0;

int main(){
	std::thread newThread([](){
        for (int i = 0; i &lt; 10000000; i++)
        {
            counter++; 
        }   
    });
	for(int i = 0; i &lt; 10000000; i++){
		counter++;
	}
    newThread.join();
	printf("I counted: %d\n", counting);
	return 0;
}
<br>运行后的结果可能是：<br>du@DVM:~/Desktop/DSA$ for i in {1..10}; do    ./stack; done
Counting is 10586215
Counting is 11715366
Counting is 10550633
Counting is 11083560
Counting is 10850192
Counting is 10812720
Counting is 10717796
Counting is 10972930
Counting is 11482931
Counting is 11098842
<br>而通过使用 std::atomic 将 counter 定义为原子变量，为其提供原子性，我们就可以得到我们想要的输出。这里面的逻辑就是当我们进行 counter++; 操作时，原子性使得从读取到寄存器、对寄存器中的值进行加1操作和写回这些操作是不间断的，从而避免了数据竞争。<br>#include &lt;stdio.h&gt;
#include &lt;thread&gt;
#include &lt;atomic&gt;

std::atomic&lt;int&gt; counter = 0;

int main(){
	std::thread newThread([](){
        for (int i = 0; i &lt; 10000000; i++)
        {
            counter++; 
        }   
    });
	for(int i = 0; i &lt; 10000000; i++){
		counter++;
	}
    newThread.join();
	printf("I counted: %d\n", counting.load());
	return 0;
}
<br><br><a data-tooltip-position="top" aria-label="https://en.cppreference.com/w/cpp/atomic/atomic" rel="noopener nofollow" class="external-link" href="https://en.cppreference.com/w/cpp/atomic/atomic" target="_blank">std::atomic - cppreference.com</a><br><br>C++标准库并没有直接提供自旋锁，但我们可以利用原子变量来实现如下的自旋忙等待：<br>#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;atomic&gt;
int main(){
    std::atomic&lt;bool&gt; ready = false;
    std::thread chld_thread = std::thread([&amp;](){
        while(!ready){
        }
        printf("HELLO FROM CHILD.\n");
    });
        
    printf("CHILD, WAKE-UP.\n");
	ready = true;
    chld_thread.join();
    return 0;
}
<br>在这里，我们需要确保忙等待是有限的等待，不然可能会造成死锁问题。<br><br><br>虽然没有提供自旋锁，但 C++标准库提供了互斥锁这种二元信号量。在使用互斥锁前，我们需要包含头文件 #include &lt;mutex&gt; 。同样是上面的例子，互斥锁的实现方式如下：<br>#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;mutex&gt;
int main(){
    std::mutex mtx;;
    std::thread chld_thread = std::thread([&amp;](){
        mtx.lock();
        printf("HELLO FROM CHILD.\n");
    });
        
    printf("CHILD, WAKE-UP.\n");
	mtx.unlock();
    chld_thread.join();
    return 0;
}
<br>与自旋锁不同，阻塞锁并不会浪费CPU资源。如果条件不满足，它会将线程阻塞起来。与我们在操作系统课程中学习的pthread相比，C++的std:mutex相当于对pthread的封装。<br><br><br><br>那假如加锁之后程序出现异常退出怎么办？上面的代码是 thread safe 的，但并不是 exception safe 的。假如线程在解锁前异常退出，那么解锁操作将永远无法完成，死锁就会发生。C++ 为我们提供了 RAII ，我们可以将清理和 mutex 解锁操作都放到析构函数中去完成，确保 exception safe。<br>C++ 为我们提供了 std::lock_guard&lt;T&gt; ，它接受一个 BasicLockable 的类型参数，即它只接受特定的锁类型。为了满足对 BasicLockable 的要求，规定我们必须在类类型中提供 lock() 和 unlock() 的成员函数，不然就会导致编译出错。下面是使用 std::lock_guard&lt;T&gt; guard 自定义锁的例子：<br>#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;mutex&gt;

class myLock{
public:
    void lock(){
        std::cout &lt;&lt; "locked" &lt;&lt; std::endl;
    }
    void unlock(){
        std::cout &lt;&lt; "unlocked" &lt;&lt; std::endl;
    }
};
int main(){
    myLock lk;
	std::cout &lt;&lt; "In main thread." &lt;&lt; std::endl;
    std::thread myThread([&amp;lk](){ 
                                std::lock_guard&lt;myLock&gt; lock(lk); // calls myLock::lock()
                                std::cout &lt;&lt; "Hello, this is thread.\n"; 
                            }); // calls myLock::unlock() automatically
    myThread.join();
    return 0;
}
<br>一般而言，我们使用 std::lock_guard 作为 std::mutex 的 wrapper。当 std::lock_guard 对象被创建时，立即锁定传递的 std::mutex。要是 std::lock_guard 对象超出其作用域（例如函数返回或异常抛出）时，它的析构函数会自动解锁 std::mutex。这就是 std::lock_guard&lt;T&gt; 的作用，确保在异常发生时资源也能得到正确释放。<br>下面是一个例子：<br>#include &lt;iostream&gt;
#include &lt;mutex&gt;
#include &lt;vector&gt;

std::mutex mtx;
std::vector&lt;int&gt; data;

void addData(int value) {
    std::lock_guard&lt;std::mutex&gt; lk(mtx); // Locks the mutex
    data.push_back(value); // If this throws, the mutex is still unlocked
}

int main() {
    try {
        addData(42);
    } catch (const std::exception&amp; e) {
        std::cerr &lt;&lt; "Exception: " &lt;&lt; e.what() &lt;&lt; std::endl;
    }
    return 0;
}
<br><br>我们有 unique_ptr，我们也有unique_lock。unique_lock确保当前锁的持有者是唯一的。相比于lock_guard，std::unique_lock更加地灵活。std::unique_lock同样遵循RAII，你可以在一个作用域内加锁和解锁多次，相比于lock_guard ，你还可以对锁的所有权进行转移。<br>#include &lt;iostream&gt;
#include &lt;mutex&gt;
#include &lt;vector&gt;

std::mutex mtx;
std::vector&lt;int&gt; data;

void addData(int value) {
    std::unique_lock&lt;std::mutex&gt; lk(mtx); // Locks the mutex
    data.push_back(value); // If this throws, the mutex is still unlocked
    lk.unlock(); // Manually unlock the mutex
    // Do some other work
    lk.lock(); // Lock the mutex again if needed
}

int main() {
    try {
        addData(42);
    } catch (const std::exception&amp; e) {
        std::cerr &lt;&lt; "Exception: " &lt;&lt; e.what() &lt;&lt; std::endl;
    }
    return 0;
}
<br><br>在C++17引入了std::scoped_lock&lt;Ts...&gt;作为std::lock_guard&lt;&gt;的升级版。scoped_lock&lt;&gt;允许你一次性对多个 mutexes 进行锁定。C++17 还引入一项新特性 CATD(Class Template Argument Deduction)，类模板参数推导。CTAD 通过自动推导模板参数类型，使得代码更加简洁和易读。<br>template &lt;typename T1, typename T2&gt;
struct Pair {
    T1 first;
    T2 second;
    Pair(T1 f, T2 s) : first(f), second(s) {}
};
Pair&lt;int, double&gt; p(42, 3.14);
Pair p(42, 3.14); // CATD to Pair&lt;int, double&gt;

<br><br><br><br><br>std::condition_variable 是一种同步原语，用于阻塞一个或多个线程，直到某个条件变为真。它通常与 std::mutex 一起使用，以确保对共享数据的访问是线程安全的。<br><br><br><br>#include &lt;iostream&gt;
#include &lt;future&gt;
#include &lt;thread&gt;
#include &lt;chrono&gt;

bool videoLoader(size_t video_size){


}
<br><br><br><br>]]></description><link>https://congzhi.wiki/c-plus-plus/concurrency-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Concurrency in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 04 Mar 2025 18:10:20 GMT</pubDate></item><item><title><![CDATA[Const in C++]]></title><description><![CDATA[ 
 <br><br>现代C++中，我们会用const来来做以下的三件事情：<br>
<br>定义一个常符号/常量；
<br>传递一个不可修改的参数；
<br>定义常成员函数以防止潜在的修改；
<br>对于第一种，constexpr 通常是更好的选择。对于 const 而言，最主要的作用就是用指针或引用传递参数、返回值时防止修改指令 (modifiable operand) 对参数和返回值的修改。防止修改指令对参数/返回值的修改，实际上就是将潜在的运行时 bugs 转换成了编译时的一些错误。而通常情况下，编译时错误很难被忽略，所以使用 const 可以让我们更好地创建接口 (interfaces) 。<br>而 constexpr 的职责是将运行时的一些计算转换成编译时计算。<br><br>在使用const的时候，我们经常看到：<br>int const number = 123456;
char const msg[] = "hello";
<br>上面的示例中，我们使用const来定义一些不可修改的类型，第一个定义了一个不可修改的int类型，下面定义了一个用const char所组成的array。这些类型的共同点是可读但不可修改（写）。<br><br>这些不可修改的类型只有在初始化的时候给初值，并且C++要求const类型的对象必须初始化。<br>namespace example{
	int const un_initialized_;  // Error: missing initializer.
	extern int const initialized_;  // Ok: this is a declaration, not a def
}
<br><br>
Constexpr is conster than const.
<br>在 C/C++ 中，在 array 中对维度的定义也必须是一个常值，叫做 integer constant expression。<br>int x[n];  // Error
int y[10]; // OK

int const level = 10;
int x[2 * level + 1];  // OK
<br>在定义一个位域长度时也是一样的。<br>int bf: W; // Firld width, W must be constant.
<br>C++允许你将一个非const对象用const来初始化。下面的程序允许你在运行时初始化变量 level，也因此，在编译时的level不是一个const object，对应的表达式也不再是constant expression。<br>int n = 10;
int const level = n;  // Ok
int x[2 * level + 1]; // Error, this is not a constant expression
<br>constexpr 就是在这种情况下诞生的，一个 constexpr 的对象必须用一个 constant expression 来初始化：<br>int n = 10;
constexpr int m = n; // Not ok, n is not a constant expression.
constexpr int l = 10; // Ok, 10 is a const expression.
<br><br>每个对象和函数的声明都有两个部分：declaration specifiers 和 declarator。在下面的例子中前面一长串static unsigned long int都是declaration specifiers，后面的*x[N]是declarator。<br>static unsigned long int *x[N];
<br>Declaration specifiers进一步又分为type specifier（int、unsigned、long等）和non-type specifier（extern、static、inline等）。<br><br>Declarator是一个declarator-id，围绕着一些operators。上面的例子中，x就是这个declarator-id，*和[]都属于operator。这些operators有一定的优先级关系。<br><br>根据优先级关系，我们能够轻易说出后面的*x[N]是一个array of pointers。而我们很容易能够想清楚，(*x)[N]就是一个指针指向一个array of N integers。<br><br>我们提到过，Declaration specifiers进一步又分为type specifier和non-type specifier。它们分别的作用是什么？假如我们有下面的声明：<br>static unsigned long int *x[N];
<br>其中static是修饰declarator-idx的，其他的type specifiers都是修饰其他的type specifier。所以下面的几种表达都是一样的：<br>const unsigned int x;
unsigned int const x;
unsigned const int x;
int const unsigned x;
<br><br>在我们之前学习的过程中，常常会困惑于是指向常量的指针？还是常指针指向一个变量？我们需要注意：const是一个type specifier，而constexpr是一个non-type specifier。<br>constexpr unsigned long int *x[N]; // 指向变量数组的常指针 
const unsigned long int *x[N]; // 指向常量的数组指针
unsigned long int *const x[N]; // 指向变量数组的常指针
<br><br>非const类型可以转换成const类型的变量，但是反过来并不成立。const相当于一种保证，使用变量的函数或表达式（借），可以使用const保证原先的变量（被借）不被改变。但是反过来，如果变量本来就不允许被改变，但是函数或表达式不提供不被改变的保证，那么就会出错。<br>int ver;
const int const_ver = 10;

int add1(const int const_ver, const int ver); // ok
int add2(const int const_ver, int ver); // ok
int add3(int const_ver, int ver); // error
<br>add a const is ok, but not to lose it.(同样适用于volatile, const-volatile 被称为CV qulifier)]]></description><link>https://congzhi.wiki/c-plus-plus/const-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Const in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sun, 02 Mar 2025 18:36:18 GMT</pubDate></item><item><title><![CDATA[Consteval in C++ (ENG)]]></title><description><![CDATA[ 
 <br><br>After learning about the constexpr specifier, we have got some understandings about compile-time optimization. In this note, let's explore the consteval specifier.<br>The consteval specifier was introduced in C++20 and it declares a function as an "immediate function", meaning that every call to the function must produce a compile-time constant expression. This enforces that the function is always evaluated at compile-time.<br>You can put constexpr anywhere, but consteval is only allowed in function and function template declarations.<br><br>Our question here is: what's the different between constexpr and consteval? We have one main difference though. The constexpr specifier does not provide a guarantee about function evaluation at compile-time, which means the the machine code may vary depending on the compiler. However, consteval can give you a guarantee, ensuring Compile-Time Function Execution(CTFE).<br>For example, GCC may be strict about CTFE, making every possible constexpr declared function inlined and a constant expression at compile-time. On the other hand, MSVC may be more lenient about CTFE, possibly not performing the work at compile-time. And if the constexpr function do executing at run-time which we would not like to, the compiler won't complain anything about it.<br>Let's dive into an example we are familiar with:<br>#include &lt;iostream&gt;

constexpr int add(int a, int b){
    return a + b;
}

int main() {
    int a = 100; // no constexpr declared this time
    int b = 200; // no constexpr declared this time
    int c = add(a, b); // no constexpr declared this time
    return 0;
}
<br>After compilation, let's see what we get:<br>add(int, int):
        push    rbp
        mov     rbp, rsp
        mov     DWORD PTR [rbp-4], edi
        mov     DWORD PTR [rbp-8], esi
        mov     edx, DWORD PTR [rbp-4]
        mov     eax, DWORD PTR [rbp-8]
        add     eax, edx
        pop     rbp
        ret
main:
        push    rbp
        mov     rbp, rsp
        sub     rsp, 16
        mov     DWORD PTR [rbp-4], 100
        mov     DWORD PTR [rbp-8], 200
        mov     edx, DWORD PTR [rbp-8]
        mov     eax, DWORD PTR [rbp-4]
        mov     esi, edx
        mov     edi, eax
        call    add(int, int)
        mov     DWORD PTR [rbp-12], eax
        mov     eax, 0
        leave
        ret
<br>The add() function is back, which means the function will execute at runtime. This is because the variables a and b are regular variables, while a constant expression evaluation cannot depend on any runtime-modifiable regular variables. Even with constexpr, compiler cannot give you a guarantee about CTFE.<br>But with consteval, you will get a compiler error instead. This is because the function add is declared consteval, but the compiler cannot determine the function value at compile-time with regular values.<br>#include &lt;iostream&gt;

consteval int add(int a, int b){
    return a + b;
}

int main() {
	const int a = 100; // constexpr declaration will also work
	const int b = 200; // constexpr declaration will also work
	int c = add(a, b); // okay
	int c2 = add(a, add(a, b)); // okay
	
    int d = 100; // error, must be constant expression
    int e = 200; // error, must be constant expression
    int f = add(d, e); // error, add(a, b) is not a constant expression
    return 0;
}
]]></description><link>https://congzhi.wiki/c-plus-plus/consteval-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Consteval in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sun, 02 Mar 2025 08:54:28 GMT</pubDate></item><item><title><![CDATA[Constexpr in C++ (ENG)]]></title><description><![CDATA[ 
 <br><br>We always want our programs to be faster and faster, and people are constantly searching for algorithms that make our programs run swiftly at runtime. Typically, these algorithms calculate a number or perform other tasks. The lower the time complexity, the better the algorithm.<br>Since C++11 introduced the constexpr specifier, we can evaluate the value of entities at compile time, allowing the compiler to determine the results during the compilation process. This can significantly improve runtime performance by shifting some of the work from runtime to compile-time, thus it's called compile-time optimization.<br>Additionally, with the constexpr specifier, you can catch errors at compile time, making the code even safer. However, there is a trade-off because performing all calculations at compile-time makes the process compiler-dependent. The result may vary with different compilers.<br><br>Let's first go dive in a real example to see how the compile-time optimization happens. This code example following below will serve as our first example today:<br>#include &lt;iostream&gt;

int add(int a, int b){ // No constant expression
    return a + b;
}

int main() {
    int a = 100;
    int b = 200;    
    int c = add(a, b);
    return 0;
}
<br>This example demonstrates a simple function add that adds two integers. In the main function, we call add with a and b as arguments. Currently, the function does not use constexpr, so the addition is performed at runtime.<br>After compilation:<br>add(int, int):
        push    rbp
        mov     rbp, rsp
        mov     DWORD PTR [rbp-4], edi
        mov     DWORD PTR [rbp-8], esi
        mov     edx, DWORD PTR [rbp-4]
        mov     eax, DWORD PTR [rbp-8]
        add     eax, edx
        pop     rbp
        ret
main:
        push    rbp
        mov     rbp, rsp
        sub     rsp, 16
        mov     DWORD PTR [rbp-4], 100
        mov     DWORD PTR [rbp-8], 200
        mov     edx, DWORD PTR [rbp-8]
        mov     eax, DWORD PTR [rbp-4]
        mov     esi, edx
        mov     edi, eax
        call    add(int, int)
        mov     DWORD PTR [rbp-12], eax
        mov     eax, 0
        leave
        ret
<br>So you can see how many assembly instructions there are needed to be execute in the run-time.<br>With the using of constexpr , our C++ code turns into:<br>#include &lt;iostream&gt;

constexpr int add(int a, int b){
    return a + b;
}

int main() {
    constexpr int a = 100;
    constexpr int b = 200;    
    constexpr int c = add(a, b);
    return 0;
}
<br>After compilation without any compiler optimization:<br>main:
        push    rbp
        mov     rbp, rsp
        mov     DWORD PTR [rbp-4], 100
        mov     DWORD PTR [rbp-8], 200
        mov     DWORD PTR [rbp-12], 300
        mov     eax, 0
        pop     rbp
        ret
<br>You see, we don't have the add() function symbol here. Why? You may have guessed it, the constexpr specifier implies inline semantics. <br><br>The previous example might not be very intuitive, now let's do another experiment to see how awesome constexpr can be.<br>#include &lt;iostream&gt;

int fibonacci(int n) {
    return (n &lt;= 1) ? n : (fibonacci(n - 1) + fibonacci(n - 2));
}
int main() {
    int fib10 = fibonacci(10);
    int fib20 = fibonacci(20);
	int fib30 = fibonacci(30);
	int fib40 = fibonacci(40);
    std::cout &lt;&lt; "Fibonacci(10): " &lt;&lt; fib10 &lt;&lt; std::endl;
    std::cout &lt;&lt; "Fibonacci(20): " &lt;&lt; fib20 &lt;&lt; std::endl;
    std::cout &lt;&lt; "Fibonacci(30): " &lt;&lt; fib30 &lt;&lt; std::endl;
	std::cout &lt;&lt; "Fibonacci(40): " &lt;&lt; fib40 &lt;&lt; std::endl;
    return 0;
}
<br>This code calculates the Fibonacci sequence at runtime. The output might look like this:<br>du@DVM:~/cpp$ time ./proc 
Fibonacci(10): 55
Fibonacci(20): 6765
Fibonacci(30): 832040
Fibonacci(40): 102334155

real    0m0.604s
user    0m0.600s
sys     0m0.003s
<br>And with constexpr, our source code look like this:<br>#include &lt;iostream&gt;

// constexpr function to calculate Fibonacci numbers at compile-time
constexpr int fibonacci(int n) {
    return (n &lt;= 1) ? n : (fibonacci(n - 1) + fibonacci(n - 2));
}

int main() {
    constexpr int fib10 = fibonacci(10);
    constexpr int fib20 = fibonacci(20);
	constexpr int fib30 = fibonacci(30);
    std::cout &lt;&lt; "Fibonacci(10): " &lt;&lt; fib10 &lt;&lt; std::endl;
    std::cout &lt;&lt; "Fibonacci(20): " &lt;&lt; fib20 &lt;&lt; std::endl;
    std::cout &lt;&lt; "Fibonacci(30): " &lt;&lt; fib20 &lt;&lt; std::endl;
    return 0;
}
<br>With the use of constexpr, the output might look like this:<br>du@DVM:~/cpp$ time ./proc 
Fibonacci(10): 55
Fibonacci(20): 6765
Fibonacci(30): 832040
Fibonacci(40): 102334155

real    0m0.005s
user    0m0.003s
sys     0m0.002s
<br>You can see how crazy the difference is—in user time, the optimized version is 200 times faster! This demonstrates the significant impact of compile-time optimization using constexpr.<br><br>We have demonstrated the main idea about the constexpr specifier, which is to evaluate the value of the expressions at compile time. This means the compiler will provide a constant value at the compile-time (or literals, if you will). For this reason, the object declared by constexpr would imply a const semantics.<br>For example:<br>constexpr int i = 100;
i = 200; // error

int j = 100; // j is a regular value, which can be modified at runtime. A constant expression must not depend on runtime values.
/*
there might be some j value modification operations...
so you cannot say the j value down below in the compile-time
*/
constexpr int k = j; // error

<br>Here, we have some points to keep in mind. You must noted the right-hand side of constexpr variable declaration must be a constant expression. Because everything should be figured out at compile-time, thus everything should be known at compile-time. Otherwise, an error will occur.<br>Also, we saw the function declared by constexpr implies an inline semantics, and since C++17, the static data member declared by constexpr would imply inline semantics as well.<br>#include &lt;iostream&gt;
class myClass {
public:
	constexpr static int a = 50;
	// Equivalent to inline const static int a = 50;
	constexpr int a_square();
};
constexpr int myClass::a_square(){ // myClass::a_square would be inlined
	return myClass::a * myClass::a;
}

int main() {

    myClass obj;
    constexpr int i = obj.a_square();
    return 0;
}
<br>And variable/function template can be declared constexpr too.]]></description><link>https://congzhi.wiki/c-plus-plus/constexpr-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Constexpr in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sat, 01 Mar 2025 15:02:15 GMT</pubDate></item><item><title><![CDATA[Constinit in C++ (ENG)]]></title><description><![CDATA[ 
 <br><br>We have discussed constexpr and consteval, so in this note, let's delve into the details of constinit. The constinit specifier was introduced in C++20 along with consteval. While consteval specifies that a function must produce a constant expression at compile-time, it is easy to guess that constinit is used to ensure a variable must be initialized at compile-time, quite similar to how consteval applies to functions.<br>To use constinit, the approach differs from what we do with consteval. We mentioned that constexpr can be used anywhere, but it does not guarantee compile-time function execution. This is where consteval comes in—it is more strict and provides guaranteed compile-time function evaluation (CTFE) semantics. So, does the constinit specifier simply provide compile-time initialization to variables compared to constexpr? Nuh-uh!<br>The constinit specifier is only allowed to declare variables with static storage duration(global variable has this static semantics by default) and thread-local variables. This means that regular stack variables(automatic storage duration) cannot be declared as constinit. Here's some examples:<br>constinit int globalVar = 100; // Allowed because globalVar has static storage duration
int main() {
    constexpr int localVar = 100; // okay 
    constinit int localVar2 = 100; // Error: localVar has automatic storage 
    constinit static int staticVar = 100; // okay 
    return 0;
}
<br>In contrast to static storage duration, we have dynamic storage duration too. Objects with dynamic storage duration are often created and destroyed using the new and delete keywords. Since these objects are allocated and deallocated at run-time, you cannot force the compiler to allocate any memory for them at compile-time. Therefore, if you try to declare a variable with dynamic storage duration as constinit, it will cause you an error.]]></description><link>https://congzhi.wiki/c-plus-plus/constinit-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Constinit in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Mon, 03 Mar 2025 07:25:07 GMT</pubDate></item><item><title><![CDATA[Copying and Copy Constructors in C++]]></title><description><![CDATA[ 
 <br><br>拷贝是指将数据从一块内存复制到另一块内存。当我们在栈中进行拷贝时，栈中会出现两份相同的内存块。而当我们拷贝堆上的变量（对象）时，通常会将整个对象先搬到栈上，然后再复制一份到堆上。拷贝的过程涉及两次内存操作，可能会影响性能，如果堆上对象过大还可能引发栈溢出。为了避免拷贝带来的性能开销和不必要的对象，从而引入了<a data-tooltip-position="top" aria-label="Move Semantics in C++" data-href="Move Semantics in C++" href="https://congzhi.wiki/c-plus-plus/move-semantics-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">移动语义</a>。<br>所以当我们拷贝传参时，在函数内部对拷贝对象所作出的改变并不会影响我们原先内存中的数据。对象所占内存越大，拷贝所用的空间开销和时间开销就会越大。某些情况下，我们会尽量避免拷贝造成的开销。我们课堂上学习过两种方式：（1）指针 和 （2）引用。<br>我们下面先用一些简单的拷贝作为示例：<br>示例一：<br>int main(){
	int a = 10;
	int b = a;  // b对a的拷贝
	int* ptr1 = a;
	int* ptr2 = ptr1;   // ptr2对ptr1的拷贝	
	return 0;
}
<br>示例二：<br>void increment(int x) {
    x++;
}
int main() {
    int a = 5;
    increment(a);
    // a 仍然是 5
}
<br>我们将函数拆开放在主函数里面，像内联inline那样，就是如下这样：<br>// 内敛后的代码
int main() {
    int a = 5;
    {
		int x = a;
		x++;
	}
    // a 仍然是 5
}
<br><br>当我们使用指针进行值传递和值改变的时候，实际上仍然使用了拷贝，即指针的拷贝。但相比类对象的拷贝而言，拷贝指针的代价要小很多。我们将上面的代码改成如下的指针传递。我们发现a的值改变了，这是因为我们将a的地址赋值给了指针x。当我们改变指针x所指向的值（也就是a）时，a当然会改变了。<br>void increment(int* x) {
    (*x)++;
}
int main() {
    int a = 5;
    increment(&amp;a);
    // a 变为 6
}

// 相当于
int main() {
    int a = 5;
    {
		int* x = &amp;a;
		(*x)++;
	}
    // a 变为 6
}

<br><br>另一种避免拷贝的方式就是引用了，引用是对现有对象的别名，并不会创建新的对象。当我们用int&amp; x = a;时，a的引用x会直接指向对象的内存地址。这样子好像我们为x分配了内存用于存储&amp;a即a的地址。其实不然，引用和被引用对象共享同一个内存地址，因此对引用的任何修改都会直接反映在被引用对象上。<br>我们用链接视角可能更清楚一点。在C++中，引用（reference）和被引用对象在连接时的符号是一样的。引用只是被引用对象的别名，它们共享同一个内存地址。因此，对引用的任何操作实际上都是对原对象的操作。<br>void increment(int&amp; x) {
    x++;
}
int main() {
    int a = 5;
    increment(a);
    // a 变为 6
}

//相当于
int main() {
    int a = 5;
    {
		int&amp; x = a;
		x++;
	}
    // a 变为 6
}

// 相当于
int main() {
    int a = 5;
    {
	    a++;
    }
    // a 变为 6
}
<br>上面的例子很好的展示了引用的作用。我们创建了a的引用x，但x作为a的别名（其实就是a），当我们操作x实际也就是对a的操作。<br><br>This is why we need a copy constructor/copy assignment operator. That is - the rule of three.<br><br>在一个类中，由于我们没有定义拷贝构造函数，编译器会生成默认的拷贝构造函数进行浅拷贝。那究竟做了什么呢？我们创建了新的String对象string2，随后编译器将string对象中变量m_Buffer 和 m_Size;赋予string2中的变量。带来的后果就是string和string2的m_Buffer指向同一片内存区域。在析构的时候就会导致内存的双重释放。<br>#include &lt;iostream&gt;
#include &lt;string.h&gt;

class String
{
private:
    char* m_Buffer;
    unsigned int m_Size;
public:
    String(const char* str)
    {
        m_Size = strlen(str);
        m_Buffer = new char[m_Size + 1];
        memcpy(m_Buffer, str, m_Size + 1);
        std::cout &lt;&lt; "Constructor's been called." &lt;&lt; std::endl;
    }
    ~String()
    {
        delete[] m_Buffer;
        std::cout &lt;&lt; "Destructor's been called." &lt;&lt; std::endl;
    }
    friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; stream, const String&amp; str);
};

std::ostream&amp; operator&lt;&lt;(std::ostream&amp; stream, const String&amp; str)
{
    stream &lt;&lt; str.m_Buffer;
    return stream;
}

int main(){

    String string = "CongZhi";
    String string2 = string;
    std::cout &lt;&lt; string &lt;&lt; std::endl;
    std::cout &lt;&lt; string2 &lt;&lt; std::endl;
    return 0;
}
<br>运行结果如下：<br>Constructor's been called.
CongZhi
CongZhi
Destructor's been called.
free(): double free detected in tcache 2
Aborted
<br>编译器所做的就是一个浅拷贝：<br>String(const String&amp; other)
{
	memcpy(this, &amp;other, sizeof(String));
}
// 也就是
String(const String&amp; other)
	: m_Buffer(other.m_Buffer), m_Size(other.m_Size)
{}
<br><br>如何避免上面的这种情况发生呢？我们可以用深拷贝。在上面浅拷贝的用例中，我们发现类对象的拷贝仅仅停留在指向string的指针上，但是我们期望对字符串本身的拷贝，而不是指向字符串的指针。我们定义一个拷贝构造函数来避免这种浅拷贝的情况发生。<br>String(const String&amp; other)
    : m_Size(other.m_Size)
{
    m_Buffer = new char[m_Size + 1];
    memcpy(m_Buffer, other.m_Buffer, m_Size + 1);
    std::cout &lt;&lt; "Cpoy constructor's been called." &lt;&lt; std::endl;
}
<br>但是我们不想在main()函数中打印，我们封装一个printStr()函数，用printStr()打印类对象会怎么样？<br>void printStr(String str)
{
    std::cout &lt;&lt; str &lt;&lt; std::endl;
}
int main(){

    String string = "CongZhi";
    String string2 = string;
    printStr(string);
    printStr(string2);
    return 0;
}
<br>我们会调用非常多的构造和析构函数，这完全是不必要的。平白无故占用系统资源，这当然不是我们想看到的，所以我们应避免使用拷贝。我们可以用const引用，void printStr(String&amp; str)。<br>Constructor's been called.
Cpoy constructor's been called.
Cpoy constructor's been called.
CongZhi
Destructor's been called.
Cpoy constructor's been called.
CongZhi
Destructor's been called.
Destructor's been called.
Destructor's been called.
<br>使用引用后：<br>Constructor's been called.
Cpoy constructor's been called.
CongZhi
CongZhi
Destructor's been called.
Destructor's been called.
]]></description><link>https://congzhi.wiki/c-plus-plus/copying-and-copy-constructors-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Copying and Copy Constructors in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Wed, 26 Feb 2025 07:35:42 GMT</pubDate></item><item><title><![CDATA[Decltype in C++]]></title><description><![CDATA[ 
 <br><br>decltype 是在 C++11 引入的关键字，用来推导 entity 或者 expression 的类型。它允许在编译时获取表达式的静态类型，用该类型声明变量、定义函数返回类型等。当需要保留引用、CV qualifier 等修饰符时，decltype 提供精确的类型推导。<br>一个简单的例子，下面是如何推导变量类型：<br>int a = 10; // 'a' is an int type variable
decltype(a) b = 20; // 'b' has the same type as 'a'

const int c_a = 10; // 'c_a' is a const int type variable
decltype(c_a) c_b = 20; // 'c_b' has the same type as 'c_a'

<br>下面是推导表达式类型的例子：<br>int a = 10;
double b = 3.14;
decltype(a + b) c = a + b;
<br><br>decltype 还能显性的指示函数的返回值，使用 decltype 配合 auto 将返回类型后置，被称为 trailing return type 。同样的，函数的返回类型将在编译时推导出来。这种写法尤其适合泛型编程。<br>template&lt;typename T, typename U&gt;
auto add(T a, U b) -&gt; decltype(a + b) {
    return a + b;
}
<br>template&lt;typename T, typename U&gt;
auto add(T a, U b) { // C++14
    return a + b;
}
<br>实际上，自 C++14，auto 也可以用于推导返回类型，那要 decltype 有什么好处呢？我们现在可以明确的好处有：declytpe 会保留所有的修饰符，而 auto 会忽略掉引用和 const。<br><br>使用 decltype(auto) 推导变量类型会保留引用、const 等修饰符。<br>#include &lt;type_traits&gt;

const int&amp; getVal();

int main(){
	auto i = getVal(); // i is deduced as int type
	static_assert(std::is_same_v&lt;decltype(i), int&gt;)
	
	decltype(auto) j = getVal(); // j is deduced as const int&amp; type
	static_assert(std::is_same_v&lt;decltype(j), const int&amp;&gt;)
	return 0;
}
<br>使用 decltype(auto) 推导表达式不需要尾置返回类型：<br>#include &lt;type_traits&gt;

decltype(auto) getVal(){

}

int main(){

	return 0;
}
]]></description><link>https://congzhi.wiki/c-plus-plus/decltype-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Decltype in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 09:04:41 GMT</pubDate></item><item><title><![CDATA[Delegating Constructors in C++ (ENG, NC)]]></title><description><![CDATA[ 
 <br>]]></description><link>https://congzhi.wiki/c-plus-plus/delegating-constructors-in-c++-(eng,-nc).html</link><guid isPermaLink="false">C Plus Plus/Delegating Constructors in C++ (ENG, NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Wed, 26 Feb 2025 07:24:09 GMT</pubDate></item><item><title><![CDATA[Exception Control in C++ (NC)]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/c-plus-plus/exception-control-in-c++-(nc).html</link><guid isPermaLink="false">C Plus Plus/Exception Control in C++ (NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:56:10 GMT</pubDate></item><item><title><![CDATA[Explicit Specifier in C++ (ENG)]]></title><description><![CDATA[ 
 <br>ref: <a data-tooltip-position="top" aria-label="https://en.cppreference.com/w/cpp/language/explicit" rel="noopener nofollow" class="external-link" href="https://en.cppreference.com/w/cpp/language/explicit" target="_blank">explicit specifier - cppreference.com</a><br><br>In some official code, you may see the explicit specifier used inside a class, especially when specifying a constructor. Since C++11, this specifier is also be used for conversion functions and deduction guides. Today, I will take a peek at how this specifier works inside a class.<br>Before we delve into the technical details, let's first understand the word "explicit."<br><br>In the <a data-tooltip-position="top" aria-label="https://www.etymonline.com/word/explicitly#etymonline_v_32876" rel="noopener nofollow" class="external-link" href="https://www.etymonline.com/word/explicitly#etymonline_v_32876" target="_blank">dictionary</a>, the word "explicit" in English is barrowed from the French loanword "explicite" from the 1610s. It originally comes from the Latin word "explicitus" meaning "unobstructed", which is the variant past participle of the Latin verb "explicare" original meaning "unfold, explain".<br>The word "explicit" means "open to understanding, specific, clear" nowadays, which is similar to the old Latin "explicare," meaning "to unfold." You might say, "why don't you unfold/explain your language" to ask for a specific answer (equals to "why don't you explicate your language"). In Chinese, you may call it "显性、明确", indicating something should be obvious or specific.<br>The opposite "implicit" means "vogue, no specific", which refers to something implied or understood without being directly stated.<br><br>In C++, you may have heard about "implicit conversions" or "implicit casts," which act as follows:<br>class MyClass {
public:
    MyClass(int x) {
        // Constructor logic
    }
};

void someFunction(MyClass obj) {
    // Function logic
}

int main() {
    someFunction(42); // Implicitly converts 42 to MyClass using MyClass(int)
    return 0;
}
<br>Without the explicit specifier, the compiler will do implicit conversions. Meaning the compiler will automatically convert the input into a type-specific class or type, which can lead to unintended behavior because of the uncertainty and lack of definition.<br>To prevent implicit conversions and ensure that conversions are type-specific and intentional, you can use the explicit keyword. Here’s how it works:<br>class MyClass {
public:
    explicit MyClass(int x) {
        // Constructor logic
    }
};

void someFunction(MyClass obj) {
    // Function logic
}

int main() {
    // someFunction(42); // Error: cannot convert int to MyClass implicitly
    someFunction(MyClass(42)); // OK: Explicitly create a MyClass object
    return 0;
}
<br>By marking the constructor as explicit, you prevent unintended implicit conversions and ensure that object creation is always intentional and clear. This helps avoid errors and unexpected behavior in more complex scenarios.]]></description><link>https://congzhi.wiki/c-plus-plus/explicit-specifier-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Explicit Specifier in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:56:14 GMT</pubDate></item><item><title><![CDATA[Extern Keyword in C++]]></title><description><![CDATA[ 
 <br>Do this at first: <a data-href="Static Keyword in C++" href="https://congzhi.wiki/c-plus-plus/static-keyword-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Static Keyword in C++</a><br><br>在学习 static 关键字的时候，我们了解到了内部链接性：被&nbsp;static&nbsp;修饰的变量和函数仅在定义它们的翻译单元（即当前.cpp文件）内可见。这种封装特性为代码模块化提供了基础。如果不加入 static 关键字，那么所有的全局变量和函数在所有的翻译单元中都可见，这就是所谓外部链接性。（局部变量不具有链接性）<br>我们用下面的例子来解释，我们有两个文件 a.cpp 和 main.cpp，也就是说我们有两个翻译单元：<br>// a.cpp
int global_var_a = 1;    // external definition with external linkage
static int static_var_a = 0; // internal linkage

int global_fun_a(void)   // external definition with external linkage
{
    int local_a = 1; // non-external
    b += local_a;
    return b;
}

static void staitc_func_a() // internal linkage
{
}
<br>在 a.cpp 中，我们定义了一个全局变量 global_var_a、一个静态变量 static_var_a 并用 extern 声明了一个变量 b 。后面，我们还定义了一个全局的函数和静态的函数。<br>我们上面所定义的所有全局的变量、函数都具备外部链接性。所有其他的 .cpp 文件都可以看到并使用这些全局符号，如在下面的 main.cpp 中所作的一样。<br>// main.cpp
extern int global_var_a; // external declaration with external linkage
extern int global_fun_a; // external declaration with external linkage

int main(){
	global_var_a = 100;
	global_fun_a();	
	return 0;
}
<br>但为什么在使用前，我用 extern 声明了这些全局变量？extern 的作用是告诉链接器这些符号是其他翻译单元的。因为链接器需要确保每个符号的单一定义规则。如果你不加 extern 链接器可能会误以为你在 main.cpp 里定义了一个未初始化的全局变量。extern 存在的意义就是为避免一定程度上的命名冲突。<br><br>在现代 C++ 中，我们常用 namespace 来封装全局变量，避免全局符号的精确定义。你也可以用 inline 请求编译器将某个全局符号内联化。<br><br>此外，我们还可能经常看到如下的 extern 用法：<br>// example.h
#ifndef EXAMPLE_H
#define EXAMPLE_H

#ifdef __cplusplus
extern "C" {
#endif

void my_c_function();

#ifdef __cplusplus
}
#endif

#endif // EXAMPLE_H
<br>通常我们在 C++ 中调用 C 的函数库时会用到 extern "C"。这是因为 C++ 会对函数名进行名词修饰（name mangling）。简单的来说，就是 C++ 支持函数重载，而 C 语言并不支持。这就导致 C++ 编译器生成的符号和 C 编译器生成的符号有差别，进而导致链接错误。<br>比如我们有下面的函数：<br>int add(int i, int j){}
<br>使用 C++ 编译器编译后生成的符号名是 _Z3addii 而使用 C 编译器所生成的汇编函数名直接就是 add。你看到 C++ 编译器添加了许多字符来修饰函数，这是 C++ 实现静态多态的基石。如果直接链接 C 编译后的代码，链接器会无法识别这些符号。]]></description><link>https://congzhi.wiki/c-plus-plus/extern-keyword-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Extern Keyword in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 13 Mar 2025 16:33:59 GMT</pubDate></item><item><title><![CDATA[Forwarding in C++]]></title><description><![CDATA[ 
 <br>Do these at first:<br>
<br><a data-href="Move Semantics in C++" href="https://congzhi.wiki/c-plus-plus/move-semantics-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Move Semantics in C++</a>
<br><a data-href="Generics Programming in C++" href="https://congzhi.wiki/c-plus-plus/generics-programming-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Generics Programming in C++</a>
<br><br>在 <a data-tooltip-position="top" aria-label="Move Semantics in C++" data-href="Move Semantics in C++" href="https://congzhi.wiki/c-plus-plus/move-semantics-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Move Semantics</a> 中，我们提到，左值引用只能绑定左值，右值引用只能绑定右值。右值的应用让那些绑定右值的函数能够对物体直接进行所有权转移的操作，避免了不必要的拷贝。<br>然而，你会发现有时候当你传递左值给一个右值引用时，仍然行得通。但这应当是非法的。为什么呢？这是因为函数模板参数类型推导过程中会发生引用折叠。<br>#include &lt;cstdio&gt;
template&lt;typename T&gt;
void foo(T &amp;&amp;){
	printf("foo(T&amp;&amp;)");
}
int main(){
	int i = 5;
	foo(i); // i is a lvalue
	foo(5); // pass a rvalue
	return 0;
}
<br>这里会发生 "reference collapsing"。我们传入了一个左值 i，在编译器推导函数 foo() 接收的类型时，会将其推导成 T&amp; &amp;&amp;。而 C++ 有一些 reference collapsing rules 如下所示。进一步地，编译器会将类型推导成一个接受左值的函数 foo(T&amp;)。（引用折叠，自 C++11）<br><br>那传入一个右值会怎么样？传递右值给 foo 函数当然会推导出 T&amp;&amp;，从而保持右值引用的性质。也就是说，传递左值时，会折叠成左值引用；传递右值时，会保持右值引用。<br><br>有时候，我们希望写出一个既能够接受左值，也能接受右值的函数。在这种情况下，C++11 引入了转发引用（forwarding references），也称为通用引用（universal references）。了解了引用折叠是怎么回事后，我们可以利用其特性编写一个中继函数来同时接受左值和右值。再通过中继函数对参数的转发，我们就实现了完美转发。<br>要实现完美转发，需要根据原始参数的值类别（左值/右值），保留其引用性质。这些都是在中继函数中完成的。我们需要用到 std::forward 保留原始的引用类别来传递给下层的函数。<br>template&lt;typename T&gt;
T&amp;&amp; forward(typename std::remove_reference&lt;T&gt;::type&amp; arg) noexcept {
    return static_cast&lt;T&amp;&amp;&gt;(arg);
}
/*
std::move turns a arg into a rvalue
std::forward turns arg into a rvalue ref
*/
<br>如：<br>#include &lt;cstdio&gt;
#include &lt;utility&gt;

template&lt;typename T&gt;
void foo(T&amp; arg) {
    printf("lvalue foo\n");
}

template&lt;typename T&gt;
void foo(T&amp;&amp; arg) {
    printf("rvalue foo\n");
}

template&lt;typename T&gt;
void relay(T&amp;&amp; arg) {
    foo(std::forward&lt;T&gt;(arg)); // correctly forward the argument
}

int main() {
    int i = 5;
    relay(i); // i is a lvalue
    relay(5); // pass a rvalue
    return 0;
}

<br>通过使用模板参数和 std::forward，我们实现了完美转发，从而在编写泛型代码时处理不同类型的引用。<br><br>如果我们有几个重载的引用转发，我们有下面的代码， f(w) 等调用这些重载的顺序是什么？<br>#include &lt;utility&gt;
struct Widget{};
// function with lvalue ref (1)
void f( Widget&amp; ){}

// function with lvalue ref to const (2)
void f( const Widget&amp; ){}

// function with rvalue ref (3)
void f( Widget&amp;&amp; ){}

// function with rvalue ref to const (4)
void f( const Widget&amp;&amp; ){};

// function with forwarding ref (5)
template&lt; typename T &gt;
void f( T&amp;&amp; ){}

// function template with rvalue ref to const (6)
template&lt; typename T &gt;
void f( const T&amp;&amp; ){}

int main(){
	Widget w{};
	f(w); // (1), (5), (2)

	const Widget w2{};
	f(w2); // (2), (5)

	f(std::move(w)); // (3), (5), (4), (6), (2)

	const Widget w3{std::move(w)};
	f(w3); // (4), (6), (5), (2)
	return 0;
}
<br>Avoid overloading on forward references.]]></description><link>https://congzhi.wiki/c-plus-plus/forwarding-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Forwarding in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 06 Mar 2025 09:14:34 GMT</pubDate></item><item><title><![CDATA[Friend Keyword in C++ (ENG)]]></title><description><![CDATA[ 
 <br><br>In C++, we use the friend keyword in the class body to declare a function or a class as a friend to the current class. This means that the friend function or class will have access to the private and protected members of the current class. The declaration syntax is as follows:<br>class MyClass {
    int a, b, c; // private members

    // Friend function declaration
    friend void printMember();

    // Friend class declaration
    friend class AnotherClass;
};
<br>#include &lt;iostream&gt;

class MyClass {
private:
    int a, b, c;

public:
    MyClass(int x, int y, int z) : a(x), b(y), c(z) {}

    // Declare AnotherClass as a friend
    friend class AnotherClass;
};

class AnotherClass {
public:
    void showValues(const MyClass&amp; obj) {
        std::cout &lt;&lt; "a: " &lt;&lt; obj.a &lt;&lt; ", b: " &lt;&lt; obj.b &lt;&lt; ", c: " &lt;&lt; obj.c &lt;&lt; std::endl;
    }
};

int main() {
    MyClass obj(1, 2, 3);
    AnotherClass anotherObj;
    anotherObj.showValues(obj); // Friend class can access private members
    return 0;
}
<br><br>Interestingly, the friendship friend brings is not transitive, which means a friend of your friend is not your friend. Additionally, friendship is not inherited.<br>Using the friend keyword makes private data transparent, which can be convenient, but it breaks the encapsulation of a class. In most cases, your code should not include any friend declarations, as this might indicate poor design.<br>One of the most common use cases for the friend keyword in C++ is in non-member operator overloads. By declaring a non-member operator function as a friend, you grant it access to the private and protected members of your class. This is particularly useful for operator overloading, such as the &lt;&lt; operator for output streams.<br>#include &lt;iostream&gt;

class MyClass {
private:
    int a, b, c; // private members

public:
    MyClass(int x, int y, int z) : a(x), b(y), c(z) {}

    // Friend function declaration for operator&lt;&lt;
    friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, const MyClass&amp; obj);
};

// Definition for operator&lt;&lt;
std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, const MyClass&amp; obj) {
    os &lt;&lt; "a: " &lt;&lt; obj.a &lt;&lt; ", b: " &lt;&lt; obj.b &lt;&lt; ", c: " &lt;&lt; obj.c;
    return os;
}

int main() {
    MyClass obj(1, 2, 3);
    std::cout &lt;&lt; obj &lt;&lt; std::endl; // Uses the friend function to access private members
    return 0;
}

]]></description><link>https://congzhi.wiki/c-plus-plus/friend-keyword-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Friend Keyword in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:56:23 GMT</pubDate></item><item><title><![CDATA[Function Pointers in C++ (Examples)]]></title><description><![CDATA[ 
 <br>#include &lt;iostream&gt;

int add(int a, int b){
    return a + b;
}
int multiply(int a, int b){
    return a * b;
}
int main(){
	auto (*fp)(int, int);
    bool sel = 1;
    if(sel == 0){
        fp = add;
        std::cout &lt;&lt; fp(1, 2) &lt;&lt; std::endl;
    }else{
        fp = multiply;
        std::cout &lt;&lt; fp(1, 2) &lt;&lt; std::endl;
    }
    return 0;
}
<br>#include &lt;iostream&gt;

// 定义回调函数类型
typedef void (*Callback)(int);

void process(int value, Callback cb) {
    std::cout &lt;&lt; "Processing value: " &lt;&lt; value &lt;&lt; std::endl;
    cb(value); // 调用回调函数
}

void myCallback(int result) {
    std::cout &lt;&lt; "Callback function called with result: " &lt;&lt; result &lt;&lt; std::endl;
}

int main() {
    // 使用回调函数
    process(42, myCallback);
    return 0;
}

<br>std::function<br>std::function&lt;int(int, int)&gt; op;
]]></description><link>https://congzhi.wiki/c-plus-plus/function-pointers-in-c++-(examples).html</link><guid isPermaLink="false">C Plus Plus/Function Pointers in C++ (Examples).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:56:27 GMT</pubDate></item><item><title><![CDATA[Functions in Standard Library (Examples)]]></title><description><![CDATA[ 
 <br>#include &lt;iostream&gt;
#include &lt;typeinfo&gt;

int main(){

	int x = 10;
	std::cout &lt;&lt; "x type: " &lt;&lt; typeid(x).name() &lt;&lt; std::endl;

	return 0;
}
<br>check if a variable is const type<br>#include &lt;iostream&gt;
#include &lt;type_traits&gt;

int main(){

	int x = 10;
	std::cout &lt;&lt; std::is_const_v&lt;decltype(x)&gt; &lt;&lt;std::endl; //C++17
	//or
	std::cout &lt;&lt; std::is_const&lt;decltype(x)&gt;::value &lt;&lt; std::endl;
	return 0;
}
]]></description><link>https://congzhi.wiki/c-plus-plus/functions-in-standard-library-(examples).html</link><guid isPermaLink="false">C Plus Plus/Functions in Standard Library (Examples).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:56:31 GMT</pubDate></item><item><title><![CDATA[Generics Programming in C++]]></title><description><![CDATA[ 
 <br><br><br><br>C 语言不支持函数重载(function overloading)，这就意味着我们必须给不同的函数起不同的函数名，这对于完成相同任务但接收不同参数的函数来说非常麻烦。而 C++ 从一开始就支持函数重载，允许代码实现静态多态性。通过传递不同的参数，编译器会调用相应的函数。<br>函数重载当然是一个伟大的特性，但是如果我们要重载许多函数，我们就需要复制粘贴许多遍。但使用函数重载会给我们带来一些潜在问题。除了复制粘贴许多遍之外，我们还可能碰到一些未定义重载函数的情况，比如下面我们使用 long long sum_ll = sum(5342ll, 5864ll); 我们并没有定义相关的函数重载，编译器就不知道调用哪个函数。<br>函数重载当然是一个伟大的特性，但是如果我们要重载许多函数，我们就需要复制粘贴许多遍。但使用函数重载会带来一些潜在问题。除了需要复制粘贴许多遍之外，我们还可能碰到一些未定义重载函数的情况，比如下面我们使用 long long sum_ll = sum(5342ll, 5864ll); 我们并没有定义相关的函数重载，编译器就不知道调用哪个函数。<br>int add(int a, int b){
	return a + b;
}
float add(float a, float b){
	return a + b;
}
double add(double a, double b){
	return a + b;
}
// ...
int main(){
	int sum_i = add(20, 30); // Call int add(int a, int b)
	float sum_f = add(3.14f, 5.58f); // Call float add(float a, float b)
	double sum_d = sum(3.254, 2.546); // Call double add(double a, double b)
	long long sum_ll = sum(5342ll, 5864ll); // Which to call? It's ambiguous!
	return 0;
}
<br>而在 C++98 后，函数模板（泛型函数）的出现避免了多次代码的复制粘贴。模板相当于一个你编写的蓝图，编译器在编译代码的时候会根据你提供的蓝图帮你生成重载函数。从而，你不需要记忆你到底重载了哪些函数。<br>// Compiler will generate function code at compile-time
// And function template is not a function btw
template&lt;typename T&gt;
T add(T a, T b) {
    return a + b;
}
int main() {
    int sum_i = add&lt;int&gt;(20, 30); // Same as add(20, 30) expicitly
    float sum_f = add&lt;float&gt;(3.14f, 5.58f); // Same as add(3.14f, 5.58f)
    double sum_d = add&lt;double&gt;(3.254, 2.546); // Same as add(3.254, 2.546)
    long long sum_ll = add&lt;long long&gt;(5342, 5864); // Same as add(5232ll, 5864ll)
    return 0;
}
<br>上面的例子中，编译器帮我们实例化生成了四个重载函数。在 C++17 后，你实际上可以不再显式地提供模板重载类型，编译器会帮你推导相关的类型。<br><br>每个模板类型都至少被类型推断一次<br>multiple template parameters and non object type params<br>with auto<br>Variadic arguments and Variadic Function Templates<br><br><br><br><br><br>reference collapsing<br><br><br>同样，类模板也不是一个类。它是让编译器帮我们创建类的模板蓝图。<br>STL - you use all the time<br>class myContainer {
public:
	myContainer(int N) {
		m_data = new int[N];
	}
	~myContainer() {
		delete[] m_data;
	}
private:
	int* m_data;
};

class myContainer {
public:
	myContainer(int N) {
		m_data = new float[N];
	}
	~myContainer() {
		delete[] m_data;
	}
private:
	float* m_data;
};
<br>template&lt;typename T&gt;
class myContainer {
public:
	myContainer(int N) {
		m_data = new T[N];
	}
	~myContainer() {
		delete[] m_data;
	}
private:
	T* m_data;
};
<br>还可以提供一个 non-type object<br>#include &lt;cstddef&gt; // For size_t

template&lt;typename T, size_t N&gt;
class myContainer {
public:
    myContainer() {
        m_data = new T[N];
    }
    ~myContainer() {
        delete[] m_data;
    }
private:
    T* m_data;
};

int main() {
    myContainer&lt;int, 5&gt; container;
    return 0;
}
<br><br><br><br>typeid().name()<br><br><br>#include &lt;vector&gt;

// Without alias templates:
typedef std::vector&lt;int&gt; myvec_int; // C++03 alias syntax
typedef std::vector&lt;float&gt; myvec_float; // C++03 alias syntax

// With alias templates:
template&lt;typename T&gt;
using myvec = std::vector&lt;T&gt;; // C++11 syntax

int main(){
    myvec_int vi = {1, 2, 3, 4, 5}; // Using the old alias syntax
    myvec_float vf = {1.1f, 2.2f, 3.3f}; // Using the old alias syntax

    myvec&lt;int&gt; vi_alias = {6, 7, 8, 9, 10}; // Using the new alias template syntax
    myvec&lt;float&gt; vf_alias = {4.4f, 5.5f, 6.6f}; // Using the alias template syntax
    return 0;
}
<br>Alias template cannot be specialized.<br><br><br><br>模板的参数并不必须为一种”类型“：<br>template&lt;class T, size_t N&gt;
class Array{
	T    m_data[N];
	// ...
};

Array&lt;foobar, 10&gt; some_foobars;
<br>NTTPs中的常数类型必须在编译阶段或链接时确定好，而且类型必须为：<br>
<br>整型或枚举（最常见）
<br>指针
<br>std::nullptr_t
<br>其他
<br>Unwatched: <a data-tooltip-position="top" aria-label="https://www.youtube.com/watch?v=VIz6xBvwYd8&amp;t=11s" rel="noopener nofollow" class="external-link" href="https://www.youtube.com/watch?v=VIz6xBvwYd8&amp;t=11s" target="_blank">CppCon 2016: Arthur O'Dwyer “Template Normal Programming (part 2 of 2)"</a>]]></description><link>https://congzhi.wiki/c-plus-plus/generics-programming-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Generics Programming in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 04 Mar 2025 16:17:40 GMT</pubDate></item><item><title><![CDATA[Inheritance in C++]]></title><description><![CDATA[ 
 <br><br>继承是面向对象技术得以发扬光大的原因之一。本节课，我们来学习 C++ 中最基础的继承知识，简单了解一下继承是什么。我们一般将被继承的类称为基类（也称为父类、祖先类），将继承其他类的类称为派生类（也称为子类、扩展类）。下面用一个例子展示这种关系：<br>class Base{ // parent class or ancestor class
// Some implementation
};
class Derived : public Base{
// Some implementation
};
<br>一个类可以被继承和派生，正如上面基类 Base 和派生类 Derived 的关系。这里的继承可以理解为派生类接收到来自基类的传承，脉脉相承就是继承最主要的思想。类与类之间有两种关系："is-a" 和 "has-a"，请不要混淆，我们下面就来解释这两种关系。<br><br>我们所说的继承是 "is-a" 的关系，也就是“是一种”的关系。而 "has-a" 表示的是“有一个”的关系，即“composition”。我们用下面的示例来直观地感受这两种关系：<br>class Widget {};
class Base {};
class Derived : public Base { // class Derived is-a Base
    // Class data member
    Widget w; // class Derived has-a Widget
};
<br>在这个例子中，我们说派生类 Derived 继承了基类 Base，所以 Derived 是一种 Base。而派生类内有个 Widget 成员，所以我们说派生类 Derived 中有一个 Widget，也就是 "has-a" 的关系。<br>And by the way, we also have another 'has-a' relationship called aggregation, which has a weaker relationship than compositional 'has-a'. For example, you may say a car has an engine, this is compositional 'has-a'. And also, a school could have many students, this is aggregational 'has-a'.<br><br>通过继承，你能得到什么呢？我们说派生类 is-a 基类。那么，我们是否可以将派生类中的一些共性提炼出来放在基类中？实际上，我们的确就是这么做的。通过继承，派生类重用基类的代码，减少了代码的重复，提高了代码的可维护性。在功能扩展时，只需要让派生类在基类的基础上增加新的功能。<br>此外，继承使得基类提供不同的接口，使得派生类可以通过相同的接口做出不同的实现，这被称为多态（或动态多态）。这与我们在 <a data-tooltip-position="top" aria-label="Static Dispatch in C++ (ENG)" data-href="Static Dispatch in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/static-dispatch-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">静态多态</a> 中介绍的“假”多态不同。多态的出现可以使代码在运行时通过不同的接口调用不同的派生类方法。我们将在 <a data-href="Virtual Dispatch in C++" href="https://congzhi.wiki/c-plus-plus/virtual-dispatch-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Virtual Dispatch in C++</a> 介绍这种动态多态。 <br><br>在 C++ 中，我们有三种不同的继承访问控制方式： public、protected 和 private。不同的继承访问方式决定了派生类中对基类成员的不同访问权限。我们用一个例子来展示这三种不同的继承访问控制方式的作用：<br>class Base {
public:
    int pub_i; // Public members are accessible from outside
protected:
    int prot_i; // Protected members are accessible to derived classes
private: 
    int pri_i; // Private members are only accessible within Base class
};

class Pub_Derived : public Base {
public:
    void accessBase() {
        pub_i = 1; // Accessible
        prot_i = 2; // Accessible
        // pri_i = 3; // Not accessible
    }
};

class Prot_Derived : protected Base {
public:
    void accessBase() {
        pub_i = 1; // Accessible
        prot_i = 2; // Accessible
        // pri_i = 3; // Not accessible
    }
};

class Pri_Derived : private Base {
public:
    void accessBase() {
        pub_i = 1; // Accessible
        prot_i = 2; // Accessible
        // pri_i = 3; // Not accessible
    }
};

int main() {
    Pub_Derived pubDerived;
    pubDerived.pub_i = 1; // Accessible from outside
    // pubDerived.prot_i = 2; // Not accessible from outside
    // pubDerived.pri_i = 3; // Not accessible from outside
    
    Prot_Derived protDerived;
    // protDerived.pub_i = 1; // Not accessible from outside
    // protDerived.prot_i = 2; // Not accessible from outside
    // protDerived.pri_i = 3; // Not accessible from outside

    Pri_Derived priDerived;
    // priDerived.pub_i = 1; // Not accessible from outside
    // priDerived.prot_i = 2; // Not accessible from outside
    // priDerived.pri_i = 3; // Not accessible from outside
    return 0;
}
<br>从例子中，你可以看到这三种不同的继承访问控制方式的作用。我们发现，无论是哪种继承关系，派生类都不能访问基类中的 private 成员。对于 public 继承，基类中的 public 和 protected 成员在派生类中的访问权限不变。对于 protected 继承，基类中的 public 成员在派生类中的访问权限会变为 protected。对于 private 继承，基类中所有类型的成员在派生类中都会变为 private 成员。<br><img alt="Pasted image 20250225102217.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20250225102217.png"><br><br>
<br>构造顺序：基类 → 派生类成员变量（按声明顺序）→ 派生类构造函数体。
<br>析构顺序：派生类析构函数体 → 派生类成员变量（逆声明顺序）→ 基类析构函数
<br>class Base {
public:
    Base() { std::cout &lt;&lt; "Base constructed\n"; }
    ~Base() { std::cout &lt;&lt; "Base destroyed\n"; }
};

class Derived : public Base {
public:
    Derived() { std::cout &lt;&lt; "Derived constructed\n"; }
    ~Derived() { std::cout &lt;&lt; "Derived destroyed\n"; }
};

int main() {
    Derived d;
}
<br><br>当有多个不同的基类构造函数时，派生类需要在构造函数初始化列表中显式指定要调用的基类构造函数，不然编译器尝试调用基类默认构造函数。<br>class Base {
public:
    Base() { std::cout &lt;&lt; "Base()\n"; }
    Base(int x) { std::cout &lt;&lt; "Base(" &lt;&lt; x &lt;&lt; ")\n"; }
};

class Derived : public Base {
public:
    Derived() { std::cout &lt;&lt; "Derived()\n"; }
    Derived(int x) : Base(x) { std::cout &lt;&lt; "Derived(int)\n"; }

    Derived(int x, double y) : Base(x), y_(y) { 
        std::cout &lt;&lt; "Derived(int, double)\n"; 
    }
private:
    double y_;
};

int main() {
    Derived d1;        // Base() → Derived()
    Derived d2(10);    // Base(10) → Derived(int)
    Derived d3(5, 3.14);// Base(5) → Derived(int, double)
}
<br><br>如果我们在派生类中定义了与基类同名的函数（non-virtual），无论该函数的参数列表是否相同，基类中的函数都会被隐藏，而不是简简单单的覆盖（override）。这种隐藏现象是名称级别的，即基类的同名函数被“隐藏”。因而，你不能直接通过派生类对象调用基类的同名函数。<br>#include &lt;iostream&gt;
class Base {
public:
    void func() {
        std::cout &lt;&lt; "Base::func()" &lt;&lt; std::endl;
    }
};

class Derived : public Base {
public:
    void func(int x) {
        std::cout &lt;&lt; "Derived::func(int)" &lt;&lt; std::endl;
    }
};

int main() {
    Derived d;
    d.func(42);  // call Derived::func(int)
    // d.func(); // error, because Base::func() was hiden
    d.Base::func(); // call Base::func()
    return 0;
}
<br>上面的例子中，如果你想重写基类中的同名函数，你就需要用到虚函数，我们会在<a data-tooltip-position="top" aria-label="Virtual Dispatch in C++" data-href="Virtual Dispatch in C++" href="https://congzhi.wiki/c-plus-plus/virtual-dispatch-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">虚多态</a>介绍这种机制，这是 C++ 中多态实现的方式。]]></description><link>https://congzhi.wiki/c-plus-plus/inheritance-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Inheritance in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sat, 22 Mar 2025 09:22:13 GMT</pubDate><enclosure url="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20250225102217.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/c-plus-plus/pics/pasted-image-20250225102217.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Inline in C++ (ENG)]]></title><description><![CDATA[ 
 <br>Do this at first: <a data-href="Call Stack in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/call-stack-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Call Stack in C++ (ENG)</a><br><br>When a function is called, typically, a stack frame is established. To build the frame, the machine needs to do a lot of work, including saving register values, copying parameters, saving the return address, and keeping track of rbp and rsp. After that, the function does its work.<br>The inline specifier simply tells the compiler to not build this frame, effectively "unboxing" the function code and adding it directly into the caller's frame. This can provide several benefits, such as reducing function call overhead (thus improving performance) and slightly improving readability.<br>Although the inline specifier declares the function to be inlined, it serves merely just as a suggestion to the compiler. If the compiler finds no need to be inlined, it may not take the suggestion. As a result, in most cases, the inline specifier might not be applied at all.<br>With GCC optimizations, the compiler can often eliminate the stack frame even without the use of the inline specifier, which is funny.<br><br>The inline specifier is particularly useful when dealing with external linkage, whether for inline functions or inline variables (since C++17). The use of inline helps prevent linker errors caused by naming conflicts, which would otherwise violate the One Definition Rule (ODR). This is because inline functions and variables can be defined in multiple translation units without causing conflicts during linking.<br>To comply with the ODR, the inline specifier comes into play. In the example below, the compiler ensures that the rule is followed by inlining the test function in the test.cpp file during the compilation stage, replacing function calls with the actual function code in the assembly output.<br>// test.cpp
#include &lt;cstdio&gt;
inline void test() { // This function will not exist in its original form after compilation.
// The compiler will replace calls to this inline function with the actual code during compilation.
    printf("This is an inlined hello in %s\n", __FILE__);
}

void printsomething() {
    test(); // Calls the inline version of the test function defined in this file.
}

// main.cpp
#include &lt;cstdio&gt;
extern void printsomething(); // Declares the external function implemented in test.cpp.
void test() { // This is a regular (non-inline) function definition.
    printf("This is a hello in %s\n", __FILE__);
}

int main() {
    test(); // Calls the test function defined in main.cpp.
    printsomething(); // Calls the printsomething function from test.cpp, which, in turn, calls the inline test function from test.cpp.
    return 0;
}
<br>After compilation, these inline functions and variables are directly inserted into the assembly code at their call sites. Consequently, they do not have separate names in the generated object files, thereby avoiding potential conflicts. However, the inline functions or variables must still be declared in every translation unit where they are used.<br>Note: A function declared constexpr or consteval in its first declaration is implicitly inline. Similarly, a static data member declared constexpr in its first declaration is implicitly an inline variable.<br><br>Inline variables are a feature introduced in C++17, which allows variables to be declared with the inline specifier. Inline variables allow variables to be dealt with external linkage like inline functions.<br>Besides, inline variables are also very useful when dealing with header-only libraries. Some design specifics dictate that the interface (.h/.hpp) should be separate from the implementation (.c/.cpp). Inside a class, when we declare a static variable or function, we are traditionally told not to put the definition (initialization) inside the class, as it is forbidden. However, you can do so if you are using the inline specifier.<br>Old way:<br>// .hpp file
class myLib{
	static int counter; // Declareation
	// Other data member
public:
    // Other member functions and definitions
};
<br>// .cpp file
int myLib::counter = 0;
// some other definition and implementation
<br>Header-only library way:<br>// header_only_library.hpp
// This hpp file contains all the declarations and definitions
// An example to "class as a library"

class myLib {
    // static int counter = 0; // Not allowed, definition must be outside the class
    // const static int counter = 0; // Okay, but requires constexpr for inline
    // const static int counter; // Not allowed, must be initialized (defined)
    inline static int counter = 0; // Okay, inline allows definition inside the class
    // inline static int counter; // Also okay, will be default initialized to 0
    // constexpr static int counter = 0; // Okay, constexpr implies inline
    // inline constexpr static int counter = 0; // Same as above

    // Other data members

public:
    // Other member functions and definitions
};
]]></description><link>https://congzhi.wiki/c-plus-plus/inline-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Inline in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 18 Mar 2025 06:40:19 GMT</pubDate></item><item><title><![CDATA[Integer Literal & Float Literal in C++]]></title><description><![CDATA[ 
 <br>Do this at first: <a data-href="Auto in C++" href="https://congzhi.wiki/c-plus-plus/auto-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Auto in C++</a><br><br>在使用 auto 关键字时，我们发现 auto 往往会将整数字面量推导成 int 类型。如下，我们给 a 赋值 0 远远小于 int 能够表示的最大值。既然 short 类型也能表示 0 ，甚至 char 类型也可以。那为什么 auto 不将这个表达式中的 a 推导成 short 类型，甚至 char 类型？<br>auto a = 0; // a is deduced as int type, why not short or char?
<br>这是因为在 C++ 中，整数字面量（例如 0）的默认类型是 int。编译器会优先选择最适合的类型来表示这个字面量，因此在这种情况下，auto 会推导出 int 类型，而不是其他的类型。<br><br>在 C++ 中，整数字面量可以是十进制的、八进制的、十六进制的和二进制的（C++14）。通过加入不同的前缀，我们就可以改变整数的基数。如下：<br>int decimal = 16;
int octal = 020; // 16 on decimal
int hexdecimal = 0x10; // or 0X10
int binary = 0b10000;
<br><br>当整数字面量不带任何后缀时，一般默认的类型就是 int 类型。C++ 整型字面量一共有这几种不同的后缀（基数为10）：<br>
<br>u 或 U：表示 unsigned int （默认）
<br>l 或 L：表示 long int （默认）
<br>ul / UL 等 ：表示 unsigned long int （默认）
<br>ll 或 LL：long long int
<br>ull 或 ULL 等：表示 unsigned long long int
<br>z 或 Z：表示 std::size 类型（C++23）
<br>uz 或 UZ：同上。
<br>auto a = 0; // a is deduced as type int
auto b = 0u; // b is deduced as type unsigned int
auto c = 0l; // c is deduced as type long
auto d = 0ul; // d is deduced as type unsigned long
auto e = 0ll; // e is deduced as type long long
auto f = 0ull; // f is deduced as type unsigned long long
<br>当字面量很长时，你可以用单引号作为分隔符在任意位置将字面量分隔开。在确定字面量时会忽略这些单引号。<br><br>同样的，浮点字面量也可以通过后缀来决定字面量的类型。当没有后缀时，默认定义为 double 类型。对于浮点数字面量，C++ 有以下的后缀：<br>
<br>f 或 F：表示 float
<br>l 或 L：表示 long double
<br>自 C++23 起，C++ 还引入了 f16、f32、f64、f128、bf16、F16、F32、F64、F128、BF16 的后缀。
<br>auto a = 0.0; // a is deduced as type double
auto b = 0.0f; // b is deduced as type float
auto c = 0.0l; // c is deduced as type long double
<br>下一节：<a data-href="Character Literal &amp; String Literal in C++" href="https://congzhi.wiki/c-plus-plus/character-literal-&amp;-string-literal-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Character Literal &amp; String Literal in C++</a>]]></description><link>https://congzhi.wiki/c-plus-plus/integer-literal-&amp;-float-literal-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Integer Literal &amp; Float Literal in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 21 Feb 2025 18:13:37 GMT</pubDate></item><item><title><![CDATA[Lambdas in C++]]></title><description><![CDATA[ 
 <br><br>我们将函数视为对黑匣子内部操作的抽象封装。函数隐藏了内部细节，只向外界暴露其提供的接口。而在内存中，这个黑匣子需要占用存储空间（.text&nbsp;段）。因此，函数是有地址的。函数地址就是指向内存中‘黑匣子’所存放的起始地址，而函数指针则是指向函数地址的指针。<br>因为函数可以取地址，所以我们可以将函数指针作为参数去传递。我们下面举例：<br>#include &lt;iostream&gt;
void hello(){
	std::cout &lt;&lt; "Hello" &lt;&lt; std::endl;
}
void test(void(*ptr)()){
    ptr();
}
int main(){
	auto funcPtr = hello; // same as `void(*funcPtr)() = hello;`
	test(funcPtr); // passing function pointer as a parameter
    funcPtr(); // call hello() using function pointer
}
<br>例二：<br>#include &lt;iostream&gt;
#include &lt;vector&gt;

void PrintValue(int value){
	std::cout &lt;&lt; "Value: " &lt;&lt; value &lt;&lt; std::endl;
}
void ForEach(const std::vector&lt;int&gt;&amp; values, void(*print)(int)){
	for(int value : values)
		print(value);
}

int main(){
	std::vector&lt;int&gt; values = {1, 2, 3, 5, 9};
	ForEach(values, PrintValue);
	return 0;
}
<br>例二使用模板和lambda表达式后，我们能够优雅地遍历打印基本类型的vector。从这里我们就能够感受到lambda表达式的便利性，因为你不需要单独定义一个函数了，简化了代码。<br>#include &lt;iostream&gt;
#include &lt;vector&gt;

template&lt;typename T&gt;
void ForEach(const std::vector&lt;T&gt;&amp; values, void(*funcPtr)(T))
{
    for (const T&amp; value : values)
        print(value);
}
int main()
{
    std::vector&lt;int&gt; values = {1, 2, 3, 5, 9};
    ForEach(values, [](int value){std::cout &lt;&lt; "Value: " &lt;&lt; value &lt;&lt; std::endl;});
    return 0;
}
<br><br><br>仿函数，也叫函数对象(function object)，是可以像函数一样被调用的对象，常常用重载运算符 operator() 实现。我们用一个例子来说明为什么被称为仿函数：<br>#include &lt;iostream&gt;
struct Increment
{
    int number;
    Increment(int n) : number(n) {}
    int operator()(int x) {
        number += x;
        return number;
    }
};

int main() {
    Increment inc(5);
    std::cout &lt;&lt; inc(15) &lt;&lt; std::endl; // call functor just like functions
    return 0;
}
<br>由于重载了 operator()，仿函数的调用能够像调用函数一样方便自然。而且通过类内的变量 number 能够保留每次被调用后的状态信息，这时函数所不能够做到的。仿函数结合了类的状态管理和函数的调用方式，提供了比普通函数更高的灵活性和功能。<br><br>#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;algorithm&gt;

class Print {
public:
    void operator()(int x) const {
        std::cout &lt;&lt; "Value: " &lt;&lt; x &lt;&lt; std::endl;
    }
};
int main() {
    std::vector&lt;int&gt; values = {1, 2, 3, 4, 5};
    std::for_each(values.begin(), values.end(), Print());
    return 0;
}
<br><br>如果刚刚接触Lambdas，你一定会困惑于如此多的括号。在Lambda中，我们有()、[]、{}。如果带有参数模板你甚至还会看到&lt;&gt;。我们先看看这些Lambda表达式。<br><br><br>
Lambda constructs a closure : an unnamed function object capable of capturing variables in scope.
<br>Lambda表达式构造了一个闭包，在3.2节中我们将会学到（其中[]叫做捕获列表）。通过Lambda表达式，我们实际上能够定义一个具有捕获作用域内变量能力的匿名函数对象。什么意思呢？即在仿函数（函数对象）的基础上，还加入了捕获当前栈帧中局部变量的能力。<br>虽然匿名函数对象虽然是匿名的，但我们仍然可以让一个函数指针指向我们的 Lambda 表达式，从而达到 Store the Lambda 的目的。在下面的例子中，Lambda 表达式被转换为函数指针&nbsp;Print，并且我们可以通过这个指针调用 Lambda 表达式，实现存储和调用。<br>#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;algorithm&gt;

int main() {
	int i = 5;
	double j = 6;
	char c = 's';
    //auto Print = [=](int v){
    //    std::cout &lt;&lt; "value:" &lt;&lt; v &lt;&lt; std::endl;
    //};
    std::vector&lt;int&gt; values = {1, 2, 3, 4, 5};
    std::for_each(values.begin(), values.end(), 
					[=](int v){
					    std::cout &lt;&lt; "value:" &lt;&lt; v &lt;&lt; std::endl;
					}); 
    // std::for_each(values.begin(), values.end(), Print); 
    return 0;
}
<br>如果我们想看看 Lambda 背后的仿函数真身是什么，接着上面的例子，我们会看到编译器实际上生成了一个仿函数，捕获的成员变量会作为仿函数类中的私有成员变量存储。编译器生成的代码大概是这样的：<br>#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;algorithm&gt;

int main()
{
  int i = 5;
  double j = 6;
  char c = 's';
  std::vector&lt;int, std::allocator&lt;int&gt; &gt; values = std::vector&lt;int, std::allocator&lt;int&gt; &gt;{std::initializer_list&lt;int&gt;{1, 2, 3, 4, 5}, std::allocator&lt;int&gt;()};
    
  class __lambda_14_6
  {
    public: 
    __lambda_14_6(int i, double j, char c) : i(i), j(j), c(c) {}
    
    inline /*constexpr */ void operator()(int v) const
    {
      std::operator&lt;&lt;(std::cout, "value:").operator&lt;&lt;(v).operator&lt;&lt;(std::endl);
    }
    
    private:
    int i;
    double j;
    char c;
  };
  
  std::for_each(values.begin(), values.end(), __lambda_14_6(i, j, c));
  return 0;
}
<br><br>所以，Lambda 表达式是如何实现的？我们现在能明白的是编译器会将 Lambda 表达式转换成一个匿名类，而且 Lambda 是由仿函数实现的，捕获的变量会作为仿函数类中的成员变量。那从 Lambda 表达式到仿函数这一过程中会发生什么？<br>首先会进行语法解析和捕获，[] 叫做 CAPCHA method，它会按照既定方式捕获作用域内的局部变量（按值或按引用）虽然我们[=]自动按值捕获所有的局部变量，但由于一个都没有用，所有匿名类中也是不会对这些局部变量进行构造的。之后会生成匿名类，类中包括我们所捕获的变量并完成对运算符operator()的重载。<br>Lambda 中 CAPCHA method 中捕获的变量就会在生成匿名类时对这些变量进行构造，当然，这些变量会被作为类内的 private 变量存在。下面，我们来看看 Lambda 的捕获规则。<br><br>我们用捕获std::string对象作为例子来展示不同类型的捕获类型。我们下面会介绍按值捕获、按引用捕获和按右值捕获。<br><br>首先，我们来看看当捕获列表中按值捕获一个对象时会发生什么。最开始，我们用&nbsp;std::string str = "Hello!";&nbsp;定义了一个&nbsp;std::string&nbsp;类型的对象。这时，str&nbsp;指针在栈上，而字符串内容&nbsp;"Hello!"&nbsp;实际上存储在堆上。<br>然后，auto&nbsp;capFunc&nbsp;=&nbsp;[newStr&nbsp;=&nbsp;str]()&nbsp;mutable&nbsp;{}&nbsp;这行代码将&nbsp;lambda&nbsp;表达式的地址赋给了&nbsp;capFunc。在&nbsp;lambda&nbsp;表达式中，[newStr&nbsp;=&nbsp;str]&nbsp;相当于auto newStr = str;。在构造匿名类时，会在匿名类的&nbsp;private&nbsp;域中增加一个&nbsp;std::string&nbsp;newStr;&nbsp;成员，并生成相应的复制构造函数。<br>由于 std::string 类中对拷贝赋值运算符进行了重写，拷贝时进行深拷贝。所以按值捕获后，我们在栈上有两个不同的指针指向两个堆上字符串。我们对拷贝的字符串进行修改，打印出来。<br>#include &lt;iostream&gt;
#include &lt;string&gt;

int main()
{
    std::string str = "Hello!";
    auto capFunc = [newStr = str]() mutable
    {
        std::cout &lt;&lt; "In lambda: " &lt;&lt; newStr &lt;&lt; std::endl;
        if (!(newStr).empty())
        {
            newStr = "Changed!";
            std::cout &lt;&lt; "In lambda: " &lt;&lt; newStr &lt;&lt; std::endl;
        }
    };
    capFunc();
    std::cout &lt;&lt; str &lt;&lt; std::endl;
	return 0;
}
<br>按值拷贝的对象改变并不会影响原来的被拷贝对象。<br>$ ./lambda
In lambda: Hello!
In lambda: Changed!
Hello!
<br>使用&nbsp;mutable&nbsp;关键字的原因是，在生成匿名类时，它会去掉重载运算符后的&nbsp;const&nbsp;限定符，这样我们就可以在&nbsp;lambda&nbsp;中修改按值捕获的变量。如下所示，常方法不允许对类内对象进行修改，所以加入&nbsp;mutable&nbsp;关键字，使得修改按值捕获的副本成为可能。<br>inline /*constexpr */ void operator()() const {} // const by default
<br><br>当我们像下面这样按指针或是用引用捕获时，我们其实不太需要考虑 mutable 了。反而，我们这时应当开始关注指针悬挂或引用悬挂的问题。（按指针捕获可以看作是按值捕获）<br>int i = 5;
std::string str0 = "Hello ";
std::string str1 = "World!";
	// captured by pointer
    auto capFunc = [_i = &amp;i, _str0 = &amp;str0, _str1 = &amp;str1]() 
    {
    // any dereference operations will change original object
    }

    // captured by reference
    auto capFunc = [&amp;_i = i, &amp;_str0 = str0, &amp;_str1 = str1]() 
    {
    // any operations will change original object
    }
<br>由于我们用指针解引用和引用修改源对象的方式实际上修改的是指针指向的值或引用原对象的值，并不会修改匿名类内的对象，所以我们并不需要去添加mutable关键字。然而，我们需要注意，假如lambda返回了相关的指针或是引用，而原对象在使用返回值之前释放掉了，就会引发指针悬挂或引用悬挂的问题。<br><br>除了常见的按值捕获、按引用捕获和按指针捕获，我们还可以在此引入移动语义从而实现按右值捕获。通过 std::move 将 str 转移到 _str ，使得 _str 拥有原 str 的资源（即所有权转移了）。对象的所有权一旦转移，str 就不再可用，想要之后继续用到同一个 string 对象，我们可用返回该对象的引用，甚至返回其右值，转移所有权。<br>#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;utility&gt; // std::move

int main() {
    std::string str = "Hello World!";
    auto capFunc = [_str = std::move(str)]() mutable -&gt; std::string&amp; {
        std::cout &lt;&lt; "In lambda: " &lt;&lt; _str &lt;&lt; std::endl;
        if (!_str.empty()) {
            _str = "Changed!";
            std::cout &lt;&lt; "In lambda: " &lt;&lt; _str &lt;&lt; std::endl;
        }
        return _str;
    };
    std::string&amp; refStr = capFunc();
    // str is moved, thus it's now unusable
    std::cout &lt;&lt; "Original string after move: " &lt;&lt; str &lt;&lt; std::endl;
    // 
    std::cout &lt;&lt; "Original string after move: " &lt;&lt; refStr &lt;&lt; std::endl;
    return 0;
}
<br>同样，我们能这么做是因为 std::string 中对<a data-href="The Rule of Five in C++" href="https://congzhi.wiki/c-plus-plus/the-rule-of-five-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">The Rule of Five in C++</a>有完整的实现。<br><br>当我们在类成员函数中使用 lambda 表达式时，我们可能想要在 lambda 中输出类成员变量的值。如下面代码中所示：<br>#include &lt;iostream&gt;

class myClass {
private:
    int counter{0};
public:
    void printCounter() {
        auto lambda = []() {
            std::cout &lt;&lt; "counter: " &lt;&lt; counter &lt;&lt; std::endl;
        };
        lambda();
    }
};

int main() {
    myClass obj;
    obj.printCounter();
    return 0;
}

<br>因为我们的捕获列表中并没有捕获任何东西，所以编译器会报错。我们学过 this 关键字，知道每个实例化的类都会有一个 this 指针指向实例的数据成员（相当于指向 C-style struct）。由于 this 指针是隐性提供的，所以对 this 的捕获是特殊的。<br>class myClass {
private:
    int counter{0};
public:
    void printCounter() {
        auto lambda = [this](){}; // capture `this` by reference
        auto lambda = [*this](){}; // capture `this` by value(since c++17)
    }
};
<br>我们可以按值捕获或者按引用捕获 this 指针。]]></description><link>https://congzhi.wiki/c-plus-plus/lambdas-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Lambdas in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 04 Mar 2025 08:40:02 GMT</pubDate></item><item><title><![CDATA[Malloc in C (ENG)]]></title><description><![CDATA[ 
 <br><br>In simple terms, malloc() is an abstraction built on system calls like mmap() and brk(). This means you don’t need to worry about the underlying system details. This is what high-level languages have provided such conveniences for us since the 1970s.<br>If you are familiar with how systems allocate memory, you would know that a page (typically 4KB) is the smallest unit that an operating system can process for memory allocation. However, in C, C++, or other high-level languages, you actually can allocate as little as a single byte(in reality, this might round up to 32 bytes). Then there's must be something happened under the hood.<br>For those who aren’t familiar with these system calls or OS memory management, you are encouraged to learn more about mmap() and brk() from <a data-tooltip-position="top" aria-label="6.5 Inter-Process Communications > 4.2.1 `mmap()`" data-href="6.5 Inter-Process Communications#4.2.1 `mmap()`" href="https://congzhi.wiki/congzhi's-os-series/6.5-inter-process-communications.html#4.2.1_`mmap()`" class="internal-link" target="_self" rel="noopener nofollow">here</a> and <a data-tooltip-position="top" aria-label="11. Memory Management > 10.x.2 Dynamic Memory Allocation" data-href="11. Memory Management#10.x.2 Dynamic Memory Allocation" href="https://congzhi.wiki/congzhi's-os-series/11.-memory-management.html#10.x.2_Dynamic_Memory_Allocation" class="internal-link" target="_self" rel="noopener nofollow">here</a>. If you’re entirely new to memory management, feel free to explore my OS series, [Chapter 11](<a data-href="11. Memory Management" href="https://congzhi.wiki/congzhi's-os-series/11.-memory-management.html" class="internal-link" target="_self" rel="noopener nofollow">11. Memory Management</a>).<br><br>At first, let's look at how malloc is originally declared in &lt;stdlib.h&gt;:<br>#include &lt;stdlib.h&gt;
void* malloc(size_t size);
/*
Parameters:
    1. size: The number of bytes to allocate. This specifies the size of the process memory block to be allocated.
   
Return value: 
    - On success: Returns a pointer to the beginning of the allocated memory block. The memory is uninitialized.
    - On failure: Returns NULL, and errno is set to indicate the error.
*/
<br>malloc accepts only one parameter, which specifies the number of bytes to allocate. If the memory chunk allocation succeeds, the function returns a pointer to the beginning of the allocated memory chunk. If the allocation fails, it returns NULL, and then errno is set.<br>Pretty easy, right? But this is only scratching the surface—we want to dig deeper and uncover the inner workings of malloc. In this section, we’ll use the following example to see what’s happening beneath the surface:<br>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
struct linked_chunk{
	int chunk_value;
	struct linked_chunk* next_chunk;
};

int main(){
	struct linked_chunk *chunk1;
    printf("Size of struct linked_chunk is %ld bytes.\n", sizeof(struct linked_chunk));
	chunk1 = malloc(sizeof(struct linked_chunk));
	chunk1 -&gt; chunk_value = 100;
	printf("The address of first chunk is: %p\n", chunk1);
	block1 -&gt; next_block = malloc(sizeof(struct linked_block));
	printf("The address of second chunk is: %p\n", chunk1 -&gt; next_chunk);
	chunk1 -&gt; next_chunk -&gt; chunk_value = 200;
	chunk1 -&gt; next_chunk -&gt; next_chunk = NULL;
    free(chunk1 -&gt; next_chunk);
    free(chunk1);
	return 0;
}
<br>Using this example, we have just allocated memory chunk with malloc. Let's analyze this with the image under below:<br>
<img alt="linked_block.png" src="https://congzhi.wiki/c-plus-plus/pics/linked_block.png"><br>
Outputs:<br>du@DVM:~/cpp$ setarch $(uname -m) -R ./proc
Size of struct linked_chunk is 16 bytes.
The address of first chunk is: 0x5555555596b0
The address of second chunk is: 0x5555555596d0
<br>Notice anything unusual? Our structure is a 16-byte struct, yet there is a 0x10-byte gap (16 bytes) between allocations. Why is that? Because there’s metadata behind the scenes. As said, the OS only allows processes to allocate memory in multiples of the system's page size. However, with malloc metadata, your compiler does a remarkable fine-grained job for you. For example, it allocates a 32-byte memory chunk, and we are going to explore how that happens.<br>Use your GNU debugger, and you will uncover what’s happening in that gap at 0x5555555596c0, which is a total of 16 bytes (system-specific). Within this space, we encounter 0x21, and it is reasonable to deduce that this is where our metadata resides. So, what does 0x21 signify?<br>(gdb) print chunk1
$1 = (struct linked_block *) 0x5555555596b0
(gdb) x/20x 0x5555555596b0
0x5555555596b0: 0x00000064      0x00000000      0x555596d0      0x00005555
0x5555555596c0: 0x00000000      0x00000000      0x00000021      0x00000000
0x5555555596d0: 0x000000c8      0x00000000      0x00000000      0x00000000
0x5555555596e0: 0x00000000      0x00000000      0x00020921      0x00000000
0x5555555596f0: 0x00000000      0x00000000      0x00000000      0x00000000
<br>To be straightforward, the metadata includes how many bytes are allocated and whether that memory chunk is occupied. For example, 0x20 in 0x21 denote the allocated memory size, while 0x1 indicates that this allocated memory is occupied. To free the chunk, simply set the occupied bit to 0x0, and it's all done. Quite straightforward no? (That explained why you only allocate 1 byte but actually allocated 32 bytes of memory)<br>Understanding that, let's now delve into how malloc manages heap memory. Using gdb, we can observe that our heap spans from 0x555555559000 to 0x55555557a000, totaling 0x21000 bytes in size.<br>Mapped address spaces:

Start Addr           End Addr       Size     Offset  Perms  objfile
0x555555559000     0x55555557a000  0x21000    0x0     rw-p   [heap]
<br>0x555555559000: 0x00000000      0x00000000      0x00000291      0x00000000
0x555555559290: 0x00000000      0x00000000      0x00000411      0x00000000
0x5555555596a0: 0x00000000      0x00000000      0x00000021      0x00000000
0x5555555596c0: 0x00000000      0x00000000      0x00000021      0x00000000
0x5555555596e0: 0x00000000      0x00000000      0x00020921      0x00000000
<br>Bit by bit, we can observe how malloc manages heap memory. In total, we have 0x21000 bytes of heap memory (0x290 + 0x410 + 0x20 + 0x20 + 0x20920 = 0x21000). Visually, it looks like this:<br>
<img alt="malloc_map.png" src="https://congzhi.wiki/c-plus-plus/pics/malloc_map.png"><br>
Also in memory mapping segment, you can find this metadata behind the dynamic allocated memory.]]></description><link>https://congzhi.wiki/c-plus-plus/malloc-in-c-(eng).html</link><guid isPermaLink="false">C Plus Plus/Malloc in C (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 21 Mar 2025 08:34:54 GMT</pubDate><enclosure url="https://congzhi.wiki/c-plus-plus/pics/linked_block.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/c-plus-plus/pics/linked_block.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Member Initializer List in C++ (ENG)]]></title><description><![CDATA[ 
 <br>
<br><a data-tooltip-position="top" aria-label="Member Initializer List" data-href="#Member Initializer List" href="https://congzhi.wiki/about:blank#Member_Initializer_List" class="internal-link" target="_self" rel="noopener nofollow">Member Initializer List</a>
<br><a data-tooltip-position="top" aria-label="Curly Brace vs. Parenthesis" data-href="#Curly Brace vs. Parenthesis" href="https://congzhi.wiki/about:blank#Curly_Brace_vs._Parenthesis" class="internal-link" target="_self" rel="noopener nofollow">Curly Brace vs. Parenthesis</a>
<br><a data-tooltip-position="top" aria-label="`std::initializer_list`" data-href="#`std::initializer_list`" href="https://congzhi.wiki/about:blank#`std::initializer_list`" class="internal-link" target="_self" rel="noopener nofollow">`std::initializer_list`</a>
<br><br>There isn't much talk about this member initializer list really. We only use initializer list to initialize a new class object. You may see the member initializer list after a function definition of any kind of constructor, syntax with a colon character : . For example, consider the following:<br>class MyClass{
	int x, y, z;
public:
	// Most commonly used and seen
	MyClass(int _x, int _y, int _z) : x(_x), y(_y), z(_z) {}

	// Brace-enclosed initializer list semantics after C++11
	MyClass(int _x, int _y, int _z) : x{_x}, y{_y}, z{_z} {}
};
<br>But we have to following some rules here to order:<br>
<br>Reference members cannot be bound to temporaries in a member initializer list.
class MyClass{
	const int&amp; ref;
	MyClass() : ref(10) {} // This would cause an error
};


<br>Initialization do follow some orders:

<br>The compiler will initialize the object members in the order they are declared in the class, not the order they appear in the initializer list.

class MyClass {
    int x, y, z;
public:
	// x is still initialized before y and z
    MyClass(int _x, int _y, int _z) : z(_z), y(_y), x(_x) {} 
};


<br>So, when the x is initialized after y or z, or we say y is initialized after z, shit happens:

class MyClass {
    int x, y, z;
public:
	// x is initialized using the uninitialized y
	MyClass(int _x, int _y, int _z) : x(y), y(_y), z(_z) {}
};


<br><br>So, why are you recommended to use {} to initialize an object even though we have ()? Because they have different semantics. An exact example is how they are used in STL container.<br>std::vector&lt;int&gt; v(100, 1);  // Initializes a vector containing 100 items of value 1
std::vector&lt;int&gt; v{100, 1};  // Initializes a vector containing 2 items: 100 and 1

int i(3.14);  // Okay, i will be assigned the value 3 (narrowing conversion)
int i{3.14};  // Error, the assigned value must be type-specific (no narrowing)
<br>Another great thing with curly braces {} is automatically initial everything to zero for basic data types. For example:<br>int a{}; // a is initialized to 0
void* ptr{}; // ptr is initialized to nullptr

class MyClass {
public:
    int a;
    void* ptr;
    MyClass() = default;
};

MyClass obj{}; // All members are initialized to 0 (pointer to nullptr)
<br>But note that if you have a user-defined constructor like this, it can cause undefined behavior:<br>class MyClass {
public:
    int a;
    void* ptr;
    MyClass() {} // Would cause undefined behavior
};

MyClass obj{}; // Not all members are initialized
<br><br>Use initializer list for copy avoidance purposes.<br>#include &lt;iostream&gt;

class MyClass {
public:
    MyClass(int x, int y) {
        std::cout &lt;&lt; "Regular constructor called with " &lt;&lt; x &lt;&lt; " and " &lt;&lt; y &lt;&lt; std::endl;
    }

    MyClass(std::initializer_list&lt;int&gt; list) {
        std::cout &lt;&lt; "Initializer list constructor called with ";
        for (auto elem : list) {
            std::cout &lt;&lt; elem &lt;&lt; " ";
        }
        std::cout &lt;&lt; std::endl;
    }
};

int main() {
    MyClass obj1(100, 200);     // Calls the regular constructor
    MyClass obj2{100, 200};     // Calls the initializer list constructor
	// MyClass obj3{100.5, 200.5}; // No narrowing conversion
    return 0;
}
]]></description><link>https://congzhi.wiki/c-plus-plus/member-initializer-list-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Member Initializer List in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Wed, 26 Feb 2025 04:00:12 GMT</pubDate></item><item><title><![CDATA[Memory Management in C++ (Abandoned)]]></title><description><![CDATA[ 
 <br><br>在 ICS 中，我们学习了可执行目标文件视图的ELF可执行文件。我们了解了堆内存、栈内存、bss段、data段、text段等等的作用。程序运行时总是需要内存的，怎么办呢？我们要使用动态内存分配器，如malloc来让程序载入内存运行时能获取内存。<br>动态内存分配器管理进程虚拟内存的堆内存，在32位机器上，堆内存往往能占到进程虚拟内存的1/2甚至3/4，即2GB-3GB的空间。我们将虚拟内存划分成一个个“块(Blocks)"，这也是内存分配器分配内存的最小单位。通常来说，一个块的大小是512KB或4096KB，和磁盘的最小存储单位相同。<br><br><br>如C语言中的malloc和free，需要手动人工释放已经分配的内存。<br><br>如Java（Garbage Collection）。应用申请内存，释放自动完成。<br><br><br><br>#include &lt;stdlib.h&gt;

void *malloc(size_t size)
<br>当申请成功，返回一个指向申请内存块的的指针，申请的内存以字节为单位。如果 size == 0返回NULL或errno也就是申请失败。<br>在程序启动的时候，glibc库中的malloc会为用户申请一小段堆内存作为内存池。<br><br>参数: ptr: 指向要释放的内存块的指针。如果 ptr 为 NULL，则 free 不执行任何操作。<br>
注意事项:<br>
<br>释放内存后，指针 ptr 变为悬空指针（dangling pointer），应将其设置为 NULL 以避免悬空指针错误。
<br>释放未分配或已释放的内存会导致未定义行为。<br>
示例代码：
<br>#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;

int main() {
    int *p = (int *)malloc(10 * sizeof(int));
    if (p == NULL) {
        printf("Memory allocation failed\n");
        return 1;
    }

    // 使用分配的内存
    for (int i = 0; i &lt; 10; i++) {
        p[i] = i;
    }

    // 释放内存
    free(p);
    p = NULL; // 避免悬空指针

    return 0;
}
<br>这个示例中，malloc 分配了一个包含 10 个 int 类型元素的内存块，使用完后通过 free 释放内存，并将指针 p 设置为 NULL。<br>free怎么知道释放哪些内存空间？这是因为在内存分配时，分配器会在分配的内存块中存储一些额外的信息。这些信息通常包括内存块的大小和其他管理数据。<br><br>new和malloc的区别就是new在申请时会调用构造函数，如：<br>int parr = new int(10);//调用构造函数
int parr = new int;
<br>#include &lt;iostream&gt;
#include &lt;functional&gt;

int (*FuncPtr)(int, int) funcp1;

typedef int (*FuncPtrII)(int, int);
FuntPointerII funcp2;

std::function&lt;int(int,int)&gt; funcp3;
]]></description><link>https://congzhi.wiki/c-plus-plus/memory-management-in-c++-(abandoned).html</link><guid isPermaLink="false">C Plus Plus/Memory Management in C++ (Abandoned).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:57:11 GMT</pubDate></item><item><title><![CDATA[Move Semantics in C++]]></title><description><![CDATA[ 
 <br><br>在 C 中，我们常看到这样的表达式：int i = 10;。这种式子中，变量 i 是有地址属性的，而数字 10 是一个栈中的临时量，它只有值属性。由于 i 这样拥有地址属性的变量总是出现在等号的左边而 10 这种只有值属性的值总是出现在等号右侧。我们就将这种有地址属性在内存中有存储区域的表达式或变量称作左值(lvalue)，而不具有持久存储的值我们称作右值(rvalue)。<br>int i = 1; // okay
int j = i;  // okay
int 1 = j; // error
int k = (i + j); // okay, (i + j) is a rvalue
int (i + j) = k; // error
<br>由于左值有地址属性，所以我们可以对左值取地址，也就是 &amp;i 。<br>int i = 10;
int* pi = &amp;i; // okay
int* pi2 = i + i; // error, (i + i) is a rvalue
<br>除了一些字面量，一般而言，函数的返回值也是典型的右值。<br>int addValue(int a, int b)
{
	return a + b;
}
int main(){
	int i = addValue(3, 4); // okay
	addValue() = 5;     // error
}
<br><br>在我们学习引用的时候，我们说引用是另一个变量的别名。比如我们有以下的程序，在这里，变量 ref 是变量 i 的别名。也就是说，这两个变量共用一个地址空间。而右值没有地址空间，所以左值引用对右值的引用就是非法的。编译器会提示你：cannot bind non-const lvalue reference of type ‘int&amp;’ to an rvalue of type ‘int’。<br>int i = 10;
int&amp; lvref = i; // okay
int&amp; lvref = 10;// error, lvalue ref only bind to the lvalue
<br>我们并不能给没有地址的右值起一个别名。但为什么下面的程序就是可以合法的？<br>int main{
	const int&amp; lvref = 10;
	// as same as:
	const int temp = 10;
	const int&amp; lvref = temp;
}
<br>这是由于编译器会隐式地生成一个临时对象来存储右值，这被称为 temporary materialization 。所以实际上我们创建的仍然是对 10(temp) 的左值引用。当然，这种方式只是 C++11 之前右值引用没有出现时 C++ 绑定右值的方式。<br>我们从汇编也能窥见一二。<br>main:

        push    rbp
        mov     rbp, rsp
        mov     dword ptr [rbp - 4], 0
        
		; const int&amp; ref = 10;
        mov     dword ptr [rbp - 20], 10
        lea     rax, [rbp - 20]
        mov     qword ptr [rbp - 16], rax
		
		; const int temp = 10;
		; const int&amp; ref = temp;
        mov     dword ptr [rbp - 24], 10
        lea     rax, [rbp - 24]
        mov     qword ptr [rbp - 32], rax

        xor     eax, eax
        pop     rbp
        ret
<br>在左值引用中，我们最常见的用法就是用左值引用替换掉传统用指针传参的做法。引用和指针汇编后是一样的，但是指针我们需要取地址解引用。而引用完全不需要，你可以把引用理解成一种用户友好化的指针。<br>#include &lt;iostream&gt;

void printVal(int&amp; val) {
    std::cout &lt;&lt; val &lt;&lt; std::endl;
}
int main() {
    int x = 1;
    printVal(x);
    printVal(20); // cannot bind non-const lvalue reference to an rvalue
}
<br>同样的，在传递右值（20）的时候，你也需要用 const int&amp; 绑定右值参数。这时，编译器会生成一个临时的 const int 左值对象，并将其绑定到 val 上。<br>#include &lt;iostream&gt;

void printVal(const int&amp; val) {
    std::cout &lt;&lt; val &lt;&lt; std::endl;
}
int main() {
    int x = 1;
    printVal(x); // ok
    printVal(20);// ok
}
<br>此外，我们还可以将函数的返回值变成左值引用类型。比如我们有一个 access_Val ，这样，函数返回引用就会使 int&amp; access_Val() 的返回值变为一个左值引用。在类中，我们可以用这种方式来 set 或 get 类内变量：<br>#include &lt;iostream&gt;

class example{
	int val;
public:
	int&amp; access_Val(){
		return val;
	}
};
int main(){
	example e1;
	e1.access_Val() = 10;
    std::cout &lt;&lt; e1.access_Val() &lt;&lt; std::endl;
	return 0;
}
<br>通过这种方式，我们实际上让 accessVal() 变成数据双向流向的函数。还可以避免不必要的拷贝。这样，我们可以直接操作类中的成员变量，并且在需要时进行赋值和获取，所有这些操作都避免了不必要的拷贝操作，提高了性能和效率。<br><br>在前面，我们发现类似这样的语句是非法的：int&amp; rvref = 10;。编译器会告诉你cannot bind non-const lvalue reference of type ‘int&amp;’ to an rvalue of type ‘int’。因为左值引用所引用的对象是一个右值，而左值引用是不能绑定到右值的。<br>而且我们注意到加上 const 实际上绑定的实际上还是左值。为了实现对右值的绑定，C++11 引入了右值引用 &amp;&amp; 。右值引用只能绑定右值，而不能绑定左值：<br>int&amp;&amp; rvref = 10;

int i = 10;
int&amp;&amp; rvref = i; // cannot bind rvalue reference of type to lvalue
<br>当我们试图去打印 rvref 时，我们可以得到期望的结果。但为什么要这样做？<br>#include &lt;iostream&gt;

int main(){
	int&amp;&amp; rvref = 10; // difference from `int i = 10;` ?
	int i = rvref;
	std::cout &lt;&lt; rvref &lt;&lt; std::endl; // prints out the integer 10
	std::cout &lt;&lt; &amp;rcref &lt;&lt; std:endl; // okay
	std::cout &lt;&lt; &amp;i &lt;&lt; std:endl;     // okay
	return 0;
}
<br>接着之前的例子：<br>#include &lt;iostream&gt;

// lvalue ref copy
void printVal(const int&amp; lval) {
    std::cout &lt;&lt; lval &lt;&lt; std::endl;
}
// rvalue ref no copy
void printVal(int&amp;&amp; rval) {
    std::cout &lt;&lt; rval &lt;&lt; std::endl;
}
// thus, this is not allowed with whose overloading above:
// void printVal(int val){
//
// } // not allowed
int main() {
    int x = 1;
    printVal(x); // ok, call printVal(const int&amp; lval)
    printVal(20);// ok, call printVal(int&amp;&amp; rval)
}
<br>有了因为右值引用绑定右值，所以当我们在函数里面传递的是右值时，它会调用右值引用的重载函数。我们后面会看到，使用右值引用可以减少不必要的内存拷贝的次数。当对象很大的时候，使用右值引用就可以显著优化资源管理和执行效率。<br><br>移动语义是C++11引入的一项特性，右值或右值引用是其最主要的应用。它允许对象的资源（如堆上分配的内存）在不进行深度复制的情况下进行所有权的转移。可以将对象的资源所有权从一个对象转移到另一个对象，从而避免不必要的内存拷贝，提高程序性能和效率。<br>假如我们有如下程序：<br>#inlcude &lt;vector&gt;
int main(){
	std::vector&lt;int&gt; v1{ 1, 2, 3, 4, 5 }; 
	std::vector&lt;int&gt; v2{}; 
	v2 = v1;
	return 0;
}
<br>在进行拷贝操作时，标准库容器会进行深拷贝，这就意味着v2会拥有v1的所有资源的拷贝。<br><img alt="Pasted image 20250111194242.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20250111194242.png"><br>虽然深拷贝可以避免数据的不一致性，但通常会涉及大量的内存操作，进而造成一定的存储和性能开销。而移动语义通过移动构造函数和移动赋值运算符，可以将资源“移动”到新对象中，而不是复制，从而减少了开销。<br><br>std::move 是 C++11 引入的一个标准库函数，std::move()并不移动任何东西。而是将其输入无条件地转换为右值引用（rvalue reference）。这意味着无论传递给 std::move 的是什么类型的对象，它都会被转换为右值引用，从而允许移动语义的应用。<br>template&lt;typename _Tp&gt;
    _GLIBCXX_NODISCARD
    constexpr typename std::remove_reference&lt;_Tp&gt;::type&amp;&amp;
    move(_Tp&amp;&amp; __t) noexcept
    { return static_cast&lt;typename std::remove_reference&lt;_Tp&gt;::type&amp;&amp;&gt;(__t); }
<br>为了避免额外的复制开销，C++ 引入了移动语义。在 STL 标准容器库中，移动赋值运算符已经在类内进行了重载、移动构造函数也进行了实现。确保等号的右边是右值的时候可以进行移动赋值。<br>假如我们有如下程序：<br>#inlcude &lt;vector&gt;
int main(){
	std::vector&lt;int&gt; v1{ 1, 2, 3, 4, 5 }; 
	std::vector&lt;int&gt; v2{}; 
	v2 = std::move(v1);
	return 0;
}
<br>这个例子中，我们用std::move()将v1的资源移动到v2，避免了深拷贝。这个过程图示如下：<br>
<br>
v2将v1所持有的资源进行引用：<br>
<img alt="Pasted image 20250111204014.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20250111204014.png">

<br>
所有权进行转移，v1不再持有资源，进而重置v1：<br>
<img alt="Pasted image 20250111204033.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20250111204033.png">

<br>通过std::move()，资源从v1转移到v2，v1不再持有这些资源。移动后的v1处于有效但未定义的状态，不再持有原资源。对于程序员而言，我们需要承诺在所有权转移后不再使用v1。<br><br>移动语义出现之后，我们想实践对象所有权的转移，我们需要两个特别的新函数：移动构造函数和移动赋值运算符(move constructor and move assignment operator)。从下面的代码中，你可以窥见所有权的转移是怎么样的。<br>#include &lt;string&gt;
class Widget {
private:
    int i{0};
    std::string s{};
    int* pi{nullptr}; // with unique opinter, you can make move constructor defalut
public:
    Widget(Widget&amp;&amp; w) noexcept
        : i(std::move(w.i)), s(std::move(w.s)), pi(std::move(w.pi)) // member-wise move
    {
        w.pi = nullptr; // Reset
    }
    Widget&amp; operator=(Widget&amp;&amp; w) noexcept {
        if (this != &amp;w) {
            delete pi; // Clean-up
            i = std::move(w.i); // Member-wise move
            s = std::move(w.s); // Member-wise move
            pi = std::move(w.pi); // Member-wise move
            w.pi = nullptr; // Reset
        }
        return *this;
    }
};
/*
#include &lt;string&gt;
#include &lt;memory&gt;

class Widget {
private: 
    int i{0};
    std::string s{};
    std::unique_ptr&lt;int&gt; pi{nullptr};
public:
    Widget(Widget&amp;&amp; w) = default; // noexcept by default
    Widget&amp; operator=(Widget&amp;&amp; w) = default; // noexcept by default
};
*/
<br>为了避免不必要的拷贝操作，“五法则”成为了 class designing 的最佳实践。然而，随着 C++11 引入了移动语义和智能指针等特性，“零法则”逐渐成为一种更理想的设计哲学。<br>“零法则”提倡不要手动定义任何特殊成员函数，而是依赖于编译器生成的默认实现。通过组合已有的类和资源管理器（例如 std::unique_ptr 和 std::shared_ptr），我们可以在需要时自动拥有正确的拷贝或移动行为。<br>// The Rule of Zero
#include &lt;memory&gt;

class myClass {
private:
    std::unique_ptr&lt;int&gt; data;
public:
    myClass() = default;
    ~myClass() = default;
    // No declaration of copy/move constructor or copy/move assignment operator
};

<br><br>例如，考虑一个简单的类 MyString，它包含一个指向字符数组的指针。在使用移动构造函数时，新的 MyString 对象会接管原对象的指针，而原对象的指针会被置为空指针，这样在销毁原对象时就不会重复释放内存。<br>#include &lt;iostream&gt;
#include &lt;string.h&gt;

class String{
private:
   char* m_Data;
   uint32_t m_Size;
public:
    String() = default;
    String(const char* string){
        m_Size = strlen(string);
        m_Data = new char[m_Size];
        memcpy(m_Data, string, m_Size);
        std::cout &lt;&lt; "String created!" &lt;&lt; std::endl;
    }
    String(const String&amp; other){
        m_Size = other.m_Size;
        m_Data = new char[m_Size];
        memcpy(m_Data, other.m_Data, m_Size);
        std::cout &lt;&lt; "String copied!" &lt;&lt; std::endl;
    }
    String(String&amp;&amp; other) noexcept{
        m_Size = other.m_Size;
        m_Data = other.m_Data;
        other.m_Size = 0;
        other.m_Data = nullptr;
        std::cout &lt;&lt; "String Moved!" &lt;&lt; std::endl;
    }
    ~String(){
        delete m_Data;
        std::cout &lt;&lt; "String destroyed!" &lt;&lt; std::endl;
    }
    void Print(){
        for (uint32_t i = 0; i &lt; m_Size; i++)
        {
            printf("%c", m_Data[i]);
        }
    }
};
class Entity{
private:
    String s_Name;
public:
    Entity(const String&amp; name) : s_Name(name){}
    Entity(String&amp;&amp; name) : s_Name((String&amp;&amp;)name){}

    void printName(){
        s_Name.Print();
    }
};

int main(){

    Entity entity("Hello\n");
    entity.printName();
    std::cin.get();
    return 0;
}
<br>在这个例子中，MyString 的移动构造函数通过 std::move 将资源从一个对象转移到另一个对象，从而避免了不必要的复制操作。]]></description><link>https://congzhi.wiki/c-plus-plus/move-semantics-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Move Semantics in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Mon, 24 Mar 2025 09:44:16 GMT</pubDate><enclosure url="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20250111194242.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/c-plus-plus/pics/pasted-image-20250111194242.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mutable and The M&M Rule in C++ (ENG)]]></title><description><![CDATA[ 
 <br>Do this at first: <a data-href="Const in C++" href="https://congzhi.wiki/c-plus-plus/const-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Const in C++</a><br><br>The mutable specifier allows a member to be modified in a const member function. In the example below, we qualify a function with const, which means we are not supposed to change the class members in the function. However, we do modify the mutable count member within the function scope.<br>class myClass{
private:
	int variable = 0;
	mutable int count;
public:
	int getVar() const{
	    count++;
	    return variable;
    }
};
int main(){
    myClass obj;
    int value = obj.getVar();
    return 0;
}
<br>"Const as a promise", using mutable specifier can break the constness of a function, which can be seen as poor code design. The principal of "const as a promise" implies that a const member function should not modify any member variables. But mutable is an exception to this rule, which can lead to unexcepted behavior.<br>However, mutable could be useful in some situations like mutexes for safer code(the M&amp;M rule), cache memory, and lazy evaluation.<br><br>This code example is copied from  <a data-tooltip-position="top" aria-label="https://en.cppreference.com/w/cpp/language/cv" rel="noopener nofollow" class="external-link" href="https://en.cppreference.com/w/cpp/language/cv" target="_blank">cppreference</a>. As you can see, we have a const get() function, and with std::mutex, we create safe concurrent code. Why is that? While we are not supposed to modify anything in the const specified functions, with mutable, another thread can actually modify the data in a const specified function. This is no thread-safe.<br>class ThreadsafeCounter
{
    mutable std::mutex m; // The "M&amp;M rule": mutable and mutex go together
    int data = 0;
public:
    int get() const
    {
        std::lock_guard&lt;std::mutex&gt; lk(m);
        return data;
    }
 
    void inc()
    {
        std::lock_guard&lt;std::mutex&gt; lk(m);
        ++data;
    }
};
<br>For achieving the goal of safer code and const correctness at the same time, we have to use the mutable keyword to make the mutex mutable in the const function. While a thread is modifying the critical section, using a lock to prevent other threads from entering and accessing the resource is thus necessary.]]></description><link>https://congzhi.wiki/c-plus-plus/mutable-and-the-m&amp;m-rule-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Mutable and The M&amp;M Rule in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Mon, 17 Mar 2025 05:52:20 GMT</pubDate></item><item><title><![CDATA[Namespaces in C++ (ENG)]]></title><description><![CDATA[ 
 <br><br><br>People have family names to help distinguish individuals who have the exact same first name. This is a worldwide practice, no matter where you live. In C++, we do the same thing. We create specific namespaces to avoid name conflicts.<br><br>To the most of us, the very first encounter with namespace in C++ would be likely using namespace std; as shown in the example below:<br>#include &lt;iostream&gt;
using namespace std;

int main(){
	cout &lt;&lt; "Hello world!" &lt;&lt; endl;
	return 0;
}
<br>Using using namespace std; globally allows us to avoid repeatedly typing the std:: prefix. However, this practice can be harmful when handling large projects. Why?<br><br>As we just discussed, namespaces in C++ help us avoid name conflicts. Imagine this scenario: you're using multiple libraries that define functions with the same name. When you call these functions, how can the compiler (or linker) know which function to use? Just like if there are two people named Henry in your class, you don't just call out "Henry" because both might respond.<br>Since this would cause a loading error, we must have some mechanism to solve this problem. In C++, this mechanism is the namespace. It's like giving a function a name suffix. Let me give an easy example:<br>int sum(int a, int b) {
    return a + b;
}
namespace congzhi{ // namespace definition
    int sum(int a, int b) {
    // Do something else...
        return a + b;
    }
}
int main() {
    sum(1, 2);
    {
		using namespace congzhi;
		sum(1,2); // call congzhi::sum(1,2);
    }
//  congzhi::sum(1,2); // Same
    return 0;
}
<br>Let's say we use a math library that has a sum() function, but we would like our own sum() function to do something else inside the function scope. What we do is add a suffix name to the function using a namespace.<br>After compiling, you would see the difference: the congzhi namespace is actually added before the function name, resulting in _ZN7congzhi3sumEii, exactly like a suffix name or family name if you will.<br>_Z3sumii:
	pushq	%rbp
	movq	%rsp, %rbp
	movl	%edi, -4(%rbp)
	movl	%esi, -8(%rbp)
	movl	-4(%rbp), %edx
	movl	-8(%rbp), %eax
	addl	%edx, %eax
	popq	%rbp
	ret
_ZN7congzhi3sumEii:
	pushq	%rbp
	movq	%rsp, %rbp
	movl	%edi, -4(%rbp)
	movl	%esi, -8(%rbp)
	movl	-4(%rbp), %edx
	movl	-8(%rbp), %eax
	addl	%edx, %eax
	popq	%rbp
	ret
main:
	pushq	%rbp
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	movl	$2, %esi
	movl	$1, %edi
	call	_Z3sumii
	movl	$2, %esi
	movl	$1, %edi
	call	_ZN7congzhi3sumEii
	movl	$0, %eax
	popq	%rbp
	ret
<br>By the way, :: is called the scope resolution operator in C++, and it is used to specify which namespace or class a particular function or variable belongs to. The :: operator is also used to refer to the global namespace. As in:<br>int func(){ // global function
}
int var; // global variable

int main(){
	::var = 10; // equals to var = 10;
	::func(); // equals to func();
}
<br><br>Just like namespaces, classes can also play a similar role in C++. By defining member functions within a class, you can ensure that functions with the same name do not conflict with each other.<br>class MathLib {
public:
    int sum(int a, int b) {
        return a + b;
    }
    inline static int i = 0;
};

int main() {
    MathLib math;
    int result1 = math.sum(1, 2); // Calls MathLib::sum
    MathLib::i = 5; // Accesses static variable i
    return 0;
}
<br>Differently, unlike namespaces, classes provide encapsulation for member variables and member functions. This is something you cannot achieve with namespaces. That's why in most large projects, we use this pattern:<br>namespace congzhi{
	class MathLib{};
	class GraphLib{};
	class IOLib{};
}
<br>Thus we can group those related functionalities and avoid name conflicts.<br><br>Nested namespaces are not recommended in good design in most cases. We use namespaces primarily to distinguish different libraries. For example, std is used for the C++ standard library, and sdl is used for the SDL library. However, if you wish, you can add suffixes to function names as much as you like.<br>You simply use nested namespaces like this:<br>// nested namespaces
namespace A{ // Equals to: namespace A::B::C{ }
	namespace B{
		namespace C{
			exampleFunc(){
				// ...
			}
			// Some functions here...
		}
	}
}
int main(){
	{ // using derectives
		using namespace A::B::C;
		exampleFunc();
	} // A using namespace scope with life time
	A::B::C::exampleFunc(); // Same
	return 0;
}
<br><br>No denying, using the using namespace directive can be convenient. However, it can also bring issues that are not easy to identify, especially as the project grows larger.<br>// lib.hpp
namespace A{
	int sum(int a, int b){ // A::sum()
		return a + b;
	}
}
namespace B{
	int sum(int a, int b){ // B::sum()
		return a + b;
	}
}
<br>// main.cpp
#include "lib.hpp"
using namespace A; // gloabl namespace
using namespace B; // global namespace in another file
int main(){

	sum(1, 2); // which sum() would it call?
}
<br>In this simple example, try to guess which function it would call. You might think, "Well, I could just use the scope resolution operator B:: in this case, right?" But in a large project built by a team of people, this sum() call becomes ambiguous. Which one does it call? Even the compiler won't know, leading to compilation errors and potential big problems in the future.<br>Warning!!!
NEVER EVER WRITE using namespace AT GLOABL SCOPE IN A HEADER FILE
<br>So a good practice is as follows:<br>// main.cpp
#include "lib.hpp"

// No global namespace directives are allowed.

int function_using_lib_a(int a, int b) {
    using namespace A;
    return sum(a, b); // Calls A::sum
}
int main() {
    function_using_lib_a(1, 2);
    { // Samll scope
        using namespace B;
        sum(1, 2); // Calls B::sum
    }
    
    // Or like this:
    B::sum(1, 2); // Calls B::sum, even cleaner...
    return 0;
}
<br>Make the scope of using namespace as small as possible, or try not to use it at all.<br><br><br>Remember we had a example look like this? Every time we wanted to use exampleFunc(), we had to add the long suffix A::B::C::, this can be annoying. So, we can use namespace alias to define a alternate name for a namespace.<br>// nested namespaces
namespace A{ // Equals to: namespace A::B::C{ }
	namespace B{
		namespace C{
			exampleFunc(){
				// ...
			}
			// Some functions here...
		}
	}
}

namespace ABC = A::B::C; // namespace alias

int main(){
	A::B::C::exampleFunc();
	ABC::exampleFunc(); // Same
	return 0;
}
]]></description><link>https://congzhi.wiki/c-plus-plus/namespaces-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Namespaces in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 21 Feb 2025 02:13:06 GMT</pubDate></item><item><title><![CDATA[Networking - CS model]]></title><description><![CDATA[ 
 <br>在 Computer Networking: A Top-Down Approach 课程中，我们学习了数据是如何从 application layer 经由 transport layer 和 network layer 的两层封装，将数据传送到另一台主机上的特定端口号进程上的。在这个过程中，底层的网络如同一道道传送门，我们开发人员是不需要知道其中的实现细节的。当我们要将数据传送给另一台主机上的 application layer 进程时。我们只需要告诉网络目标主机的IP地址和端口号就能够使用网络进行数据的传输了。<br><br>在TCP实现的C/S原型模型中，我们实现的功能极为简单：服务器进程一直检测来自客户端进程的连接，一旦检测到有客户端“敲门”，就创建客户端Socket并给客户端发送"hello world"字符串，然后客户端回发，服务器显示。<br>//server
#include &lt;iostream&gt;
#include &lt;WinSock2.h&gt;	//声明
#include &lt;WS2tcpip.h&gt;
#include &lt;thread&gt;
#include &lt;chrono&gt;       //时间头函数
#pragma comment(lib, "ws2_32.lib")	//实现

const u_int BACKLOG = 128;
u_int link_count = 0;
const char* msg = "hello world";

//若当前socket连接数量小于BACKLOG，则每隔一秒打印一次打印监听信息。
void printListeningStatus() {
    while (link_count &lt; BACKLOG) {
        std::cout &lt;&lt; "Server is listening on port 2345...\tWe now can connect " 
                  &lt;&lt;BACKLOG - link_count&lt;&lt;" hosts." &lt;&lt; std::endl;
        std::this_thread::sleep_for(std::chrono::seconds(2));
    }
}
//管理客户端进程
int clientHandle(SOCKET* servSock, SOCKET*clntSock) {

    // 打印客户端信息
    link_count++;
    sockaddr_in clntAddr;
    int clntAddrSize = sizeof(clntAddr);
    getpeername(*clntSock, (sockaddr*)&amp;clntAddr, &amp;clntAddrSize);
    char clntIP[INET_ADDRSTRLEN];
    inet_ntop(AF_INET, &amp;clntAddr.sin_addr, clntIP, INET_ADDRSTRLEN);
    std::cout &lt;&lt; "Client connected from IP: " &lt;&lt; clntIP &lt;&lt; " and port: " 
              &lt;&lt; ntohs(clntAddr.sin_port) &lt;&lt; std::endl;
    
    //处理与client的会话
    char recvBuf[128]{};
    if (send(*clntSock, msg, strlen(msg), 0) == -1) {
        std::cout &lt;&lt; "Sending fail!\tError number is:" &lt;&lt; WSAGetLastError() &lt;&lt; std::endl;
        closesocket(*servSock);
        closesocket(*clntSock);
        WSACleanup();
        return -1;
    }
    int recvRet = recv(*clntSock, recvBuf, 128, 0);
    if (recvRet == 0) {
        std::cout &lt;&lt; "Client drop the connection gracefully." &lt;&lt; std::endl;
    }
    else if (recvRet &lt; 0) {
        int ErrNum = WSAGetLastError();
        if (ErrNum == 10054) {
            std::cout &lt;&lt; "Client drop the connection forcefully." &lt;&lt; std::endl;
        }
        else {
            std::cout &lt;&lt; "Receiving fail!\tError number is:" &lt;&lt; ErrNum &lt;&lt; std::endl;
            closesocket(*servSock);
            closesocket(*clntSock);
            WSACleanup();
            return -1;
        }
    }
    std::cout &lt;&lt; recvBuf &lt;&lt; std::endl;
    closesocket(*clntSock);
    link_count--;
    std::cout &lt;&lt; "Client from IP: " &lt;&lt; clntIP &lt;&lt; " Port:" &lt;&lt; ntohs(clntAddr.sin_port) 
              &lt;&lt;" has been disconnected."&lt;&lt; std::endl;
    return 0;
}
int main() {
    //初始化WSADATA结构。
    WSADATA data{};
    if (WSAStartup(MAKEWORD(2, 2), &amp;data) == SOCKET_ERROR) {
        std::cout &lt;&lt; "WSAStart failed! \tError number is:" &lt;&lt; WSAGetLastError() &lt;&lt; std::endl;
        WSACleanup();
        return -1;
    }
    //为服务器进程创建用于TCP/IP通信的套接字。
    SOCKET servSock = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);
    if (servSock == INVALID_SOCKET) {
        std::cout &lt;&lt; "Server socket creation fail!\tError number is:" &lt;&lt; WSAGetLastError() &lt;&lt; std::endl;
        WSACleanup();
        return -1;
    }
    /*定义一个sockaddr_in(Socket address internet)的结构体变量用来存储IP地址、端口号信息。
    之后将进程的“地址信息”一律转换成网络字节序（大端序）。*/
    sockaddr_in servAddr;
    servAddr.sin_family = AF_INET;      //设置地址族为IPv4
    servAddr.sin_port = htons(2345);	//将port号转换成网络字节序
    inet_pton(AF_INET, "127.0.0.1", &amp;servAddr.sin_addr.S_un.S_addr);//将IP地址转换成网络字节序

    //将服务器进程和特定的端口号进行绑定
    if (bind(servSock, (sockaddr*)&amp;servAddr, sizeof(sockAddr)) == SOCKET_ERROR) {
        std::cout &lt;&lt; "Binding fail!\tError number is:" &lt;&lt; WSAGetLastError() &lt;&lt; std::endl;
        closesocket(servSock);
        WSACleanup();
        return -1;
    }

    //服务器socket状态从closed转换成listening。
    if (listen(servSock, BACKLOG) == -1) {
        std::cout &lt;&lt; "Listen function fail!\tError number is:" &lt;&lt; WSAGetLastError() &lt;&lt; std::endl;
        closesocket(servSock);
        WSACleanup();
        return -1;
    }

    // 启动一个线程来打印监听状态
    std::thread statusThread(printListeningStatus);

    //当有client进程“敲门”，服务器进程就创建一个client socket线程来与客户端进程进行通信。
    while(link_count &lt; BACKLOG){
        SOCKET clntSock = accept(servSock, nullptr, nullptr);
        if (clntSock == INVALID_SOCKET) {
            std::cout &lt;&lt; "Client socket creation fail!\tError number is:" &lt;&lt; WSAGetLastError() &lt;&lt; std::endl;
            closesocket(servSock);
            WSACleanup();
            return -1;
        }
        // 创建一个线程来处理客户端通信
        std::thread clientThread(clientHandle, &amp;servSock, &amp;clntSock);
        //分离线程，让线程单独执行
        clientThread.detach();
    }

    // 等待线程结束
    statusThread.join(); 
    
    closesocket(servSock);

    WSACleanup();

    system("pause");
    return 0;
}
<br>// client
#include &lt;WinSock2.h&gt;
#include &lt;WS2tcpip.h&gt;
#include &lt;iostream&gt;
#pragma comment(lib, "ws2_32.lib")

int main() {
    // 初始化 WSADATA 结构。
    WSADATA data{};
    if (WSAStartup(MAKEWORD(2, 2), &amp;data) == SOCKET_ERROR) {
        std::cout &lt;&lt; "WSAStartup failed! \tError number is:" &lt;&lt; WSAGetLastError() &lt;&lt; std::endl;
        return -1;
    }

    // 为客户端进程创建用于 TCP/IP 通信的套接字。
    SOCKET servSock = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);
    if (servSock == INVALID_SOCKET) {
        std::cout &lt;&lt; "Client socket creation failed!\tError number is:" &lt;&lt; WSAGetLastError() &lt;&lt; std::endl;
        WSACleanup();
        return -1;
    }

    // 定义一个 sockaddr_in 结构体变量用来存储服务器的 IP 地址和端口号信息。
    sockaddr_in servAddr;
    servAddr.sin_family = AF_INET;      // 设置地址族为 IPv4
    servAddr.sin_port = htons(2345);    // 将端口号转换成网络字节序
    inet_pton(AF_INET, "127.0.0.1", &amp;servAddr.sin_addr.S_un.S_addr); // 将 IP 地址转换成网络字节序

    // 连接到服务器
    if (connect(servSock, (sockaddr*)&amp;servAddr, sizeof(servAddr)) == SOCKET_ERROR) {
        std::cout &lt;&lt; "Connection failed!\tError number is:" &lt;&lt; WSAGetLastError() &lt;&lt; std::endl;
        closesocket(servSock);
        WSACleanup();
        return -1;
    }

    // 接收服务器发送的数据
    char recvBuf[128]{};
    int recvRet = recv(servSock, recvBuf, 128, 0);
    if (recvRet == 0) {
        std::cout &lt;&lt; "Server dropped the connection gracefully." &lt;&lt; std::endl;
    }
    else if (recvRet &lt; 0) {
        int ErrNum = WSAGetLastError();
        if (ErrNum == 10054) {
            std::cout &lt;&lt; "Server dropped the connection forcefully." &lt;&lt; std::endl;
        }
        else {
            std::cout &lt;&lt; "Receiving failed!\tError number is:" &lt;&lt; ErrNum &lt;&lt; std::endl;
            closesocket(servSock);
            WSACleanup();
            return -1;
        }
    }

    // 发送数据到服务器
    if (send(servSock, recvBuf, recvRet, 0) == SOCKET_ERROR) {
        std::cout &lt;&lt; "Sending failed!\tError number is:" &lt;&lt; WSAGetLastError() &lt;&lt; std::endl;
        closesocket(servSock);
        WSACleanup();
        return -1;
    }

    closesocket(servSock);
    WSACleanup();
    system("pause");
    return 0;
}
<br><br>
void fileDirMnagr::listDir(int depth = 0)
{
	DIR *dir = opendir(currDir.c_str());
	if (!dir)
	{
		formattedMesg == "Cannot open " + currDir + ".\n";
		perror("Fail to open directory");
		return;
	}
	dirent *pDirent = nullptr;
	while ((pDirent = readdir(dir)) != nullptr)
	{
		const std::string filename = pDirent-&gt;d_name;
		if (filename == "." || filename == "..")
		{
			continue;
		}
		for (int i = 0; i &lt; depth; ++i)
		{
			formattedMesg += "    ";
		}
		formattedMesg += "|---" + filename;
		if (pDirent-&gt;d_type == DT_DIR)
		{
			formattedMesg += "/\n";
			std::string previousDir = currDir;
			currDir = currDir + "/" + filename;
			listDir(depth + 1);
			currDir = previousDir;
		}
		else
		{
			formattedMesg += "\n";
		}
	}
	if (closedir(dir) != 0)
	{
		perror("Fail to close directory");
	}
}

]]></description><link>https://congzhi.wiki/c-plus-plus/networking-cs-model.html</link><guid isPermaLink="false">C Plus Plus/Networking - CS model.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:57:20 GMT</pubDate></item><item><title><![CDATA[Noexcept in C++ (ENG)]]></title><description><![CDATA[ 
 <br><br>I believe most of us will question what noexpct keyword does when we start learning "the rule of five". The move constructor and the move assignment operator often have a specifier noexcept, what for? Why do we always need to make the move constructor noexcept?<br>class myClass{
private:
	// data members
public:
	myClass(){}
	~myClass(){}
	myClass(const myClass&amp; obj){} // Copy constructor
	myClass&amp; operator=(const myClass&amp; obj){} // Copy assignment operator
	myClass(myClass&amp;&amp; obj) noexcept {} // Move constructor
	myClass&amp; operator=(myClass&amp;&amp; obj) noexcept {} // Move assignment operator
};
<br>If you go to the reference, you will get a simple answer. It's for two purposes: one is for the compiler to generate better code, and the other is for better readability for the user. Every function in C++ is either&nbsp;non-throwing&nbsp;or&nbsp;potentially throwing, and you could specify them explicitly:<br>void funcA() noexcept {} // non-throwing, which means the function guarantees that it won't throw any exceptions
void funcB() noexcept(true) {} // non-throwing, more explicitly stating that the function guarantees it won't throw any exceptions

void funcA() {} // potentially throwing, meaning the function might throw exceptions
void funcB() noexcept(false) {} // potentially throwing, explicitly stating that the function might throw exceptions
<br>You see, every time you specify noexcept(noexcept(true)) , you are simply telling the compiler that the function will not throw errors at run-time, so that the compiler will do its best to optimize the code. Additionally, users can immediately understand that the function will not throw errors by seeing noexcept.<br>noexcept is a promise to the compiler and the runtime that the function will not throw exceptions, and breaking this promise will lead to program termination.<br>The noexcept specifier doesn't make the compiler check for potential exceptions at compile-time. It simply means that if an exception occurs within a function marked noexcept, the program will call std::terminate and terminate abruptly since the promise is broken. <br><br>Then back to our question, why do we need a noexcept with the move constructor? The real reason lies in STL containers. Functions marked with noexcept can enable move semantics, while without noexcept, they fallback to copy operations.<br>Normally, during a move operation, there should only be ownership transfers (just pointer evaluations). So you cannot really have anything fail happening there.<br>Is this a must? Well, it's not a must. If you call some potentially throwing function inside a noexcept specified function, there would be an error. It's easy to understand because you break the promise. Here’s an example illustrating a bad practice:<br>#include &lt;utility&gt;
class myClass {
private:
    // data members
public:
    // other member functions
    void throwing() {
        throw 20;
    } // not marked as noexcept
    myClass(){}
    myClass(myClass&amp;&amp; obj) noexcept(true) {
        // data moves
        throwing();
    } // this would be an error because the throwing function is not noexcept
};
int main(){

    myClass obj;
    myClass obj2(std::move(obj)); // throw an exception
    return 0;
}
]]></description><link>https://congzhi.wiki/c-plus-plus/noexcept-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Noexcept in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sun, 09 Mar 2025 08:47:56 GMT</pubDate></item><item><title><![CDATA[Object Oriented Programming in C++]]></title><description><![CDATA[ 
 <br><br>在课堂中，我们学过 OOP 的三大特征，即封装、继承和多态。但时过境迁，OOP 的编程范式随着各种新技术的出现而不断更新。在这个文档中，我们会概述现代的 OOP 编程(A best practice)。<br><br>
Separation from interface and implementation.
<br><br>我们先从最基本的封装性谈起。C++&nbsp;用 “类类型&nbsp;(class&nbsp;types)” 来对数据进行封装。封装很好理解，即将类内成员变量和函数与外界分开。不像在&nbsp;C&nbsp;语言中，函数的实现光溜溜地暴露在全局范围&nbsp; (global&nbsp;scope)&nbsp;。在&nbsp;C++&nbsp;中，我们可以用类类型将这些函数的实现封装起来，只暴露使用的接口。<br>C++提供三种类类型：class、struct、union，而只有前两者提供对数据的有效封装性，我们忽略union类型。<br><br>
Don’t inherit for code reuse. Inherit, when you want to express a logical structure.
<br><br>继承是对一个类的继承。当我们继承一个类得到新的类时，我们需要明白，在不同的继承访问控制修饰符下，成员变量的可见性和访问权限是怎么样的。<br>class Account{
public:
  int pub{0};
protected:
  int prot{0};
private:
  int pri{0};
};
class PubAccount: public Account{
public:
  PubAccount(){
    pub + prot;  // public + protected
  }
};
class ProtAccount: protected Account{
public:
  ProtAccount(){
    pub + prot;  // protected + protected
  }
};
class PriAccount: private Account{
public:
  PriAccount(){
    pub + prot;  // private + private
  }
};

int main(){
  PubAccount pubAccount;
  ProtAccount proAccount;
  PriAccount priAccount;
  pubAccount.pub;
}
<br>为了封装性，基类的私有成员是不可以被继承到派生类中的。上面的例子中，展示了基类的不同成员的访问权限在不同继承方式下的访问权限。<br><br>在C++中，class 和 struct 的区别就是 struct 因为C兼容的缘故，默认的成员变量和成员函数是 public 的，而不像 class 中的 private。还有一个区别就是继承时，struct 默认的继承方式为 public ，而 class 默认的继承方式是 private 。这就是它们的区别。<br><br>Make every class in your hierarchy either a base-only or leaf only. <br><br>
The separation of the interface and its implementation is one of the crucial ideas of modern software design.
<br><br>多-态，即一种物体的多种状态。多态分为编译时多态性和运行时多态性。在OOP中，通常指后者。<br><br>也称为静态多态性，主要通过函数的重载和模板实现。C语言并不支持相同函数名的重载，C++通过将参数类型也作为符号名的一部分来支持函数的重载。如plus(int i)的符号名可能是_Z4plusi，最后面的i就表示有一个int类型的参数。如果在类中可能是这样的_ZN5Class4plus<br>由于这种多态性在编译期就确定下来了，所以效率要高一点。由于这种在编译时就确定的多态性，有时并不将静态多态性看作是真正意义上的多态。我们用模板的代码简单演示一下。<br>#include &lt;iostream&gt;

template&lt;typename T&gt;
T plus(T x){
    return x+1;
}
int main(){
    auto y = plus(20);
    auto z = plus(3.14);
    auto e = plus('c');
    return 0;
}
<br>由于模板只有在调用相应类型的时候才会实例化，所以在这段代码中，我们在编写代码时就能说出来编译后会相应地产生三个关于 plus 的函数符号。而且这三个符号是独立的，链接时并不将其看作一个函数看待。<br>编译完成后查看符号表，我们确实看到了三个不同的函数符号：<br>du@DVM:~/Desktop/DSA$ nm -n stat_poly
                 U __cxa_atexit
                 U __dso_handle
                 U _GLOBAL_OFFSET_TABLE_
                 U _ZNSt8ios_base4InitC1Ev
                 U _ZNSt8ios_base4InitD1Ev
0000000000000000 T main
0000000000000000 W _Z4plusIcET_S0_
0000000000000000 W _Z4plusIdET_S0_
0000000000000000 W _Z4plusIiET_S0_
0000000000000000 b _ZStL8__ioinit
0000000000000047 t _Z41__static_initialization_and_destruction_0ii
000000000000009d t _GLOBAL__sub_I_main

<br><br>也称动态多态性，通过虚函数和继承来实现。由于虚多态只有在程序运行时才能确定实际调用的时哪个函数，所以效率较低。（存储虚表造成的空间复杂度和虚指针索引导致的时间复杂度增加）<br>相关请参阅<a data-href="Virtual Dispatch in C++" href="https://congzhi.wiki/c-plus-plus/virtual-dispatch-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Virtual Dispatch in C++</a>。<br><br>
OOP is a programming paradigm in C++ using polymorphism based on runtime function dispatch using virtual functions.
<br><br>在OOP范式中，由于派生类是基类派生而来的，所以它们的库所用的API是相同的。通过创建对象将派生类实例化，每个对象可以具有不同的状态和行为。这种特性就是由"virtual"所提供的动态多态性。即基类定义的API可以被派生类对象重写，从而在不同对象中表现出不同的实现。在编译期(compile time)，确定派生对象的类型。在运行时(runtime)，我们才能知道派生类的状态。]]></description><link>https://congzhi.wiki/c-plus-plus/object-oriented-programming-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Object Oriented Programming in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 28 Feb 2025 04:41:31 GMT</pubDate></item><item><title><![CDATA[Operator Overloading in C++ (ENG)]]></title><description><![CDATA[ 
 <br>We introduce operator overloading mainly to address situations where the existing operators do not align with the unique properties of a class. Besides the concept, you will also learn some in-depth details about how it works. Here is what you will learn in this note:<br>
<br><a data-tooltip-position="top" aria-label="Overloading Syntaxes" data-href="#Overloading Syntaxes" href="https://congzhi.wiki/about:blank#Overloading_Syntaxes" class="internal-link" target="_self" rel="noopener nofollow">Overloading Syntaxes</a>

<br><a data-tooltip-position="top" aria-label="Overloading Syntaxes > Binary Operators" data-href="#Overloading Syntaxes#Binary Operators" href="https://congzhi.wiki/about:blank#Overloading_Syntaxes#Binary_Operators" class="internal-link" target="_self" rel="noopener nofollow">Binary Operators</a>
<br><a data-tooltip-position="top" aria-label="Overloading Syntaxes > Unary Operators" data-href="#Overloading Syntaxes#Unary Operators" href="https://congzhi.wiki/about:blank#Overloading_Syntaxes#Unary_Operators" class="internal-link" target="_self" rel="noopener nofollow">Unary Operators</a>
<br><a data-tooltip-position="top" aria-label="Overloading Syntaxes > Special Operators" data-href="#Overloading Syntaxes#Special Operators" href="https://congzhi.wiki/about:blank#Overloading_Syntaxes#Special_Operators" class="internal-link" target="_self" rel="noopener nofollow">Special Operators</a>
<br><a data-tooltip-position="top" aria-label="Overloading Syntaxes > Operator Matters" data-href="#Overloading Syntaxes#Operator Matters" href="https://congzhi.wiki/about:blank#Overloading_Syntaxes#Operator_Matters" class="internal-link" target="_self" rel="noopener nofollow">Operator Matters</a>


<br><a data-tooltip-position="top" aria-label="Finally, Easy Examples" data-href="#Finally, Easy Examples" href="https://congzhi.wiki/about:blank#Finally,_Easy_Examples" class="internal-link" target="_self" rel="noopener nofollow">Finally, Easy Examples</a>

<br><a data-tooltip-position="top" aria-label="Finally, Easy Examples > This is about Static Polymorphism, Right?" data-href="#Finally, Easy Examples#This is about Static Polymorphism, Right?" href="https://congzhi.wiki/about:blank#Finally,_Easy_Examples#This_is_about_Static_Polymorphism,_Right" class="internal-link" target="_self" rel="noopener nofollow">This is about Static Polymorphism, Right?</a>
<br><a data-tooltip-position="top" aria-label="Finally, Easy Examples > Overloading `+`" data-href="#Finally, Easy Examples#Overloading `+`" href="https://congzhi.wiki/about:blank#Finally,_Easy_Examples#Overloading_`+`" class="internal-link" target="_self" rel="noopener nofollow">Overloading `+`</a>
<br><a data-tooltip-position="top" aria-label="Finally, Easy Examples > Overloading `++`" data-href="#Finally, Easy Examples#Overloading `++`" href="https://congzhi.wiki/about:blank#Finally,_Easy_Examples#Overloading_`++`" class="internal-link" target="_self" rel="noopener nofollow">Overloading `++`</a>
<br><a data-tooltip-position="top" aria-label="Finally, Easy Examples > Overloading `<<`" data-href="#Finally, Easy Examples#Overloading `<<`" href="https://congzhi.wiki/about:blank#Finally,_Easy_Examples#Overloading_`<<`" class="internal-link" target="_self" rel="noopener nofollow">Overloading `&lt;&lt;`</a>
<br><a data-tooltip-position="top" aria-label="Finally, Easy Examples > Overloading `new` and `delete`" data-href="#Finally, Easy Examples#Overloading `new` and `delete`" href="https://congzhi.wiki/about:blank#Finally,_Easy_Examples#Overloading_`new`_and_`delete`" class="internal-link" target="_self" rel="noopener nofollow">Overloading `new` and `delete`</a>
<br><a data-tooltip-position="top" aria-label="Finally, Easy Examples > `inline` Overloading for Comparison Operators" data-href="#Finally, Easy Examples#`inline` Overloading for Comparison Operators" href="https://congzhi.wiki/about:blank#Finally,_Easy_Examples#`inline`_Overloading_for_Comparison_Operators" class="internal-link" target="_self" rel="noopener nofollow">`inline` Overloading for Comparison Operators</a>


<br><br>C++ provides us a lot of operators, and some special operators like new and new[], delete and delete[], as well as co_await since C++20. Before we go under the hood, let's first take a look at the kinds of operators we have in C++.<br><br>Binary operators operate on two operands. Here are the binary operators in your list:<br>
<br>+, -, *, /, % (Arithmetic operators)<br>

<br>^, &amp;, | (Bitwise operators)<br>

<br>=, +=, -=, *=, /=, %=, ^=, &amp;=, |=, &lt;&lt;=, &gt;&gt;= (Assignment operators)<br>

<br>&lt;, &gt;, &lt;=, &gt;=, ==, !=, &lt;=&gt; (Comparison operators)<br>

<br>&amp;&amp;, || (Logical operators)<br>

<br>&lt;&lt;, &gt;&gt; (Bitwise shift operators)<br>

<br>, (Comma operator)<br>

<br>-&gt;*, -&gt; (Member access operators)<br>

<br>[], () (Subscript and function call operators)
<br><br>Unary operators operate on a single operand. Here are the unary operators in your list:<br>
<br>~ (Bitwise NOT)<br>

<br>! (Logical NOT)<br>

<br>++, -- (Increment and Decrement operators)
<br><br>Such as new, new[] etc...<br><br>Later, we will create an overloaded operator ourselves. Before that, it's important to understand that different operators play a significant role in operator overloading. We categorized these operators into binary and unary operators, their signatures can vary depending on the operator.<br>Those signatures match the following:<br><br>And be aware, the operators =, (), [], and -&gt; cannot be non-member functions for specific reasons, Copilot says this is because those operators need direct access to the object.<br><br><br>We use the keyword operator to define operator overloading, which allows us to provide custom implementations for operators in user-defined types or classes. When you overload an operator, it behaves exactly like a function with a special name, different parameter means different function symbol. And yes, this is a familiar concept we known as <a data-tooltip-position="top" aria-label="Static Dispatch in C++ (ENG)" data-href="Static Dispatch in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/static-dispatch-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">static polymorphism</a>.<br><br>#include &lt;iostream&gt;
#include &lt;cstring&gt;
struct vector {
    float x, y, z;

    vector operator+(const vector&amp; rhs) const {
        vector result;
        result.x = this-&gt;x + rhs.x;
        result.y = this-&gt;y + rhs.y;
        result.z = this-&gt;z + rhs.z;
        return result;
    }
};
struct string{
	char* str;
    int str_len;
	string(const char* s = "") {
        str_len = std::strlen(s);
        str = new char[str_len + 1];
        for(int i = 0; i &lt; str_len + 1; i++)
            str[i] = s[i];
    }
    ~string() {
        delete[] str;
    }
	string operator+(const string&amp; other) const {
        int new_length = str_len + other.str_len;
        char* new_str = new char[new_length];
        std::strcpy(new_str, str);
        std::strcat(new_str, other.str);
        return string(new_str);
    
    }
};

int main() {
    vector v1 = {1.0, 2.0, 3.0};
    vector v2 = {4.0, 5.0, 6.0};
    vector v3 = v1 + v2;

    std::cout &lt;&lt; "Result: (" &lt;&lt; v3.x &lt;&lt; ", " &lt;&lt; v3.y &lt;&lt; ", " &lt;&lt; v3.z &lt;&lt; ")" &lt;&lt; std::endl;
    string s1 = string("hello, ");
    string s2 = string("world!");
    string s3 = s1 + s2;
    std::cout &lt;&lt; "Result: " &lt;&lt; s3.str &lt;&lt; std::endl;
    return 0;
}
<br><br><br><br><br>For operators that are simple to implement, we usually use the inline keyword to instruct the compiler to inline the overloaded operator. We can get several benefits after this:<br>
<br>Performance Improvement
<br>Code Optimization
]]></description><link>https://congzhi.wiki/c-plus-plus/operator-overloading-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Operator Overloading in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:57:33 GMT</pubDate></item><item><title><![CDATA[Parameter Pack in C++ (ENG, NC)]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/c-plus-plus/parameter-pack-in-c++-(eng,-nc).html</link><guid isPermaLink="false">C Plus Plus/Parameter Pack in C++ (ENG, NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 27 Feb 2025 08:54:30 GMT</pubDate></item><item><title><![CDATA[Part1：C++11 (Abandoned)]]></title><description><![CDATA[ 
 <br><br>const(ant)，望文生义就是"常值"的意思。在C++中，我们使用 const 修饰符用来表示修饰后的数值或字符串是不可改动的，如：<br>const int i = 20;//int const i = 20;一个道理
const char ch = 'a';
const char* s = "hello world";
const int* p = 100;//指针p指向的数字100是常值，但是指针可以变
int* const p = 100;//定义了一个常指针指向数值为100的区域，这里的数值是可以改变的
const int* const p = 100;//定义了一个指向常量100的常指针
<br>const修饰的变量和常量是不一样的。常量常常会放到.text段或.rodata段，但是const修饰的变量不一定放在.rodata段。如果变量是局部变量，它的生命周期会随着函数的返回、栈帧的销毁一同消逝。但是如果const修饰的是全局变量，则一般会将这个全局变量放在.rodata段中。<br>我们在下面的例子中进一步学习。我们定义了全局变量和许多局部变量。其中 const_global 会放到.rodata段中，global 会放在bss/data段中。在函数中，字符串"hello world"是一个常字符串，会被放到.rodata段中，其余函数内用const修饰局部变量的生命周期都会随着栈帧的摧毁而消逝。<br>const int const_global = 0;
int global = 20;

int constFunc(const char** d,const int** e) {
	const char* s = "hello world";
	const int i = 5;
	*d = s;
	*e = &amp;i;
	return 0;
}
int main() {
	int x = 30;
	int y = 40;
	const char* a;
	const int* b;
	constFunc(&amp;a, &amp;b);
	return 0;
}
<br><br>auto 是C++11新加入的关键字，用于自动推导变量的类型。它可以让编译器根据初始化表达式自动确定变量的类型，从而简化代码编写和提高代码的可读性。但是要注意，在使用 auto 时要清楚编译器会给 auto 什么类型。我们可以使用 boost库 来判断变量的具体类型。<br>在使用auto时，我们要注意以下几点：<br>
<br>auto只能推断出类型，而引用不是类型，所以auto无法推断出引用，要引用只能自己加引用符号。代码演示如下：
<br>int i = 100;
auto i2 = i;//i2为 int 类型
auto&amp; refI = i;//refI 为 int&amp; 类型
/*
我们看到，只有自己加入引用类型后 refI 才能变成 int&amp;。
*/
<br>
<br>auto关键字在推断引用的类型时，会直接将引用替换为引用指向的对象。引用不是对象，任何使用引用的地方都可以直接替换成引用指向的对象。
<br>int i = 100;
int&amp; refI = i;
auto i2 = refI;//相当于 auto i2 = i;  i2 类型为 int
auto&amp; i3 = refI;//相当于auto&amp; i3 = i;  i3 类型为 int&amp;
<br>
<br>auto关键字在推断带const关键字的类型时，若没有引用符号，则会忽略const的修饰。而保留指向对象的const，典型的就是指针。
<br>const int i = 100;
auto i2 = i;//i2 为 int 类型

int j = 100;
const int* const p = &amp;j;//定义了一个指向常量 int 的常指针p
auto p2 = p;//p2的类型为const int*，是指向常量 int 的指针。

static int k = 100;
auto k2 = k;//k2 为 int 类型
<br>请留意：在这行代码中const int* const p = &amp;j;//定义了一个指向常量 int 的常指针p，j&nbsp;并没有被设置为常量。p&nbsp;是一个指向&nbsp;const int&nbsp;的常指针，但这并不改变&nbsp;j&nbsp;的本质。只是说不能通过&nbsp;p&nbsp;来修改&nbsp;j&nbsp;的值。<br>
4. 在auto关键字推断类型时，如果带引用符号则会保留值类型。<br>const int i = 100;
auto&amp; i2 = i;//i2 为 const int 类型

int j = 100;
const int *const p = &amp;j;//定义了一个指向常量 int 的常指针p
auto&amp; p2 = p;//p2的类型为const int* const&amp;。

static int k = 100;
auto&amp; k2 = k;//k2 为 int&amp; 类型
<br>
<br>如果在auto前面加上const，就会永远有const的含义。
<br>int i = 100;
const auto i2 = i;//i2 为 const int 类型
<br><br>全局变量和静态变量都是存放在.data/.bss段中的，这些变量在编译过程中就已经被赋予地址，在执行时不会再次调用。我们用代码做简单的演示。<br>int global_1 = 100;//.data
int global;//.bss

void test(){
	static int i;//.bss，在程序启动时自动初始化为0
	static int i2 = 0;//.data，且这行代码不会再进程运行时执行
	++i;
}

int main(){
	test();
	test();
}
<br><br>C++的表达式一般有两部分对象组成，如int i = 100;。在表达式中，左值(lvalue) 就是能够取地址的那部分（有地址属性，表达式结束后依然存在的持久对象），而不能够取地址的我们称之为右值(rvalue)（表达式结束后就不再存在的对象）。在上面的表达式中，变量对象i就是左值，10这样的字面量（字符字面量除外）对象就是右值。<br>左值来源于C语言的说法，即可以放在等号左边的就叫左值，左值也可以放在等号右边。但右值只能放到赋值操作符的右边，这是因为右值没有持久的存储位置（临时对象），所以不能作为赋值操作的目标。<br><br>
<br>普通左值引用：一个对象的别名，只能绑定左值，无法绑定右值。
<br>int i = 100;
int&amp; ref = i;//lvalue reference, no mistake

const int i2 = 100;
int&amp; ref2 = i2;//错误：非常量引用不能绑定到常量
const int&amp; ref2 = i2;//正确
ref2 = 200;//如果绑定后就会违反常量的不可变原则

int&amp; ref3 = 100;//错误：非常量引用不能绑定到右值
<br>
<br>const左值引用：可以对常量起别名，可以绑定左值和右值。
<br>const int i =100;
const int&amp; ref = i;//正确

const int&amp; ref = 100;//正确
<br>
<br>右值引用：右值引用只能绑定到右值。右值引用的主要用途是实现移动语义和优化性能。
<br>int i = 100;
int&amp;&amp; rref = 200;//正确
int&amp;&amp; rref2 = (i+1);//正确
int&amp;&amp; rref3 = i++;//正确，i++是一个右值表达式，因为它返回 i 的旧值（临时对象）

int&amp;&amp; rref4 = i;//错误，i是右值
int&amp;&amp; rref5 = ++i;//错误，++i是左值，因为它返回的是 i 的引用类型
<br>
<br>万能引用：属于模板的部分：万能引用、引用折叠、完美转发。在学习模板时再学习。
<br><br>在上节课中，我们看到，在使用右值引用时不能绑定左值。在C++11中，我们可以通过move函数来将左值转换为右值引用。<br><br>
<br>右值看重对象的值而不考虑地址，move函数可以对一个左值使用，使操作系统不再在意其地址属性，将其完全视作一个右值看待。
<br>当我们使用了move函数后，操作对象就失去了其地址属性。因此，我们有义务保证之后避免使用该变量的地址属性，也就是不再使用该变量，因为再次使用该变量不可避免地会使用到变量的地址属性。在后面移动语义时会体现move函数意义。
<br>#include&lt;utility&gt;
int i = 100;
int&amp;&amp; rref = i;//错误，因为 i 是左值，不能绑定到右值引用

int&amp;&amp; rref2 = std::move(i);//正确，std::move 将 i 转换成右值引用
int&amp;&amp; rref3 = srd::move(++i);//正确，++i 是左值，std::move 将 ++i 转换成右值引用
<br><br>临时对象是程序执行时生成的中间对象，所有的临时对象都是右值对象，因为临时对象产生后很快就会被销毁。常见的临时对象有：<br>
<br>函数返回值：当函数返回一个对象时，会创建一个临时对象来存储返回值，如：
<br>int get20(){
	return 20;//返回一个临时对象
}
int&amp;&amp; i = get20();
<br>
<br>类型转换：当需要进行类型转换时，编译器会创建临时对象。如：
<br>double d = 3.14;
int i = static_cast&lt;int&gt;(d);//临时对象存储转换后的值，然后赋给 i 。
<br>
<br>表达式中的中间结果：在复杂表达式中，临时对象用于存储中间结果。
<br>int a = 5, b = 10;
int result = (a + b) * 2; // 临时对象存储 a + b 的结果   
<br><br>如果一个对象可以使用调用运算符"()"，()里面可以放参数。那么这个对象就是可调用对象。可调用对象的分类有：<br> Lambda表达式：也称为匿名函数，是一种需要一个函数但不想命名它的情况下使用的简便方法。基本语法是：[capture list] (parameter list) -&gt; return_type { function body }	<br>
<br>捕获列表 []：指定Lambda表达式可以访问的外部变量，可以按值（=）或按引用（&amp;）捕获。

<br>[ ]表示不捕获任何变量。
<br>[=]表示按值捕获所有变量。
<br>[&amp;]表示按照引用捕获所有变量。
<br>[=,&amp; i]除了 i 按引用传递，其他所有变量按值转递。
<br>[&amp;, i]表示除了 i 按值传递，其他变量按引用传递。
<br>也可以捕获单独变量，如[i]，[&amp;i]。


<br>参数列表（parameter list）：与普通函数的参数列表类似，可以为空。
<br>返回类型（return type）：可以省略，由编译器推导，也可以显式指定。
<br>函数体（function body）：Lambda表达式的具体逻辑。
]]></description><link>https://congzhi.wiki/c-plus-plus/part1：c++11-(abandoned).html</link><guid isPermaLink="false">C Plus Plus/Part1：C++11 (Abandoned).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:57:39 GMT</pubDate></item><item><title><![CDATA[Part2：Class (Abandoned)]]></title><description><![CDATA[ 
 <br><br>在C语言中，我们常用struct关键字来定义我们想要的数据类型，但结构体中不能包含函数。这是因为结构体中的变量存储在数据段（如.bss、.data）或堆栈上，而函数存储在代码区（.text）。我们要对结构体的数据进行操作，只能在结构体外定义各种函数，这不仅不利于数据的封装性，而且独立的函数也容易让人一头雾水。（C++中，struct和class的唯一区别就是默认类内/结构体中的属性不同，还有继承）<br>以下是一个面向过程的“把大象放进冰箱”的操作示例：<br>#include &lt;stdio.h&gt;

typedef struct {
    unsigned int height;
    unsigned int weight;
    unsigned int age;
} person;

typedef struct {
    unsigned int volume;
} elephant;

typedef struct {
    unsigned int volume;
} fridge;

void person_cutting_elephant(person p, elephant e) {
    /*
    cutting operations
    */
    printf("Elephant has been cut\n");
}

void person_fill_fridge(person p, elephant e, fridge f) {
    /*
    filling operations
    */
    printf("Fridge has been filled\n");
}

int main() {
    person p = {180, 70, 24};
    elephant e = {5};
    fridge f = {6};
    person_cutting_elephant(p, e);
    person_fill_fridge(p, e, f);
    return 0;
}
<br>在这个例子中，我们定义了人、大象和冰箱三个结构体，并在结构体外编写了相关函数。虽然这样可以完成任务，但数据和操作分离的形式并不直观。当使用结构体，操作函数描述起来的着重点是函数，如：人把大象切开了，其中人是p、大象是e（有了类，我们就可以说p人把e大象切开了）。<br>而C++提供了class类描述符，可以将对象的操作（方法函数）放到类内，不仅提升了数据元素的封装性，还使整个过程的思维流程更加通顺易懂。在开发大型项目时，海量的操作函数并不利于项目迭代和操作不同的对象。而类能做什么，只需查看类内成员函数就一目了然了。在写一个面向对象的“把大象放进冰箱”的操作示例之前，我们先学习类的构造函数和析构函数。<br><br><br>类相当于一个新类型，该类型的成员变量可以放在数据段或堆栈上，同样成员函数会存储在代码区（.text段）。构造函数就是在类对象创建时就在对应内存将数据初始化的成员函数。<br><br>
<br>默认构造函数：没有参数的构造函数。我们可以定义自己的默认构造函数来初始化不带参数的对象。如果我们没有定义默认构造函数，编译器会自动生成一个默认构造函数，这个默认构造函数什么都不干。
<br>普通构造函数：带参数的构造函数。普通构造函数是用于初始化对象的构造函数。
<br>复制构造函数：用于创建对象的副本。该对象是通过复制现有对象来初始化的。它接受一个同类对象的引用作为参数。
<br>移动构造函数：移动构造函数用于创建一个新对象，它接受一个右值引用（&amp;&amp;）作为参数。移动构造函数会将右值引用对象资源移动到新对象，并”人工地“将源对象的成员变量重置。
<br>class person
{
public:
	unsigned int height;
	unsigned int weight;
	unsigned int age;
public:
	//默认构造函数
	person() :height(0), weight(0), age(0) {
		std::cout &lt;&lt; "Default constructor has been called." &lt;&lt; std::endl;
	}
	//普通构造函数
	person(unsigned int height_, unsigned int weight_, unsigned int age_)
		:height(height_), weight(weight_), age(age_) {
		std::cout &lt;&lt; "A person object is constructed." &lt;&lt; std::endl;
	}
	//复制构造函数
	person(const person&amp; other_person)
		:height(other_person.height), weight(other_person.weight), age(other_person.age) {
		std::cout &lt;&lt; "Copy constructor has been called." &lt;&lt; std::endl;
	}
	//移动构造函数
	person(person&amp;&amp; other_person)
		noexcept:height(other_person.height), weight(other_person.weight), age(other_person.age) {
		other_person.height = 0;
		other_person.weight = 0;
		other_person.age = 0;
		std::cout &lt;&lt; "Move constructor has been called." &lt;&lt; std::endl;
	}
		~person() {}
};
<br><br>析构函数（Deconstructor）是C++中的一种特殊成员函数，用于在对象的生命周期结束时执行清理操作。析构函数的名称与类名相同，但前面有一个波浪号（~），并且没有返回类型和参数，所以不能够重载。<br>析构函数的作用是释放类对象的资源，只有当类内成员申请内存才需要在析构函数中显式定义delete操作，否则析构函数不需要释放什么资源。如果类管理其他资源（如文件句柄、网络连接、数据库连接等），需要在析构函数中释放这些资源。<br><br>我们忽略大象类、冰箱类的实现和操作的实现细节，以下是一个面向对象的“把大象放进冰箱”的操作示例：<br>#include&lt;iostream&gt;
class person;
class elephant;
class fridge;

class person
{
public:
	unsigned int height;
	unsigned int weight;
	unsigned int age;
public:
	//默认构造函数
	person() :height(0), weight(0), age(0) {
		std::cout &lt;&lt; "Default constructor has been called." &lt;&lt; std::endl;
	}
	//普通构造函数
	person(unsigned int height_, unsigned int weight_, unsigned int age_)
		:height(height_), weight(weight_), age(age_) {
		std::cout &lt;&lt; "A person object is constructed." &lt;&lt; std::endl;
	}
	//复制构造函数
	person(const person&amp; other_person)
		:height(other_person.height), weight(other_person.weight), age(other_person.age) {
		std::cout &lt;&lt; "Copy constructor has been called." &lt;&lt; std::endl;
	}
	//移动构造函数
	person(person&amp;&amp; other_person)
		noexcept:height(other_person.height), weight(other_person.weight), age(other_person.age) {
		other_person.height = 0;
		other_person.weight = 0;
		other_person.age = 0;
		std::cout &lt;&lt; "Move constructor has been called." &lt;&lt; std::endl;
	}
		~person() {}
		void person_cut_elephant(const person p, elephant e) ;
		void person_fill_fridge(const person p, elephant e, fridge f) ;
};
int main() {
	person p(180, 70, 24);
	elephant e(5);
	fridge f(6);
	p.person_cut_elephant();
	p.person_fill_fridge();
	return 0;
}
<br>这样，我们能明显的感受到前面“人把大象切开了，其中人是p、大象是e（有了类，我们就可以说p人把e大象切开了）。”这句话的含义。<br><br><br>this 是&nbsp;C++&nbsp;中的一个关键字，也是一个 const&nbsp;指针，它指向当前对象，通过它可以访问当前对象的所有成员。所谓当前对象，是指正在使用的对象。this 只能用在类的内部，通过 this 可以访问类的所有成员，包括 private、protected、public 属性的。this的简单用法如下：<br>#include &lt;iostream&gt;

class person {
	int height;
	int weight;
	int age;
public:
	person(int h, int w, int a) :height(h), weight(w), age(a) {
		std::cout &lt;&lt; "A person object has been added." &lt;&lt; std::endl;
	}
	~person() {}
	void getter() {
		std::cout &lt;&lt; "Height: " &lt;&lt; this-&gt;height &lt;&lt; std::endl &lt;&lt; "Weight: "
			&lt;&lt; this-&gt;weight &lt;&lt; std::endl &lt;&lt; "Age: " &lt;&lt; this-&gt;age &lt;&lt; std::endl;
	}
	void setter(int height, int weight, int age) {
		this-&gt;height = height;// 使用 this-&gt;height 表示成员变量
		this-&gt;weight = weight;
        this-&gt;age = age; 
    }
};

int main() {
	person Pa(160, 50, 22);
	person Pb(175, 60, 20);
	Pa.getter();
	Pb.getter();
	return 0;
}
<br>编译器将this关键字解释为指向函数所作用的对象的指针。 C++类的本质就是C语言的结构体外加几个类外的函数，C++最后都要转化为C语言来实现，类外的函数就是通过this来指向这个类的。上面的类在 C 语言中的实现如下：<br>#include &lt;stdio.h&gt;

typedef struct {
    int height;
    int weight;
    int age;
} Person;

void initPerson(Person *this, int height, int weight, int age) {
    this-&gt;height = height;
    this-&gt;weight = weight;
    this-&gt;age = age;
    printf("A person object has been added.\n");
}

void getter(const Person *this) {
    printf("Height: %d\nWeight: %d\nAge: %d\n", 
    this-&gt;height, this-&gt;weight, this-&gt;age);
}

void setter(Person *this, int height, int weight, int age) {
    this-&gt;height = height; // 使用 p-&gt;height 表示成员变量
    this-&gt;weight = weight;
    this-&gt;age = age;
}

int main() {
    Person Pa, Pb;
    initPerson(&amp;Pa, 160, 50, 22);
    initPerson(&amp;Pb, 175, 60, 20);
    getter(&amp;Pa);
    getter(&amp;Pb);
    return 0;
}

<br>this有很多功能是单纯的指针无法满足的。比如每个类函数的参数根本没有名叫this的指针。这是编译器赋予的功能。<br><br>const除了修饰变量，还可以用来修饰类内函数。用 const 修饰的函数我们称为常成员函数。C++规定常成员函数在调用时不会修改类的成员变量。<br>class MyClass {
public:
    int getValue() const { // 常成员函数
        return value;
    }
    void setValue(int val) {
        value = val;
    }
private:
    int value;
};
<br>函数括号后的const实际上是为了修饰this，常成员函数会隐式地转换为：<br>void outPut(const myClass* const myThis){
	std::cout &lt;&lt; myThis-&gt;name &lt;&lt; std::endl;
}
<br>但由于this是隐式的，所以将const放到括号外。<br><br>同样，加入const关键字就可以定义一个常对象。理解起来也很方便，常对象的对象变量是不可改变的。这样一来，常对象和普通对象可以使用的类内函数就有一些区别。即 常对象只能使用常成员函数。在函数重载的情况下，普通对象只能使用普通成员函数，常对象只能使用常成员函数。我们举例说明一下：<br>#include &lt;iostream&gt;

class person {
	int height;
	int weight;
	int age;
public:
	person(int h, int w, int a) :height(h), weight(w), age(a) {
		std::cout &lt;&lt; "A person object has been added." &lt;&lt; std::endl;
	}
	~person() {}
	void getter() {
		std::cout &lt;&lt; "Height: " &lt;&lt; height &lt;&lt; std::endl &lt;&lt; "Weight: "
			&lt;&lt; weight &lt;&lt; std::endl &lt;&lt; "Age: " &lt;&lt; age &lt;&lt; std::endl &lt;&lt; this &lt;&lt; std::endl;
	}
	void getter()const {
		std::cout &lt;&lt; "Height: " &lt;&lt; height &lt;&lt; std::endl &lt;&lt; "Weight: "
			&lt;&lt; weight &lt;&lt; std::endl &lt;&lt; "Age: " &lt;&lt; age &lt;&lt; std::endl &lt;&lt; this &lt;&lt; std::endl;
		std::cout &lt;&lt; "this is a const func" &lt;&lt; std::endl;
	}
};

int main() {
	person Pa(160, 50, 22);
	const person Pb(175, 60, 20);
	Pa.getter();
	Pb.getter();
	return 0;
}
<br><br><br>我们用&nbsp;inline&nbsp;关键字来指定某一个函数为内联函数。我们知道，当函数被调用时，会在栈空间里生成栈帧。函数的调用和返回对应着栈帧的生成与销毁，这往往意味着开销。内联函数就是让调用函数将被调用函数看作自身的一部分（即被调用函数不需要生成栈帧，空间换时间），节省了调用其他函数时生成和销毁栈帧的时间开销。因此，内联函数往往设置为较为短小的函数，因为当函数很大时，内联会导致代码膨胀，增加指令缓存的压力，反而可能降低性能。<br>我们在使用inline关键字时需要有以下几点注意：<br>
<br>关键字必须与函数定义放在一起才能使函数成为内联，放在函数声明前不起作用。
<br>函数在类内实现时，默认是内联的。
<br>内联函数只是对编译器的一种建议，只有符合内联的情况编译器才会采纳将函数设置为内联。
<br>#include&lt;iostream&gt;

class test {
public:
	inline void print();
	void print2();
	void print3(){
		std::cout &lt;&lt; "print3" &lt;&lt; std::endl;
	}
};
void test::print() {
	std::cout &lt;&lt; "hello" &lt;&lt; std::endl;
}
inline void test::print2(){
	std::cout &lt;&lt; "print2" &lt;&lt; std::endl;
}
int main() {
	test test1;
	test1.print(); //test1.print(); 不是内联函数
	test1.print2();//test1.print2();是内联函数
	test1.print3();//是内联函数
}
<br><br>mutable可变的，这个关键字与const相对。const关键字突出的是“常”而mutable关键字突出的是“变”。我们延续上面的例子来看看mutable可以做什么：<br>#include&lt;iostream&gt;

class test {
	mutable unsigned int print_Count;
public:
	test(unsigned int Count_init) :print_Count(Count_init) {}
	inline void print()const;
};
void test::print()const {
	std::cout &lt;&lt; "hello" &lt;&lt; std::endl;
	print_Count++;
	std::cout &lt;&lt; print_Count &lt;&lt; std::endl;
}
int main() {
	test test1(20);
	test1.print();
	test1.print();
}
<br>我们看到，即使我们定义了一个常成员函数，我们依然可以因为变量是mutable修饰的而修改print_Count的值。<br>mutable关键字一般万不得已才会使用，为了提高程序设计应当避免使用mutable关键字。另外注意，mutable不能修饰静态成员变量和常成员变量。<br><br>提高代码的可读性。<br><br>delete关键字最基本的用途就是释放掉申请的堆内存，如：<br>//删去单个对象
int* ptr = new int;
delete ptr;

//删去对象数组
int* ptr = new int[10];
delete[] ptr;
<br>但在C++ 11，delete关键字可以用于disable特定函数，用于阻止某些特定操作。比如，我们就可以在类内disable复制构造函数，delete关键字也可以用于disable类外的函数。<br><br>C++提供friend关键字来声明友元函数和友元类。如：<br>#include &lt;iostream&gt;
class person;
class dog;
void gym(person&amp; p);

class person {
	int height;
	int weight;
	int age;
public:
	friend class dog;
	friend void gym(person&amp; p);
	person(int h, int w, int a) :height(h), weight(w), age(a) {
		std::cout &lt;&lt; "A person object has been added." &lt;&lt; std::endl;
	}
	~person() {}
	void getter()const {
		std::cout &lt;&lt; "Height: " &lt;&lt; height &lt;&lt; std::endl &lt;&lt; "Weight: "
			&lt;&lt; weight &lt;&lt; std::endl &lt;&lt; "Age: " &lt;&lt; age &lt;&lt; std::endl &lt;&lt; this &lt;&lt; std::endl;
	}
};
class dog {
public:
	void bark_person(person&amp; p) {
		p.age = 0;
		p.height = 0;
		p.weight = 0;
		p.getter();
	}
};
void gym(person&amp; p) {
	p.weight -= 5;
	p.getter();
}
int main() {
	person Pa(160, 50, 22);
	person Pb(175, 65, 30);
	dog D;
	D.bark_person(Pb);
	gym(Pa);
	return 0;
}
<br>我们看到，友元函数和友元类可以任意操作person类中的任意成员，无论成员是什么属性。这样会破坏类的封装性，使得类内私有成员在友元函数和友元类下一览无余，而友元函数和友元类可能只是需要访问类内的某几个私有成员。我们可以用getter来代替友元对象，但也各有利弊。有些运算符的重载必须用到友元的功能，我们下节课会介绍。<br><br><br>在C++程序设计课程中，我们就听到多C++面向对象的三大特征——封装、继承和多态。这节课，我们来简单了解一下继承。<br>我们先试想一个场景，假如我们要开发一款游戏，主人公需要使用法杖来过五关斩六将。火之杖、水之杖、冰之杖、土之杖......这么多法杖我们开发时需要如下这样做么？<br>class fire_wand{...};
class water_wand{...};
class ice_wand{...};
class earth_wand{...};
class air_wand{...};
...
<br>我们显然不会这也做，将法杖一个个枚举起来既延长了开发时长，也不利于后面的拓展。C++提供了子类对父类的继承派生，这就大大减少了我们的工作量。假如父类法杖有3个属性，加入继承后，子类只需要实现子类法杖的属性，有关父类的各种属性只需要继承就好了。代码如下：<br>class wand {
	char name[10];
	char element[10];
	unsigned int length;
};
class fire_wand :public wand {//子类fire_wand继承父类wand的所有成员变量
    unsigned char* elem_paricle;
    int particle_width;
    int particle_height;
};
...
<br>接着我们来演示一下父子类的构造和析构函数。在此之前，我们需要注意：<br>
<br>C++的继承是在创建子类成员对象前先创建父类的成员变量，也就是先调用父类的构造函数构造父类成员变量，之后再调用子类的构造函数。
<br>析构函数的调用顺序是先调用子类的析构函数，再调用父类析构函数。
<br>父类的指针是可以指向子类对象的。这在C++中也叫向上转型，这是由于子类对象包含了父类对象的所有成员。
<br>#include &lt;iostream&gt;
#include &lt;cstring&gt;
class wand {
	std::string name;
	std::string element;
	unsigned length;
public:
	wand(std::string name_, std::string element_, unsigned length_) 
	:name(name_), element(element_), length(length_) {
		std::cout &lt;&lt; "Father class constructor." &lt;&lt; std::endl;
	}
	~wand() {
		std::cout &lt;&lt; "Father class deconstrutor." &lt;&lt; std::endl;
	}
};
class fire_wand :public wand {
	unsigned char* elem_paricle;
	int particle_width;
	int particle_height;
public:
	fire_wand(std::string name_, std::string element_, unsigned length_,
		unsigned char* elem_particle_, int parti_width_, int parti_height_)
		:wand(name_, element_, length_), elem_paricle(elem_particle_),
		particle_width(parti_width_), particle_height(parti_height_) {
		std::cout &lt;&lt; "Child class constructor." &lt;&lt; std::endl;
	}
	~fire_wand() {
		std::cout &lt;&lt; "Child class deconstructor" &lt;&lt; std::endl;
	}

};
int main() {
	unsigned char parti_data[2 * 35] = { 0 };
	fire_wand fw("Blacken blast", "Fire", 20, parti_data, 2, 35);
	wand* w = &amp;fw;//父类指针指向子类对象
	return 0;
}
<br><br><br>
polymorphism — providing a single interface to entities of different types. virtual functions provide dynamic (run-time) polymorphism through an interface provided by a base class. Overloaded functions and templates provide static (compile-time) polymorphism.     
<br>多态(Polymorphism)是面向对象编程(OOP)的一个核心概念。它允许同一个接口调用不同类型的对象，并根据对象的实际类型执行相应的操作。多态性可以分为两种类型：编译时多态性（静态多态性）和运行时多态性（动态多态性）。<br><br>编译时多态性通过函数重载(Overload) 和模板实现。在编译期间，编译器根据函数的参数类型和数量来确定调用哪个函数。这种多态性在编译时就已经确定了函数调用的地址，因此称为早绑定（early binding）。<br>重载函数虽然函数名是相同的，但由于不同的参数列表（不同的参数类型和数量）使得编译器能够区分这些函数。编译器在编译时根据传递的参数类型和数量来确定调用哪个重载函数。<br><br>运行时多态性通过虚函数实现。虚函数允许子类重写(Override) 基类中的函数。当通过基类指针或引用调用虚函数时，实际调用的是子类的实现。这种多态性在运行时才确定函数调用的地址，因此称为晚绑定（late binding）。<br><br><br>虚函数实现了运行时(Run-time) 的多态性。函数的多态性就意味着父类对象可以调用子类对象中的成员函数。我们之前说过，因为子类对象包含父类的所有成员变量，所以父类对象的指针是可以指向子类对象的。这样父类的析构函数就必须是虚函数，不然就可能会造成内存泄漏。<br><br>每个有虚函数的类都会有一个虚函数表，对象其实就是指向虚函数表的指针，编译时编译器只告诉了程序会在运行时查找虚函数表的对应函数。每个类都会有自己的虚函数表，所以当父类指针引用的是子类虚函数表时，自然调用的就是子类的函数。<br><br>override&nbsp;关键字用于在子类中重写基类中的虚函数。它告诉编译器该函数是用来重写基类中的虚函数的，如果没有正确匹配基类中的虚函数，编译器会报错。这有助于避免由于拼写错误或参数不匹配而导致的意外行为。<br>我们举例说明：<br>class wand {
public:
	wand(){}
	virtual ~wand() {}
	virtual void test() {}
};
class fire_wand : public wand {
public:
	fire_wand(){}
	virtual ~fire_wand()override {}
	virtual void test()override{}//标准写法
	virtual void teste(){}//，函数名写错了，但不会报错
	virtual void teste()override{}//报错，因为父类中没有能够匹配的虚函数
};

int main() {
	return 0;
}
<br><br>由于父类中并没有申请任何堆内存，我们就将父类析构函数的提示输出给注释掉。我们让父类的test函数输出一串字符串，让子类test函数申请一段堆内存。由于父类test是虚函数，所以子类中的test函数即使不加virtual关键字，编译器也会隐式地认为这个函数是虚函数。一旦父类对象调用了子类的test函数，就会动态申请一段堆内存。所以父类的析构函数必须也是虚函数，不然会造成内存泄漏。<br>#include &lt;iostream&gt;
#include &lt;cstring&gt;

class wand {
	std::string name;
	std::string element;
	unsigned length;
public:
	wand(std::string name_, std::string element_, unsigned length_)
		:name(name_), element(element_), length(length_) {
		std::cout &lt;&lt; "Father class constructor." &lt;&lt; std::endl;
	}
	virtual ~wand() { // 虚析构函数
		//std::cout &lt;&lt; "Father class destructor." &lt;&lt; std::endl;
	}
	virtual void test() {
		std::cout &lt;&lt; "Base class" &lt;&lt; std::endl;
	}
};

class fire_wand : public wand {
	unsigned char* elem_paricle;
	int particle_width;
	int particle_height;
	fire_wand* fw_ptr = NULL;
public:
	fire_wand(std::string name_, std::string element_, unsigned length_,
		unsigned char* elem_particle_, int parti_width_, int parti_height_)
		: wand(name_, element_, length_), elem_paricle(elem_particle_),
		particle_width(parti_width_), particle_height(parti_height_) {
		std::cout &lt;&lt; "Child class constructor." &lt;&lt; std::endl;
	}
	virtual ~fire_wand()override {
		if (fw_ptr == NULL) {
			std::cout &lt;&lt; "Child class destructor" &lt;&lt; std::endl;
		}
		else {
			delete fw_ptr;
			std::cout &lt;&lt; "Heap space freed." &lt;&lt; std::endl;
		}
	}
	void test(){
		unsigned char parti_data[2 * 35] = { 0 };
		fw_ptr = new fire_wand("Blacken blast", "Fire", 20, parti_data, 2, 35);
		std::cout &lt;&lt; "Derived class" &lt;&lt; std::endl;
	}
};

int main() {
	unsigned char parti_data[2 * 35] = { 0 };
	wand* wand_ptr = new fire_wand("Blacken blast", "Fire", 20, parti_data, 2, 35);
	wand_ptr-&gt;test();
	delete wand_ptr;
	return 0;
}
<br>代码执行后结果如下：<br>Father class constructor.
Child class constructor.
Father class constructor.
Child class constructor.
Derived class
Child class destructor
Heap space freed.
<br><br>该函数为虚函数：父类指针调用的是子类的成员函数。<br>
该函数不是虚函数：父类指针调用的是父类的成员函数。<br><br><br>之前说过，如果静态变量未初始化就会载入bss.段并在程序加载时初始化为0。但是静态成员变量必须在类外进行初始化。这是因为静态成员变量属于整个类。无论创建多少个对象，静态成员变量在内存中也只有一份拷贝，存储在静态存储区中，而不在堆栈区。在类外初始化可以避免静态成员变量多次初始化，保证了静态成员变量的唯一性。（不能用构造函数初始化）<br>而且由于静态成员变量为整个类所共享的特性，所以它可以通过类名来调用，当然也能用类对象调用。创建一个静态成员变量如下所示：<br>#include &lt;iostream&gt;

class Test {
public:
	static int var;
	static const int vari = 10;//可以
};
int Test::var = 0;

int main() {
	Test t;
	std::cout &lt;&lt; Test::var &lt;&lt; std::endl;
	std::cout &lt;&lt; t.var &lt;&lt; std::endl;
	return 0;
}
<br><br>静态成员函数和静态成员变量一样，可以用类名调用Test::static_func();，同样可以用类对象调用。静态成员函数只能访问静态成员变量，由于没有this指针，所以也不能访问非静态成员变量。也由于静态的特性，使得静态成员函数不需要生成对象就可调用。<br>虽然静态成员函数和普通成员函数都可以访问静态成员变量，但是由于静态成员函数可以在不创建类对象的情况下被调用，所以多用静态成员函数调用静态成员变量。<br>代码示例：<br>#include &lt;iostream&gt;

class Test {
	static int var;
public:
	static void getter() {
		std::cout &lt;&lt; var &lt;&lt; std::endl;
	}
};
int Test::var = 0;

int main() {
	Test::getter();//没有创建实例对象。
	return 0;
}
<br><br>父类子类继承中，父类唯一的作用就是被子类继承。父类不产生任何对象，父类的虚函数实现过程也是没有意义的，唯一的作用就是为子类重写。为了不让这些无意义的代码占用内存空间，纯虚函数的语法就诞生了。<br>纯虚函数是一种特殊的虚函数，它没有实现，只提供接口。纯虚函数的语法是将函数声明为&nbsp;= 0。包含纯虚函数的类称为抽象类，不能实例化对象。抽象类的主要作用是作为其他类的基类，提供一个接口框架。<br>在法杖的例子中，我们用virtual void test() = 0;将test()函数定义成纯虚函数，这样，这条语句就不会产生任何的函数对象，编译器会忽略之。由于子类还是需要父类构造函数和析构函数，所以构造函数和析构函数不能声明成纯虚函数。<br>class wand {
	std::string name;
	std::string element;
	unsigned length;
public:
	wand(std::string name_, std::string element_, unsigned length_)
		:name(name_), element(element_), length(length_) {
		std::cout &lt;&lt; "Father class constructor." &lt;&lt; std::endl;
	}
	virtual ~wand() { // 虚析构函数
		std::cout &lt;&lt; "Father class destructor." &lt;&lt; std::endl;
	}
	virtual void test() = 0;
};
<br>
<br>纯虚函数：virtual void test() = 0;&nbsp;声明了一个纯虚函数，这意味着&nbsp;wand&nbsp;类是一个抽象类，不能实例化对象。
<br>抽象类：由于&nbsp;wand&nbsp;类包含纯虚函数，它被认为是抽象类，不能直接创建&nbsp;wand&nbsp;类的对象。

<br>在上面的例子中，由于类内包含纯虚函数test()，所以下面的语句都会是错误的。


<br>	  wand* wand_ptr = new fire_wand("Blacken blast", "Fire", 20,); 
	  wand* wand_ptr("Blacken blast", "Fire", 20);
<br>
<br>实现纯虚函数：fire_wand&nbsp;类实现了&nbsp;wand&nbsp;类中的纯虚函数&nbsp;test()，因此&nbsp;fire_wand&nbsp;类可以实例化对象。
]]></description><link>https://congzhi.wiki/c-plus-plus/part2：class-(abandoned).html</link><guid isPermaLink="false">C Plus Plus/Part2：Class (Abandoned).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Mon, 24 Feb 2025 05:20:18 GMT</pubDate></item><item><title><![CDATA[Preprocessor in C++ (Part I, NC)]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/c-plus-plus/preprocessor-in-c++-(part-i,-nc).html</link><guid isPermaLink="false">C Plus Plus/Preprocessor in C++ (Part I, NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:57:50 GMT</pubDate></item><item><title><![CDATA[Preprocessor in C++ (Part II, NC)]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/c-plus-plus/preprocessor-in-c++-(part-ii,-nc).html</link><guid isPermaLink="false">C Plus Plus/Preprocessor in C++ (Part II, NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:57:54 GMT</pubDate></item><item><title><![CDATA[Preprocessor in C++ (Part III, NC)]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/c-plus-plus/preprocessor-in-c++-(part-iii,-nc).html</link><guid isPermaLink="false">C Plus Plus/Preprocessor in C++ (Part III, NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:57:58 GMT</pubDate></item><item><title><![CDATA[Preprocessor in C++ (Part IV, NC)]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/c-plus-plus/preprocessor-in-c++-(part-iv,-nc).html</link><guid isPermaLink="false">C Plus Plus/Preprocessor in C++ (Part IV, NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:58:11 GMT</pubDate></item><item><title><![CDATA[Preprocessor in C++ (Part V, NC)]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/c-plus-plus/preprocessor-in-c++-(part-v,-nc).html</link><guid isPermaLink="false">C Plus Plus/Preprocessor in C++ (Part V, NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:58:04 GMT</pubDate></item><item><title><![CDATA[Preprocessor in C++ (Part VI, NC)]]></title><description><![CDATA[ 
 <br>__line__<br>std::source_location (since C++20)]]></description><link>https://congzhi.wiki/c-plus-plus/preprocessor-in-c++-(part-vi,-nc).html</link><guid isPermaLink="false">C Plus Plus/Preprocessor in C++ (Part VI, NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:58:15 GMT</pubDate></item><item><title><![CDATA[Program Arguments Handling in C++]]></title><description><![CDATA[ 
 <br><br>main() 函数作为我们的程序入口，我们可以在启动程序的时候传入许多参数。偷懒的 main() 写法是这样的，但这样，你不能从外界给你的程序传入参数：<br>int main(){

	return 0;
}
<br>而如果你想在程序启动的时候传入数组参数，你可以使用如下的写法：<br>int main(int argc, char* argv[]) {

    return 0;
}
<br>如果你的程序需要特定的环境才能运行，你还可以接受 envp 参数用于访问环境变量。但请注意，这并不属于 C++ 标准：<br>int main(int argc, char* argv[], char* envp[]) {

    return 0;
}
<br>下面，我们就来逐步解释每个参数的含义。<br><br>argc 是传入参数的数量，这是隐式提供的。当程序启动时，操作系统会将传入字符串参数的数量隐式地提供给 main() 函数。假如我们将下面的程序编译并运行：<br>#include &lt;iostream&gt;
int main(int argc, char* argv[]
) {

    for (int i = 0; i &lt; argc; ++i) {
        std::cout &lt;&lt; "Argument " &lt;&lt; i &lt;&lt; ": " &lt;&lt; argv[i] &lt;&lt; std::endl;
    }
    return 0;
}
<br>./test argv1 "hello world" # use "this is one string" to pass a string
<br>提问，这里我们提供的参数数 argc 有多少个？答案是三个。观察输出结果：<br>Argument 0: ./test
Argument 1: argv[1]
Argument 2: hello world
<br><br>上面在学习 argc 的时候，我们实际上已经学到了 argv 。这是一个字符串参数列表，是这三个参数中我们唯一能够提供给程序的参数。其余的 argc 和 envp 都是操作系统隐式提供给 main() 函数的。<br><br>环境变量也是系统隐式提供的。通过获取环境变量，我们能够知道我们程序的运行环境。对于依赖某些环境才能运行的程序来说，获取环境变量可以帮助此程序动态地配置运行参数。此外，环境变量可能存储一些系统相关的信息，这对于跨平台的程序而言是极其重要的。<br>我们可以遍历打印所有的环境变量：<br>#include &lt;iostream&gt;

int main(int argc, char* argv[], char* envp[]) {
    for (int i = 0; envp[i] != nullptr; ++i) {
        std::cout &lt;&lt; "Environment Variable " &lt;&lt; i &lt;&lt; ": " &lt;&lt; envp[i] &lt;&lt; std::endl;
    }
    return 0;
}
<br>在 C++ 中，标准地获取环境变量的方式是 std::getenv 。]]></description><link>https://congzhi.wiki/c-plus-plus/program-arguments-handling-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Program Arguments Handling in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Mon, 10 Mar 2025 06:52:01 GMT</pubDate></item><item><title><![CDATA[RAII and Scope in C++]]></title><description><![CDATA[ 
 <br><br><br>在C++中，资源是程序管理的各类资源，比如内存、POSIX文件、可合并的进程和互斥锁等。我们能够通过某些表达（系统调用、库函数等）来获取(require)资源，同样，我们也能通过某些表达来释放(dispose)资源。<br>资源的正确管理十分重要，错误的资源的管理会导致资源的泄漏，比如内存的泄漏（可能导致系统崩溃）、文件句柄的泄漏（可能导致无法创建文件）、持续上锁的互斥锁（可能导致死锁）等。除此，还可能造成资源的双重释放、释放后使用等问题。<br><br>C++中，对象的生命周期是可以被定义的，对象生命的开始与结束都相应的会对应一个事件。这些事件背后的代码会在对象生命的开始与结束自动的执行对象初始化和对象消逝的代码。这些代码也被称作构造函数(constructors) 和析构函数(destructors)。<br>当我们需要创建对象时，我们通过构造函数初始化对象。而当对象需要销毁时我们则需要考虑额外的因素。对于局部变量对象而言，当期超出作用域时，就会自动地调用析构函数。而对于哪些动态分配内存的对象，使用delete或delete[]显式地释放内存时，析构函数才会被调用。<br><br>The RAII class is said to "own" the resource. It is responsible for cleaning up that resource at the appropriate time.<br><br>Resource&nbsp;acquisition&nbsp;is&nbsp;initialization（RAII），或称为&nbsp;Constructor&nbsp;Acquires,&nbsp;Destructor&nbsp;Releases (CADRe)，即构造函数获取资源，析构函数释放资源。这是最初用于C++的编程惯用法，旨在通过对象的生命周期来管理资源的获取和释放。<br>通过RAII，我们可以显式地定义相应的构造函数和析构函数，在对象生命周期的开始通过构造函数自动初始化并获取资源，并在对象超出作用域或删除对象时自动调用析构函数来释放资源，避免资源泄漏。需要显式定义的函数包括析构函数、拷贝构造函数、拷贝赋值运算符、移动构造函数、移动赋值运算符，这被称为"The&nbsp;Rule&nbsp;of&nbsp;Five"。<br>标准库中大量使用RAII和The&nbsp;Rule&nbsp;of&nbsp;Five，从而达到自动释放资源的目的。通过使用标准库和RAII，我们能够尽量避免手动管理资源，从而简化代码，提高安全性和可维护性。<br><br><br>局部对象就是在栈上创建的对象。当你在栈上创建对象时，它会自动调用构造函数。这是因为栈上的对象具有自动存储期（automatic storage duration），它们的生命周期由作用域(scope) 控制。当执行到 '}' 时，就会自动调用析构函数，随之栈帧销毁、函数返回。<br>#include &lt;iostream&gt;

class scope
{
public:
	scope(){
		std::cout &lt;&lt; "scope constructor" &lt;&lt; std::endl;
	}
	~scope(){
		std::cout &lt;&lt; "scope deconstructor" &lt;&lt; std::endl;
	}
};
struct test
{
	test(){
		std::cout &lt;&lt; "test constructor" &lt;&lt; std::endl;
	}
	~test(){
		std::cout &lt;&lt; "test deconstructor" &lt;&lt; std::endl;
	}
};

int main(){

	scope s;
	test t;
	return 0;
} // &lt;- End of scope
<br>du@DVM:~/Desktop/Cpp$ ./scope 
scope constructor
test constructor
test deconstructor
scope deconstructor
<br><br>由于堆上对象的生命周期通常比栈上对象的生命周期更长，因此堆上对象的构造和析构通常与&nbsp;new&nbsp;和&nbsp;delete&nbsp;关键字的使用相关联。当你使用&nbsp;new&nbsp;关键字创建一个新的对象时，会调用该对象的构造函数；而当你使用&nbsp;delete&nbsp;关键字销毁对象时，会自动调用该对象的析构函数。<br><br>malloc 和 free 函数改变为 new 和 delete 关键字的使用是从C语言过渡到C++内存管理方式的改进。虽然 new 和 delete 关键字在底层还是会调用 malloc 和 free，但是使用 new 和 delete 会调用对象的构造函数和析构函数，这是 malloc 和 free 所不具有的。<br>也就是说，new和delete提供RAII这种机制。这也是 new、delete 和 malloc、free 的最主要的差别。以下展示 new 和 delete的底层实现：<br>#include &lt;iostream&gt;
#include &lt;cstdlib&gt; // for malloc and free

void* operator new(size_t size) {
    void* ptr = std::malloc(size);
    if (!ptr) {
        throw std::bad_alloc();
    }
    return ptr;
}

void operator delete(void* ptr) noexcept {
    std::free(ptr);
}

class Entity {
public:
    Entity() {
        std::cout &lt;&lt; "Entity created" &lt;&lt; std::endl;
    }
    ~Entity() {
        std::cout &lt;&lt; "Entity destroyed" &lt;&lt; std::endl;
    }
};

int main() {
    Entity* e = new Entity();
    delete e;
    return 0;
}
<br><br>
<br>智能指针：C++11 引入了&nbsp;std::unique_ptr&nbsp;和&nbsp;std::shared_ptr&nbsp;智能指针。它们在构造时获取动态内存，在析构时自动释放内存。
<br>互斥锁：在多线程编程中，std::lock_guard&nbsp;和&nbsp;std::unique_lock&nbsp;利用 RAII 管理互斥锁的获取和释放。
<br>文件操作：C++ 标准库中的&nbsp;std::ifstream&nbsp;和&nbsp;std::ofstream&nbsp;也使用 RAII 来管理文件的打开和关闭。
<br><br>当我们想要申请堆内存资源时，我们会用 new 和 delete 关键字来申请和释放我们的内存资源。这两者总是成对出现，即当我们使用 new ，就不要忘记使用 delete。但是智能指针为我们提供了省去使用 delete 的便利。<br>智能指针有三种：<br>
<br>Unique pointers：是最简单的智能指针。unique_ptr可以看作一种作用域指针(scoped pointer)，在超出作用域时会自动销毁所管理的对象。（RAII）
<br>Shared pointer：引用计数，多个shared_ptr可以共享同一个对象。当引用数为0，自动释放堆内存资源。（RAII）
<br>Weak pointer：不增加引用计数，解决shared_ptr之间循环引用的问题。辅助 shared_ptr 防止循环计数导致的内存资源泄漏。
<br>智能指针实际上就是对裸指针的封装，实际上两个关键字仍然成对出现。其中规定 unique_ptr 所指向的堆对象只能有一个引用，不可以拷贝，也就是为什么叫做 unique pointer。例如：<br>std::unique_ptr&lt;Entity&gt; entity0 = std::make_unique&lt;Entity&gt;();
auto entity1 = entity0; // error
<br>unique_ptr 还提供异常安全性（exception safety）。也就是说它能够在异常发生时确保资源的正确释放，避免资源泄漏。具体来说，unique_ptr&nbsp;通过 RAII机制管理动态分配的内存，确保在对象生命周期结束时自动释放内存。<br>#include &lt;iostream&gt;
#include &lt;memory&gt;

class Entity
{
public:
	Entity(){
		std::cout &lt;&lt; "Entity created" &lt;&lt; std::endl;
	}
	~Entity(){
		std::cout &lt;&lt; "Entity destroyed" &lt;&lt; std::endl;
	}
	
};

template&lt;class T&gt;
class scopedPointer
{
private:
	T* m_ptr;
public:
	scopedPointer(const T* other_ptr) = delete;
	scopedPointer(T* other_ptr) = delete;
	scopedPointer&amp; operator=(const scopedPointer&amp; other) = delete;
	scopedPointer(T* ptr)
		: m_ptr(ptr)
	{
	}
	~scopedPointer(){
		delete m_ptr;
	}
    scopedPointer&amp; operator=(scopedPointer&amp;&amp; other) noexcept {
        if (this != &amp;other) {
            delete m_ptr;
            m_ptr = other.m_ptr;
            other.m_ptr = nullptr;
        }
        return *this;
	}
};
int main(){
	{
		scopedPointer* s_ptr = new Entity();

	}//&lt;--s_ptr销毁的时刻
	{
		std::unique_ptr&lt;Entity&gt; entity(new Enity()); 
		std::unique_ptr&lt;Entity&gt; entity = std::make_unique&lt;Entity&gt;();
	}
	std::cin.get();
	return 0;
}
<br>Copyable? NO! Movable? YES! 由于unique_ptr可移动不可拷贝，所以我们应当删去拷贝构造函数和对拷贝赋值运算符的重载。]]></description><link>https://congzhi.wiki/c-plus-plus/raii-and-scope-in-c++.html</link><guid isPermaLink="false">C Plus Plus/RAII and Scope in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Wed, 05 Mar 2025 16:39:54 GMT</pubDate></item><item><title><![CDATA[Smart Pointers in C++]]></title><description><![CDATA[ 
 <br>Do this at first: <a data-href="RAII and Scope in C++" href="https://congzhi.wiki/c-plus-plus/raii-and-scope-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">RAII and Scope in C++</a><br><br>在C++中，我们使用 new 和 delete/delete[] 在堆上实例化和删除对象。当你使用裸指针时，同一个作用域中的 new 和 delete 的数量总是需要匹配的，不然就可能引起内存泄漏。在使用裸指针删除对象时，你还需要注意类型的匹配（single-object form using delete, array using delete[]），不然就可能引起未定义行为。<br>尽管裸指针的使用强大且高效，但是人为地管理这些资源的释放是容不得一点粗心的。C++的标准库（C++11/C++14标准）中，我们有四种类型的智能指针，分别是：<br>
<br>auto_ptr<br>
C++98:&nbsp;初次引入。<br>
C++11:&nbsp;被标记为过时（Deprecated）。<br>
C++17:&nbsp;被移除。
<br>unique_ptr<br>
C++11:&nbsp;引入作为&nbsp;auto_ptr&nbsp;的替代品，独占所有权的智能指针。<br>
C++14:&nbsp;添加了&nbsp;make_unique&nbsp;工厂函数。
<br>shared_ptr<br>
C++11:&nbsp;引入引用计数智能指针，伴随&nbsp;make_shared&lt;T&gt;&nbsp;的使用。<br>
C++20:&nbsp;添加了对&nbsp;make_shared&lt;T[]&gt;&nbsp;的支持。
<br>weak_ptr<br>
C++11:&nbsp;引入“弱”引用智能指针，用于解决循环引用问题。
<br>这些智能指针通过对裸指针的包装，使得我们可以放心地申请资源而不担心发生任何的资源泄漏。这些智能指针会管理动态申请对象的生命周期，并在合适的适合销毁对象（包括异常事件）。<br>C++程序的编写目标就是去除所有的 raw pointer, raw new and raw delete。所以我们会用工厂函数来创建自己需要的智能指针。<br><br>当我们有使用智能指针的需求时，std::unique_ptr该是我们第一个想到的。作为一种scoped pointer，如我们在 <a data-href="RAII and Scope in C++" href="https://congzhi.wiki/c-plus-plus/raii-and-scope-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">RAII and Scope in C++</a> 中展示的一样，std::unique_ptr的大小和裸指针的大小是一样的。当你使用std::unique_ptr时，所使用的指令和使用裸指针的指令是一样的。<br><img alt="Pasted image 20241023154500.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20241023154500.png"><br><br>std::unique_ptr&nbsp;提供独占所有权的特性，也就是说在任何时候，std::unique_ptr&nbsp;都能保证只能有一个指针拥有资源。因此我们不能进行复制/拷贝操作，只能实现移动操作。试想，如果我们对&nbsp;std::unique_ptr&nbsp;进行了复制，就会有两个拥有对象所有权的指针，这与其的设计初衷相悖。当&nbsp;std::unique_ptr&nbsp;移动时，所有权转移，原来的指针会丢失对资源的所有权（nullptr），从而保持独占所有权的特性。<br><img alt="Pasted image 20241023153930.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20241023153930.png"><br>std::unique_ptr移动的操作示例：<br>#include &lt;memory&gt;
// Create a unique pointer using make_unique factory function.
std::unique_ptr&lt;Entity&gt; uptr1 = std::make_unique&lt;Entity&gt;();
// or `std::unique_ptr&lt;Entity&gt; uptr1 = std::unique_ptr&lt;Entity&gt;(new Entity);`

// Change ownership to uptr2.
std::unique_ptr&lt;Entity&gt; uptr2 = std::move(upre1);
<br><br>当你需要一个指向数组的&nbsp;unique&nbsp;pointer&nbsp;时，我们就要用到&nbsp;std::unique_ptr&lt;T[]&gt;。这种智能指针在析构时会调用&nbsp;delete[]，以正确释放数组内存。<br><img alt="Pasted image 20241023154839.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20241023154839.png"><br><br>除了模板参数T之外，std::unique_ptr也一直有第二个模板参数，我们称之为Deleter，即删除器。删除器的作用是什么呢？智能指针难道不应该接管一切么？智能指针让我们免于资源泄漏，但是我们需要删除器来释放这些资源。通过智能指针管理非常见的资源（非堆上资源）时，我们就需要定义一个自己的删除器。<br><img alt="Pasted image 20241023155605.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20241023155605.png"><br>如果不定义任何的Deleter，unique_ptr就会使用默认的删除器std::default_delete。默认的删除器负责对堆上动态资源进行释放。<br>template&lt;class T, class Deleter = std::default_delete&lt;T&gt;&gt;
class unique_ptr {
    T *p_ = nullptr;
    Deleter d_;
public:
    explicit unique_ptr(T* p = nullptr, Deleter d = Deleter()) : p_(p), d_(d) {}
    ~unique_ptr() {
        if (p_) d_(p_);
    }
    // Copy is not allowed.
    unique_ptr(const unique_ptr&amp;) = delete;
    unique_ptr&amp; operator=(const unique_ptr&amp;) = delete;
    // Object is movable.
    unique_ptr(unique_ptr&amp;&amp; other) noexcept : p_(other.p_), d_(std::move(other.d_)) {
        other.p_ = nullptr;
    }
    unique_ptr&amp; operator=(unique_ptr&amp;&amp; other) noexcept {
        if (this != &amp;other) {
            if (p_) d_(p_);
            p_ = other.p_;
            d_ = std::move(other.d_);
            other.p_ = nullptr;
        }
        return *this;
    }
    T* get() const { return p_; }
    T* release() { T* tmp = p_; p_ = nullptr; return tmp; }
    void reset(T* p = nullptr) {
        if (p_ != p) {
            if (p_) d_(p_);
            p_ = p;
        }
    }
};
template&lt;class T&gt;
struct default_delete {
    void operator()(T *p) const { delete p; }
};
<br>如果我们想在作用域内释放内存，我们可以使用reset()方法提前释放内存。<br><br>文件句柄、网络连接、设备句柄等这些资源可能并不是在堆上分配的，我们并不能用delete删除这些资源。Deleter的作用就显现出来了，对那些不能delete的资源进行管理。智能指针可以通过自定义删除器来正确释放它们。假设我们有一个数据库连接：<br>struct DBConnection{
// All kinds of resources.
// All kinds of methods.
};
struct DBDeleter{
	void operator()(DBConnection* db){
		std::cout &lt;&lt; "Closing Database Connection.\n";
		dbClosing(db);
	}
};
class DBManager{
	std::unique_ptr&lt;DBConnection, DBDeleter&gt; dbConnect_;
public:
	explicit DBManager(DBConnection* dbConnect) : dbConnect_(dbConnect){}
	void query(const std::string&amp; q){
		if(dbConnect_){
			db_query(dbConnection_.get(), q.c_str());
		}
	}
	void close(){
		dbConnection_.reset();
	}
};

int main(){
	DBConnection* db = dbOpen("example.db");
	DBManager dbManager(db);
	dbManager.query("SELECT * FROM Student");
	// dbManager.close(); // &lt;-Close the database now.
	return 0;
} // &lt;- Close the database by using DBDeleter.
<br><br>std::shared_ptr&nbsp;是最接近裸指针的智能指针。不同于上一节中的&nbsp;std::unique_ptr，使用&nbsp;std::shared_ptr&nbsp;创建的对象的所有权是由所有指向该对象的&nbsp;std::shared_ptr&nbsp;共享的。只有当最后一个&nbsp;std::shared_ptr&nbsp;停止指向对象时，对象的资源才会被释放。<br><br>std::shared_ptr&nbsp;的这种&nbsp;共享&nbsp;特性是通过&nbsp;引用计数&nbsp;来实现的。通过引用计数，shared_ptr 就能知道当前有多少个指针在共享资源。这种对对象资源的控制使得&nbsp;std::shared_ptr&nbsp;需要额外的控制块来管理对象资源的释放。那么控制块放到哪里？<br>控制块通常会放在堆上，与对象一起分配。这样做的好处是确保控制块的生命周期与对象的生命周期一致。当所有指向对象的&nbsp;shared_ptr&nbsp;被销毁时（并且这时如果weak ref count = 0），控制块也会被自动释放。如果控制块放在栈上，当函数返回或栈帧被销毁时，控制块就会被销毁，而不管是否还有&nbsp;shared_ptr&nbsp;指向对象。这将导致引用计数失效，可能在某些情况下导致对象被提前销毁，或者造成资源泄漏。<br>因而，std::make_shared工厂函数总会创建一个控制块，并且 std::shared_ptr的大小是裸指针大小的两倍大（一个指针指向对象，一个指针指向控制块）。而且控制块的内存必须在堆上动态分配。当std::unique_ptr转换为std::shared_ptr时，构造函数也是会生成相应的控制块。<br><img alt="Pasted image 20241024004507.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20241024004507.png"><br>
要实现引用计数，我们在构造函数中加入reference_count++;，并在拷贝操作时做同样的事情来增加引用计数。并且要在引用计数为0时释放掉对象资源。在对引用计数（弱引用计数同）进行操作时，由于++、--是read-modify-write操作指令，所以对引用计数的操作必须是原子性的。<br>下面我们对std::shared_ptr进行拷贝时，我们拷贝了ptr to T和ptr to control block，并使得引用计数增加1。但当我们进行移动操作时，我们不需要对引用计数进行操作，这是因为所有权转移了。<br><img alt="Pasted image 20241024005717.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20241024005717.png"><br><br>我们已经有一个指向对象的指针了，为什么控制块中还有指向执行对象的指针？假设我有这几个类<br>struct Fruit { int juice; }; 
struct Vegetable { int fiber; }; 
struct Tomato : Fruit, Vegetable { int sauce; };
<br>当我创建了：<br>std::shared_ptr&lt;Tomato&gt; tomato = make_shared&lt;Tomato&gt;;
std::shared_ptr&lt;Fruit&gt; fruit = tomato;
std::shared_ptr&lt;Vegetable&gt; fruit = tomato;
<br>当我们创建一个指向&nbsp;Tomato&nbsp;实例的&nbsp;std::shared_ptr&lt;Fruit&gt;&nbsp;或&nbsp;std::shared_ptr&lt;Vegetable&gt;，这些指针会指向&nbsp;Tomato&nbsp;对象内的&nbsp;Fruit&nbsp;或&nbsp;Vegetable&nbsp;部分。由于控制块仍然是共享的，它们最终管理的是同一个&nbsp;Tomato&nbsp;实例，所以控制块会指向这个完整的对象。<br><br>和&nbsp;std::unique_ptr&nbsp;一样，std::shared_ptr&nbsp;也使用&nbsp;delete&nbsp;作为其默认的资源销毁机制（Resource-destruction&nbsp;mechanism）。但是不同的是，每个&nbsp;std::unique_ptr&nbsp;独立持有对所指对象的控制权，而&nbsp;std::shared_ptr&nbsp;的控制权是共享的。对象资源的控制由控制块来完成。<br><img alt="Pasted image 20241024015023.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20241024015023.png"><br>这种由于控制权的不同，就使得std::unique_ptr本身有权力来管理对象。所以std::unique_ptr中，deleter是智能指针的一部分。<br>struct CustomDeleter {
    void operator()(int* p) const {
        delete p;
    }
};
// Deleter type is part of the smart pointer.
std::unique_ptr&lt;int, CustomDeleter&gt; p1(new int); 
<br>而std::shared_ptr不同，没有指针真正拥有对象的ownership，ownership由控制块管理管理。因此，在std::shared_ptr中，deleter并不作为智能指针的一部分。而控制块又只有一个，所以即使我们有两个std::shared_ptr，只要指向资源相同，Deleter就是相同的：<br>struct CustomDeleter {
    void operator()(int* p) const {
        delete p;
    }
};
// Deleter is not part of the smart pointer.
std::shared_ptr&lt;int&gt; p(new int, CustomDeleter()); 
std::shared_ptr&lt;int&gt; p2 = p; 
<br><br>当我们用工厂函数创建好std::shared_ptr了之后，我们在堆上会存在两块空间，我们可以将这两块空间合并起来，以避免外部碎片的产生。大多数的库都支持下面这种实现方式。<br><img alt="Pasted image 20241024145414.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20241024145414.png"><br>由于我们的控制块和对象资源在同一块内存块中，我们甚至能够将控制块中的指针优化掉。<br><img alt="Pasted image 20241024145703.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20241024145703.png"><br><br>在shared_ptr中，我们用ref count来控制对象的生命周期。然而，当两或多个shared_ptr相互持有对方的shared_ptr时，就可能发生循环引用，导致引用计数永远不会降到0，从而导致内存泄漏。为了避免循环引用的情况，我们可以使用weak_ptr，它不会增加引用计数，允许对象正常销毁。<br>prevent dangling pointer<br>循环XX<br><img alt="Pasted image 20241214224127.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20241214224127.png"><br>shared_ptr共享controlled object，因此其指向对象的生命周期由shared_ptr所控制。而weak_ptr之间共享控制块。当对象已经被销毁，如果这时weak ref count为0，控制块就会被销毁。<br><img alt="Pasted image 20241214224219.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20241214224219.png"><br><br>weak_ptr 的内存结构和 shared_ptr 是相同的。在学习shared_ptr时，我们实际上并没有用到weak reference，而这个结构的存在和控制块的生命周期是息息相关的。weak_ptr并不和shared_ptr一样共享其指向的对象，也就是说，你并不能解引用一个weak_ptr，你必须用lock()方法先将其转换成一个shared_ptr，这个方法是线程安全的。<br>#include &lt;iostream&gt;
#include &lt;memory&gt;

struct test {
    int a = 10;
};

int main() {
    std::shared_ptr&lt;test&gt; t1 = std::make_shared&lt;test&gt;();
    std::weak_ptr&lt;test&gt; t2 = t1;

    if (auto t2_shared = t2.lock()) {
        std::cout &lt;&lt; t1-&gt;a &lt;&lt; " " &lt;&lt; t2_shared-&gt;a &lt;&lt; std::endl;
    } else {
        std::cout &lt;&lt; "t2 is expired" &lt;&lt; std::endl;
    }
    return 0;
}
<br><br>CRTP]]></description><link>https://congzhi.wiki/c-plus-plus/smart-pointers-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Smart Pointers in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Mon, 24 Mar 2025 12:40:56 GMT</pubDate><enclosure url="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20241023154500.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/c-plus-plus/pics/pasted-image-20241023154500.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Standard Array Basics (ENG)]]></title><description><![CDATA[ 
 <br>This note is not about std::array at the first place. We are going to talk about the C-style array.<br><br>Array is a homogeneous data structure where you store all items of same kind together. The data is stored in a contiguous block of memory (Virtual Memory in particular). In programming languages, you could often see something like int id[100];, which basically means an array named id that can store 100 integers. <br>This type of data structure offers many advantages. It is easy to use, simple to index, and changes are quite straightforward. Moreover, if you are familiar with the memory layout of the operating system, you would notice that arrays allow for efficient memory usage and provide fast access to elements due to their contiguous memory allocation. (Caching and buffering)<br>When you want to index an element, you basically indicate the offset of the element, which starts at [0]. If you want to iterate through the entire id array, you can do it like this:<br>#include &lt;iostream&gt;

int main(){
	int id[100]; // Assuming the array is already initialized
	for(int i = 0; i &lt; 100; i++){
		std::cout &lt;&lt; id[i];
	}
}
<br>But with the help of standard library, it could be like this, we would talk this later:<br>#include &lt;iostream&gt;
#include &lt;array&gt;

int main() {
    std::array&lt;int, 100&gt; id; // Assuming the array is already initialized
    for(const int&amp; element : id) {
        std::cout &lt;&lt; element &lt;&lt; std::endl;
    }
    return 0;
}
<br>This also be called range-based for loop, we will also cover this later on.<br><br>C++ standard library provides a wealth of algorithms to use. We could use this function iota help us initialize our array with sequential values starting from a specified value. Below is a example of how you can do about this: <br>#include &lt;iostream&gt;
#include &lt;numeric&gt;
#include &lt;iterator&gt; 

int main() {
    int ids[100];
    std::iota(std::begin(ids), std::end(ids), 0);
    for(int i = 0; i &lt; 100; i++) {
        std::cout &lt;&lt; ids[i] &lt;&lt; std::endl;
    }
    return 0;
}
<br>Because this iterates the array, you may should include the &lt;iterator&gt; for a good practice.<br>Everything looks good so far, but there is one limitation: the size of an array is fixed, and you cannot resize it. In the example above, we have ids[100];, which is a raw array. The array size is decided only at compile time only, you cannot change this at runtime, this 100 element size is all you can get.<br>If you try to index an element beyond the size limit of an array, you will likely encounter an error. So, what if you want an array with a bigger range? What machine can really do for you is allocate another new piece of memory, copy the data to it, and then free the current array. And we have so called dynamic array std::vector is actually following this pattern internally, managing memory allocation and resizing automatically for you.<br><br>The standard array is still a fixed-size array provided by the C++ Standard Library (STL). It offers the same semantics as a struct type holding a C-style array T[N] as its only non-static data member, but it doesn't decay to T* automatically.<br>template&lt;  
    class T,  
    std::size_t N  
&gt; struct array;
<br>Standard array can be initialized like this:<br>std::array&lt;int, 3&gt; a = {1, 2, 3};
<br>And alone with this data type, STL provides tons of member functions you can use. Now you can access the element using at function with a bound checking.<br>#include &lt;iostream&gt;
#include &lt;numeric&gt;
#include &lt;iterator&gt; // because &lt;array&gt; library covered the &lt;iterator&gt;, you dont really need this explicitly...
#include &lt;array&gt;

int main() {
    std::array&lt;int, 100&gt; ids = {};
    std::iota(std::begin(ids), std::end(ids), 0);
    // std::iota(ids.begin(), ids.end(), 0);
    ids.at(1) = 5; // ok
    ids.at(1000) = 0; //You will get a error instead of a segmentation fault.
    for(int i = 0; i &lt; 100; i++) {
        std::cout &lt;&lt; ids[i] &lt;&lt; std::endl;
    }
    return 0;
}
/*
You can also use std::fill() to initialize your array with a specific value.
#include &lt;algorithm&gt;
	std::fill(ids.begin(), ids.end(), 0); // Fill every element in array ids to 0
*/
<br><br>#include &lt;iostream&gt;
#include &lt;numeric&gt;
#include &lt;iterator&gt; 
#include &lt;array&gt;

int main() {
    std::array&lt;int, 100&gt; ids = {};
    std::iota(std::begin(ids), std::end(ids), 0);
    ids.at(1) = 5; // ok
    ids.at(1000) = 0; //You will get a error instead of a segmentation fault.
    for(int element: ids) {
        std::cout &lt;&lt; elememt &lt;&lt; std::endl;
    }
    for(auto element: ids){
	    std::cout &lt;&lt; element &lt;&lt; std::endl;
    }
    return 0;
}
<br><br>We talk about Big-Oh in computer science. We know that array operations have different time complexities based on the type of operation being performed. When we traverse an array, we have a time complexity of O(n). On the other hand, tree structures, for example, searching for an element in a balanced binary search tree has a time complexity of O(log n).<br>It looks like trees are somehow better for certain traversals than arrays. However, on modern machines, we have something called cache. In this case, arrays can be quicker when the size n is not excessively large. Due to arrays' contiguous memory layout, they can benefit from spatial locality, which means more cache hits. Tree structures, on the other hand, may experience a lot of cache misses due to their non-contiguous layout.]]></description><link>https://congzhi.wiki/c-plus-plus/standard-array-basics-(eng).html</link><guid isPermaLink="false">C Plus Plus/Standard Array Basics (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Wed, 19 Mar 2025 15:49:41 GMT</pubDate></item><item><title><![CDATA[Standard Variant in C++]]></title><description><![CDATA[ 
 <br>Do this at first: <a data-href="Unions in C++" href="https://congzhi.wiki/c-plus-plus/unions-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Unions in C++</a><br><br>在联合体的小节中，我们谈到由于联合体的特性，每次只能有一个成员处于 active 的活跃状态，而其他的成员会处于 inactive 的非活跃状态（也就是未定义状态）。这就导致了我们对这些未定义数据成员的访问都算是未定义行为。而大多数的编译器并不会阻止我们对这些非活跃成员的访问。<br>而 std::variant 是一个对 union 的封装，它不允许用户访问那些可能引起未定义行为的非活跃成员。它提供 std::get() 的接口给用户来访问某个类型或索引的值。当用户访问到非活跃的成员时，就会抛出一个异常。我们用下面这个例子说明一下：<br>#include &lt;iostream&gt;
#include &lt;variant&gt;

int main() {
    std::variant&lt;short, int, float, double&gt; U;
    
    U = 7; // assigns 7, which is interpreted as int
    std::cout &lt;&lt; std::get&lt;short&gt;(U) &lt;&lt; std::endl; // not okay, U currently holds int, throw std::bad_variant_access type exception
    std::cout &lt;&lt; std::get&lt;int&gt;(U) &lt;&lt; std::endl; // okay
    
	U = 7.5; // assigns 7.5, which is interpreted as double
	std::cout &lt;&lt; std::get&lt;double&gt;(U) &lt;&lt; std::endl; // okay
	std::cout &lt;&lt; std::get&lt;float&gt;(U) &lt;&lt; std::endl; // not okay
    return 0;
}
<br>此外，我们还可以通过 std::get_if() 来获取 std::variant 中存储的值（指针）。和上面的 std::get() 不同的是， std::get_if() 并不会抛出异常，如果类型不匹配或者提供的索引是无效的，它会返回一个 nullptr。如果类型是匹配的，就会返回指向存储值的指针。<br>std::variant&lt;short, int&gt; U = 42;
if (int* pval = std::get_if&lt;int&gt;(&amp;U)) {
    std::cout &lt;&lt; "Value: " &lt;&lt; *pval &lt;&lt; std::endl;
} else {
    std::cout &lt;&lt; "Type mismatch or invalid access." &lt;&lt; std::endl;
}
<br><br>为了实现类型安全， std::variant 额外用一个 4 字节的 index 值来存储当前处于活跃状态成员变量的索引值。这也就是为什么当你用 sizeof() 查看大小时，你会发现 std::variant 类型往往比相同结构的 union 大四个字节。<br>std::variant 实际上就相当于：<br>namespace std {
    template&lt;typename... Types&gt;
    class variant {
    private:
        union Storage {
            std::aligned_union_t&lt;0, Types...&gt; data; // aligned storage for the largest type
        } storage;
        int type_index; // keeps track of the current active type
    public:
        // Constructors, destructors, assignment operators, and member functions would be implemented here
        // Example accessor function
        int index() const {
            return type_index;
        }
    };
}
<br>每个值都能够对应着一个 union 里面的类型，通过当前保存的 index 值，std::variant 就能够知道哪个数据成员是活跃的，从而保证了类型安全。我们用 index() 函数来获取当前活跃类型的索引值。<br>#include &lt;iostream&gt;
#include &lt;variant&gt;

int main() {
    std::variant&lt;short, int, float, double&gt; U;
    
    U = static_cast&lt;short&gt;(7); // assigns to short type, which index is 0
    std::cout &lt;&lt; U.index() &lt;&lt; std::endl; // 0
    
    U = static_cast&lt;int&gt;(7); //  assigns to short type, which index is 0 1
    std::cout &lt;&lt; U.index() &lt;&lt; std::endl; // 1
    
	U = static_cast&lt;float&gt;(7.5); //  assigns to float type, which index is 2
    std::cout &lt;&lt; U.index() &lt;&lt; std::endl; // 2
    
	U = static_cast&lt;double&gt;(7.5); //  assigns to double type, which index is 3
    std::cout &lt;&lt; U.index() &lt;&lt; std::endl; // 3
    
    return 0;
}
<br>既然索引对应着唯一的类型，我们实际上也可以直接用 index 值对数据成员进行访问。同样的，如果访问的索引并不是活跃成员的索引，也会抛出一个异常。如：<br>#include &lt;iostream&gt;
#include &lt;variant&gt;

int main() {
    std::variant&lt;short, int, float, double&gt; U = 7; // int type, index = 1
    std::cout &lt;&lt; std::get&lt;1&gt;(U) &lt;&lt; std::endl; // 7
    std::cout &lt;&lt; std::get&lt;0&gt;(U) &lt;&lt; std::endl; // throw std::bad_variant_access
    return 0;
}
<br><br>当抛出异常时，我们可以对其进行捕获并处理。<br>#include &lt;iostream&gt;
#include &lt;variant&gt;

int main(){
	std::variant&lt;short, int&gt; U = 7; // int type, index = 1
    try {
        std::cout &lt;&lt; std::get&lt;short&gt;(U) &lt;&lt; std::endl;
	} catch (const std::bad_variant_access&amp; ex) {
        std::cout &lt;&lt; ex.what() &lt;&lt; std::endl;
    }
    return 0;
}
]]></description><link>https://congzhi.wiki/c-plus-plus/standard-variant-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Standard Variant in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Mon, 03 Mar 2025 14:49:24 GMT</pubDate></item><item><title><![CDATA[Static Dispatch in C++ (ENG)]]></title><description><![CDATA[ 
 <br>Static Dispatch has nothing to do with <a data-href="Static Keyword in C++" href="https://congzhi.wiki/c-plus-plus/static-keyword-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Static Keyword in C++</a>.<br><br>Static dispatch, or you might be more familiar with the term "static polymorphism." In C++, static polymorphism is achieved using templates and function overloading. It allows polymorphism in compile-time, meaning the function to be called is determined at compile time. To make that happen, there has to be some way to distinguish overloaded functions.<br>What static polymorphism does is make the parameter a part of the function signature. In the following example, although we call the function print twice, because the parameter type is different, we actually call different functions:<br>// Achieve static polymorphism with function overloading:

#include &lt;iostream&gt;

void print(int x) {
    std::cout &lt;&lt; "Called print(int): " &lt;&lt; x &lt;&lt; std::endl; // _Z5printi
}

void print(double x) {
    std::cout &lt;&lt; "Called print(double): " &lt;&lt; x &lt;&lt; std::endl; // _Z5printd
}

int main() {
    print(4);   // Calls print(int)
    print(4.5); // Calls print(double)
    return 0;
}
<br>This demonstrates how static polymorphism allows the compiler to determine the correct function to call based on the parameter types at compile time, ensuring efficient and type-safe code.<br>In C, static polymorphism is not allowed because the name mangling is different between C and C++. In C, the function name generated by the compiler is unique and does not include any parameter information. As a result, function overloading is not supported:<br>void print(int x){} // The compiler generates the symbol _print
void print(double x){} // Error: void print(int x) already exists
<br>This is why you often see extern "C" used when incorporating a C library into a C++ project. It tells the C++ compiler to disable name mangling for the specified code, ensuring the function names remain compatible with the naming conventions in C.<br><br>Static polymorphism is always achieved using templates, allowing you to write generic code that works with any type. The template will help you generate the actual function code at compile time. In the code below, we only define one single function template, and the compiler will generate print&lt;int&gt;(int) and print&lt;double&gt;(double) for us automatically, which allows you to write flexible and reusable code.<br>// Achieve static polymorphism with templates:

#include &lt;iostream&gt;

template &lt;typename T&gt;
void print(T t) {
    std::cout &lt;&lt; "Called print: " &lt;&lt; t &lt;&lt; std::endl;
}

int main() {
    print(4);   // Calls print&lt;int&gt;(int)
    print(4.5); // Calls print&lt;double&gt;(double)
    return 0;
}
<br>This concept can also be applied to class member function overloading:<br>#include &lt;iostream&gt;

template &lt;typename T&gt;
void show(T t) {
    t.show(); // Static dispatch
}

class Base {
public:
    void show() const {
        std::cout &lt;&lt; "Base class show" &lt;&lt; std::endl;
    }
};

class Derived {
public:
    void show() const {
        std::cout &lt;&lt; "Derived class show" &lt;&lt; std::endl;
    }
};

int main() {
    Base b;
    Derived d;
    show(b); // Calls Base::show
    show(d); // Calls Derived::show
    return 0;
}
<br>Now, you're welcomed here: <a data-href="Operator Overloading in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/operator-overloading-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Operator Overloading in C++ (ENG)</a>]]></description><link>https://congzhi.wiki/c-plus-plus/static-dispatch-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Static Dispatch in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Mar 2025 17:01:36 GMT</pubDate></item><item><title><![CDATA[Static Keyword in C++]]></title><description><![CDATA[ 
 <br><br>当变量或者函数被声明为 static 后，我们就称其为静态变量/函数。那么静态代表了什么？在进程的虚拟内存空间里，我们看到，当变量被声明为 static 后，它会被放在数据段（初始化非 0 ）或 BSS 段（初始化为 0 /未初始化）中。这意味着静态变量的生命周期会一直持续到程序结束。也被称作 static storage duration 。<br>#include &lt;iostream&gt;

int global_var; // Un-initialized, will be placed in the BSS segment
static int static_var; // Un-initialized, also placed in the BSS segment

static void static_func() {
    global_var++;
    static_var++;
}

// Non-static function accessible from other translation units
// Increments static_var
void func() {
    static_var++;
}

int main() {
    int local_var; // Un-initialized local variable, will be placed on the stack

    std::cout &lt;&lt; global_var &lt;&lt; std::endl
              &lt;&lt; static_var &lt;&lt; std::endl;
    return 0;
}
<br>那静态函数有什么用呢？这就不得不提到 static 的另一个特性：内部链接性。<br><br>我们说被声明为 static 的静态函数和变量具有内部链接性，什么意思呢？就是说我们定义的静态变量/函数只在定义它们的翻译单元（translation unit）内可见。一个翻译单元是由一个源文件及其直接或间接包含的所有头文件组成。编译器会独立编译每个翻译单元，最后链接器会将这些编译好的翻译单元合并成一个可执行程序。<br>我们用一个例子说明：<br>// main.cpp
#include &lt;iostream&gt;
#include "static_unit.hpp"

int main() {
    // static_unit_func(); // ld error, no function definition
    static_func(); // Calls static_func() defined in static_unit.hpp
    func(); // Calls func() which is defined in static_unit.cpp
    return 0;
}
<br>// static_unit.hpp
extern int global_var; // Declares that global_var is defined in another translation unit.

static int static_var; // Declaration

// Function declarations
static void static_unit_func();
static void static_func();
void func();

static void static_func(){ // No naming conflict, no linker error
	global_var += 10;
	static_var += 10;
	std::cout &lt;&lt; "global_var shared by all the tranlation unit : " &lt;&lt; global_var &lt;&lt; std::endl
              &lt;&lt; "static_var specific owning by main.cpp       : " &lt;&lt; static_var &lt;&lt; std::endl;
}
<br>在这个例子中， main.cpp 和 static_unit.hpp 是一个翻译单元。 #include 预编译指令的作用就是把被 included 的文件全部复制到源文件中。这里的 static_unit.hpp 作为 static_unit.cpp 的接口。包含一些变量和函数的声明，在编译的时候提醒编译器我们有这个变量/函数。<br>static_unit.cpp 是另外一个翻译单元。待会当你运行程序后，你会发现静态变量/函数只能在相同的翻译单元中被使用。<br>// static_unit.cpp
#include &lt;iostream&gt;
// #include "static_unit.cpp" // Be commented

int global_var; // Uninitialized, will be placed in the BSS segment.
static int static_var = 0; // Definition

static void static_unit_func(){ // A static_unit.cpp specific function
}

static void static_func() {
    global_var++;
    static_var++;
}

// Non-static function accessible from other translation units. (An interface)
// Increments both global_var and static_var.
void func() {
    global_var++;
    static_var++;
    std::cout &lt;&lt; "global_var shared by all the tranlation unit : " &lt;&lt; global_var &lt;&lt; std::endl
              &lt;&lt; "static_var specific owning by static_unit.cpp: " &lt;&lt; static_var &lt;&lt; std::endl;
}
<br>运行上面的代码，你会发现尽管我们在不同的翻译单元内同时定义了一个 static_func() 函数，但链接时并没有引发任何的命名冲突。而且每个翻译单元中的静态变量只能由翻译单元内的函数进行访问。不难发现，内部链接性能够规避不同单元之间的命名冲突，确保变量或函数在其他翻译单元中不可见。<br>运行结果如下：<br>global_var shared by all the tranlation unit : 10
static_var specific owning by main.cpp       : 10
global_var shared by all the tranlation unit : 11
static_var specific owning by static_unit.cpp: 1
<br><br>在类中，我们还有静态成员变量和静态成员函数。和前面我们了解到的 static 语义不同，在类中，static 关键字用于声明这些成员并不受类实例的约束。换言之，静态成员变量/函数是被所有实例所共享的。<br>比如，我们有下面的例子：<br>// example.hpp

class Example{
public:
	static int s_var;
	static int get_s_var();
	Example();
	~Example();
};
<br>// main.cpp
#include &lt;iostream&gt;
#include "example.hpp"
int main(){
	Example e1;
	Example e2;
	{
		Example e3;
		Example e4;
		std::cout &lt;&lt; "We now have " &lt;&lt; Example::get_s_var() &lt;&lt; " instance." &lt;&lt; std::endl;
	}
	std::cout &lt;&lt; "We now have " &lt;&lt; Example::get_s_var() &lt;&lt; " instance." &lt;&lt; std::endl;
	std::cout &lt;&lt; "I can read the static data member: " &lt;&lt; Example::s_var &lt;&lt; std::endl;
}
<br>// example.cpp
#include "example.hpp"

int Example::s_var = 0;
int Example::get_s_var(){
	return s_var; // Equals return Example::s_var;
}
Example::Example(){
	s_var++;
}
Example::~Example(){
	s_var--;
}
<br>输出结果：<br>We now have 4 instance.
We now have 2 instance.
<br>我们发现，即使类成员变量/函数的定义在 example.cpp 这个文件域(file scope)中，和 main.cpp 是独立的翻译单元，但是我们仍然能在 main.cpp 中访问得到静态的成员变量和成员函数。也就是说，静态的成员函数和成员变量并不具有内部链接性(internal linkage)。<br><br>静态成员函数只能访问静态成员变量。因为静态成员函数没有 this 指针，所以不能访问非静态的成员变量。这是一个例子：<br>class Example{
public:
	int var;
	static int s_var;
	static int s_func();
};
int Example::s_var = 0;
int Example::s_func(){
	var++; // invalid use of member 'Example::var' in static member function
	s_var++; 
	return s_var;
}
int main(){

	return 0;
}
<br>由于 var 不是静态成员变量，所以编译会出错。<br><br>静态成员变量相当于一个带有访问属性的全局静态变量，namespace 是类的类名。和类外的静态变量一样，它们都具有 static storage duration 。静态成员变量存储在静态存储区（通常是 .data 段或 .bss 段），但它的作用域仍然是类的作用域（命名空间）。<br>因为静态成员变量是在类的所有实例之间共享的，而类的定义通常在头文件中。如果在类内部初始化静态成员变量，这样的初始化将在每个包含这个头文件的翻译单元中重复进行，从而导致链接时出现多重定义错误。<br><br>在 local scope {} 内定义的局部 static 变量的生命周期和全局 static 变量一样。但它也具有局部的访问属性，也就是说，只有在 local scope 内部才能访问到这个静态变量。<br><br>class Singleton
{
public:
	static Singleton&amp; Get
	{
		static Singleton* s_Instance = nullptr;
		return *s_Instance; 
	}
};
]]></description><link>https://congzhi.wiki/c-plus-plus/static-keyword-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Static Keyword in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sat, 15 Mar 2025 10:34:34 GMT</pubDate></item><item><title><![CDATA[STL Container - Standard Array in C++]]></title><description><![CDATA[ 
 <br>Do this at first: <a data-href="Standard Array Basics (ENG)" href="https://congzhi.wiki/c-plus-plus/standard-array-basics-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Standard Array Basics (ENG)</a><br>at有bound checking<br>
[] 没有bound checking]]></description><link>https://congzhi.wiki/c-plus-plus/stl-container-standard-array-in-c++.html</link><guid isPermaLink="false">C Plus Plus/STL Container - Standard Array in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Wed, 19 Mar 2025 15:55:59 GMT</pubDate></item><item><title><![CDATA[STL Container - Standard Span Since C++20]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/c-plus-plus/stl-container-standard-span-since-c++20.html</link><guid isPermaLink="false">C Plus Plus/STL Container - Standard Span Since C++20.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Wed, 19 Mar 2025 16:04:29 GMT</pubDate></item><item><title><![CDATA[STL Container - Standard Vector in C++]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/c-plus-plus/stl-container-standard-vector-in-c++.html</link><guid isPermaLink="false">C Plus Plus/STL Container - Standard Vector in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Wed, 19 Mar 2025 16:08:13 GMT</pubDate></item><item><title><![CDATA[STL in C++ (Pre-Part)]]></title><description><![CDATA[ 
 <br><br>STL，全称标准模板库（Standard Template Library），是 C++ 中最为重要的部件之一，也是 C++ 如此强大的一大因素。STL 的架构思想主要由 Alexander Stepanov 所创建，他也是最早提出泛型编程概念的人之一。<br>C++ STL 最早由 Alexander Stepanov 在 1992 年向 ANSI/ISO C++ 标准委员会提交，并在 1994 年被正式采纳，最终在 C++98 标准中成为 C++ 标准库的一部分。自此，STL 经过多次改进和扩展，并在 C++11 和后续版本中增加了更多功能和优化（移动语义等）。<br><br>STL 提供了四大部件：算法、容器、函数和迭代器。并且这四大部件彼此分离，使得 STL 的可扩展性非常好，你可以实现自己的容器或迭代器等来匹配标准模板库中的其他部件。<br>STL 容器包括泛型的序列容器和关联容器。容器是存储数据的对象，通过模板，你可以用 STL 容器存储任何内置类型或是用户自定义类型。常见的容器有：<br>
<br><a data-tooltip-position="top" aria-label="STL Container - Standard Array in C++" data-href="STL Container - Standard Array in C++" href="https://congzhi.wiki/c-plus-plus/stl-container-standard-array-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">std::array</a>
<br><a data-tooltip-position="top" aria-label="STL Container - Standard Vector in C++" data-href="STL Container - Standard Vector in C++" href="https://congzhi.wiki/c-plus-plus/stl-container-standard-vector-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">std::vector</a>
<br>std::deque: A double-ended queue providing fast insertion and deletion at both ends.
<br>std::list: A doubly circular linked list that allows bidirectional traversal.
<br>std::forward_list :A singly forward linked list that supports only forward traversal.
<br>std::set: An ordered container that stores unique elements and uses a balanced binary search tree.
<br>std::map: An ordered container that stores key-value pairs with unique keys, using a balanced binary search tree.
<br>std::unordered_map
<br>std::unordered_set
<br>迭代器是 STL 中访问容器的方式。迭代器是对裸指针的封装，相当于指向当前位置的指针。与裸指针相比，迭代器通常包含边界检查(bound checking)、统一性和可扩展性。不同的迭代器还会提供不同访问容器的语义。在 STL 中，我们有五种类型的迭代器：<br>
<br>输入迭代器：只能读
<br>输出迭代器：只能写
<br>前向迭代器：可读可写，向前移动
<br>双向迭代器：可读可写，双向移动
<br>随机访问迭代器
<br>算法提供了对容器进行操作的方法。这些算法是通用的，可以与任何容器和迭代器配合使用。常见的算法有：<br>
<br>std::sort
<br>std::find
<br>std::accumulate
<br>std::copy
<br>std::transform
<br>std::for_each
<br>函数对象是可以像函数一样使用的对象。它们通常用于算法中来提供灵活的操作。常见的函数对象有：<br>
<br>std::less
<br>std::greater
<br>std::plus
<br>std::minus
]]></description><link>https://congzhi.wiki/c-plus-plus/stl-in-c++-(pre-part).html</link><guid isPermaLink="false">C Plus Plus/STL in C++ (Pre-Part).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sun, 23 Mar 2025 09:29:00 GMT</pubDate></item><item><title><![CDATA[String Library in C++]]></title><description><![CDATA[ 
 <br>Do this at first: <a data-href="Character Literal &amp; String Literal in C++" href="https://congzhi.wiki/c-plus-plus/character-literal-&amp;-string-literal-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Character Literal &amp; String Literal in C++</a><br><br>template&lt;
    class CharType,  
    class Traits = std::char_traits&lt;CharType&gt;,  
    class Allocator = std::allocator&lt;CharType&gt;  
&gt; class basic_string;
<br><br>实际上，字符串 string 就是关于不同字符的数组。在 C++ 中，我们有 std::array 的标准库容器，我们还需要 std::basic_string 干嘛？主要是字符串用得太广泛了，许多语言也都有专门的字符串库，甚至在 C++ reference 上，字符串库也被单独罗列了出来。 std::basic_string 是个特别的容器，它只和字符打交道，而且提供许多专门处理字符串的方法。<br>对于不同的字符，我们使用不同的 string 类。我们最常见的 string 类是 std::string，但实际上 std::string 只处理 char 类型的字符串。要想让字符串显示更多的信息，我们还有其他的类如 std::wstring 和 std::u32string 等。而这些不同的 string 类实际上就是：<br>typedef std::basic_string&lt;char&gt; std::string;
typedef std::basic_string&lt;char8_t&gt; std::u8string; // Since C++20
typedef std::basic_string&lt;wchar_t&gt; std::wstring;
typedef std::basic_string&lt;char16_t&gt; std::u16string;
typedef std::basic_string&lt;char32_t&gt; std::u32string;
<br>不同的 string 类中只是字符类型不同，它们的操作都是一样的。我们下面以 std::string 为例来进行讲解。<br><br>上面，我们看到 std::string 实际上就是 std::basic_string&lt;char&gt;。在这小节，我们将依托 std::basic_string&lt;char&gt; 学习 std::basic_string 库中的一些成员函数。<br>std::string 并不仅仅包括字符串数据，它还存储了字符串数据长度和字符串数组容量的信息。这些信息用于支持简便好用的库成员函数能够发挥作用。<br>举个例子，在下面的代码中，我们用了一个一个字符串字面量 hello, world!\n （ const char*, 即一个 C 类型字符串）来初始化一个 std::string 类型的变量。这里，我们先是输出了变量 s 的地址，后面再用 s.data() 选择输出字符串所在的地址。你会发现它们输出的地址并不会相同。<br>#include &lt;iostream&gt;
#include &lt;string&gt;

int main(){
	std::string s = "hello, world!\n";
	std::cout &lt;&lt; &amp;s &lt;&lt; std::endl;
	std::cout &lt;&lt; (void*)s.data() &lt;&lt; std::endl;
	return 0;
}
<br><br>namespace pmr {  
template&lt;  
    class CharType,  
    class Traits = std::char_traits&lt;ChatType&gt;
&gt; using basic_string =  
    std::basic_string&lt;CharT, Traits, std::pmr::polymorphic_allocator&lt;CharType&gt;&gt;;
}
<br>待补充......<br><br>按值传递：拷贝发送<br>按引用传递+const:避免了拷贝的发生同时避免了修改<br>但如果原值是一个 const char*呢<br>void allocPrint(std::string&amp; str){ // A string allocation on heap is made

}
void noAllocPrint(std::string_view&amp; str){ // No heap allocation is made

}
int main(){
	const str* = "hello, world!";
	printStr(str);
	noAllocPrint(str);
}
<br>实现仅为一个CharType指针和string大小]]></description><link>https://congzhi.wiki/c-plus-plus/string-library-in-c++.html</link><guid isPermaLink="false">C Plus Plus/String Library in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Mar 2025 17:04:40 GMT</pubDate></item><item><title><![CDATA[The pIMPL Idiom in C++ (ENG)]]></title><description><![CDATA[ 
 <br><br>In many code design patterns, people make all the declarations in the hpp file and definitions in the cpp file. This is called separating the interface and the implementation. Here’s an example:<br>// myLib.hpp
#ifndef MYLIB_HPP
#define MYLIB_HPP

class myLib {
private:
    int num;
public:
    myLib(int n); // Constructor taking an int parameter
    ~myLib() = default; // Destructor doing nothing
    int add(int n); // Method taking an int parameter
    int sub(int n); // Method taking an int parameter
};
#endif

// myLib.cpp
#include "myLib.hpp"

myLib::myLib(int n) : num{n} {}
int myLib::add(int n) {
    num += n;
    return num;
}
int myLib::sub(int n) {
    num -= n;
    return num;
}
<br>After compilation, the user will not see any implementation details of the library, that is, our cpp file. This approach has several benefits, such as encapsulation and ease of use. But, sometimes it is better not to expose any interface details about the implementation. In such cases, we can introduce the pimpl idiom.<br><br>We will demonstrate how our last code example above applies the pimpl idiom. With the pimpl idiom, the example above will look like:<br>// myLib.hpp

#ifndef MYLIB_HPP
#define MYLIB_HPP

class myLibImpl; // Forward declaration of the implementation class

class myLib {
private:
    myLibImpl* pImpl; // Pointer to the implementation class
public:
	void operation(int n);
    myLib(int n); // Constructor taking an int parameter
    ~myLib();
    int add(int n);
    int sub(int n);
// Rule of five...
};
#endif

// myLib.cpp
#include "myLib.hpp"
#include &lt;iostream&gt;

// Implementation of the myLibImpl class
class myLibImpl {
public:
    int num;
    myLibImpl(int n) : num{n} {}

    int add(int n) {
        num += n;
        return num;
    }
    int sub(int n) {
        num -= n;
        return num;
    }
    void operation(int n) {
        std::cout &lt;&lt; "Operation with value: " &lt;&lt; n &lt;&lt; std::endl;
    }
};

// Constructor
myLib::myLib(int n) : pImpl{new myLibImpl(n)} {}
// Destructor
myLib::~myLib() {
    delete pImpl;
}
// Operation method
void myLib::operation(int n) {
    pImpl-&gt;operation(n);
}

// Rule of five implementations...
<br>We see, everything about the implementation is in one translation unit, and what we have in myLib.hpp is really an interface to myLibImpl.<br>You can see the code is now safer to use, but one level of indirection is added, which may impact performance.<br><br>I am not done with the pIMPL design pattern.]]></description><link>https://congzhi.wiki/c-plus-plus/the-pimpl-idiom-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/The pIMPL Idiom in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Mon, 03 Mar 2025 16:23:35 GMT</pubDate></item><item><title><![CDATA[The Rule of Five in C++]]></title><description><![CDATA[ 
 <br>Do this at first: <a data-href="Move Semantics in C++" href="https://congzhi.wiki/c-plus-plus/move-semantics-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Move Semantics in C++</a><br><br>假设我们有这样一个类，类内只有一个 std::string 类型的成员变量和一个负责打印的成员函数。我们将他们的访问权限都变为 public，这样，我们就可以对类内的成员变量进行赋值操作了。这时，我们对类内成员变量的构造简单而直接。如下：<br>#include &lt;iostream&gt;
#include &lt;string&gt;

class Name{
public:
	std::string m_name;
	void printName(){
		std::cout &lt;&lt; m_name &lt;&lt; std::endl;
	}
};

int main(){
	Name alice;
    alice.m_name = "Alice";
    alice.printName();
	return 0;
}
<br>但为了保证类内数据的封装性，我们一般将成员变量的访问权限设置为 private。这个时候我们就不能对这些变量直接进行操作了，现在的规则是：“你只能通过类内一些特殊的函数初始化类内私有的成员变量”。在面向对象程序设计中，我们将这些特殊的函数称为构造函数。同时，我们还有一种特殊的函数叫析构函数，它会在对象的生命周期结束后自动调用用于清理对象（见<a data-tooltip-position="top" aria-label="RAII and Scope in C++" data-href="RAII and Scope in C++" href="https://congzhi.wiki/c-plus-plus/raii-and-scope-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">RAII</a>）。<br><br>在将成员变量设为私有后，我们需要一些特殊的函数来初始化和清理这些变量。构造函数会在类实例化对象时自动调用，用于初始化成员变量。而析构函数则会在对象的生命周期结束时自动调用，用于清理资源。通常而言，我们加入 const 是为了避免对原对象的修改。<br>#include &lt;iostream&gt;
#include &lt;string&gt;

class Name {
private:
    std::string m_name{"NO NAME"};
public:
    Name() = default;

    // Constructor that accepts std::string
    Name(const std::string&amp; name) : m_name(name) {}
    void printName() const {
        std::cout &lt;&lt; m_name &lt;&lt; std::endl;
    }
};

int main() {
    Name alice("Alice");
    Name alice2(alice); // compiler provided for free
    Name alice3 = alice;// compiler provided for free
    alice.printName();
    alice2.printName();
    alice3.printName();
    return 0;
}
<br>上面，我们添加了一个接受 std::string 类型的构造函数。但在下面的例子中，我们发现虽然我们没有显式添加接受 Name 类类型的拷贝构造函数和拷贝赋值运算符，但它们仍然能够正常工作。这是因为编译器为我们自动生成了默认的拷贝构造函数和赋值运算符。<br>    // Default copy constructor, copy assignment operator provided by compiler.
    Name(const Name&amp; other_name) : m_name(other_name.m_name){}
    Name&amp; operator=(const Name&amp; other_name) : m_name(other_name.m_name){}
<br>这些默认的拷贝构造函数和赋值运算符会逐个成员地复制对象中的每个成员，这种拷贝被称为浅拷贝。在含有成员指针的类中，这种浅拷贝可能会造成资源的二次释放。详见<a data-tooltip-position="top" aria-label="Copying and Copy Constructors in C++ > 2. Shallow Copying and Deep Copying" data-href="Copying and Copy Constructors in C++#2. Shallow Copying and Deep Copying" href="https://congzhi.wiki/c-plus-plus/copying-and-copy-constructors-in-c++.html#2._Shallow_Copying_and_Deep_Copying" class="internal-link" target="_self" rel="noopener nofollow">浅拷贝和深拷贝</a>。<br><br>在 C++11 前，C++ 没有移动语义的概念。因此，那时我们不需要考虑移动构造函数和移动赋值运算符。如果你要实现一个类，那你就应当实现所有的三个重要函数和一个析构函数，即构造函数、析构函数、拷贝构造函数和拷贝赋值运算符。这就是“三法则”（A best practice）。<br>如果类内资源不涉及内存分配，实际上你可以依赖编译器为你提供的默认的构造函数和赋值运算符重载。简化了类的设计和实现，这种原则叫做 the rule of zero 。<br>You may be curious about why we always pass an object by reference in C++, even in the copy constructor. You might know this is to avoid copying the object. While it's true that we need to copy the object in the copy constructor, the way we achieve this is different.<br>We use a reference to avoid creating a new copy of the object on the stack of the current function. By passing a reference (or a pointer) to the existing object, the function can operate directly on the original object without the overhead of making a copy. This method ensures that we're not creating unnecessary copies, which can be expensive in terms of CPU time and memory usage.<br>If you're still feeling confused, you're welcome to learn more <a data-tooltip-position="top" aria-label="Call Stack in C++ (ENG)" data-href="Call Stack in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/call-stack-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">here</a>.<br><br><br>自 C++11 引入移动语义之后，一个类可以通过移动构造函数和重写移动赋值运算符来构造对象。"The Rule of Five" 或 “五法则” 是 C++11 后定义构造函数的指导原则。五法则规定要实现一个类，你不仅需要实现三法则（即定义析构函数、拷贝构造函数和拷贝赋值运算符），还需要在类中添加移动构造函数和移动赋值运算符，以支持移动语义。<br><br>Rule of Zero旨在简化类的设计和实现。它的核心思想是：如果一个类不需要自定义的析构函数、拷贝构造函数、拷贝赋值运算符、移动构造函数或移动赋值运算符，那么就不应该定义这些函数。相反，应该信任并依赖编译器生成的默认实现。<br>#include &lt;string&gt;
#include &lt;memory&gt;

class Widget {
private:
    int i{0};
    std::string s{};
    std::unique_ptr&lt;int&gt; pi{nullptr};

public:
    Widget() = default;
    ~Widget() = default;
    Widget(const Widget&amp;) = default;
    Widget&amp; operator=(const Widget&amp;) = default;
    Widget(Widget&amp;&amp;) = default;
    Widget&amp; operator=(Widget&amp;&amp;) = default;
};
]]></description><link>https://congzhi.wiki/c-plus-plus/the-rule-of-five-in-c++.html</link><guid isPermaLink="false">C Plus Plus/The Rule of Five in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:58:53 GMT</pubDate></item><item><title><![CDATA[This Keyword in C++ (ENG)]]></title><description><![CDATA[ 
 <br><br>If you're a C++ newbie, the this keyword in a class can definitely be confusing, and you might find yourself asking, "What the heck is this?"<br>According to <a data-tooltip-position="top" aria-label="https://en.cppreference.com/w/cpp/language/this" rel="noopener nofollow" class="external-link" href="https://en.cppreference.com/w/cpp/language/this" target="_blank">cppreference</a>, the this expression is a pure rvalue expression, which represents the address value of the implicit object parameter. Simply put, you can consider this as a pointer points to the current instance of the object.<br>When you use this in a member function, it allows you to refer to the calling object itself. In this example down below, the this pointer inside the showAddr function points to the object obj. The this expression provides a way for member functions to refer to the instance of the class they were called on.<br>class MyClass {
public:
    void showAddr() {
        std::cout &lt;&lt; "Address of this object: " &lt;&lt; this &lt;&lt; std::endl;
    }
};

int main() {
    MyClass obj;
    obj.showAddr(); // Will print the address of the object `obj`
    return 0;
}

<br><br>You can see this in every implicit object member function body, including member initializer list and lambda expression body (you can capture this within a capture list).<br>class MyClass {
public:
	// implicit member function getValue()
    int getValue() const { // const member function
        return value; // implicit form of return this-&gt;value;
    }
private:
	int value;
};
<br>In any practice, explicitly using this is often considered a good practice for clarity. Consider a scenario where you have passed a parameter with the exact same name as a class member variable. In the function setValue, the use of this helps to avoid ambiguity.<br>#include &lt;iostream&gt;

class MyClass {
public:
    int getValue() const { // const member function
        return this-&gt;value;
    }
    void setValue(int value) {
        value = value; // parameter value will shadow the member with the same name
    }
private:
    int value = 50;
};

int main(){
    MyClass obj;
    obj.setValue(20);
    std::cout &lt;&lt; obj.getValue() &lt;&lt; std::endl; // print 50
    return 0;
}
<br><br>In the <a data-href="Const in C++" href="https://congzhi.wiki/c-plus-plus/const-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Const in C++</a> section, we talked about constant member functions in C++. const member functions are not allowed to mutate the member variables of the class. So what is happening under the hood? Let's imagine we have a class as follows:<br>class MyClass {
public:
    int getValue() const { // const member function
        return this-&gt;value;
    }
    void setValue(int value) {
        this-&gt;value = value;
    }
private:
    int value;
};
<br>What really happens is a implicit casting, as we will examine this process:<br>int getValue() const {
	return value;
}
// is the same as:
int getValue(const myClass* const this){
	return this-&gt;value;
	}
<br>Because this casting is implicit, the const is put on the outside of () to indicate that the member function cannot modify the object it is called on. Preserving the const-correctness of the function.<br><br>Because "this" was introduced into C++ before references were added.]]></description><link>https://congzhi.wiki/c-plus-plus/this-keyword-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/This Keyword in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 27 Feb 2025 14:19:56 GMT</pubDate></item><item><title><![CDATA[Typename Keyword in C++ (ENG)]]></title><description><![CDATA[ 
 <br><br>The typename keyword in C++ is used to introduce type template parameters and template template parameters (since C++17). It serves as an alternative to the class keyword in this context.<br>template &lt;typename T&gt;
T add(T a, T b) {
    return a + b;
}
// The code above is as the same as:
template &lt;class T&gt;
T add(T a, T b) {
    return a + b;
}
<br>In both cases, T is a type parameter that will be replaced by the actual data type when you call the function.<br><br>The typename keyword is also used to indicate that a dependent name(often means a class name) is a type. This helps the compiler understand that the name refers to a type, preventing ambiguity. This is particularly useful in templates where the type depends on a template parameter.<br>#include &lt;iostream&gt;

// Example of a class with a nested type
class Example {
public:
    using value_type = int; // Define 'Example::value_type' as 'int'
};
class Example2 {
public:
    using value_type = double; // Define 'Example2::value_type' as 'double'
};

template &lt;typename T&gt;
class MyClass {
    typename T::value_type member; // 'typename' tells the compiler that 'value_type' is a type inside 'T'
public:
    void setMember(typename T::value_type value) {
        member = value;
    }
    typename T::value_type getMember() const {
        return member;
    }
};

int main() {
    MyClass&lt;Example&gt; myObj; // 'Example' has 'value_type' defined as 'int'
    MyClass&lt;Example2&gt; myobj2; // 'Example2' has 'value_type' defined as 'double'
    return 0;
}
]]></description><link>https://congzhi.wiki/c-plus-plus/typename-keyword-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Typename Keyword in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 28 Feb 2025 04:38:03 GMT</pubDate></item><item><title><![CDATA[Unions in C++]]></title><description><![CDATA[ 
 <br><br>在 C++ 中，大多数人可能都知道 class 和 struct 的类类型，但是许多人会忽略 union 也是一种类类型，这是因为 C++ 中的联合体也可以拥有自己的成员函数（包括构造和析构函数）。但它的使用是特别的，因为其特性，联合体类 union 内每次只能有一个活跃的成员。<br>由于联合体需要保证类内任何一个成员都能够被访问到，所以联合体类型至少要和类内最大的数据成员的大小一样大，通常等于联合体类内最大的数据成员的大小。当我们访问联合体类时，其类内的每个数据成员都会像是类内唯一的数据成员。<br>union 的一个简单用例如下，我们用 union 定义了一个联合体类型 U。其中有三个数据成员：<br>#include &lt;iostream&gt;

union U{ // public access by default
	int u_i; // 4 bytes
	short u_s; // 2 bytes, hold integer number no bigger than 65535
	float u_f; // 4 bytes
}; // thus the size of U class is 4 bytes 

int main(){
	U u = {65536}; // initializes the first member u.u_i
	// U u.u_i = {65536};
	std::cout &lt;&lt; u_i &lt;&lt; std::endl 
			  &lt;&lt; u_s &lt;&lt; std::endl 
			  &lt;&lt; u_f &lt;&lt; std::endl;
	return 0;
}
<br>输出：<br>65536
0
9.18355e-41
<br>上面的代码中，我们定义了一个包含三个数据成员的 union 类。在 union 中，所有的数据变量都共享一个地址，但是它们访问数据的方式和大小各不相同。我们初始化了第一个成员 u_i，这意味着剩下的两个变量的状态在此时是未定义的。这也就不难理解为什么我们会得到如此奇怪的输出。<br>在一时刻， union 的内存布局如下所示：<br>
<img alt="member_union.png" src="https://congzhi.wiki/c-plus-plus/pics/member_union.png"><br>
因为 short 类型大小为两个字节，所以即使 short 和 int 都表示整型数，在赋值 65536 时，short 仍然不能访问高二字节地址的数据。而 float 数据的访问方式又与整型数有所不同，我们会得到不一样的结果。如果后面我们对 u_s 进行赋值，那么 u_i 的生命周期也就随之结束。<br>以上是联合体最常用的方式。这样做有什么好处？节省内存。<br><br>作为一种特殊的类， union 可以拥有自己的成员函数。但需要注意的是 union 不允许继承和派生，因此也不允许出现虚函数。union 中，拷贝构造函数、移动构造函数、拷贝赋值运算符、移动赋值运算符和析构函数默认会被删除。除非显式地定义这些函数。<br><br>匿名联合体是匿名的，它不能有任何成员函数、静态数据成员而且所有的数据成员都需要是公有的。匿名联合体必须定义在作用域 (scope) 中，而且其成员不能与作用域中已声明的名字冲突。接着上面的例子，它的匿名联合体会是这样的：<br>#include &lt;iostream&gt;
namespace U {
    long u_l;
    union { // public access by default
        int u_i; // 4 bytes
        short u_s; // 2 bytes, holds integer numbers no bigger than 65535
        float u_f; // 4 bytes
	    // long u_l; // not allowed
    } static; // anonymous unions at namespace scope must be static
}

int main() {
    U::u_i = 65536; // initializes the first member myspace::u_i
    std::cout &lt;&lt; U::u_i &lt;&lt; std::endl 
              &lt;&lt; U::u_s &lt;&lt; std::endl 
              &lt;&lt; U::u_f &lt;&lt; std::endl;
    return 0;
}
<br>如果在一个函数的作用域中，匿名函数就是这样的：<br>#include &lt;iostream&gt;

int main() {
	union { // public access by default
        int u_i; // 4 bytes
        short u_s; // 2 bytes, holds integer numbers no bigger than 65535
        float u_f; // 4 bytes
    };
    u_i = 65536; // initializes u_i
    std::cout &lt;&lt; u_i &lt;&lt; std::endl 
              &lt;&lt; u_s &lt;&lt; std::endl 
              &lt;&lt; u_f &lt;&lt; std::endl;
    return 0;
}
<br>]]></description><link>https://congzhi.wiki/c-plus-plus/unions-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Unions in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:59:04 GMT</pubDate><enclosure url="https://congzhi.wiki/c-plus-plus/pics/member_union.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/c-plus-plus/pics/member_union.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Using Keyword in C++ (ENG)]]></title><description><![CDATA[ 
 <br>Do this at first: <a data-href="Namespaces in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/namespaces-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">Namespaces in C++ (ENG)</a><br><br>We will add some details about what happens behind the scenes in this section. Before that, make sure you have completed the <a data-tooltip-position="top" aria-label="Namespaces in C++ (ENG)" data-href="Namespaces in C++ (ENG)" href="https://congzhi.wiki/c-plus-plus/namespaces-in-c++-(eng).html" class="internal-link" target="_self" rel="noopener nofollow">namespace</a> part.<br>We use the using declaration to introduce namespace members into other namespaces and block scopes. Global functions and variables can also be introduced into other namespaces using using declarations. This might sound dizzying, but no hard to understand.<br>Without further ado, let's dive into some code:<br>#include &lt;iostream&gt;

void func(); // Global function declaration
int var; // Global variable
void func(){ // Global function difinition
    std::cout &lt;&lt; "In global func." &lt;&lt; std::endl;
}
namespace A {
    void A_func(); // A::A_func(), this is also global, but with a suffix name A
}
void A::A_func(){
    std::cout &lt;&lt; "In A::A_func." &lt;&lt; std::endl;
}

namespace B {
    using ::func; // Global func() is now visible as B::func
    using ::var; // Global var is now visible as B::var
    using A::A_func; // A::A_func() is now visible as B::A_func
}
int main() {

    var = 0;
    std::cout &lt;&lt; var &lt;&lt; std::endl;
    
    ::var = 10; // Modify the global variable to 10
    std::cout &lt;&lt; ::var &lt;&lt; std::endl;
    
    B::var = 20; // Okay
    std::cout &lt;&lt; ::B::var &lt;&lt; std::endl;
    
    B::func(); // Calls func() // as the same as ::func() or func()
    B::A_func(); // Calls A::A_func()
    
    return 0;
}
<br>This code demonstrates how you can introduce global variables and functions into a namespace using the using declaration. By doing this, you make global names accessible within the namespace B, allowing you to use them without fully qualifying their names.<br>And once you can do the step forward, you can do the backward. This is allowed as well:<br>namespace A {
    int var; // A::var
}
using A::var; // A::var is now available as ::var

int main() {
    ::var = 10; // This refers to A::var
    A::var = 30; // refers to A::var
    return 0;
}
<br>But when you introduce names from one namespace into another, you need to be cautious not to create ambiguities. If two namespaces have members with the same name, using declarations can lead to confusion and potential conflicts.<br><br>When you use a using declaration within a block scope, it's often referred to as a using directive within that block. Which we have seen as in using namespace blabla;.<br>This is a example from <a data-tooltip-position="top" aria-label="https://en.cppreference.com/w/cpp/language/namespace#Using-directives" rel="noopener nofollow" class="external-link" href="https://en.cppreference.com/w/cpp/language/namespace#Using-directives" target="_blank">cppreference</a>:<br>namespace A
{
    int i;
}
 
namespace B
{
    int i;
    int j;
 
    namespace C
    {
        namespace D
        {
            using namespace A;
            // Names from A are "injected" into D.
            // Unqualified lookup within D considers these names to have the same
            // scope as the global scope (e.g. for the purposes of name hiding).
            // Qualified lookup referring to D (D::name for some name)
            // will find the same name as unqualified lookup within D.
 
            int j;
            int k;
            int a = i;   // i is B::i, because A::i is hidden by B::i
            int b = ::i; // error: there is still no i in the global namespace
        }
 
        using namespace D; // names from D and A are injected into C
 
        int k = 89; // OK to declare name identical to one introduced by a using
        int l = k;  // ambiguous: C::k or D::k
        int m = i;  // ok: B::i hides A::i
        int n = j;  // ok: D::j hides B::j
    }
}
 
// These are all equivalent definitions:
int t0 = B::i;
int t1 = B::C::a;
int t2 = B::C::D::a;
<br><br>You can create type aliases with the using keyword, similar to typedef.<br>using cout = std::cout;

int my_variable = 0;
using var = my_variable; 
typedef my_variable = var; // same
<br>You can also create type aliases for template classes using using. This is true beast, which typedef cannot do.<br>template&lt;class T&gt; using myClass = myOriginalClass&lt;T&gt;;

// typedef syntax is not allowed with templates:
template&lt;class T&gt; typedef myOriginalClass&lt;T&gt; myClass; // error, this is not allowed
]]></description><link>https://congzhi.wiki/c-plus-plus/using-keyword-in-c++-(eng).html</link><guid isPermaLink="false">C Plus Plus/Using Keyword in C++ (ENG).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 04 Mar 2025 14:15:22 GMT</pubDate></item><item><title><![CDATA[Virtual Dispatch in C++]]></title><description><![CDATA[ 
 <br>Do this at first: <a data-href="Inheritance in C++" href="https://congzhi.wiki/c-plus-plus/inheritance-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">Inheritance in C++</a><br><br>类里面没有数据成员时，它的大小为1字节，如果定义virtual，它的大小就会为8字节（存放虚表指针<br>之前，我们学习了继承是怎么回事，还了解了派生类对基类同名函数的隐藏机制。<br>我们用虚函数就是为了动态多态（虚多态）即决定函数执行是在运行时完成的，而不在编译时决定<br>动态多态就是用基类指针来调用派生类对象函数的<br>#include &lt;iostream&gt;
class Base {
public:
    void func() {
        std::cout &lt;&lt; "Base::func()" &lt;&lt; std::endl;
    }
};

class Derived : public Base {
public:
    void func() {
        std::cout &lt;&lt; "Derived::func()" &lt;&lt; std::endl;
    }
    void func1(){}
};

int main() {
    Base *b = new Derived;
    b-&gt;func();
    return 0;
}
<br>是对基类函数的重写，所以在派生类定义的函数用基类指针是访问不到的<br>只用声明基类函数为virtual就可以了<br>只能和指针或引用一起使用。指针的话，对象在堆上创建<br>引用对象在栈上创建<br>
<img alt="Pasted image 20250322232054.png" src="https://congzhi.wiki/lib/media/pasted-image-20250322232054.png"><br>基类的作用是制定一些规则（派生类可以重写哪些函数）但是基类不能干涉派生类重写函数的实现<br>
纯虚函数就是告诉派生类。。。。如果派生类不实现基类的纯虚函数，派生类也会变为抽象类（不可实例化<br><br>虚函数就是允许子类对该函数进行重写(override)，引入了动态多态/运行时多态的概念。函数重写和函数重载(overload)这两个概念很容易混淆，但它们不是一个概念。<br>在<a data-href="Part2：Class (Abandoned)" href="https://congzhi.wiki/c-plus-plus/part2：class-(abandoned).html" class="internal-link" target="_self" rel="noopener nofollow">Part2：Class (Abandoned)</a>中，我们了解了当我们在制作游戏法杖类时，派生类直接继承基类能为我们带来多少的便利。但是在那个例子中，我们没有考虑如何在派生类中对基类函数重新实现。虚函数就使得我们在子类中重写(overwrite) 函数。也引入了运行时多态的概念。<br>#include &lt;iostream&gt;
#include &lt;string&gt;

class wand{
    std::string name;
    std::string element;
    unsigned length;
public:
    wand(std::string name_, std::string element_, unsigned length_)
        : name(name_), element(element_), length(length_){
        std::cout &lt;&lt; "Father class constructor." &lt;&lt; std::endl;
    }
    ~wand(){
        std::cout &lt;&lt; "Father class deconstrutor." &lt;&lt; std::endl;
    }
    virtual void printName(){
        std::cout &lt;&lt; "This is a wand." &lt;&lt; std::endl;
    }
};
class fire_wand : public wand{
public:
    fire_wand(std::string name_, std::string element_, unsigned length_)
        : wand(name_, element_, length_){
        std::cout &lt;&lt; "Child class constructor." &lt;&lt; std::endl;
    }
    ~fire_wand(){
        std::cout &lt;&lt; "Child class deconstructor" &lt;&lt; std::endl;
    }
    void printName(){
        std::cout &lt;&lt; "This is a fire wand." &lt;&lt; std::endl;
    }
    /*
    int printName(){} // Incorrect
	int printName(int i){} // Correct, but it's no longer runtime polymorphism
	*/
};
int main(){
    fire_wand fw("Blacken blast", "Fire", 20);
    wand *w = &amp;fw; 
    w-&gt;printName();
    return 0;
}
<br>在上面的例子中，我们在 fire_wand 中重写了 printName() 函数，所以在调用函数的时候实际上调用的是派生类中实现的 printName()。但如果在派生类中没有给出重写实现，那就会调用基类默认的实现。<br>需要注意的是，派生类中重写的函数必须和基类中的虚函数类型相同（函数名、参数列表、常量性）。在派生类中重写虚函数的时候可以使用 virtual 和 override 关键字。override 关键字override&nbsp;关键字用于在子类中重写基类中的虚函数。它告诉编译器该函数是用来重写基类中的虚函数的，如果没有正确匹配基类中的虚函数，编译器就会报错。<br>例如：<br>class wand {
public:
    virtual void printName() {
        std::cout &lt;&lt; "This is a wand." &lt;&lt; std::endl;
    }
};

class fire_wand : public wand {
public:
    // In this case, the compiler will check if this function correctly overrides a virtual function in the base class
     virtual void printName() override {
        std::cout &lt;&lt; "This is a fire wand." &lt;&lt; std::endl;
    }

    // This will be incorrect because there is no virtual function with this name in the base class
    virtual void printLeng() override { // Error: 'printLeng' does not override any base class method
        std::cout &lt;&lt; "Length" &lt;&lt; std::endl;
    }
};

<br>如果不想派生类再重写虚函数，我们可以使用C++提供的 final 关键字。<br>class wand{
public:
    virtual void printName() final {
        std::cout &lt;&lt; "This is a wand." &lt;&lt; std::endl;
    }
};
class fire_wand : public wand{
public:
    void printName() override { // Incorrect, cannot override 'final' function
	    std::cout &lt;&lt; "This is a fire wand." &lt;&lt; std::endl;
    }
};
<br>如果想在继承时强制在派生类中定义基类中的虚函数，我们可以用 virtual void printName() = 0;，即纯虚函数。  <br><br>
After the base class guarantees the preconditions and postconditions of an operation, any derived class must respect those guarantees. An override can ask for less and provide more, but it must never require more or promise less because that would break the contrack that was promised to calling code.
<br>interface dont do something<br>
派生类中实现了基类中没有的方法还能使用动态多态么<br>接口是可以有函数体的：(但是抽象类不能实例化)<br>class Example{
	virtual void print() = 0;
};
void Example::print(){
	std::cout &lt;&lt; "test" &lt;&lt; std::endl;
}
<br>在C++中，我们称纯虚函数为接口（interface），这是因为纯虚函数定义了一组必须由派生类实现的函数，从而为派生类提供了一种规范和约束。<br>纯虚函数是在基类中声明但没有实现的函数，声明格式为&nbsp;virtual void functionName() = 0;。接口是一种只包含未实现方法的类，用于定义一组必须由派生类实现的函数。在C++中，接口通常通过包含纯虚函数的抽象类来实现。<br>当类中声明某函数为纯虚函数时，该类即为抽象类（abstract class），不能直接实例化。虽然你仍然可以在抽象类中给出纯虚函数的实现，但由于抽象类不能实例化，这种实现通常没有实际作用。继承抽象类的派生类必须在类中实现这些接口函数，正是这种对派生类的规范，所以称为接口。<br>#include &lt;iostream&gt;
#include &lt;string&gt;

class Printable {
public:
    virtual std::string getClassName() const = 0; // pure virtual
};

class Document : public Printable {
public:
    std::string getClassName() const override {
        return "Document";
    }
};

class Book : public Document {
public:
    std::string getClassName() const override {
        return "Book";
    }
};

void printClassName(const Printable&amp; obj) {
    std::cout &lt;&lt; obj.getClassName() &lt;&lt; std::endl;
}

int main() {
    Document doc;
    Book book;

    printClassName(doc);  // Document
    printClassName(book); // Book

    return 0;
}
<br><br>纯虚函数为代码提供了许多规范性和扩展性：<br>
<br>
规范和约束：

<br>纯虚函数强制派生类实现这些函数，从而确保所有派生类都具有相同的接口。这提供了一种规范和约束，使得代码更一致和可维护。


<br>
多态性：

<br>接口允许通过基类指针或引用调用派生类的实现，从而实现多态性。这使得代码更加灵活和可扩展。


<br>
设计模式：

<br>在面向对象设计中，接口用于定义一组相关的功能，而不关心具体的实现细节。这种设计模式在大型项目中尤为重要，因为它提高了代码的可扩展性和可维护性。


<br><br>在了解虚析构函数前，我们先写一段代码并观察其输出结果，我们会看到删除指向派生类对象的基类指针时，析构函数的调用是错误的。观察并思考一下为什么会出现这种现象。<br>#include &lt;iostream&gt;

class Base
{
public:
    Base(){ std::cout &lt;&lt; "Base constructor." &lt;&lt; std::endl; }
    ~Base(){ std::cout &lt;&lt; "Base deconstructor." &lt;&lt; std::endl; }
};
class Derived : public Base
{
public:
    Derived(){ std::cout &lt;&lt; "Derived constructor." &lt;&lt; std::endl; }
    ~Derived(){ std::cout &lt;&lt; "Derived deconstructor." &lt;&lt; std::endl; }
};

int main(){

    Base* base = new Base();
    delete base;
    std::cout &lt;&lt; "---------------------\n";
    Derived* derived = new Derived();
    delete derived;
    std::cout &lt;&lt; "---------------------\n";
    Base* poly = new Derived();
    delete poly;
    return 0;
}
<br>Base constructor.
Base deconstructor.
---------------------
Base constructor.
Derived constructor.
Derived deconstructor.
Base deconstructor.
---------------------
Base constructor.
Derived constructor.
Base deconstructor.
<br>输出很奇怪，当我们删除 poly 时，我们发现虽然我们new了一个 Derived 类对象，但是删除对象的时候确没有调用基类的析构函数。为什么？你可能会得到一个一头雾水的回答：因为基类的析构函数没有被声明为虚析构函数。<br><br>当基类的析构函数声明为虚函数时，C++的虚函数机制会确保在删除一个指向派生类对象的基类指针时，调用的是派生类的析构函数。这是因为虚函数表(vtable) 会在运行时动态绑定到正确的析构函数，从而确保派生类的析构函数被调用。<br><br>虚拟函数依赖于一个完整的对象布局，而在构造函数执行时，对象还处于不完全状态。此外，虚拟函数的机制依赖于 vtable 的初始化，但在调用构造函数时， vtable 还未完全建立或指向正确的类型。这就是为什么 C++ 设计者决定不允许构造函数是 virtual 的。<br><br>当我声明 Base::~Base() 纯虚析构函数，将 Base 类实例化过程删去。运行代码，gcc 告诉我们链接出错了。为什么？undefined reference to 'Base::~Base()' 不难理解，因为链接器没有找到 Base::~Base() 的定义。gcc 还说错误是在 Derived::Derived() 和 Derived::~Derived() 对 Base::~Base() 引用时没有找到定义而造成的。<br>/usr/bin/ld: /tmp/ccXCFzYQ.o: in function `Derived::Derived()':
stack2.cpp:(.text._ZN7DerivedC2Ev[_ZN7DerivedC5Ev]+0x67): undefined reference to `Base::~Base()'
/usr/bin/ld: /tmp/ccXCFzYQ.o: in function `Derived::~Derived()':
stack2.cpp:(.text._ZN7DerivedD2Ev[_ZN7DerivedD5Ev]+0x51): undefined reference to `Base::~Base()'
collect2: error: ld returned 1 exit status
<br>理解Derived::~Derived()中有对Base::~Base()的引用并不难，为什么&nbsp;Derived::Derived()&nbsp;中有对&nbsp;Base::~Base()&nbsp;的引用？<br>在我们定义纯虚函数的时候，一般而言并不需要给出实现，因为抽象类不能实例化，还有就是派生类也必须给出其实现。纯虚函数即便实现一般也不会调用，但纯虚析构函数是一个例外，纯虚析构函数必须有一个定义。因为在删除派生类对象时，基类的析构函数仍然需要被调用。<br><br>当我们使用 virtual 关键字时，C++就会帮我们创建一个vtable。vtable会被存放到类定义模块的数据段中，而且所有相同类型的 instances 共享同一个vtable。<br>可能上面的话我们并不好理解，没关系，我们先用一个例子说明。如下，我们让将基类 Animal 定义为了一个抽象类，为其他的动物提供函数/方法接口。我们定义基类 Animal 和三个派生类，然后在 main 里面用基类指针指向 new 的派生类对象，在运行时动态调用派生类的实现。这就是动态时多态(Dynamic dispatch) 。<br>#include &lt;iostream&gt;

class Animal{
public:
    virtual void Say() {
	    std::cout &lt;&lt; "Dingggg~" &lt;&lt; std::endl;
    }
    virtual void Whoami() {
	    std::cout &lt;&lt; "I am an animal." &lt;&lt; std::endl;
	}
};
class Cat : public Animal{
    void Say() override {
        std::cout &lt;&lt; "Meowwww~" &lt;&lt; std::endl;
    }
    void Whoami() override {
	    std::cout &lt;&lt; "I am a cat." &lt;&lt; std::endl;
    }
};
class Cow : public Animal{
public:
    void Say() override {
        std::cout &lt;&lt; "Moooooo~" &lt;&lt; std::endl;
    }
};
class Pig : public Animal{
public:
    void Say() override {
        std::cout &lt;&lt; "Oinnnnk~" &lt;&lt; std::endl;
    }
};
int main(){

    Animal* animal = new Cat();
    animal-&gt;Say();
    delete animal;
    Animal* animal = new Cow();
    animal-&gt;Whoami();
    delete animal;
    return 0;
}
<br>Meowwww~
I am an animal.
<br>派生类继承基类时，如果没有重载虚函数，虚表中的指针仍然指向基类的虚函数实现。也就造成了我们所看到的 I am an animal. 。虚表(vtable) 的存在是实现动态多态性和默认基类实现的核心所在。通过虚表，可以在运行时决定调用哪个具体的函数实现，我们现在就来了解它。<br><br>上面我们观察了一些现象，我们下面就来看看虚表和我们的代码在内存中是怎么样的。关于这个话题，暂时不会过于深入，我们仅用一张图来说明一下。<br><img alt="vtable.png" src="https://congzhi.wiki/c-plus-plus/pics/vtable.png"><br>在这个例子中，每个类都有一个自己的虚表，某个类的所有实例都会共享一个虚表，当类被实例化时，实例会有一个指向其类的虚指针（指向虚表的指针）。<br>虚表中包含类的所有虚函数的指针。我们的基类&nbsp;Animal&nbsp;有两个虚函数&nbsp;Say()&nbsp;和&nbsp;Whoami()，所以&nbsp;Animal&nbsp;类的虚表中会有两个指针分别指向&nbsp;Say()&nbsp;和&nbsp;Whoami()&nbsp;的实现。对于派生类中没有重载基类的某个虚函数，那么它的虚表中会包含指向基类&nbsp;Animal&nbsp;中相应虚函数的指针。<br>从上图中能清楚地看到：<br>
<br>Cat&nbsp;类的虚表会有指向&nbsp;Cat::Say()&nbsp;和&nbsp;Cat::Whoami()&nbsp;的虚指针。
<br>Cow&nbsp;类的虚表会有指向&nbsp;Cow::Say()&nbsp;和&nbsp;Animal::Whoami()&nbsp;的虚指针。
<br>Pig&nbsp;类的虚表会有指向&nbsp;Pig::Say()&nbsp;和&nbsp;Animal::Whoami()&nbsp;的虚指针。
<br>请留意：这里并没有画栈这个内存中极其重要的一部分。在堆中的实例需要通过栈上的指针来进行寻址，完整的寻址过程如下：栈上指针&nbsp;-&gt;&nbsp;堆上实例中的虚指针&nbsp;-&gt;&nbsp;虚表中的函数指针&nbsp;-&gt;&nbsp;虚函数。这也是动态多态性较慢的原因之一。<br>虚表的建立比模板特化早。所以虚函数不允许写成模板。<br><br>
解决菱形继承的代码重复问题。
<br>Virtual&nbsp;Base&nbsp;Class：这是在多重继承中用来避免重复继承的一种机制。假设我们有一个基类A，还有两个从A继承的类B和C。如果再创建一个类D，它同时继承自B和C，那么D将拥有A的两份副本。但在某些情况下，我们只希望有A的一份副本，这时就需要使用virtual&nbsp;base&nbsp;class。<br>class A {
    // Base class A
};

class B : virtual public A {
    // B is virtually inherited from class A
};

class C : virtual public A {
    // C is also virtually inherited from class A
};

class D : public B, public C {
    // D inherited from B and C
};
<br>Virtual&nbsp;Inheritance是为了实现上面说的virtual&nbsp;base&nbsp;class机制而引入的。通过virtual&nbsp;inheritance，派生类D将只拥有基类A的一份副本，避免了重复继承的问题。这在多重继承层次结构中尤其有用。<br>
<img alt="Pasted image 20241009225008.png" src="https://congzhi.wiki/c-plus-plus/pics/pasted-image-20241009225008.png"><br>
使用虚继承后，C++会确保无论多少个派生类，它们都共享同一个虚基类实例。编译器会在派生类的vtable中添加指向虚基类的指针，确保正确访问虚基类。<br>if not using virtual keyword, B and C both will point to their owning entity <br>points to the same entity using virtual keyword<br>ambiguous<br>
odr???????<br><br><br><br>why make destructor virtual?<br><br>avoid it]]></description><link>https://congzhi.wiki/c-plus-plus/virtual-dispatch-in-c++.html</link><guid isPermaLink="false">C Plus Plus/Virtual Dispatch in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sun, 23 Mar 2025 13:27:49 GMT</pubDate><enclosure url="https://congzhi.wiki/lib/media/pasted-image-20250322232054.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/lib/media/pasted-image-20250322232054.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Volatile Specifier in C++ (Questioning)]]></title><description><![CDATA[ 
 <br>volatile 的作用到底是什么？我知道 volatile 声明的变量不会被编译器优化到寄存器中去。意思说用 volatile 声明的变量只能从内存中取，然后放到内存中。然后使用 volatile 会 back-off 编译器的优化。C++ 经常把 const 和 volatile 称为 cv qualifier。<br>硬件开发的程序中，经常会出现 volatile 这个修饰符，网上给出的解释是告诉编译器该变量可能会在程序外被改变，因此不应该对变量进行优化？理解不了。]]></description><link>https://congzhi.wiki/c-plus-plus/volatile-specifier-in-c++-(questioning).html</link><guid isPermaLink="false">C Plus Plus/Volatile Specifier in C++ (Questioning).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Mon, 03 Mar 2025 10:34:46 GMT</pubDate></item><item><title><![CDATA[Chapter 1: Computer Networks and the Internet]]></title><description><![CDATA[ 
 <br><br><br>■ Get "feel", "big picture", introduction to terminology<br><br>■ What is the Internet? What is a protocol?<br>
■ Network edge: hosts, access network, physical media<br>
■ Network core: packet/circuit switching, internet structure<br>
■ Performance: loss, delay, throughput<br>
■ Protocol layers, service models<br>
■ Security<br>
■ History<br><br>Internet is a network of networks.<br><br>In the “Nuts and Bolts” description of the Internet, we consider several components that constitute the network.<br>
<br>Hosts: These are the end systems of the network.

<br>主机/终端(Host/End system) 通过Packet switches和communication links 钩织形成的网络相连在一起。
<br>为终端提供Internet access服务的是ISPs(Internet Service Providers)，服务商包括 residential ISPs， corporate ISPs， university ISPs等。大的服务商给小的服务商提供Internet access，局部服务商管理小的 internet，网际Internet 由所有的 internet 组成。


<br>Packet Switches

<br>Link-layer Switches: They provide hosts with access to the network.
<br>Routers: These devices receive packets and forward the information to the designated host.


<br>Communication Links: 将互联网Internet中的所有主机及互联网核心连接在一起。

<br>链接媒介有铜线、同轴电缆、光纤等。不同的媒介会提供不同的传输率(Transmission rate) ，用bits/second 表示。


<br>Networks: collection of devices, routers, switches, links: managed by an organization
<br>Protocols and Internet standards:<br>
- Every node in the network runs a common set of protocols, such as TCP/IP, to ensure reliable communication and interoperability. These protocols are the rules that govern the exchange of information over the network.<br>
- Internet标准主要由Internet Engineering Task Force (IETF)组织制定。IETF标准文档叫做requests for comments (RFCs)，这些文档由世界各地的工程师参与制定。<br>
<img alt="Pasted image 20240511220056.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240511220056.png">
<br><br>如其名所示，这种Internet的描述从应用的角度将Internet分为两大部分：<br>
<br>分布式应用(Distributed Applications)

<br>在多台主机上可能运行着不同的应用，不同主机上的应用有交换信息的需求时，就需要其余更底层的设施为信息的交换铺平道路。
<br>这时，主机end systems会为应用提供一个socket interface ，然后给发送程序规定了一系列delivery rules 。随后发送程序(Sending program)将socket中的信息通过基础设施(Infrastructure) 将信息传递发给另一台主机。


<br>为分布式应用提供服务的基础设施(infrastructure that provides services to applications)

<br>这些infrastructure的使命就是为应用提供服务。在"nuts and bolts" view中的部件如host、swtiches、routers和linking media就是infrastructure。


<br><br>A protocol defines the format and the order of messages exchanged between two or more communicating entities, as well as the actions taken on the transmission and/or receipt of a message or other event.<br>
<br>网际协议(Internet protocols) 规定、规范了一系列规则使得end systems、packet switches可以按照既有规则进行工作。这些设备无关生产厂家，只要遵守相关的protocols就可以接入Internet和其他设备进行通信。
<br>不同的协议有着不同的功能，以TCP和UDP为例，TCP 是面向连接的协议（通信的状态只在端系统之间维护，网络(core)不知情），它在数据传输前需要建立一个稳定的连接。而UDP 是无连接的协议，它不需要建立连接就可以发送数据，这使得它能够更快地传输数据。与人类社交中有礼貌和粗鲁的提问类似，遵守TCP协议的人类在提问前会先有礼貌地打招呼，而遵守UDP协议的人类会直接发问。这样带来的后果就是遵守TCP协议的人类尽管多花了打招呼的时间，但相比粗鲁的UDP更有可能得到问题的答案。
<br><br>End systems are also referred to as hosts because they host (that is, run) application programs.<br><br>网络边缘(The network edge),即主机系统host/end systems，边缘系统上运行的网络应用是网络之所以存在的原因。有时也将hosts更细分为客户机(Clients)和服务器(Servers)。数以千计的服务器共同组成服务器农场(server farm) 也叫数据中心(Data center)，用于content residence。<br>
<br>端系统(End systems)

<br>运行应用程序
<br>位于网络边缘


<br>客户机/服务器模式(Client/Server Mode)

<br>客户端向服务器请求、接收服务


<br>对等模式(Peer to peer mode)
<br><br><br>
<br>握手:在数据传输之前做好准备

<br>人类协议中:你好、你好
<br>两个通信主机之间为连接建立状态


<br>TCP-传输控制协议(Transmission Control Protocol )

<br>Internet上面向连接的服务


<br><br>
<br>可靠地、按顺序地传送数据（确认和重传）
<br>流量控制（发送方不会淹没接收方）
<br>拥塞控制（当网络拥塞时，发送方降低发送速率）
<br><br><br>
<br>无连接服务
<br><br>
<br>无连接
<br>不可靠数据传输
<br>无流量控制
<br>无拥塞控制<br>
<img alt="Pasted image 20240512121540.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240512121540.png">
<br><br>The network that physically connects an end system to the first router (also known as the “edge router”)<br>
<br>接入网络连接用户和边缘网络，通常包括宽带接入如DSL、光纤到户（FTTH）或移动网络接入。接入网络为用户提供进入互联网的通道，并将用户的数据传输到边缘网络。<br>
<img alt="Pasted image 20240512142716.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240512142716.png">
<br><br>□ 数字用户线(Digital Subscriber Line)<br>
<br>
居民通常从电信公司(Telephone company) 获得DSL的接入网服务，因此当用户使用DSL上网时，telco就是用户的ISP；

<br>
在下图中，Home PC使用数字用户线(Digital Subscriber Line)

<br>
居民通常从电信公司(Telephone company) 获得DSL的接入网服务，因此当用户使用DSL上网时，telco既是用户的ISP；

<br>
在下图中，Home PC使用DSL modem将数据在现有的DSL线路上进行交换，在线路上的数据会在电信公司本地CO中的 DSL（Digital Subscriber Line 数字用户线路）通常不是基于电路交换（circuit switching）的 DSLAM(Digital Subscriber Line Access Multiplexer) 频分复用对线路传输过来的信息进行分频处理；

<br>
在用户端，分路器(Splitter) 把电话信号发给Home phoen并将数据信号转发给DSL modem；

<br>
因为上载/下载的速率不同，所以这种接入是不对称的(Asymmetric) ,这和上载/下载所分配的频段有关。(ADSL)

<br>
Hundreds or even thousands of households connect to a single DSLAM，因而这种接入网方式是共享的。<br>
<img alt="Pasted image 20240513201503.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240513201503.png"><br>
□ Cable Internet Access(有线网络接入)

<br>
鉴于DSL network access是在电信公司telco已有电话线的基础上的network access，cable Internet access也做了类似的事情。Cable Internet access在电视公司已有电视线的基础上接入网络，由于光纤和同轴电缆同时存在于这个系统，因而又称这种网络为HFC(Hybrid Fiber Cable) 即混合光纤同轴网络。

<br>
在有线网络接入中，用户的住所需要有一个电缆调制解调器（cable modem），而有线运营商的设施（通常是有线电视的头端）则需要有一个电缆调制解调器终端系统（CMTS）。这两者通过同轴电缆连接到混合光纤同轴（HFC）网络。

<br>
电缆和光纤将每个家庭接入到ISP的路由器，各用户线缆头端的带宽共享。

<br>
使用标准：DOCSIS<br>
<img alt="Pasted image 20240513205240.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240513205240.png"><br>
□ FTTH(Fiber To The Home) 

<br>
光纤到户有两种架构(Architechure)用于实现信号的分配：

<br>Active optical networks(AONs) 有源光网络
<br>Passive optical networks(PONs)无源光网络<br>
他们的主要区别是AONs是direct fiber，one fiber leaving the CO for each home. PONs是多用户share一根fiber，如下图：<br>
<img alt="Pasted image 20240514001832.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240514001832.png"><br>
在PONs架构下，来自CO的光纤通过无源分光器(Optical splitter) 与多个家庭共享，每个家庭会有一个ONT(Optical Network Terminator)光网络终端由一根专用光纤与分光器相连，分光器与CO中的OLT(Optical Line Terminator)光线路终端相连，在ONT和OLT中会进行光/电信号之间的转换。<br>
在用户端，通常会用一个无线路由器与ONT链接以便提供接入网。


<br>□ 5G fixed wireless<br><br>□ 如下图，以太网用户使用 双绞线(Twisted-pair copper) 接入以太网交换机，随后接入Internet。以太网接入网可以为用户提供100 Mbps to tens of Gbps的带宽，鉴于服务器可能只有1 Gbps 到10 Gbps access。<br>
□ 现在，几乎每个人都会使用无线的局域网(Wireless Local-Access-Network)来上网。现在的企业也通通使用WLAN来联网，但WLAN通常只有十多米的access范围，因此企业多使用以太网接入。<br>
<img alt="Pasted image 20240514003252.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240514003252.png"><br>
即使以太网和WiFi最开始是在企业中使用的，现在也是家庭接入网中不可分割的一部分。<br>
<img alt="Pasted image 20240514003303.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240514003303.png"><br><br><br>将媒介按无线和有线可以将媒介分为两类：<br>
<br>引导性媒介(guided media) 
<br>非引导性媒介(unguided media) 
<br><br><br><br><br><br><br>
<br>核心网络是互联网的中心部分，由高速和大容量的路由器和交换机组成。它负责连接不同的边缘网络，并在全球范围内路由数据。核心网络通常具有高度的冗余和可靠性，以确保数据传输的稳定性。<br>
<img alt="Pasted image 20240512143000.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240512143000.png">
<br><br>
<br>Time to Transmit<br>
假设包长L bits，link的传输率为R bits/sec，在不考虑传播时延(propagation delay)的情况下有传输时间L/R seconds。
<br><br>
<br>存储转发传输 要求packet switches在转发报文之前必须完整地接收到全部的报文。 
<br>报文传输时延(Transmission delays)：

<br>在不考虑传播时延的前提下，使用存储转发传输的Source host向Destination host转发三个packets。由于存储转发传输方式的要求，第一个packet必须完整地发送到router中后才能向Destination host转发。即当第一个packet完整地到达router用时L/R sec，Destination host完整收到第一个packet时总用时2L/R sec。三个包全部被Destination host接收用时4L/R sec。
<br>在N个links的情况下d = N ( L / R ) sec<br>
<img alt="Pasted image 20240512155342.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240512155342.png">


<br><br>
<br>每个数据包交换机都可能连接多个links，这些packet switches有一个输出缓冲器/输出队列(Output buffer/queue) 用来储存将来向链路发送的信息。每当output buffer忙碌时，host所发送的报文就需要排队等待。packets等待的时间被称为排队时延(Queuing delays) ,排队时延的大小取决于网络拥塞度，因为buffer的空间是有限的，在buffer空间满了的时候就可能发生包丢失(Packet loss) 情况。<br>
<img alt="Pasted image 20240512161340.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240512161340.png">
<br><br>When a source end system wants to send a packet to a destination end system, the source includes the destination’s IP address in the packet’s header. When a packet arrives at a router in the network, the router examines a portion of the packet’s destination address and forwards the packet to an adjacent router. More specifically, each router has a forwarding table that maps destination addresses (or portions of the destination addresses) to that router’s outbound links. When a packet arrives at a router, the router examines the address and searches its forwarding table, using this destination address, to find the appropriate outbound link. The router then directs the packet to this outbound link.<br><br><br><br>Dedicated and guaranteed, not shared.<br>
<br>在 电路交换(Circuit Switching) 的网络中，为了在端系统之间提供通信，路径上所需的资源（如缓冲区、链路传输速率）会在通信会话期间被预留直到会话结束。在发送方向接收方发送数据前，首先要建立接-发双方之间的网络连接。通信会话一旦被建立，路径上的资源就持续服务该会话，直到通信结束。这种方式确保了通信过程中资源的连续可用性，从而提供了稳定的通信质量。但这也意味着资源即使在不使用时也不能被其他通信会话共享，可能导致资源的低效利用。
<br>下图是一个 电路交换 的例子，其中有四个电路交换机，每个交换机由四条线路组成的链路彼此连接。从而一条链路可以提供四个同样的连接。当两台主机想要通讯时，网络会在主机之间建立一个专属的端到端的连接(end to end connection) 。假设邻接的交换机之间的传输率是 1Mbps，由于链路由四条线路构成，所以每个端到端的电路交换链接都会得到250Kbps的专用传输率。这意味着该250Kbps的传数率是不可共享的。<br>
<img alt="Pasted image 20240512184019.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240512184019.png">
<br><br>
<br>A circuit in a link is implemented with either frequency-division multiplexing (FDM) or time-division multiplexing (TDM)

<br>在FDM方式下，链路的 频谱(Frequency spectrum) 被不同的链接分成多个频段，作为其链接的专用频段。如电话线网络通常占有4kHz的频带宽度，而FM广播站的频谱在88 MHz and 108 MHz之间，每个广播站都有自己专用的带宽。
<br>在TDM方式下，时间被分成固定持续时间的帧(frame)，每一帧又被划分成多个时隙(slot)。当网络通过链路建立某一链接时，这个链接就会专用每一帧时间片内固定位置的时隙。


<br>The good aspect of a dedicated connection can be a guaranteed and stable connection but the resources on the connection are not a shared, which can be wasteful because of slient periods.<br>
<img alt="Pasted image 20240512204230.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240512204230.png">
<br><br>
<br>Critics of packet switching have often argued that packet switching is not suitable for real-time services (for example, telephone calls and video conference calls) because of its variable and unpredictable end-to-end delays (due primarily to variable and unpredictable queuing delays). 
<br>Proponents of packet switching argue that (1) it offers better sharing of transmission capacity than circuit switching and (2) it is simpler, more efficient, and less costly to implement than circuit switching
<br><br><br>
<br>前文中提到，DSL network access的access ISP通常是telco而cable network access的access ISP通常是cable company。但接入网ISP不完全是这样，如大学可以为校园内的学生、职员提供接入网服务，公司可以为聘员提供接入网服务，这些都属于ISP。但无论这些ISPs为多少end systems还是content providers提供接入网服务，他们也只能算庞大Internet画面中的一小片拼图。这些"puzzles"必须相连(interconnected)来组成Internet这一庞大的拼图。这也是为何Internet is called network of networks.
<br><br>对Internet有了这样一个宏观的视角后，我们现在需要考虑的问题是如何把这些"puzzles"拼起来！一个简单的方式是让每个ISP与其他ISPs相连。但这样做的开销会随着ISP的数量指数增长(Big O-notation of n²)，因此我们需要另辟蹊径，以下介绍五种结构：<br>
<br>Network Structure 1: 在第一种结构中，每个接入ISP都与单一的全球中转ISP(Global transit ISP)相连，这个全球中转ISP拥有所有Internet core的链路、路由器、交换机等核心资源，对于access ISP来说，全球中转ISP是提供商而access ISP是客户，接入网需要向全球中转ISP缴纳费用。但这种结构对于这一单一的中转ISP成本无疑是巨大的，别国政府也不会让本国的网络通信毫无保留地暴露给这个single global transit ISP。
<br>Network Structure 2: 是一个两层结构的网络结构，出现了多个全球中转ISP，他们属于Top Tier ISP/Tier 1 ISP 。其他的access ISP属于Bottom Tier 。区域性的ISP(Reigional ISP)如大学ISP与Top tier ISP相连接入Internet。
<br>Network Structure 3：这是一个多层次的层级结构(multi-tier hierarchy)，包括访问ISP、区域ISP和一级ISP。每个层级的ISP都会向上一层的ISP支付费用，而一级ISP位于顶层，不向任何人支付费用。

<br>在中国，城市的访问ISP连接到省级ISP，省级ISP再连接到国家级ISP，最后连接到一级ISP。


<br>Network Structure 4：在网络结构3的基础上增加了存在点（PoP）、多重连接（multi-homing）、对等互联（peering）和互联网交换点（IXP）。PoP存在于除了访问ISP层级之外的所有层级，它是客户ISP可以连接到提供商ISP网络的地方。ISP可以选择多重连接，即连接到两个或更多的提供商ISP。对等互联是同一层级的两个ISP直接连接他们的网络，通常是无结算费用的。IXP是多个ISP可以相互对等互联的地方。
<br>Network Structure 5：在网络结构4的基础上增加了内容提供商网络，例如谷歌。谷歌有遍布全球的私有TCP/IP网络，它与公共互联网分开，只承载来自谷歌服务器的流量。谷歌通过在较低层级的ISP处进行对等互联或在IXP处连接来“绕过”互联网的上层，但由于许多访问ISP仍然只能通过一级网络到达，谷歌网络也连接到一级ISP，并为与它们交换的流量支付费用。
<br><img alt="Pasted image 20240514163345.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240514163345.png"><br><br>Delay和 Packet loss是计算机网络永恒的话题。人们想要瞬间传输任意大小的 packets，但由于物理法则的限制，我们只可能在尽量短的时间传输尽可能多的 packets并保证 packet尽可能少的出错，即减少 delay和 loss，增加 throughput。<br><br>
<br>在计算机网络中，数据包(Packet)始于一个end system/host，而终于另一个end system/host。在这个过程中，这个数据包会经过一个又一个node(host/router)。在结点间的传输中，数据包会经历各种各样的delay。
<br>其中，最重要的有这几个时延：nodal processing delay, queuing delay, transmission delay, and propagation delay;把它们加到一起，我们叫总共时延total nodal delay。<br>
即：
<br>这些时延会影响到应用的性能，想要深入理解报文交换(Packet switching)和计算机网络(Computer network)，我们必须学习这些delays的重要性！
<br><br>下图展示了一个end-to-end传播路径的一部分。当host上传数据包packet时，数据包会首先到达路由器A的输出缓冲器中。<br>
<br>如果packet是buffer的第一个数据包，路由器A会检查其数据包头(packet's header) 然后将数据包放在目的地链路上；
<br>如果buffer前方有数据包，则需要等待(queuing)；
<br>如果数据包到达时buffer满，则可能发生packet loss。<br>
<img alt="Pasted image 20240518004728.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240518004728.png">
<br><br>
<br>处理时延一般指解析数据包头的时长+将数据包送到目的地链路时间。但也有其他细节：如比特位纠错(checking for bit-level errors)的时间。
<br>处理时延在高速路由器中通常需要毫秒级别的时间。
<br><br>
<br>数据包在被传送到链路上前，通常会耽搁一段叫做排队时延(Queuing Delay) 的时间。同现实世界一样，排队时延的长短取决于buffer中排在packet前面的数据包数。运气好的话，我们的packet是第一个排队的，那么排队时延就为0；但如果前面已经排了很多数据包了，相应的排队时延就会长，这种情况也叫网络拥塞 (network congestion)。
<br>排队时延一般是微秒到毫秒级别的。
<br><br>
<br>假设数据包以先来先服务(First Come First Served) 传输，只有在我们的数据包前面buffer中所有的数据包传输完成后才能进行传输。
<br>我们用  L bits ==表示数据包的长度；用R bits/sec== 表示从路由器A到路由器B上链路的传输率。则我们的 传输时延 为 L/R 。这个时间是将数据包上所有bit数据送上链路的时间和。
<br>传输时延一般是微秒到毫秒级别的。
<br><br>
<br>在将数据包送上链路(Link)上后，它需要传输到路由器B。传播时延 就是从刚开始在链路上传输到路由器B的这段时间。传播时延取决于链路的物理介质(that is, fiber optics, twisted-pair copper wire, and so on)。
<br>假设物理介质的传播速度是s，需要传播长度为d，则传播时延是d/s 。
<br>在短距离的传播中，传播时延往往可以忽略不计。但在广域网中，如果传播时延是毫秒以上级别的，不可以忽略。
<br><br>
<br>在结点众多的时延中，不同于其他时延和数据包无关的特性，排队时延和数据包在queuing buffer中的位置息息相关。在queuing buffer中越靠前的packet总能获得更短的排队时延(第一个传输的包将不会有排队时延)。
<br>因此，当我们提到排队时延，我们通常指一个统计上的概念，如“平均排队时延”。我们用a表示平均每秒传输到queue的包数，用R表示传输率(Transmissioin Rate)，用L表示包中的比特数。我们用他们的比值La/R表示traffic intensity。

<br>当La/R＞1，即使不算处理时延，传输率也不能将这些排队的packets及时传输到链路上，that is , a buffer full situation，这时无论什么情况，传输到node上的packets数也超过了其所能处理的packet数，这时的排队时延将是无穷大的，还会伴随有packet loss 的情况出现。
<br>当La/R≤1，我们先讨论等于1的情况，假如每L/R秒的时间就会有一个packet传输到queuing buffer中，这时不会有任何排队时延，因为在下一个包到来的同时上一个包刚好被发送出去，这是一种周期性到达的理想情况。也可能每(L/R)N秒到达N个数据包，这时会有排队时延。但一般情况下，数据包的到达可能由一种random arriving burst的情况到达，即link沉寂m的时间，忽然有N个数据包到达。要使得不发生packet loss的情况，工程师应该合理地设置buffer的大小。<br>
<img alt="Pasted image 20240518145801.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240518145801.png">


<br><br>前面我们讨论了结点间的时延。有了这个基础，端到端的时延就是多个nodal dalay的加和。假设source和destination之间有N-1个路由器，假设网络不拥塞。即有：<br><br>
<br>为了上手感受计算机网络端到端上的时延，我们可以通过Traceroute程序追踪数据包在从源主机到目的主机的过程中所经过的路由器路径。
<br><br>在网络通信中，除了处理时延、传输时延和传播时延之外，端系统中还可能存在其他显著的时延。例如：<br>
<br>共享介质的传输延迟：在WiFi或有线调制解调器等共享介质中，端系统可能会故意延迟发送数据包，以遵循共享介质的协议。这些协议允许多个端系统共享同一介质，以避免数据包冲突。<br>

<br>媒体分组化时延：在VoIP（语音通信协议）应用中，发送方在将数据包传递到互联网之前，必须先用编码后的数字化语音填充数据包。这个填充数据包的时间被称为分组化时延，它可能相当显著，并且会影响用户对VoIP通话质量的感知。
<br><br>除去时延(delay)和数据包丢失/分组丢失(packet loss)，另一个衡量计算机网络性能的因素就是端到端的吞吐率。<br>
<br>
以主机A要向主机B发送一个大文件为假设，下面我们将介绍两个吞吐率的概念：

<br>瞬时吞吐率(Instantaneous throughput)：<br>
瞬时吞吐率是某时刻Host B收到信息的比率rate(bits/sec)。在用户界面常常会看到瞬时吞吐率，通常用来衡量“网速”的快慢，即网络最佳状态下的性能。
<br>平均吞吐率(Average throughput)<br>
假设某段时间(T seconds)内Host B总共收到的F bits，那么平均吞吐率就是F/T(bits/sec)。在某些应用中，可能会设置一个门槛(如24 kbps in telephony还有256 kbps in real-time video apps)来实现持续且低延迟的通讯。<br>
在类似下载文件这样的应用场景中，delay并不是我们关心的，这时的的吞吐率对我们而言总是多多益善的。


<br>
为更深入地理解吞吐率的概念，我们假设服务器端向客户端传输文件的一个场景如下图。在上面 a 图中，服务器通过链路吞吐率为 的链路 将文件信息传输给路由器，经路由器转发到吞吐率为的链路 ，后传输到客户端。这时的链路吞吐率由吞吐率小的链路决定。

<br>
下图图b是另一个scenario system，它由两个end system和一堆路由器组成，这时的端到端吞吐率的大小为：它由最小吞吐率的链路，即 bottleneck link 决定了整个系统的吞吐率大小 。<br>
现在，我们可以轻松地想到从Server向Client传输一个大小为F bits的文件时，大概需要的时间。<br>
<img alt="Pasted image 20240519002020.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240519002020.png">

<br>
我们观察如下图的情形。前面我们已经得知end-to-end throughput是由下面的公式：决定，然而当我们有一个10 Servers-10 Clients scenario，且这10个Server都在向Client传输文件。我们假设连接Server链路的传输率为，连接10个Client链路的传输率为，在他们之间有一条公用传输率的链路。我们可能会想当然的认为bottleneck link是传输率为的，但现在作为共用的链路，对于每个end-to-end system，这条链路的传输率为。<br>
<img alt="Pasted image 20240519004302.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240519004302.png">

<br><br><br><br>
<br>在将我们思绪放在Internet architecture上之前，我们来设想一个human analogy。下图是一个air-line system，将航线以功能性划分为多个层次(Layer)，这些层次共同提供了一个航线飞行的框架。每一层与底下的层次一同实现某些功能，或称为服务。<br>
- At the ticketing layer and below, airline-counter-to-airline-counter transfer of a person is accomplished.<br>
- At the baggage layer and below, baggage-check-to-baggage-claim transfer of a person and bags is accomplished.<br>
- At the gate layer, departure-gate-to-arrival-gate transfer of a person and bags is accomplished.<br>
- At the takeoff/landing layer, runway-to-runway transfer of people and their bags is accomplished.<br>
<img alt="Pasted image 20240519010954.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240519010954.png">
<br><br>
<br>为提供设计网络协议的结构框架，网络设计师以层次构建出协议以及更底层的硬件软件。这种分层的结构框架允许每个层次专注于特定的功能，同时提供给上层协议所需的服务。每个协议在其对应的层次上运行。
<br>我们重新着眼于下层为上层提供的services，也称作层次服务模型(Service model of a layer)。  每个层次通过：

<br>在层内执行特定的活动 Performing certain actions within that layer；
<br>使用下层所直接提供的服务 Using the services of the layer directly below it；<br>
来提供其服务。


<br>协议分层(protocol layer)可以用软件或硬件或软硬件实现。越靠近应用层(上层)，协议的实现越倾向于软件方式，应用层的如HTTP协议和SMTP协议。这是因为下层的物理层和数据链路层负责接收特定链路传输过来的数据，这些功能通常封装在网络接口卡(Network Interface Card)中。
<br>如下图所示，将各层的协议合在一起叫做 协议栈(Protocol Stack)。<br>
<img alt="Pasted image 20240519131546.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240519131546.png">
<br><br>
<br>应用层是网络应用和应用层协议所在的地方，Internet的应用层涵括了许多协议，如HTTP协议、SMTP协议还有FTP协议等。
<br>网络层协议分布在各种各样式的end system设备上，在终端设备使用应用层协议传输packet数据包时，我们把这些在应用层的数据包称为报文(Message)。
<br><br>
<br>Internet的传输层的任务时在终端的应用端点(Application endpoints)之间传输应用层报文。在应用层中最重要的两个协议TCP和UDP，它们都可以传输应用层的报文信息。

<br>TCP(Transmission Control Protocol)<br>
为应用提供面向连接的服务，这些服务包括(1)传输应用层报文到destination的保证及流量控制((Flow control)sender/receiver speed matching)，(2)TCP也会将报文划分为更小的段并提供拥塞控制机制(Congestion-control machanism)。
<br>UDP(User Datagram Protocol)<br>
UDP为应用提供无连接的服务，UDP的连接是不可靠但即时的连接，不保证对流量和拥塞的控制。<br>
我们把在传输层的数据包称为报文段(Segment)。


<br><br>
<br>Internet的网络层的职责传输网络层数据包，即数据报(Datagram)。源主机上的传输层的协议(如TCP和UDP)给网络层传递传输层报文段和目标地址。然后网络层将数据报从一个host传输到目标host的网络层上。
<br>网络层最重要的协议是IP协议，这也是Internet上最核心的协议之一，任何有网络层的网络部件都必须实现IP协议。网络层除了IP协议还要一些路由协议(Routing protocol)指明数据报传输的方向。由于IP协议的重要性，有时也将Network layer叫做IP layer。
<br><br>
<br>网络层的数据报通过源与目标主机间的许多路由器进行传输，要将packet从一个结点传给另一个结点，网络层需要依靠链路层提供的服务。
<br>链路层提供的服务取决于链路上配备的链路层协议，有些链路层协议提供可靠的传输，链路传输的可靠性是由链路介质决定的，如WiFi提供不可靠的服务，Ethernet提供可靠的服务。由于数据报在源-目标传输可能历经多种链路，每个链路层可能使用不同的链路层协议，比如数据报可能在一个链路上使用以太网协议，在另一个链路上使用点对点协议（PPP）。
<br>链路层的协议有Ethernet、WiFi、PPP(Point to Point Protocol)、还有有线传输网络的DOCSIS协议等。我们称数据链路层的数据包为帧(Frame)。
<br><br>
<br>物理层的工作是将链路层帧中的比特位从一个网络结点传给另一个网络节点。物理层的协议和链路层协议一样都是link-dependent/medium-dependent，传输介质决定了协议的内容(如双绞线、铜线、光纤等)。
<br>Ethernet有许多物理层的协议，one for twisted-pair copper wire, another for coaxial cable, another for fiber, and so on.每种协议实现的Ethernet在链路中传输bit的方式都是不同的。
<br><br>
<br>下图展示了数据从源地址host到目的地址host传递的物理路径。和end system相似，packet switches(link-layer switches和routers)也将它们的网络硬件组织成不同的layers。但与end system不同的是，packet switches并不像end system那样实现了协议栈中的所有layers，而只实现了最底层的部分。而实现全部协议栈的end system表明Internet架构在network edge上所投入的复杂度是很高的！<br>
<img alt="Pasted image 20240519150643.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240519150643.png">
<br>上图同样显明了封装(encapsulation) 的重要性：

<br>在应用层，应用层把报文M传给传输层；
<br>在传输层，传输层收到应用层的报文后会在报文头部附加一个传输层头层信息transport-layer header information  ，对报文M进行封装。 和共同组成了传输层数据段(Segment)。这些header info允许接收端host的传输层能够把报文传递给正确的应用；接收端Host也可以通过检错位判断报文在路由中是否有变化。
<br>在网络层，接收到传输层的数据段后会将其进一步进行封装，在Segment头部添加网络层头层信息  。 中包含如源/目的end system的地址等信息，将segment封装为网络层数据报(Datagram)。
<br>随后数据到达数据链路层，然后链路层加入自己的头层信息 将datagram封装成一个数据链路层帧(Frame)。<br>
通过上述的逐层封装过程，我们可以发现一个数据包(Packet)/PUD 包含两个类型的字段(field) ：头部字段(header fields) 和 有效载荷字段(payload field)/SDU。有效载荷字段通常指上层传输的数据包。


<br><br>在1.6节，我们需要了解一些网络领域的名词：<br>
<br>Malware（恶意软件）
<br>Botnet（僵尸网络）<br>
<img alt="Pasted image 20240521003828.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240521003828.png">
<br>Denial-of-Service(DoS) attack（拒绝服务攻击）

<br>Vulnerability attack（漏洞攻击）
<br>Bandwidth attack（带宽攻击）
<br>Connection flooding（TCP连接泛滥）


<br>Distributed DoS attack（分布式拒绝服务攻击）
<br>Packet sniffer（数据包嗅探器）
<br>IP spoofing（IP欺骗）
<br>更多网络安全的相关内容将留在 Chapter 8 单独介绍。<br><br>1.7节作为了解型内容。]]></description><link>https://congzhi.wiki/computer-networking-a-top-down-approach/chapter-1-computer-networks-and-the-internet.html</link><guid isPermaLink="false">Computer Networking A Top-Down Approach/Chapter 1 Computer Networks and the Internet.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 07 Mar 2025 15:27:53 GMT</pubDate><enclosure url="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240511220056.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240511220056.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Chapter 2: Application Layer]]></title><description><![CDATA[ 
 <br><br>Network applications are the raisons d’être of a computer network—if we couldn’t conceive of any useful applications, there wouldn’t be any need for networking infrastructure and protocols to support them.<br><br>当我们有一个网络应用的点子时，我们得先明白现实世界中的网络应用是如何运行的。在网络应用最核心的开发任务就是编写能够跑在不同终端并使得它们可以经由网络核心(network core)互相通信的程序代码。在Web应用中，有两类应用不断地互相通信，一类是运行在用户host上的浏览程序(browser program)，另一类是运行在Web服务器上的Web服务程序(Web server program)。<br>
<img alt="Pasted image 20240527021928.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240527021928.png"><br><br>应用程序开发者的角度来看，网络架构是固定的(fixed)，并且为应用程序提供了一套特定的服务。换句话说，当开发者创建应用程序时，他们可以依赖这个预先定义好的网络架构来构建功能，而不需要关心网络的底层细节。<br>
<br>在application architectures的选择上应用程序员通常会从下面当今主流的两种结构中进行选择：<br>
1.The client-server architecture:<br>
- 在客户机-服务器体系结构下，服务器总会一直运行等待客户机的服务请求。当Web服务器收到来自客户机的请求对象服务时，服务器就会返回被请求的对象。<br>
- 这种体系结构有一些特点值得我们注意：在客户机-服务器模式下client-hosts不能直接通信；而且服务器有一个固定且周知的地址，我们称为IP地址。因而，客户机总能通过发送packet数据包的方式和服务器进行通信连接。<br>
- 遵从客户机-服务器模式的应用有Web, FTP, Telnet, e-mail等。<br>
- 通常情况下，单服务器不足以响应来自客户机的所有请求，which can be overwhelmed to the server. 因此，数据中心(Data center) 应运而生。我们熟知的各种搜索引擎和很多大型社交应用就是运行在散布世界各地的data center上的。<br>
2.The peer-to-peer (P2P) architecture（P2P file sharing system）<br>
- 和客户机-服务器体系结构严重依赖数据中心不同，对等网络的应用对数据中心几乎没有依赖，它们通过hosts在网络上的互联间接的通信。<br>
- P2P体系结构中的每个host(被称为peer)即充当着服务器的角色——响应其他peer host的服务请求的同时它们也充当着客户机的角色——向其他peer host发起服务请求。<br>
- 这些对等体不受服务提供商所有，它们运行在用户所有的终端设备上。因为这些对等体应用之间的通信不经由data center，因而被叫做peer-to-peer。<br>
- P2P体系结构最引人入胜的特性就是自扩展性(self-scalability)。这意味着每当新用户加入P2P网络，网络的总体带宽和资源分发能力也随着新用户的加入而增长。这是因为新用户不仅从网络中下载内容，同时也成为了内容的分发者。而不是像传统的客户机-服务器模型那样，服务器的负载随用户数量增加而线性增长。例如，在BitTorrent这样的P2P文件分享系统中，每个用户在下载文件的同时，也会上传已经下载的文件部分给其他用户。这样，文件的分发不再依赖于单一的服务器，而是由网络中的所有用户共同完成，从而实现了自扩展。<br>
- Cost effective，因为P2P体系结构对数据中心的依赖降低，因此可以在组件data center服务器上省下一大笔开销。<br>
<img alt="Pasted image 20240527032107.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240527032107.png">
<br><br>
<br>当程序载入内存在host上运行的时候，它就变成了进程(process)。当我们说不同end systems之间的通信时，实际上是Application layer之间的通信，即不同宿主机中进程的通信。在计算机网络课程中，我们不关心同一宿主机里的进程间通信。
<br>不同终端间的进程通过计算机网络交换报文(exchanging messages) 来与彼此通信。 发送进程创建报文并将其转发到网络上；接收进程接收这些报文并作出回应。
<br><br>
<br>一个网络应用要实现不同end system上进程的通信，就要包括一对进程，即：<br>
（1）发送报文的进程——我们将其标为Server；<br>
（2）接收报文的进程——我们将其标为Client。

<br>在客户机-服务器体系结构下，孰是客户机孰是服务器很好辨别，因为服务器(Content Service Provider)总是向客户机(User's host)发送报文信息。
<br>在P2P体系结构下，end system的身份就相对模糊起来。因为peer host即可能是上传信息的一方(响应请求)，也可能是下载信息(发起请求)的一方。


<br>我们对client和server的定义如下:<br>
In the context of a communication session between a pair of processes, the process that initiates the communication (that is, initially contacts the other process at the beginning of the session) is labeled as the client. The process that waits to be contacted to begin the session is the server.<br>
即发起会话请求的是客户端(客户端请求)，接收并反映请求的是服务器端(服务器端回应)。
<br><br>从一个进程向另一个进程传输的报文都要经由下层网络。我们之前提到：计算机网络的下层是为上层的服务而存在的。在这里我们会有疑问，网络栈中 应用层 和 传输层 之间的接口是什么呢？这个处于应用和网络之间的软件接口API就叫做Socket——应用进程与传输层协议间的接口。<br>
<img alt="Pasted image 20240527174749.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240527174749.png"><br>
<br>在网络应用开发时，开发者只对socket接口的应用层一侧有完全的掌握，但对传输层一侧几乎没有控制。但开发者对传输层一侧能够控制的有：<br>
（1）传输层协议(choice of transport protocol)<br>
（2）修改一些传输层的参数(ability to fix a few transport-layer parameters)
<br><br>
<br>要实现两进程之间的通信，我们就得先知道destination process的地址是什么。要知道目标进程的确切地址，我们需要知道：<br>
（1）主机地址——IP address<br>
（2）区别目标主机的接收进程的标识——Port number<br>
Popular applications have been assigned specific port numbers. For example, a Web server is identified by port number 80. A mail server process (using the SMTP protocol) is identified by port number 25. A list of well-known port numbers for all Internet standard protocols can be found at <a data-tooltip-position="top" aria-label="http://www.iana.org." rel="noopener nofollow" class="external-link" href="http://www.iana.org." target="_blank">www.iana.org.</a> We’ll examine port numbers in detail later
<br><br>前文提到Socket是应用进程与传输层协议间的接口，应用进程的发送方将报文信息经由socket传给传输层协议——which has the responsibility of getting the messages to the socket of the receiving process. 因此，开发者在开发应用时必须选择一个传输层协议来保证报文从网络层向传输层的正常传递。<br>
<br>在传输层协议的选择上我们往往会考虑如下方面：

<br>数据传输的可靠度
<br>吞吐率
<br>时延
<br>安全性


<br><br>我们之前了解过，数据包packet在进程到进程传输过程中可能发生丢失、某些bit位出错的情况。在一些如e-mail、金融软件和文件传输的情况时，数据丢失可能造成严重的后果。为保证数据传输时的包完整度，一些协议提供这种可靠的信息传输。一旦传输层协议提供这种服务，发送进程即可将信息包传给socket且保证在信息传输过程中的不出错。<br>一些协议不提供这样的可靠性，这样的协议可能为那些loss-tolerant applications所用。比如一些音视频的多媒体应用，它们容许在信息传出中一定量的数据丢失。<br><br>吞吐率是用来衡量sending process能够向receiving process传输bit的速率大小。我们已经学习过在网络路径上可能不止一条通信会话，可能会有多个会话共享网络路径的带宽，随着其他会话的上线下线，可用带宽会随时间发生变化。这种现象自然地引出另一种传输层提供的服务——guaranteed available throughput at some specified rate。有这种服务的保证，应用可用要求一个最低r bits/sec的最小吞吐率，这对那些带宽敏感的应用是极为需要的。一些对吞吐率变化不敏感的应用——弹性应用(elastic application) 对这种保证性服务就没有这么需要了。<br><br>传输层协议也可以提供时间保证(time guaranteed)的服务。Timing guarantees 可以多种方式提供给应用进程，如guarantee might be that every bit that the sender pumps into the socket arrives at the receiver’s socket no more than 100 msec later.<br><br>传输层也会向应用提供一个或多个安全服务(Security services)。例如，在发送端，传输层可以加密(encrypt)发送进程所发送的所有信息，并在接收端的传输层解密(decrypt)后将信息传给接收进程。<br><br>The Internet(通常上是TCP/IP协议族网络)，向应用提供两种传输协议——TCP和UDP。开发人员在开发网络应用时，最先考虑的问题之一就是应用应当使用TCP协议还是UDP协议。这两个协议中的每种协议都提供了不同的服务集。<br>
<img alt="Pasted image 20240528195845.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240528195845.png"><br><br>TCP服务模型涵括了面向连接的服务和可靠数据传输的服务，当选用TCP作为其传输层协议时，应用就获得了TCP所提供的这两种服务。<br>
<br>Connection-oriented service ：在报文开始传输前，TCP要求客户端和服务器端互换传输层信息，这也称作握手(handshaking)。握手阶段完成之后，一个进程socket间的TCP connection就建立完成了，这个连接是全双工的。当报文发送结束，应用就必须切断连接。
<br>Reliable data transfer service：依靠TCP协议通信的进程所发送的所有信息都是顺序正确且无误的。TCP也提供拥塞控制机制(congestion-control mechanism)，当接发双方间存在拥塞时，TCP拥塞控制机制会遏制发送进程继续发送报文。
<br><br>相比TCP，UDP是”轻便“简洁的，它没有一些附加功能，是一种轻量的传输协议。<br>
<br>UDP是无连接的，因此传输报文前不需要握手。
<br>UDP也不提供可靠传输服务，因此不保证接收进程收到报文的完整和准确性。
<br>UDP也不提供拥塞控制机制。
<br>*Note that neither of these two protocol provides any securing encryption.Transport Layer Security (TLS) is Internet community developing for TCP enhancement. It's not provided by TCP<br>
or UDP itself.<br><br>我们之前通过四个维度总结传输层协议提供的服务：可靠数据传输、吞吐率、timing、安全性。在前面谈论TCP和UDP所提供服务时都漏掉时间和吞吐率保证，这是因为现今的传输层协议不提供时间和吞吐率的保证服务。但这不意为着不能使用Internet拨打电话或视频通话。这是因为如今的互联网可以为time-sensitive application提供满意的服务，但不提供任何timing和throughput的保证。<br>
<img alt="Pasted image 20240528210914.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240528210914.png"><br><br>我们已经了解到网络进程间的通信是通过socket这个API实现的。但我们仍不了解关于messages报文是如何构造的？报文中不同fields的含义是什么？进程何时发送报文？Application-layer protocol会告诉我们答案。一个应用层协议的具体定义如下：<br>
<br>The types of messages exchanged, for example, request messages and response messages 
<br>The syntax of the various message types, such as the fields in the message and how the fields are delineated 
<br>The semantics of the fields, that is, the meaning of the information in the fields 
<br>Rules for determining when and how a process sends messages and responds to messages
<br>一些应用层协议在RFC中能够找到详细定义，如HTTP；但也有一些应用层协议作为财产专利不公之于众，如Skype。<br>
弄明白网络应用和应用层协议的区别很重要，应用层协议知识网络应用的一部分，我们举一个例子：<br>
<br>Web&nbsp;是一个客户端-服务器应用，允许用户按需从Web服务器获取文档。
<br>Web应用&nbsp;包含多个组件，比如：

<br>文档格式的标准（即HTML）
<br>Web浏览器（例如Chrome和Microsoft Internet Explorer）
<br>Web服务器（例如Apache和Microsoft服务器）


<br>应用层协议，即HTTP，定义了浏览器和Web服务器之间交换的消息的格式和顺序。
<br><br>网络应用日新月异，第二章将以其中一小部分切入讲解：the Web, electronic mail, directory service, video streaming, and P2P applications。它们应用最广泛且易于理解。<br><br>90年代初期之前，网络只能做一些很简单的应用。后来，现象级的应用横空出世——World Wide Web。Web应用是第一个进入大众视线的Internet应用。Web的出现极大地改变了人们在工作环境内外的互动方式，使得互联网从众多数据网络中脱颖而出，成为了基本上唯一的全球性数据网络。<br><br>超文本传输协议(HyperText Tranfer Protocol) 是Web应用在应用层中的核心协议。HTTP完成两份程序——客户端程序和服务器程序，这些程序运行在不同的end system上并通过HTTP报文相互通信。HTTP规定了应用报文的格式和这些报文传输的方式。<br><br>
<br>A Web page(document) 包含了许多对象(文件)，例如HTML文件 、JPEG图片、JS文件、CCS格式的文本文件或一段视频等。一般的Web pages包括一个base HTML file和若干相关对象(如一些图片)组成。这些文件都有一个单一的URL(Uniform Resource Locator) 所标记，目标gif的URL的格式如下：<br>
<br>
其中是服务器主机地址，而 则是一个路径名。
<br>在Web应用中我们一般使用Web browser和Web server来表示Web应用的Client side或Server side。Web server通常由一个URL地址表示。它们都是遵循HTTP协议的程序，规范了Web clients向Web server索求Web pages的方式和Web servers向Web clients传输Web pages的方式。
<br>下图展示了一个简单的HTTP报文传输过程：首先Web clients通过HTTP请求报文向Web server发送一个网页对象的请求，随后server收到请求并通过包含对象的HTTP响应报文以响应。<br>
<img alt="Pasted image 20240603225246.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240603225246.png">
<br>由于传输过程中对准确性的要求，HTTP协议使用TCP作为下层的传输层。HTTP clent先初始化与server的TCP连接，一旦连接被建立，browser进程和server进程就可以通过其socket 接口进行TCP的通信。当client将报文发送到socket 接口之后，报文就进到TCP的掌握之中。之后，不论报文信息丢失还是恢复，这些都不是HTTP所关心的范畴(而是传输层及下面协议所关注的内容)。
<br>需要留意的是HTTP server在向HTTP client发送请求文件时，并不记录关于client的任何信息。因而，当client在短时间向server发送两次关于同一对象的请求报文时，server会死板地再次发送请求文件。正是HTTP server不保存clients的信息，HTTP因此被称作stateless protocol。
<br><br>在许多Internet应用中，client和server会彼此相互通信很长一段时间。在这一大段时间里，client发送一系列请求，server回应这一系列请求。因此，我们产生了一个疑问：这些请求-响应是应该通过多个不同的(separate)TCP连接发送？还是通过一个保持连接的(same)TCP连接发送？<br><br>
<br>我们先介绍非持续连接的HTTP协议。假设网页中由一个base HTML和10张JPEG图片，也就是11个对象在同一个服务器resident。以下是base HTML的URL：<br>
<br>
在整个非持续链接的过程中发生了： 

<br>HTTP client 通过端口80初始化与服务器 的TCP连接。其中80号端口是HTTP默认的端口号。同建立的TCP连接一道建立的还有client side和server side各自的socket 接口。
<br>HTTP client通过其socket向HTTP server发送一个请求报文，其中包括着路径名 (We will discuss HTTP messages in some detail below.)
<br>HTTP server通过其socket收到来自client的请求报文，从memory(RAM或disk)中读出请求对象的内容， 将对象在HTTP应答报文中进行封装并从其socket中向client送出应答报文。
<br>HTTP 服务进程告诉TCP关闭TCP连接。
<br>client process收到响应报文，TCP连接关闭
<br>重复直到客户端进程收到所有网页对象。<br>
以上的步骤展示了一个非持续链接的例子，下一个对象的传输与上一个对象请求所建立的TCP连接没有关系（可以串行也可以一定程度的并行传输）。HTTP/1.0采用的就是这样的非持续连接的方式。


<br>在学习Persistent Connections前，我们先了解以下RTT(Round Trip Time) 的概念。RTT是一个small packet（因为包很小，因此不考虑传输时延）从客户端进程到服务器进程再回到客户端进程的时间，与包传播时延、包排队时延、包处理时延有关。下图示例中，从用户点击一个超链接(hyperlink)开始，总共的响应时间粗略地计算为:<img alt="Pasted image 20240604010021.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240604010021.png">
<br><br>
<br>通过上面对非持续连接的HTTP的学习，我们能够看到这种方式的缺点是非常明显的：每一次的对象请求都需要建立一个全新的TCP连接。如此，必须额外地分配TCP buffer且TCP variables必须在client side和server side二者中保存起来。这样的特点使得Web server的burden会是十分严重的。而且每次重新建立TCP的初始化连接还会额外地浪费一次RTT的时间。
<br>提供持续连接的HTTP/1.1，server会在发送响应报文后仍然打开TCP连接。之后client和server之间的请求和回应就都将建立在同一个已建立的TCP连接上。如此一来，每次请求和应答就免去了TCP连接初始化的步骤，省去一个RTT时间。
<br><br> HTTP的规定了HTTP报文格式(HTTP massage formats) 。HTTP报文有两种格式：（1）HTTP请求报文格式（2）HTTP响应报文格式 。<br><br>下面我们给出一个简单的HTTP请求报文：<br>GET /somedir/page.html HTTP/1.1 
Host: www.someschool.edu 
Connection: close 
User-agent: Mozilla/5.0 
Accept-language: fr
<br>
<br>其中我们可以了解很多信息。首先，HTTP报文是用ASCII码编写的，因此我们可以通过阅读轻易了解其中的含义。为方便阅读，每一行以一个回车符(CR)和一个换行符(LF)作为结束，将报文划分为“五行”。最后一行额外地多一个CR和LF。

<br>HTTP请求报文的第一行叫作请求行(Request line) 。请求行有三个字段(field)：HTTP方法字段、URL字段、HTTP版本字段。

<br>方法字段多个不同的操作方式，GET、POST、HEAD、PUT和DELETE。本例中请求操作方式是GET，表示浏览器向服务器请求一个对象。
<br>Method field中所请求操作的对象就放在URL字段中。
<br>最后版本信息在版本字段中表示。本例中HTTP版本为HTTP/1.1。


<br>HTTP请求报文之后的行(lines)的叫做头部行(Header lines)。

<br>头部行Host: www.someschool.edu 指明了对象所在的host位置。
<br>头部行Connection: close 表示浏览器告诉服务器在自己接收到目标报文后关闭TCP连接。
<br>头部行User-agent: Mozilla/5.0 是发起此请求浏览器的种类。
<br>头部行Accept-language: fr向服务器指明用户期望得到一个法语版本的html对象。


<br>在下图中，我们发现在头部行的下面还有一片实体空间在例子中没有得到体现，这是因为一般在POST操作时才会用到下面的entity body。<br>
<img alt="Pasted image 20240605003249.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240605003249.png">


<br><br>下面我们给出一个简单的HTTP响应报文。<br>HTTP/1.1 200 OK 
Connection: close 
Date: Tue, 18 Aug 2015 15:44:04 GMT 
Server: Apache/2.2.3 (CentOS) 
Last-Modified: Tue, 18 Aug 2015 15:11:03 GMT 
Content-Length: 6821 
Content-Type: text/html 
(data data data data data ...)
<br>
<br>从响应报文的格式来看，我们不难看出它是对请求报文的响应，包含一个状态行(Status line) 、六个头部行(Header line) 和响应实体(Entity body)。

<br>状态行包括三个字段：HTTP版本字段、状态码（请求成功或失败的状态）和原因短语（提供状态码的附加信息）。

<br>在这个例子中，HTTP/1.1 200 OK 表示协议版本是HTTP/1.1，并且everything is OK。
<br>常见的状态码和原因短语有：<br>
（1）200 OK: Request succeeded and the information is returned in the response.<br>
（2）301 Moved Permanently: Requested object has been permanently moved; the new URL is specified in Location: header of the response message. The client software will automatically retrieve the new URL.<br>
（3）400 Bad Request: This is a generic error code indicating that the request could not be understood by the server.<br>
（4）404 Not Found: The requested document does not exist on this server.<br>
（5）505 HTTP Version Not Supported: The requested HTTP protocol version is not supported by the server.


<br>之后的六行都是头部行。<br>
- 头部行Connection: close 告诉客户机进程在发送完报文后就要关闭TCP连接了。<br>
- Date:头部行表示了服务器响应并发出对象报文的时间。<br>
- Server:头部行类似于User-agent头部行，指出报文是被Apache/2.2.3 (CentOS) 所发出。<br>
- Last-Modified:头部行表示源服务器认为资源最近一次被修改的日期。<br>
- Content-Length:头部行声明了对象的大小，单位为byte。<br>
- Content-Type:头部行声明了对象的格式，在本例中是html格式的文本。<br>
<img alt="Pasted image 20240605012506.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240605012506.png">


<br><br>我们前文提到，HTTP协议提供的是一个无状态的服务，这简化了服务器设计，提高了服务器的性能。然而由于user identification的需求，HTTP使用Cookies使网站能够保存用户的轨迹，以便提供面向用户的内容。<br>
<br>下图中，我们可以看到cookie由4部分组成（假设之前访问过ebay）：<br>
(1) a cookie header line in the HTTP response message;<br>
(2) a cookie header line in the HTTP request message;<br>
(3) a cookie file kept on the user’s end system and managed by the user’s browser;<br>
(4) a back-end database at the Web site.<br>
<img alt="Pasted image 20240605013943.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240605013943.png">
<br><br>Web cache—也叫代理服务器(proxy server)，是一种代表源Web服务器为HTTP请求提供服务。下图中演示了一个代理服务器的工作方式，当用户浏览器发送HTTP请求报文时，会先在Web cache中寻找是否存有请求对象，因此Web cache需要拥有自己的磁盘存储来拷贝保存最近被请求的对象。<br>
<img alt="Pasted image 20240605160542.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240605160542.png"><br>
<br>假如我们现在需要请求对象。则会有以下步骤：

<br>浏览器先建立与Web cache的TCP连接并向Web cache发送对象的HTTP请求报文。
<br>Web cache检查本地是否存储该对象，如果有，则将对象包含在HTTP响应报文的实体空间(entity body)中返回给浏览器。
<br>如果Web cache本地不存有该对象信息，Web cache就会和地址是的源服务器建立一个TCP连接。随后Web cache会在cache-server的TCP连接上向源服务器发送HTTP请求报文，然后源服务器将目标对象包含在响应报文中发送给Web cache。
<br>当Web cache收到对象后，它会将对象拷贝放在本地，然后将拷贝的对象包含在响应报文中发送给client浏览器进程。<br>
在这里我们可以发现，Web cache实际上同时充当了client和server的身份。有了Web cache，（1）client请求的响应时间会减少；（2）cache的存在减少了institution访问Internet的拥塞。<br>
一般而言，Web cache受ISP所管理。


<br>为了更深入地理解cache的工作原理，我们用下图的例子来解释。我们看到一个LAN-Institutional network还有WAN——Public Internet。其中LAN内部的网络带宽达到了100Mbps而LAN接入WAN的链路只有15Mbps的带宽。<br>
<img alt="Pasted image 20240605164341.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240605164341.png">
<br>假设每秒传输15个大小1Mbps的对象，忽略请求报文的大小，则有LAN上的网络拥塞度(traffic intensity)为：而接入WAN链路的网络拥塞度为：我们之前就了解过，当网络拥塞度达到接近1时，链路上的延时会达到分钟级别，这是无法被机构用户所接受的。一种解决办法是将公网接入链路的带宽增加到100Mbps，这样的总相应时间大约2s。另一种就是加入cache，将用户常访问的objects存储到本地，这样用户的请求就不必再占用公网的带宽了。
<br>假设Web cache的hit rate是0.4（即40%的请求都能通过cache得到满足），则平均时延就成了：而且减少了接入链路带宽的占用率，而且获得了比第一种解决方案更小的response time。
<br>即便Content Distribution Networks(CDNs) 得到了广泛的应用，但是Web cache仍然发挥着不可或缺的作用。它们的关系就如同main memory和cache memory的关系一样。
<br><br>
<br>尽管caching的方法有效的降低了响应时间，但也带来了新的问题——处在cache中的信息可能是过时的。因此，HTTP提供一种允许cache检查数据是否是”fresh“的机制叫做conditional GET。如果HTTP 请求报文（1）使用GET方法；并且（2）包含If-Modified-Since:头部行。则称这样的HTTP请求报文为conditional GET message。
<br>现在，我们用一个例子来了解一下conditional GET是如何影响报文传输的吧：

<br>首先，proxy server向Web server发送一个请求报文	```

GET /fruit/kiwi.gif HTTP/1.1 
Host: www.exotiquecuisine.com


<br>然后cache收到来自Web server的响应报文

HTTP/1.1 200 OK 
Date: Sat, 3 Oct 2015 15:39:29 
Server: Apache/1.3.0 (Unix) 
Last-Modified: Wed, 9 Sep 2015 09:23:24 
Content-Type: image/gif 
(data data data data data ...)


<br>之后cache转发响应报文给client browser，并在本地缓存对象文件。其中，cache也会将Last-Modified日期存在本地，在之后收到来自client browser的对象请求时，proxy server可以通过conditional GET来检查本地的object是否是过时的

GET /fruit/kiwi.gif HTTP/1.1 
Host: www.exotiquecuisine.com 
If-modified-since: Wed, 9 Sep 2015 09:23:24


<br>第四步，proxy cache收到源服务器的响应报文。304 Not Modified表示object并没有修改过，因此entity body 不需要放任何数据。也使得proxy server可能放心地去转发之前拷贝的object。

HTTP/1.1 304 Not Modified 
Date: Sat, 10 Oct 2015 15:39:29 
Server: Apache/1.3.0 (Unix) 
(empty entity body)


<br><br>
<br>制定于2015年的HTTP/2是千禧年后新一版的HTTP协议，之前是在1997年制定的HTTP/1.1。HTTP/2旨在通过单个TCP连接上的请求和响应多路复用来减少感知延迟，提供请求优先级和服务器推送功能，并有效压缩HTTP头字段。HTTP/2不改变HTTP方法、状态码、URL或头字段，而是改变数据在客户端和服务器之间的格式和传输方式。
<br>前面我们提到过，持久的TCP连接允许通过单个TCP连接从网页获取多个对象，但这可能会导致Head of Line(HOL) 问题，例如一个网页中有一个base HTML文本、一个长视频和视频后的一些小对象，这会导致这些小对象会一直等待长视频传输完成后才开始传输。HTTP/1.1对此的解决方法是打开多个并行的TCP连接，但这可能会导致网络的拥塞。
<br>HTTP/2的主要目标之一是减少用于传输单个网页的并行TCP连接数量。这不仅减少了服务器需要打开和维护的套接字数量，还允许TCP拥塞控制按预期运行。但是，由于只有一个TCP连接来传输网页，HTTP/2需要精心设计的机制来避免HOL阻塞。
<br><br>HTTP/2对于HOL的解决方案是将报文”打碎“为多个帧(frame)，然后多个对象轮番发送，按一定顺序发送第一帧接着第二帧等。这样能够极大的缩短用户的感知延迟。将HTTP报文成帧并在在client端重组报文是HTTP/2最大的改进之一。头部字段划分成一个帧，entity body被划分成一个或多个帧。<br><br>在client向server发送多个请求时，它可以在权重1-256之间设置请求报文的响应优先级。数字越大表示优先级越高。<br>
HTTP/2还有能力向一个client的一个请求发送多个响应报文，在发送完源请求对应的响应报文后server将额外的对象push给client。<br><br><br><br>□ 向用户主机上传输文件或从远程主机上接收文件<br>
□ 客户机/服务器模式<br>
<br>客户端：发起传输的一方
<br>服务器：远程主机<br>
□ ftp：[RFC 959]<br>
□ ftp服务器：端口号为21
<br>在TCP/IP协议中， 需要两个端口，一个是数据端口，一个是控制端口。<br>控制端口一般为21，而数据端口不一定是20，这和FTP的应用模式有关，如果是主动模式，应该为20，如果为被动模式，由服务器端和客户端协商而定。相比于HTTP，FTP协议要复杂得多。复杂的原因，是因为FTP协议要用到两个TCP连接，一个是命令链路，用来在FTP客户端与服务器之间传递命令；另一个是数据链路，用来上传或下载数据。<br><br>□ FTP客户端与FTP服务器通过端口21联系，使用TCP作为传输协议<br>
□ 客户端通过控制连接获得身份确认<br>
□ 客户端通过控制连接发送命令浏览远程目录<br>
□ 收到一个问价传输命令时，服务器打开一个到客户端的数据连接<br>
□ 一个文件传输完成后，服务器关闭连接<br>
□ 服务器打开第二个TCP数据连接用来传输另一个文件<br>□ 控制连接：带外（out of band）传送<br>
□ FTP服务器维护用户的状态信息：当前路径、用户账户与控制连接对应<br>
（即FTP服务器维护client的状态）<br><br>□ FTP 在控制连接上，信息以ASCII文本的方式传送<br>
<br>命令样例：

<br>USER username
<br>PASS password
<br>LIST：请服务器返回远程主机当前目录检索文件（gets）
<br>STOR filename：向远程主机的当前目录存放文件（puts）


<br>返回码样例：

<br>状态码与状态信息（同HTTP）
<br>331 Username OK,<br>
password required
<br>125 data connection already open;<br>
transfer starting
<br>425 Can't open data connection
<br>452 Error writing file


<br><br>Electronic mail has been around since the beginning of the Internet. It was the most popular application when the Internet was in its infancy.<br>在本节，我们将介绍Internet e-mail中最核心的应用层协议SMTP(Simple Mail Transfer Protocol) 。<br>
<br>从下图我们可以看到，Internet邮件系统由三部分构成：user agents、mail servers还有SMTP。<br>
<img alt="Pasted image 20240605212341.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240605212341.png">

<br>E-mail中一些有名的user agent包括Microsoft Outlook、Web-based Gmail、Gmail App 等。
<br>Mail server是e-mail infrastructure中的核心。每个收件人都会有一个唯一某个mail server中的mailbox。在e-mail 系统中，报文由发送人的user agent发出，经由发件人的mail server送到收件人的mail server中，等待收件人查看邮箱中的内容。不仅如此，mail server 也会对收件人mail server中传输的失败情况作出反应。发件人的server会将报文放在message queue中，如果没有收到收件server的收到反馈，发件server就会每隔一段时间发送邮件。如果很长时间仍没有反馈，则用一则email通知发件人。
<br>SMTP使用可靠的TCP传输协议来传送信件。和大多数应用层协议一样，SMTP有两个端构成—client side和server side。


<br><br>SMTP(Simlple mail trasfer protocol)是互联网最早出现的应用层协议之一（它出现于1982年，比HTTP还早）。由于它出现的时间很早，考虑的事情不完全，也因此，它在当今是一种legacy technology。例如：SMTP规定在发送E-mail报文时要先将报文的body部分编码成7-bits ASCII，7位的ASCII显然不适用于现代多媒体信息的传送，只适用文本的传输，也体现了其过时的性质。<br>
<br>我们通过下面的例子简单看看SMTP是怎么工作的：

<br>Alice给她的user agent提供Bob的邮箱地址（如bob@someschool.edu）和信件并操作user agent发送报文。
<br>User agent将报文发送给Alice的mail server处，mail server会将这些e-mail排队依次发出。
<br>Alice的mail server通过TCP与另一台mail server连接。
<br>在SMTP握手初始化完成后，SMTP client side通过TCP连接发送Alice的mail。
<br>Bob的mail server收到信件后将信件放在Bob的mailbox中。
<br>Bob随时查看。<br>
<img alt="Pasted image 20240608041543.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240608041543.png">


<br>现在我们来看看其中的更多细节：在client SMTP发送mail时，它会先和server SMTP的25号端口建立TCP连接。如果server下线，client之后会重新请求连接。一旦连接建立，client就会和server初始化SMTP应用层的握手。在这个阶段，SMTP client和server会互相发送email地址。这个过程完成后，client就可以发送报文了，SMTP可以提供报文传输的可靠性。client继续传输其他报文，如果报文没有了，client就会关闭TCP连接。 
<br>下面我们看看SMTP会话的例子：
S:&nbsp;&nbsp;220 hamburger.edu 
C:&nbsp;&nbsp;HELO crepes.fr
S:&nbsp;&nbsp;250 Hello crepes.fr, pleased to meet you 
C:&nbsp;&nbsp;MAIL FROM: &lt;alice@crepes.fr&gt;
S:&nbsp;&nbsp;250 alice@crepes.fr ... Sender ok 
C:&nbsp;&nbsp;RCPT TO: &lt;bob@hanburger.edu&gt;
S:&nbsp;&nbsp;250 bob@hamburger.edu ... Recipient ok 
C:&nbsp;&nbsp;DATA 
S:&nbsp;&nbsp;354 Enter mail, end with ”.” on a line by itself 
C:&nbsp;&nbsp;Do you like ketchup? 
C:&nbsp;&nbsp;How about pickles? 
C:&nbsp;&nbsp;. 
S:&nbsp;&nbsp;250 Message accepted for delivery 
C:&nbsp;&nbsp;QUIT 
S:&nbsp;&nbsp;221 hamburger.edu closing connection


<br>我们可以看到这里client发送的命令HELO、MAIL FROM、RCPT TO、DATA、QUIT。这些自解释性的命令我们很容易看明白。与HTTP一样，SMTP报文的每一行也是由CRLF结尾的(Carriage Return and Line Feed)。SMTP提供持久性的连接，因此，在我们没有发起QUIT请求前，我们可以一直用DATA命令向server发送多个email。
<br>我们可以通过telnet命令来直接与server建立直接的会话，像这样：<br>
telnet servername 25<br>
这样就在本地主机和邮件服务器之间建立一个TCP连接。之后，我们应当收到服务器的220回复。<br>
连接成功后，我们就可以发送SMTP命令了：

HELO yourDomain.com
MAIL FROM: &lt;yourEmail@yourDomain.com&gt;
RCPT TO:&lt;recipientEmail@recipientDomain.com&gt;
DATA
Subject: Test Email
This is a test email sent from Telnet.
.
QUIT


<br><br>在向别人写信时，我们一般会在信纸上写上“给某某”和“爱你的某某”。SMTP中mail message的格式也一样，在真正写信之前，必须先写上头部行。每个message头都必须包含From:头部行和To:头部行，Subject头部行时可以舍去的。<br>
SMTP的massage header可能是这样的：<br>From: alice@crepes.fr 
To: bob@hamburger.edu 
Subject: Searching for the meaning of life.
<br><br>通过之前对SMTP的学习，我们可能会有mail server存在意义何在的疑问。确实，信件总是先被传送到mail server后再转发给用户，总会有让用户有信息安全方面的担忧。但是，让用户时时刻刻保持在线连网的状态对很多人而言是不现实的。因此，我们在发电邮时会先将email发到一个always-on shared mail server中。<br>
<br>我们接着了解一下email message的传输路径吧！实际上，email是可以直接由发信人的agent之间发送到收信人的mail server中的。但一般我们不这样做，如下图：<br>
<img alt="Pasted image 20240609005629.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240609005629.png">

<br>至此，我们仍有一个疑问——收件人(recipient)Bob是如何收到给他的message的？我们学习了SMTP，但是SMTP只是发信的协议(push protocol)。
<br>当今，我们主要有两种方式来将mail server中的信件转发给user agent——HTTP和Internet Mail Access Protocol(IMAP)。前者一般用于Web-based email或手机应用（如Gmail），后者用在mail clients（如Outlook）。


<br><br>Just as humans can be identified in many ways, so too can Internet hosts.<br><br>在Internet中，有两种方式来识别一个主机：（1）通过hostname；（2）通过IP地址；可以理解为human name和human ID number。人们当然更喜欢便于记忆的hostname，但是router路由时当然喜欢定长结构化的IP地址进行路由。这也就是DNS的主要工作。<br>在Internet中，DNS是（1）不同层次的DNS服务器组成的分布式数据库；（2）允许hosts查询分布式数据库的的应用层协议。<br>通常情况下，DNS运行在BIND(Berkeley Internet Name Domain)软件上，DNS一般采用UDP传输层协议，使用53号端口。<br>DNS作为一个工具，常常被同为应用层的协议如：HTTP、SMTP所使用。下面举例简单说明一下DNS是怎么工作的。<br>
假设browser要请求URL 中的内容，在发送请求报文前：<br>
<br>client host在53号端口运行DNS client应用；
<br>browser从URL中拽出hostname，，将其送给DNS应用；
<br>DNS 客户端向 DNS 服务器发送包含主机名的查询；
<br>DNS 客户端从 DNS 服务器收到包含IP地址的回复；
<br>一旦browser从 DNS 收到IP地址，他就会初始化与HTTP服务进程80号端口的TCP连接。
<br>我们从上面例子中看到，DNS提供IP地址解析的服务为应用添加了额外的时延。但和Proxy Server会缓存HTTP报文一样，结构化的DNS服务器也同样会将DNS的相关数据cache到临近client host的DNS server。<br>
从此我们可以看到，DNS提供的服务不仅仅只是IP地址和hostname之间的转换。还有：<br>
<br>Host aliasing：主机别名。一个主机可以有一个规范主机名(Canonical hostname) 和 多个别名(Alias hostname)，DNS可以将这些别名映射到同一个IP地址。
<br>Mail server aliasing：邮件服务器别名。为方便记忆，e-mail地址也可以拥有别名。如Bob有一个yahoo的邮箱地址是bob@yahoo.com。我们看到的yahoo的邮件服务器主机名是简单的yahoo.com，但它的规范主机名可能会是relay1.west-coast.yahoo.com。显然，yahoo.com更容易记忆。
<br>Load distribution：负载分配。对于一些大型公司，它们可能会将Web服务器分布的放在各个地方同时为用户提供服务。这些服务器有不同的IP地址，但使用相同的hostname。DNS数据库中会将这些地址与同一hostname关联起来。DNS会决定使用哪个服务器去响应用户的Web请求。
<br><br>我们已经概况的了解了DNS提供服务的，本节我们来看看DNS所提供的 主机名-IP地址 映射服务。假设某些应用需要用到这样的服务，他会先将需要转换的信息给客户端的DNS，然后DNS完成转换工作。<br>在很多UNIX-based的机器上，系统会提供gethostbyname()函数封装转换服务。随后用户机上的DNS会接管，向网络送出query message。所有的DNS问询和其收到的回复报文都会被53号端口通过UDP数据报的方式传输。经过一段时间的时延后DNS收到映射后的内容。之后，这段内容会被传给应用。应用所看到的只是一个黑盒子，将主机名（IP地址）丢进去，黑盒会返回应用想要的IP地址（主机名）。但事实上，这”个“黑盒子涵括了分布在全球成千上万的DNS服务器和指定这些服务器通讯的应用层协议。<br>对于DNS，最简单的设计思想可能就是中心化的设计了！即让一个DNS服务器记录所有的主机名-IP地址映射关系。但我们也很容易发现其中的弊端：<br>
- A single point of failure<br>
- Traffic volume<br>
- Distant certralized database<br>
- Maintenance<br>
而DNS数据库设计是分布式的、层次化的。但中心化的单一DNS服务器just doesn't scale。<br><br>DNS是一个浩大的工程，分布式、层次化的DNS服务器遍布世界各地。得益于这种扩展性(scale)，没有一个DNS服务器需要记录全部的 主机名-IP地址 映射关系，主机名-IP地址的映射分布交叉地存放在各个DNS服务器中。<br>我们用下图来近似地描述这种分布式、层次化的关系，我们可以看到三类DNS服务器：root DNS 服务器、top-level domain(TLD) DNS服务器 和 authoritative DNS服务器。<br>
<img alt="Pasted image 20240612014451.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240612014451.png"><br>
<br>
根DNS服务器：世界上有13个IPv4的根服务器，为12个组织所管理，但是为了保证根域名服务器的可用性，会部署多个节点。因此也有说全球根服务器的数量在1000+左右（截至2020）。根域名服务器能够提供 TLD服务器的 IP地址。

<br>
顶级域服务器：TDL服务器管理并提供特定TLD的DNS服务。这些顶级域名有：com、org、net、edu、gov，还有国家TLD如：uk、cn、jp等。顶级域名由不同的公司或组织所拥有和管理，如Educause管理edu TLD。TLD服务器提供权威DNS服务器的IP地址。

<br>
权威DNS服务器：权威DNS服务器记录存储特定域名的官方DNS，记录主机名和IP地址之间的映射关系。任何提供公开访问主机的组织都需要应用权威DNS服务器。对于这些组织来说，它们可以自己搭建服务器或交给特定的服务提供商。大多数的大学和大型公司都有自己的一级和二级权威DNS服务器（备份）。

<br>从DNS服务器层次结构中我们看到root、TLD还有authoritative DNS服务器。但在DNS服务器层次结构外还有一种十分重要的DNS服务器，叫做local DNS server。尽管严格来说local DNS server并不属于architecture，但却处在architecture的C位。每个ISP都会有这样的local DNS server(也叫default name server)。下面我们演示local DNS server是怎么工作的（假设主机cse.nyu.edu想要获得主机gaia.cs.umass.edu的IP地址）：<br>
<br>主机cse.nyu.edu向local DNS server发送解析gaia.cs.umass.edu的查询报文；（query）
<br>Local DNS 服务器向 Root DNS 服务器转发查询报文；（query）
<br>Root DNS 服务器根据顶级域名edu返回负责该顶级域名TLD服务器的IP地址列；（reply）
<br>Local DNS 服务器向其中一个 TLD DNS 服务器发送请求报文；（query）
<br>TLD DNS 服务器根据umass.edu后缀返回authoritative DNS 服务器的IP地址；（reply）
<br>Local DNS 服务器直接向主机dns.umass.edu发生请求报文；（query）
<br>Authoritative DNS 服务器返回gaia.cs.umass.edu的IP地址；（reply）
<br>Local DNS 服务器将IP地址转发给主机cse.nyu.edu。（reply）<br>
在整个过程中，为了获得目标之际的IP地址映射，一共发送了8个DNS报文：四个query messages和四个reply messages。之后，我们会了解到DNS caching是怎么优化DNS查询过程的。<br>
<img alt="Pasted image 20240618164507.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240618164507.png">
<br>之前，我们假设TDL 服务器默认知道目标hostname在哪个authoritative DNS 服务器的情况，但现实中不全是这样的。可能的情况是，TLD服务器只认得一些知道authoritative DNS 服务器hostname的intermediate DNS 服务器在哪。这样，local DNS 服务器就需要额外的DNS通讯才能找到最终的authoritative DNS 服务器。（额外 N个intermediate DNS 服务器产生额外 2N个DNS messages）<br>
Recurive queries and iterative queries<br>
The example shown in Figure 2.19 makes use of both recursive queries and iterative queries. The query sent from cse.nyu.edu to dns.nyu.edu is a recursive query, since the query asks dns.nyu.edu to obtain the mapping on its behalf. However, the subsequent three queries are iterative since all of the replies are directly returned to dns.nyu.edu. In theory, any DNS query can be iterative or recursive. For example, Figure 2.20 shows a DNS query chain for which all of the queries are recursive. In practice, the queries typically follow the pattern in Figure 2.19: The query from the requesting host to the local DNS server is recursive, and the remaining queries are iterative<br><br>在上面的例子中，我们看到，请求DNS服务的client向知道目标主机 hostname/IP 映射关系的authoritative server请求DNS服务时，DNS messages的数量会随着intermediate DNS 服务器结点的增加而增加：而使用caching的方式时，当cache命中，DNS消息的数量将锐减到：从中，我们能够看到在服务器结点之间加入一个cache是多么重要。<br>DNS caching的思想十分简单，和HTTP中的proxy server(Web cache)的思想类似，都是通过保存近期请求的数据来减少未来请求的处理时间和网络流量。这种缓存机制在提高DNS解析速度和减少网络拥塞方面起着至关重要的作用。<br>在下面的例子中，在Requesting host首次请求查询gaia.cs.umass.edu的 IP 时，local DNS 服务器会将主机gaia.cs.umass.edu的 hostname/IP 映射关系缓存到本地。如果另一台主机也有查询gaia.cs.umass.edu的 IP 的话，local DNS server会直接将缓存在本地的 IP 地址转发给requesting host，即只需要2步。<br>
<img alt="Pasted image 20240618185617.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240618185617.png"><br><br>DNS 服务器共同组成了存放Resource Records(RRs) 的DNS 分布式数据库。每个DNS reply message 都包含着至少一个的资源记录(RRs)。<br>RRs是一个包含以下字段(fields)四元组(four-tuple)：这个四元组中，前三个字段我们望文生义，最后一个英文缩写 TTL(Time To Live) 表示这个RR在DNS caching 中剩余的存放时间（当RR长时间没有被访问时，RR就会从DNS caching中被清除出去）。<br>下面，我们看看 RRs 的其余三个字段的含义。其中，字段Name和字段Value的含义取决于Type字段：<br>
<br>如果Type=A，这时，Name就是一个主机名 并且 Value是主机的 IP 地址。因而，Type A 记录提供 标准的 hostname/IP 映射关系， (relay1.bar.foo.com, 145.37.93.126, A) 就是一个Type A的记录。（当Type=AAAA表示正在查询域名的IPv6地址）
<br>如果Type=NS，这时，Name就是一个域名(domain)  并且 Value是知道如何获得域名内主机 IP 地址的authoritative DNS server的主机名。(foo.com, dns.foo.com, NS)就是一个Type NS的记录。这种记录告诉其他DNS服务器如果需要解析foo.com域内的任何主机名，应该查询dns.foo.com这个权威DNS服务器。
<br>如果Type=CNAME，那么 Value 就是一个规范主机名(canonical hostname) ，这时的 Name字段用来表示主机别名 这种记录向querying hosts提供主机的规范主机名。(foo.com, relay1.bar.foo.com, CNAME)就是一种CNAME记录。
<br>如果Type=MX，则 Value表示mail server的规范名 而 Name表示mail server的别名。(foo.com, relay1.bar.foo.com, CNAME) 就是一种 CNAME 记录。<br>
Noter：<br>
MX records allow the hostnames of mail servers to have simple aliases. By using the MX record, a company can have the same aliased name for its mail server and for one of its other servers (such as its Web server). To obtain the canonical name for the mail server, a DNS client would query for an MX record; to obtain the canonical name for the other server, the DNS client would query for the CNAME record
<br>RRs 不同的Type代表着不同的含义，不同服务器中记录的RRs的种类也不尽相同。在authoritative DNS 服务器中，存储的是Type A的RRs；在其他DNS 服务器如TLD服务器中存放着Type为NS的RRs。<br><br>在之前的Figure 2.19中，我们知道DNS query messages 和 reply DNS messages 是如何传输的。我们看到两种DNS message，但事实上，不论是query messages 还是 reply messages 都使用同一DNS报文格式。DNS报文格式如下：<br>
<br>头12个字节叫DNS报头(header section)。其中又有很多不同作用的字段。

<br>标识字段（16 bits）：用于标识一次查询/响应过程，由客户端设置，服务器返回相同的值。
<br>标志字段：包含多个控制标志，如1 bit query/reply flag（query(0)/reply(1)）、操作码、是否期望递归查询等。
<br>问题计数：指示查询请求中问题的数量。
<br>回答资源记录数：指示响应中回答的数量。
<br>权威名称服务器计数：指示响应中权威名称服务器记录的数量。
<br>附加资源记录数：指示响应中附加记录的数量。


<br>接下来的DNS报文节叫做DNS question section。它包括：<br>
(1) 名称字段(Name field)，它表示querying hostname。<br>
(2) 类型字段(Type field)，它表示querying name的种类。
<br>然后来自DNS服务器的reply在DNS answer section 中存放。根据报头和question section的内容，answer section可以返回多个不同的RRs。
<br>Authority section 包括了其他权威服务器的记录信息。
<br>Additional section 中包含着其他有用的信息，比如用于支持额外功能的记录。<br>
<img alt="Pasted image 20240619182044.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240619182044.png">
<br>举一个DNS querying message的例子：<br><br>我们现在再看看DNS reply message的例子：<br><br>nslookup program<br>
<br>当我们想要请求DNS服务时，我们可以使用nslookup来获取域名和IP地址之间的映射。
<br><br>我们已经了解了如何从DNS distributed database中获取我们想要的信息。但当我们创立一个公司后，我们需要拥有自己的网站来宣传自己的产品。我们应该怎么做呢？（假设我们创立商业公司，也就是TLD为com）<br>
<br>首先，我们要在域名注册商(registrar)那里注册一个自己的域名。
<br>当域名创建之后，你需要向域名注册商提供你的主要和次要权威DNS服务器的名称和IP地址。
<br>之后，域名注册商会将一个Type NS 和 一个Type A 的记录将你的DNS服务器的hostname/IP mapping关系加入到TLD com 的服务器中。
<br>然后还需将你的Web server地址以Type A 的资源记录还有你的mail server地址以Type MX 的资源记录的方式在你的权威DNS服务器中建立 hostname/IP mappings。
<br><br>在之前的章节中，我们已经学习过的应用层应用有：Web应用、e-mail和DNS，他们都是基于C/S 体系结构。这些应用对于一个时刻响应的服务器的需求是时时刻刻都存在的。但Peer-to-peer网络体系结构对这样的服务器的依赖是很少的，由于每个终端设备（也叫节点）都可以处理请求且资源分散在各个节点上的，因此每个节点既可以作为客户端，也可以做服务器。<br>在本节中，我们将了解当今最流行的P2P file distribution protocol——BitTorrent。我们之前已经了解过，在C/S网络体系结构中，资源只保存在服务器端，资源的传输方向只能是 server-&gt;client。这样，服务器频繁的传输资源会对服务器带来严重的负担。而在P2P网络体系结构中，资源可以分布地存储在各个peer中，每个peer都可以是资源的请求者，也可以是资源的提供者。<br><br>为了展现P2P体系结构在传输文件上的优越性，我们用下图的例子来演示并计算每种architecture的分发时间。<br>我们假设服务器接入链路(access link)的上传速率为  ，第  个对等体接入链路的上传速率为  且第  个对等体接入链路的下载速率为  。我们在假设分布在服务器的文件大小是  ，分发时间(distribution time) 是将文件全部传给  个对等体的时间。<br>
<img alt="Pasted image 20240620183658.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240620183658.png"><br><br>假设采用C/S体系结构的分发时间是  。由于在C/S体系结构下，服务器需要将 File 向每个peer都发送一遍，因此服务器需要传输  bits。而我们知道服务器的上传速率是 ，因而，在理想情况下的分发时间为： 假设对等体接入链路中最慢的下载速率是  ，同时考虑到着两种情况，那么我们会得到分发时间：若只考虑服务器的上传和对等体的下载，那么分发时间：在这个等式中我们发现当时间成为瓶颈时，分发时间会随着  的增加而增加。这还是不考虑网络带宽的情况下。<br><br>当网络采用P2P体系结构时，情况则大有不同！因为每个对等体peer都可以辅助服务器分发文件，本着人多力量大的原则，随着对等体越来越多，分发时间不会像C/S网络那样线性增加。<br>
<img alt="Pasted image 20240620192758.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240620192758.png"><br>
下面，我们用计算来进一步观察在P2P网络下的分发时间的变化。<br>
<br>在向对等体发送文件之前，我们要先明确最开始的时候只有服务器拥有文件的信息。因此，服务器至少要向接入网络中传输一次。这次分发时间至少需要 。（与C/S模式不同，P2P网络的服务器在这一次的传输后就可以撒手人寰了。之后peers会将文件分布在各个peer处。）
<br>和C/S体系结构一样，下载速率最慢的对等体接收到  bits 也需要不少于  的时间。
<br>最后，我们看到系统总的上传速率等他所有对等体上传速率相加，即  。然后系统将  bits的文件分发给  个对等体。这时需要最少  。
<br>将这三部分合在一块，我们就会得到P2P的分发时间：从上面的等式我们看出，P2P结构降低了最小分发时间的负担。若不考虑其他因素，P2P系统的最小分发时间为：<br><br>BitTorrent 是一个流行的 P2P（点对点）文件分发协议。在 BitTorrent 的术语中，参与特定文件分发的所有节点（peers）的集合被称为一个 “torrent”。在 torrent 中的节点互相下载文件的等大小块（chunks），典型的块大小是 256 KB。当一个节点首次加入 torrent 时，它没有任何块。随着时间的推移，它会逐渐积累越来越多的块。在下载块的同时，它也会上传块给其他节点。一旦一个节点获得了整个文件，它可以选择离开 torrent，或者留在 torrent 中继续向其他节点上传块。此外，任何节点都可以在只有部分块的情况下随时离开 torrent，并且之后可以重新加入 torrent。<br>
<img alt="Pasted image 20240620202147.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240620202147.png"><br>
BitTorrent 是一个复杂的系统，但我们可以通过其最重要的机制来理解它的基本原理。每个 torrent 都有一个叫做 tracker 的基础设施节点。当一个 peer 加入 torrent 时，它会在 tracker 中注册，并定期通知 tracker 它仍然在 torrent 中。这样，tracker 就知道 peers 的数量。<br>当一个新的 peer，比如 Alice，加入 torrent 时，tracker 会从参与的 peers 中随机选择一部分（比如说50个）并将这些 peers 的 IP 地址发送给 Alice。Alice 拥有了这个 peers 列表后，会尝试与列表上的所有 peers 建立并发的 TCP 连接。我们称 Alice 成功建立 TCP 连接的 peers 为 “neighboring peers”。随着时间的推移，一些 peers 可能会离开，而其他的 peers（不在最初的50个之内）可能会尝试与 Alice 建立 TCP 连接。因此，一个 peer 的neighboring peers 的数量会随时间波动。<br>在任何给定的时间点，每个 peer 都会拥有文件的一部分 chunks，不同的 peers 拥有不同的 chunks 子集。Alice 会定期向她的neighboring peers 请求他们拥有的 chunks 列表。如果 Alice 有 L 个不同的neighbor，她将获得 L 个 chunks 列表。知道这些后，Alice 可以请求她当前没有的 chunks。<br>因此，在任何时候，Alice 都会拥有一部分 chunks，而且知道她的邻居拥有哪些 chunks。有了这些信息，Alice 需要做出两个重要的决定：首先，她应该首先向邻居请求哪些 chunks? 其次，她应该向哪些邻居发送请求的 chunks？在决定请求哪些 chunks 时，Alice 使用了一种叫做 “rarest first” 的技术。Rearest first 用来确定在她没有的 chunks 中，哪些 chunks 是在她的邻居中重复次数最少的 ，然后最先请求这些最稀有的 chunks。这样，最稀有的 chunks 能更快地被重新分配，目的是（大致）使 torrent 中每个 chunks 的副本数量均衡。<br>为了确定她应该回应哪些请求，BitTorrent 使用了一个巧妙的“交易”算法。基本思想是 Alice 优先回应那些当前以最高速率向她提供数据的邻居。具体来说，对于她的每个邻居，Alice 持续测量她接收比特的速率，并确定四个以最高速率向她提供比特的 peers。然后她通过向这四个相同的 peers 发送 chunks 来回报他们。每10秒，她会重新计算速率，并可能修改这四个 peers 的集合。在 BitTorrent 术语中，这四个 peers 被称为 unchoked peer。重要的是，每30秒，她还会随机选择一个额外的邻居并向其发送 chunks。我们称这个随机选择的 peer 为 Bob。这时的 Bob 就是 optimistically unchoked peer。因为 Alice 向 Bob 发送数据，她可能会成为 Bob 的前四个上传者之一，这样 Bob 就会开始向 Alice 发送数据。如果 Bob 向 Alice 发送数据的速率足够高，Bob 可能会反过来成为 Alice 的前四个上传者之一。换句话说，每30秒，Alice 会随机选择一个新的交易伙伴并开始与该伙伴交易。如果两个 peers 对交易感到满意，他们会将对方放入他们的前四个列表中，并继续彼此交易，直到其中一个 peer 找到更好的伙伴。这样，能够以兼容速率上传的 peers 往往能够找到彼此。随机邻居选择也允许新的 peers 获得 chunks，这样他们就有东西可以交易。除了这五个 peers（四个“顶级” peers 和一个探测 peer）之外的所有其他邻居 peers 都被 “choked”，即他们不会从 Alice 那里接收任何 chunks。BitTorrent 还有许多其他有趣的机制，这里没有讨论，包括 pieces（小 chunks）、pipelining、random first selection、endgame mode 和 anti-snubbing。<br>刚才描述的交易激励机制通常被称为 tit-for-tat。尽管已经有研究表明这种激励方案可以被规避，但 BitTorrent 生态系统仍然非常成功，有数百万个同时在线的 peers 在数十万个 torrents 中积极分享文件。如果 BitTorrent 没有设计 tit-for-tat（或其变体），即使其他方面完全相同，BitTorrent 都可能不会存在，因为大多数用户只想作为数据的接收者。<br>最后，我们简要提及 P2P 的另一个应用，即分布式哈希表（DHT）。分布式哈希表是一个简单的数据库，数据库记录分布在 P2P 系统的 peers 中。DHT 已被广泛实施（例如，在 BitTorrent 中）并且是广泛研究的主题。在配套网站的视频笔记中提供了一个概述。<br><br>By many estimates, streaming video account for about 80% of Internet traffic in 2020. [Cisco 2020]<br>本节课中，我们会简单了解当今网络世界中的视频流服务是怎么实现的。我们会看看这些 streaming video 是如何用应用层协议和一些 cache-like 的服务实现的。<br><br>在流存储视频应用(streaming stored video applications)中，underlying medium 就是提前录制好的视频。这些视频会被放置在服务器中，如何client向服务器发送需要视频的请求报文。<br>那么什么是 video medium 呢？我们要先明白视频就是一连串的图片，我们常常听到24帧、30帧60帧的视频。这表示视频每秒钟会显示60帧（张）的图片。而这些图片又是由一连串的像素构成的，这些像素由可以用表示亮度和颜色的 bits 来表示。这是压缩(compression)的过程，也是视频的特点之一 —— 将视频文件压缩成任何所需的比特率(bit rate)。比特率越高视频的质量越高。<br>从网络的视角来看，video 最重要的特征可能就是比特率了。一般来说，压缩后网络视频的比特率通常在100Kbps 到 4Mbps。如果想要传输4K以上的视频，那么至少需要10Mbps的比特率，这样会占用大量的网络和存储资源。为保证视频持续稳定的传输，网络就必须提供比压缩视频比特率还大的网络吞吐量(throughput)。<br>如果端到端的吞吐量小于压缩视频的比特率，我们还可以将源视频压缩成不同比特率的版本，中断设备根据当前网络吞吐量来选择多大比特率的版本。这也就是为什么视频网站上会存在144p、480p、1080p、2k、4k多个版本的视频供用户选择。<br><br>当视频采用HTTP媒体流(HTTP streaming)传输时，视频会存放在HTTP服务器的一个URL处。当用户想要观看视频时，client会建立与server的TCP连接并通过HTTP GET 方式来获取这个视频。之后，server会将视频文件包含在一个响应报文中发给client。在client端，压缩后的视频（bits）会先存放在client application buffer中。一旦buffer中的字节数量到预设阈值的时候，client端的应用就会开始播放视频。<br>尽管HTTP streaming 得到极为广泛地应用，但它仍然有一个缺点：即所有的client都会收到同样比特率的视频。这样的特点没有充分考虑到不同client目前可用带宽的大小。因此也促成 DASH(Dynamic Adaptive Streaming HTTP)技术 的发展。动态自适应流媒体技术将视频编码成多个比特率的版本，client会动态地请求一段长度的视频片段。根据目前的带宽选择响应比特率版本的视频。<br>DASH技术的出现使不同网络状况的clients能够在不同编码率下享受流媒体视频中的内容。同时DASH也支持在会话中根据网络状况动态地选择不同比特率版本。<br>有了DASH，每种不同比特率版本的视频都将存放在HTTP的服务器中，每种视频都与单一的URL相对应。而这些URL信息可以在HTTP服务器中的 清单文件(manifest file) 中看到。<br>我们最后再来在宏观上看看video是如何在server-client上传输的：<br>
<br>客户端初始化与服务器的TCP连接；
<br>TCP连接建立完成，客户端使用HTTP GET 方法请求想要的video文件的一个chunk；
<br>服务器将清单文件(manifest file)发送给客户端；
<br>客户端根据目前的网络状况在清单文件中选择合适的video chunk；
<br>服务器端压缩video chunk成bit stream并发送给客户端；
<br>客户端解码bit stream成video chunk并隔一段时间跳转到第3步。
<br><br>当今，许多流媒体视频公司需要将这些视频内容分布式地放在世界各地来时时刻刻为百万计的用户提供稳定的视频播放。<br>那么如何为这些用户提供稳定的视频播放呢？我们可以建造一个巨型的数据中心(mega data center)，将所有的视频都存放在数据中心里。但这样做会造成很多问题：<br>
<br>当client物理距离过大时，传播时延(Propagation Delay)会变得很大，在这种情况下，视频可能会经由多个ISP才能送到client端。如果在传输过程中有一条线路的吞吐率小于视频的比特率，回想我们第一章中了解的bottleneck link，这时的线路最大吞吐率将由这条bottleneck link决定！
<br>服务器会重复发送更加流行的视频，这样会浪费网络带宽。
<br>由于单一数据中心并没有备用服务器作为备份，如果这个数据中心瘫痪或和其连接的线路故障，那么data center就不会往外发送任何视频流了。
<br>为应对百万计clients的视频流请求，现在大部分公司都会采用Content Distribution Networks(CDNs)。内容分发网络通过管理分布在不同位置的服务器，将video、其他Web内容拷贝到不同的服务器（服务器农场）中。每当有用户发起内容请求，CDN就会让用户与最合适的data center进行通信，以获得最好的体验。CDN可以是私有(Private CDN)的，只为内容提供商所有。CDN也可以是第三方的(third-party CDN)，由多个内容提供商分发内容。<br>
A very readable overview of modern CDNs is [Leighton 2009; Nygren 2010].<br>CDNs的分布有两种不同的设计哲学：<br>
<br>Enter Deep*：这种策略由Akamai首创，它涉及将服务器集群部署在全球各地互联网服务提供商的接入网络中，深入到用户所在的位置。(To get close to users)
<br>Bring Home/Edge-based Plasement*：在这种方法中，CDN服务器被放置在网络的边缘，更靠近最终用户。这样做可以减少内容传输的延迟，加快内容交付速度。(To bring the ISPs home)
<br>我们做假设来理解这两种策略：假设圆的内部是network core，圆上是network edge。那么在enter deep方式中，CDN靠近一个圆的圆心，它平等的到每个client都近。而bring home更像是将CDN放在圆上，这样对一部分用户更近，但是对另外一些用户来说却更远。<br><br>了解完CDNs的两种分布策略之后，我们现在看看CDN是任何发挥作用的。当client host想要获得一个video时，CDN必须拦截(intercept)该请求并根据请求（1）决定此时刻最适合该client的CDN服务器集群；（2）将client的请求引导发送到那个集群中的服务器。<br>下面，我们用一张图直观地理解CDN的作用。我们假设有一个内容提供商（NetCinema）从 KingCDN 租用了一个第三方的CDN来完成其视频分发。在 NetCinema 网页中，每个视频都对应一个URL与其对应。在用户想要观看某个视频且视频流被送到用户的host上前，发生了以下事件：<br>
<br>用户访问 NetCinema 网页；
<br>在用户点击链接 \<a data-tooltip-position="top" aria-label="http://video.netcinema.com/XXXXX%5C" rel="noopener nofollow" class="external-link" href="http://video.netcinema.com/XXXXX%5C" target="_blank">http://video.netcinema.com/XXXXX\</a> 后，用户host发送关于 video.netcinema.com DNS query 报文；
<br>用户的 Local DNS Server(LDNS)向 NetCinema 的权威DNS服务器发送 DNS query 报文。由于 NetCinema 的视频资源都由第三方 KingCDN 管理，所以 NetCinema 的权威DNS服务器会将 KingCND的域名，如 xxxxx.kingcdn.com 交给 LDNS。
<br>知道了KingCND的域名，现在我们的发出的 DNS query 就可以进到 KingCDN 的私人 DNS infrastructure中了。然后，用户的 LDNS 发送关于 xxxxx.kingcdn.com的 DNS query 之后 LDNS 收到 KingCDN 的内容服务器的IP地址。
<br>有了 KingCDN 内容服务器的IP地址，LDNS 将IP地址转发给client host。
<br>Client host通过IP地址与目标服务器建立TCP连接，之后使用HTTP GET来获得想要的内容。如果使用 DASH ，服务器还会先将包含一连串URLs的清单文件发送给 client host ，然后 client host 通过目前的网络状态动态地选择需要的视频chunk文件。<br>
<img alt="Pasted image 20240622153238.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240622153238.png">
<br><br>在CND分发内容的时候，往往要考虑怎么选择合适的 cluster selection strategy。集群选择策略是在client host 进行查询时，CDN通过 LDNS 的IP地址来为其推荐最合适的服务器集群(cluster)。<br>CDN往往采用专有的集群选择策略。一种笨想的策略就是 geographically closest，就是根据物理距离的长短让距离 client host 最近的服务器集群（也就是数据中心）负责向 client host 传输内容信息。Content provider 会使用商业性的 geo-location databases 来获取地理位置上的信息。这种方式对与大多数用户而言都是相对较优的，但对 “Geographically close, driven far” 的情况来说，这种策略的体验可能会很差。因为地理距离上的cluster可能在跳数(number of hops)上可能不是最小的。<br>Tip*在下图的例子就很好地说明了这个问题，虽然两地相距120+km，但是开车确需要1300+km。<br>
<img alt="Pasted image 20240622164243.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240622164243.png"><br>为了解决这种问题，基于client host当前的网络状况来选择最佳的集群，CDNs可以使用 real-time measurements 策略周期性地检查与client host之间的延时（如使用ping命令）等来选择cluster。<br><br>2.6.4小节作为了解性内容。<br><br>回顾2.1节，我们讨论了由两部分组成的网络应用——客户端程序和服务器程序——运行在两台end systems上。当程序一旦被运行，客户端进程和服务器进程就会被创建，然后这些进程靠sockets进行客户端-服务器之间的读、写操作。要进行这样的客户机-服务器间的通信，程序员就要编写客户端程序和服务器端程序。<br>我们可以使用现成的[RFC]文档或其他开源的标准文档提供的协议标准来完成我们的网络应用程序（如使用HTTP[RFC 2616]来作为服务器和客户端程序的指导文档）。依这种方式，客户端程序和服务器程序的读、写操作的实现就需要安装文档规定的方式实现。<br>
之外，我们还可以使用自己规定的读写接口协议来实现我们的客户端程序和服务器程序。这种方式下实现的网络应用往往是闭源私有的。<br>我们再回顾TCP和UDP的特点。我们知道，TCP是面向连接(connection oriented) 的网络层协议，为两台终端设备之间提供可靠的字节流信道。<br>
而UDP是无连接的，它提供不可靠的、以独立传输包(independent packets)方式传输的，对传输过程中发生的意外不做任何保证。<br><br>我们将主机比做街道，应用进程比作房子，进程的端口号/sockets用房子的门牌号来表示，模拟数据包传输为快递运送的过程。<br>
我们来模拟一次数据包传输的过程：现在有一个快递包需要从房子A邮递到房屋B，我们需要在快递包上写很多邮寄信息，如送到哪个街道（主机）的哪个房子（进程）门牌号（端口号）是多少。快递员会根据这些信息将快递包送到指定的房子。<br>作为生活在房子里面的程序员，我们完全有随意布置房间和发送什么快递包的权力。但是我们不能影响到房间外快递员是如何配送包裹的。这也就是我们所说的开发者只对socket接口的application-layer side有完全的掌握，但对传输层一侧几乎没有控制。<br>如果还是不理解，不妨从网络视角再看看数据包传输的问题。在网络中，路由器会解析IP地址并将数据转发到正确的主机上，而主机上有许多进程，一个进程又可以有多个sockets，因此我们需要端口号来对这些socket进行标识。因而，有了IP地址和端口号，我们就可以将数据包送去目标主机了。<br>我们用下面的客户机-服务器应用的规则来演示一下UDP和TCP上的socket编程：<br>
<br>client从键盘读入一行数据（characters）并将其转发给server；
<br>server收到数据并将其转化成大写形式；
<br>server将修改后的数据发给client；
<br>client收到修改后的数据并将其显示到屏幕上。
<br>我们在下图中用高亮表示客户端-服务器基于UDP传输服务上的相关socket活动：<br>
<img alt="Pasted image 20240704180831.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240704180831.png"><br><br>
原书用 python 进行应用端对传输层协议的选择配置编程。相比 C++更容易理解和学习。
<br>#include &lt;iostream&gt; // 引入输入输出流库，用于控制台输入输出。
#include &lt;cstring&gt; // 引入字符串处理库，提供字符串操作函数。
#include &lt;sys/socket.h&gt; // 引入套接字接口库，用于网络通信。
#include &lt;arpa/inet.h&gt; // 引入用于IP地址转换的库。
#include &lt;unistd.h&gt; // 引入POSIX操作系统API库。

#define PORT 8080 // 定义服务器监听的端口号为8080。
#define BUFFER_SIZE 1024 // 定义缓冲区大小为1024字节。

int main() {
    int sockfd; // 套接字文件描述符，用于标识创建的套接字。
    char buffer[BUFFER_SIZE]; // 缓冲区数组，用于存储输入的消息和服务器的响应。
    struct sockaddr_in server_addr; // 服务器地址结构体，用于存储服务器的地址信息。

    // 创建UDP socket
    if ((sockfd = socket(AF_INET, SOCK_DGRAM, 0)) &lt; 0) {
        perror("socket creation failed"); // 如果创建套接字失败，打印错误信息。
        exit(EXIT_FAILURE); // 退出程序。
    }

    // 配置服务器地址
    memset(&amp;server_addr, 0, sizeof(server_addr)); // 初始化服务器地址结构体。
    server_addr.sin_family = AF_INET; // 设置地址族为IPv4。
    server_addr.sin_port = htons(PORT); // 设置端口号，htons用于将主机字节序转换为网络字节序。
    server_addr.sin_addr.s_addr = INADDR_ANY; // 设置IP地址为任意地址，即本机的任意IP。

    while (true) { // 无限循环，直到程序被手动停止。
        std::cout &lt;&lt; "Enter a message: "; // 提示用户输入消息。
        std::cin.getline(buffer, BUFFER_SIZE); // 从标准输入读取一行数据到缓冲区。
        std::cout &lt;&lt; "Message has been loaded! "&lt;&lt; std::endl;
        // 发送数据到服务器
        sendto(sockfd, buffer, strlen(buffer), 0, (const struct sockaddr *)&amp;server_addr, sizeof(server_addr));
        std::cout &lt;&lt; "Message has been sent! "&lt;&lt;std::endl;
        // 接收服务器的响应
        int n = recvfrom(sockfd, buffer, BUFFER_SIZE, 0, nullptr, nullptr); // 接收服务器响应的数据。
        buffer[n] = '\0'; // 在消息末尾添加字符串结束符。
        std::cout &lt;&lt; "Server response: " &lt;&lt; buffer &lt;&lt; std::endl; // 打印服务器的响应。
    }

    close(sockfd); // 关闭套接字。
    return 0; // 程序正常退出。
}

<br><br>#include &lt;iostream&gt;
#include &lt;cstring&gt;
#include &lt;sys/socket.h&gt;
#include &lt;netinet/in.h&gt;
#include &lt;unistd.h&gt;
#include &lt;algorithm&gt;

#define PORT 8080
#define BUFFER_SIZE 1024

void to_uppercase(char* str) {
    std::transform(str, str + strlen(str), str, ::toupper);
}

int main() {
    int sockfd;
    char buffer[BUFFER_SIZE];
    struct sockaddr_in server_addr, client_addr;
    socklen_t addr_len = sizeof(client_addr);

    // 创建UDP socket
    if ((sockfd = socket(AF_INET, SOCK_DGRAM, 0)) &lt; 0) {
        perror("socket creation failed");
        exit(EXIT_FAILURE);
    }

    // 配置服务器地址
    memset(&amp;server_addr, 0, sizeof(server_addr));
    server_addr.sin_family = AF_INET;
    server_addr.sin_addr.s_addr = INADDR_ANY;
    server_addr.sin_port = htons(PORT);

    // 绑定socket到地址
    if (bind(sockfd, (const struct sockaddr *)&amp;
	    server_addr, sizeof(server_addr)) &lt; 0) {
	    
        perror("bind failed");
        close(sockfd);
        exit(EXIT_FAILURE);
    }

    while (true) {
        memset(buffer, 0, BUFFER_SIZE);
        // 接收数据
        int n = recvfrom(sockfd, buffer, BUFFER_SIZE, 0, (struct sockaddr *)&amp;client_addr, &amp;addr_len);
        buffer[n] = '\0';
        std::cout &lt;&lt; "Received: " &lt;&lt; buffer &lt;&lt; std::endl;

        // 转换为大写
        to_uppercase(buffer);

        // 发送修改后的数据
        sendto(sockfd, buffer, strlen(buffer), 0, (const struct sockaddr *)&amp;client_addr, addr_len);
        std::cout &lt;&lt; "Sent: " &lt;&lt; buffer &lt;&lt; std::endl;
    }

    close(sockfd);
    return 0;
}

<br><br>与UDP提供的无连接服务不同，TCP提供有连接的服务。所以，在客户端和服务器端进程相互传递信息前，我们需要先通过握手(handshakes)建立TCP连接。然后用客户端connection socket和服务器connection socket建立起TCP连接。因为是面向连接的，因此在一端想向另一端发送信息时，只需要将信息送给connection socket，而不需要向UDP那样在数据包中额外加入IP地址和端口号等信息。<br>我们还要明确，在客户进程初始化TCP连接前需要：<br>
<br>服务器端的进程必须先运行起来；（UDP同）
<br>服务器进程还要提供一个额外的socket用来进行连接的确定。<br>
简单理一下过程：（1）客户进程和服务进程先创建套接字 socket；（2）客户进程用三次握手(three-way handshake)初始化TCP连接，这一步是在运输层发生的 ，对应用进程不可见。
<br>在服务进程上，它会一开始一直监听是否有客户进程与它建立TCP连接，一旦连接建立，服务器进程就会创建一个属于当前客户进程的connection socket。如下图所示，连接建立后，客户进程和服务器进程就会通过一个管道(pipe)来传输信息。TCP保证服务器进程/客户进程按序收到客户进程/服务器进程发送的全部字节，所以我们说TCP在客户进程和服务器进程间提供可靠的服务。<br>
<img alt="Pasted image 20240705114457.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240705114457.png"><br><br>#include &lt;iostream&gt;
#include &lt;cstring&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;netinet/in.h&gt;
#include &lt;arpa/inet.h&gt;
#include &lt;unistd.h&gt;

#define PORT 8080
#define BUFFER_SIZE 1024

int main() {
    int sock = 0;
    struct sockaddr_in serv_addr;
    char buffer[BUFFER_SIZE] = {0};
    std::string message;

    // 创建socket文件描述符
    if ((sock = socket(AF_INET, SOCK_STREAM, 0)) &lt; 0) {
        std::cerr &lt;&lt; "Socket creation error\n";
        return -1;
    }

    serv_addr.sin_family = AF_INET;
    serv_addr.sin_port = htons(PORT);

    // 将地址转换为二进制形式
    if (inet_pton(AF_INET, "127.0.0.1", &amp;serv_addr.sin_addr) &lt;= 0) {
        std::cerr &lt;&lt; "Invalid address/ Address not supported\n";
        return -1;
    }

    // 连接服务器
    if (connect(sock, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) &lt; 0) {
        std::cerr &lt;&lt; "Connection Failed\n";
        return -1;
    }

    // 从键盘读取数据并发送到服务器
    std::cout &lt;&lt; "Enter message: ";
    std::getline(std::cin, message);
    send(sock, message.c_str(), message.length(), 0);

    // 接收服务器返回的数据并显示
    read(sock, buffer, BUFFER_SIZE);
    std::cout &lt;&lt; "Modified message from server: " &lt;&lt; buffer &lt;&lt; std::endl;

    close(sock);
    return 0;
}

<br><br>#include &lt;iostream&gt;
#include &lt;cstring&gt;
#include &lt;cctype&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;netinet/in.h&gt;
#include &lt;unistd.h&gt;

#define PORT 8080
#define BUFFER_SIZE 1024

void to_uppercase(char* str) {
    for (int i = 0; str[i]; i++) {
        str[i] = toupper(str[i]);
    }
}

int main() {
    int server_fd, new_socket;
    struct sockaddr_in address;
    int opt = 1;
    int addrlen = sizeof(address);
    char buffer[BUFFER_SIZE] = {0};

    // 创建socket文件描述符
    if ((server_fd = socket(AF_INET, SOCK_STREAM, 0)) == 0) {
        perror("socket failed");
        exit(EXIT_FAILURE);
    }

    // 绑定端口
    if (setsockopt(server_fd, SOL_SOCKET, SO_REUSEADDR | SO_REUSEPORT, &amp;opt, sizeof(opt))) {
        perror("setsockopt");
        exit(EXIT_FAILURE);
    }
    address.sin_family = AF_INET;
    address.sin_addr.s_addr = INADDR_ANY;
    address.sin_port = htons(PORT);

    if (bind(server_fd, (struct sockaddr *)&amp;address, sizeof(address)) &lt; 0) {
        perror("bind failed");
        exit(EXIT_FAILURE);
    }

    // 监听
    if (listen(server_fd, 3) &lt; 0) {
        perror("listen");
        exit(EXIT_FAILURE);
    }

    // 接受客户端连接
    if ((new_socket = accept(server_fd, (struct sockaddr *)&amp;address, (socklen_t*)&amp;addrlen)) &lt; 0) {
        perror("accept");
        exit(EXIT_FAILURE);
    }

    // 读取数据并转换为大写
    read(new_socket, buffer, BUFFER_SIZE);
    to_uppercase(buffer);
    send(new_socket, buffer, strlen(buffer), 0);
    std::cout &lt;&lt; "Modified message sent back to client\n";

    close(new_socket);
    close(server_fd);
    return 0;
}

<br><img alt="Pasted image 20240705115300.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240705115300.png">]]></description><link>https://congzhi.wiki/computer-networking-a-top-down-approach/chapter-2-application-layer.html</link><guid isPermaLink="false">Computer Networking A Top-Down Approach/Chapter 2 Application Layer.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sun, 09 Mar 2025 08:37:18 GMT</pubDate><enclosure url="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240527021928.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240527021928.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Chapter 3 Transport Layer]]></title><description><![CDATA[ 
 <br><br>Residing between the application and network layers, the transport layer is a central piece of the layered network architecture. It has the critical role of providing communication services directly to the application processes running on different hosts.<br><br>传输层协议为运行在不同主机上的应用进程提供logical communication 。而 logical communication 的意思其实是用应用的视角来看，它们传输数据时好像主机之间是通过一道传送门直接相连一样。但通过第一章的network overview，我们知道现实上两台主机之间的通信是依靠路由器、交换机这些 physical infrastructures 来进行的。而应用进程使用传输层所提供的逻辑通信，规避底层传递信息的实现细节，使得应用开发者可以专注于应用逻辑。极大地简化了网络编程和应用开发。<br>因为传输层是 TCP/IP 协议簇中的第四层协议，所以传输层协议只在主机上实现。在发送端，传输层将来自应用层的报文(message)转化成传输层的包，也叫报文段(segment) 。在转化过程中，最先将应用报文切割成更小的块(chunks)，然后加入传输层头部报文就成了报文段。之后，传输层会将封装好的报文段传递给发送终端的网络层，由网络层将 segment 封装成数据报(datagram)后发送给目标主机。在接收端，网络层将数据报解析成报文段后发给传输层，后由传输层处理好报文段后，将数据传递给应用进程。<br><br>传输层在协议栈(protocol stack)中位于网络层的上层。传输层协议会为不同主机间运行的应用进程提供逻辑通信( provides logical communication between processes running on different hosts )，而网络层协议提供主机间的逻辑通信( provides logical communication between hosts )。<br><br>要理解传输层和网络层之间的关系，我们在下面用一个例子来近似模拟一下，我们继续使用上一章最后的 快递邮寄 的例子。我们将房子看作应用进程，将街道看成主机host，但现在我们要加入快递驿站（每个街道一个）。这样我们就可以模拟网络层及网络层向上的数据逻辑通信了。<br>每个街道中存在的房子中都有很多活动，其中就不乏有寄快递的activity。这时，”房子“就需要把这些 快递件 给驿站让驿站发出去（应用层应用将报文交给传输层）。”房子“可以选择提供的邮寄服务，快发还是慢发，有没有快递丢失赔款的服务（应用层进程可以规定传输层协议）。<br>如果快递很多，那么驿站还会将这些快递分成许多 包裹 按批次发出去（传输层将应用层报文分成一个个 chunks 然后封装传输层报文头变成传输层数据段）。驿站在发快递之前，”房子“需要将把xx街道xx收件人作为收件地址交给快递驿站，之后就不用操心任何东西了（传输层协议只为应用进程之间提供逻辑通信）。快递站将包裹交给邮寄公司，邮寄公司负责将快递送达到目标街道（网络层只为主机提供逻辑通信）。<br>我们可以在这个模拟中看到，应用进程只需要用socket接口将报文交给传输层，不需要关心之后发生了什么，而传输层需要把报文成段封装成数据段后给网络层，至于网络层之后链路带宽什么的都不需要关心。我们之后还会了解到，传输层是如何做到即使底下的网络层为用户提供不可靠的服务，传输层仍然可以保证传输是可靠的。<br><img alt="Pasted image 20240705151453.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240705151453.png"><br><br>传输层提供两个不同的协议——UDP(User Datagram Protocol) 和 TCP(Transmission Control Protocol)。其中，UDP为上层应用提供无连接的不可靠服务，TCP为上层应用提供可靠的有连接的服务。从2.7节中，我们也了解到，在进行应用程序开发时，程序员可以选择使用UDP还是TCP作为传输层协议。<br>在我们简单介绍UDP和TCP这两个传输层协议之前，我们来看看IP为上层提供什么服务。IP(Internet Protocol)协议提供尽力而为的传输服务(Best-effort delivery service)，意思是IP尽它最大努力(take its best effort)在端到端上传输，但不保证数据传输过程中的完整性和顺序。<br>看过IP提供的服务之后，我们再来看看传输层UDP和TCP的服务。UDP和TCP作为传输层协议最基本的作用就是把IP协议的端到端信息传输延伸到进程到进程上的服务。这个过程也叫传输层多路复用(transport-layer multiplexing)和解多路复用(transport-layer demultiplexing)。UDP和TCP还会通过检查段头的信息来提供数据包的完整性的检查(integrity checking)。（1）进程到进程间的传输服务；（2）数据包的完整性检查。这两个服务是传输层提供服务的最低要求(minimal transport-layer services)，也是UDP唯二提供的服务。因此，我们看到，UDP并不提供可靠性的服务。<br>而TCP为上层应用提供额外的服务。它提供可靠的数据传输(reliable data transfer) 服务。使用流控制(flow control)、序列号(sequence numbers)、确认机制(acknowledgments)和计时器(timers)，通过这些工具TCP保证数据正确且按顺序的从传输进程传到接收进程。这样，TCP将IP端系统间的不可靠服务转化成进程间的可靠的服务。除此之外，TCP还提供拥塞控制(congestion control) 的服务，这些额外的服务也给TCP增添了不少复杂性。<br><br>我们将在本节讨论传输层多路复用和解多路复用。传输层提供的这对服务拓展了网络层的端到端的传输服务，有了这对服务，我们可以在不同主机上应用进程到应用进程间进行信息传输。从这段描述中我们能够很清楚地感受到 multiplexing/demultiplexing 有多重要。<br>我们下面简单看看传输层是如何将网络层的消息传到指定的应用的。在我们上网的时候，一般会打开好多个网络应用，一个网页刷视频的同时还在某公司官网上下载着它们的应用程序。而当传输层收到来自网络层的数据包后，它需要将这些数据包给到主机上其中一个运行的应用进程。那么传输层怎么指定把这些数据转发给哪个应用进程去呢？<br>学习socket编程的时候，我们了解到一个进程（网络应用的一部分）可以有一个或多个socket接口。我们也知道，socket作为应用层和传输层的接口，在传输层想应用进程转发来自网络层的数据时，其实是通过应用的socket接口来向应用进程转发的。传输层可以通过socket的标识符来决定给哪个socket转发信息，TCP和UDP标识符的格式是不一样的，传输层还可以根据这个判断数据传输时用的上面传输层协议。<br>现在，我们有能力轻松描述multiplexing/demultiplexing的过程了。所谓demultiplexing其实就是接收主机端将收到的传输层数据段传递到正确的socket上的过程，其中，传输层会检查segment header fields中的信息来指定某个接收socket。反过来，multiplexing就是在应用进程通过socket向传输层发生数据的时候，传输层将收到的数据划分成一个个chunks并根据socket加入header field封装为传输层数据段的过程。通过multiplexing，封装好的数据就可以直接发出去，而不用顾及会不会混淆其他应用进程。<br>在下图中，中间主机的传输层就必须将来自网络层的段进行demultplexing将信息正确地转发给上层的应用进程P1/P2（直直地给响应的进程socket）。在P1和P2要向外发报文时，所在主机的传输层还需要起到收集这些报文并封装起来的任务，多个上层应用共同使用同一个传输层，实现了传输层的multiplexing。<br>
<img alt="Pasted image 20240707015702.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240707015702.png"><br>
我们再用收发快递的例子来解释一下传输层的multiplexing/demultiplexing。房间中住着很多人，可能每个人都有快递发给不同的人（我们用“人”表示socket，”房子“延续表示进程的概念）。在发快递的过程中，这些快递件会先收集到街道快递驿站（传输层），根据发件/收件信息封装成一个个快递包并交给邮寄公司（网络层），这就是快递驿站的multiplexing。在另一个街道的快递驿站处，包裹会从卡车上卸下来并根据收件人信息发给收件人（socket），实现了快递驿站的demultiplexing。<br>我们现在知道了，要实现传输层的复用，需要 （1）标有特定标识符的sockets；（2）传输层数据段中需要包含这些sockets的标识符信息。学习了这么多，那“收件人信息”到底长什么样呢？<br>
<img alt="Pasted image 20240707150002.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240707150002.png"><br>
上图展示了一个传输层数据段的构成，在传输层的header fields，包括了源地址端口号(source port number field) 和 目的地端口号(destination port number field) 各16位的二元组(two tuple)。这16位信息能够表示0-65535之间的65536个数。从中，我们明白主机上端口号数最多能有65536个。其中0-1023端口号知名端口号(well-known port numbers)，预留给如HTTP（端口号80）、FTP（端口号21）等等这样的知名应用协议的。范围从1024到49151的端口叫做注册端口号 (Registered Ports)，这些端口号可以由用户或应用程序注册使用。范围从49152到65535的端口是动态/私有端口号 (Dynamic/Private Ports)，通常用于临时或私有连接。<br><br>UDP socket是用一个二元组（源端口号，目的端口号）组成的，即报文段segments在到达传输层后只要知道这些报文段的目的端口号就可以找到相关的socket接口了。也因此在UDP中，一个特定的端口号（例如8080）在同一台主机上只能被一个应用进程绑定。正是因为采用UDP协议的传输层端口只能绑定一个应用进程。因此，知道了端口号，自然知道其唯一对应的UDP socket在哪里了。<br>
<img alt="Pasted image 20240709001051.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240709001051.png"><br>在之前C++ 的 socket编程实验中，我们用sockfd = socket(AF_INET, SOCK_DGRAM, 0)来创建一个地址族为IPv4的数据报套接字(Datagram socket)。UDP的socket用这种方式创建后，传输层会自动地分配一个从1024到65535端口号范围内的端口。<br>但是我们在配置服务器地址时也看到其实端口号是可以自定义的：<br>// 配置服务器地址
    memset(&amp;server_addr, 0, sizeof(server_addr));
    server_addr.sin_family = AF_INET;
    server_addr.sin_addr.s_addr = INADDR_ANY;
    server_addr.sin_port = htons(PORT);
//关联端口号
	bind(sockfd, (const struct sockaddr *)&amp;server_addr, sizeof(server_addr))
<br>但我们要注意，由于0-1023号端口是知名端口，所以在创建socket时往往不可以将socket于这些端口相关联！<br>有了socket端口号，再回顾2.7节的编程实验。在实验中，我们创建了两个应用进程，它们再通信时的multiplexing/demultiplexing是怎么样的？我们使用了sockfd = socket(AF_INET, SOCK_DGRAM, 0)创建了一个udp_client应用的socket接口，系统自动分配一个源端口号。然而，我们需要知道服务器socket接口的端口号是多少，因此我们自定义绑定(bind)服务器端口号为8080。当udp_server进程一打开，就开始监听来自端口8080的segments。一旦收到有客户端发来的segments，服务器上的传输层会从segment header fields中获得有用的信息（udp_client应用进程来自哪里？）。之后处理来自客户进程发来的消息，转换成大写后再发回去。<br><br>要理解传输层TCP协议的demultiplexing，我们首先需要搞明白TCP的sockets和TCP连接建立是怎么一回事。UDP socket和TCP socket最明显的区别就是UDP socket是用一个二元组标识的（源端口号，目标端口号）而TCP socket是用一个四元组标识的（源端口号，目标端口号，源IP地址，目标IP地址）。所以，当有传输层数据段到达时，传输层使用全部四个数值来寻找要找的socket。因此在TCP协议实现的传输层上，即使端口号为80的端口是唯一的，但 socket不一定是唯一的（一个socket对应一个执行流）。<br>下面，我们用图看看TCP socket与UDP socket有何不同。在 Figure 3.5 中，Host A 与 Server B 建立了一个HTTP会话，Host C 与 Server B 建立了两个HTTP会话。从而，在 Server B 的应用进程上一共有三个socket分别对应着 Host A 的一个会话和 Host C 的两个会话。因为TCP socket是用一个四元组标识的，所以即使我们看到 Host A 和 Host C 的一个源端口号是相同的，Server B 的传输层任然可以通过源IP地址分辨两个会话。也可以通过 Host C 上两个会话的源端口号分辨这两个会话。<br><img alt="Pasted image 20240709003932.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240709003932.png"><br><br>我们已经简单了解了 TCP socket 的轮廓，具体来说，假如我们有很多 clients 要通过 HTTP 访问网页。在 server host 上，每个来自 client 的 HTTP 请求报文都要发到80号端口解复用后与服务器应用进程（socket）通信，服务器的响应报文也会通过80号端口复用将信息发给客户端。<br>之前提到过，一个socket对应一个执行流。所以在 server host 上，每个来自 cilent host 的HTTP请求都会先在80号端口上建立起一个用四元组标记的socket接口（一个新的执行流）。现代高性能服务器往往采用创建线程流的方式创建新的socket。如果连接采用 persistent connection ，在连接关闭前socket连接都会保留。但如果连接采用  non-persistent connection ，每次报文传输都要频繁地进行 socket 创建、socket 销毁，这样额外的开销可能严重拖累 server host。<br><br>3.3 节课中，我们会详尽地介绍UDP这个传输层协议。在2.1节中，我们简单了解了一下UDP服务模型，2.7节中我们通过编程更深入地了解了这个传输层协议。<br>假设我们要设计一个简单轻便的传输层协议，了解过UDP的我们很难不去参照UDP的实现方式去设计。这样也催生我们思考UDP存在的意义。UDP感觉像一盆吃不死人的饭菜，相比TCP那样的饕餮盛宴，UDP只有着不讲究、上菜速度快的优点，如果只是吃不死人，为何干脆不装盘，直接让这些应用进程趴在大锅上吃？砍掉传输层，让应用进程直接和网络层进行信息交互难道不好么？但我们要明白，一个主机上不单单有一个进程，没有传输层multiplexing和demultiplexing的分盘，应用进程很有可能出现进程A吃掉进程B的饭这样吃错饭的情况！<br>作为一个合格的丐版传输层协议，UDP的服务也只限于传输层的 multiplexing/demultiplexing 和简单的检错功能。UDP接收应用层的报文→加上简单的field→将封装好的数据段发给网络层；UDP接收网络层的数据段→解封装成应用层报文→发给对应的端口。同时，UDP也不提供数据传输前的握手，也因此UDP是无连接的。<br>既然我们有TCP这样的饕餮盛宴可供选择，为什么许多应用还会选择UDP这种吃不死人的饭菜呢？原因当然有很多。一方面UDP由于提供更少的服务，所以速度会更快，没有拥塞控制，而且撤去烦人的握手礼仪，也减轻了服务器的负载。DNS就是一个采用UDP作为传输层协议的典型应用。<br>
<br>
UDP相比TCP的优点：

<br>==Finer application-level control over what data is sent, and when. ==当传输层使用UDP，它可以将应用进程发送的报文封装后马上就发出去。而TCP的 congestion-control mechaniam 一旦检测到有大的拥塞就会掐断传输，而且TCP的重传机制也使得TCP的即时性远远不如UDP。（TCP传输时的延迟）
<br>No connection establishment.在传输数据前，TCP需要三次握手(three-way handshake)确认连接，UDP发送数据不需要握手。也因为TCP的这种握手延迟，Google的Chrome浏览器使用QUIC(Quick UDP Internet Connection)代替HTTP作为其传输层协议。（传播前的延迟）
<br>No connection state.TCP维护通信两端上的连接状态，其中包括接收和发送缓冲区、拥塞控制参数、序列号和确认号等信息。服务器维护这些信息会消耗大量的资源，不适合高并发应用。而UDP恰恰相反，TCP的缺点反而是它的优点，不维护连接状态，传输速度快，适合高并发应用，但不保证数据传输的可靠性。
<br>Small packet header overhead.TCP的段头有20个字节，作为对比，UDP只有8个。


<br>
下图罗列了一些知名的Internet应用，以及它们都使用哪种传输层协议。<br>
<br>
我们可以看到，这些运行在TCP上的应用无一不是需要TCP的可靠数据传输服务。这是UDP所不能提供的。但我们也同时发现 HTTP/3 的Web应用是运行在UDP上的，这是因为HTTP/3在应用层面上提供了检错纠错和拥塞控制的机制。<br>
<img alt="Pasted image 20240709230729.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240709230729.png"><br>
尽管UDP并不控制拥塞，但UDP可能会导致拥塞状态。在当今这个流媒体直播盛行的时代如果大家都观看高码率的直播且不采用任何拥塞控制，这会导致路由器的 overflow，不但影响UDP自己的流量，TCP也会由于拥塞控制而动态降低传输率，网络中的劣币驱逐良币。因而，许多学者建议强制所有的发送源应用都采用动态拥塞控制的机制。

<br>我们前面看到HTTP/3运行在UDP上，我们看到UDP其实是可以实现可靠的信息传输的，但是这种可靠性是在应用层面实现的（例如QUIC）。尽管苦了debugging的程序员，但这让应用实现了鱼（速度）和熊掌（可靠性）的兼得。<br><br>我们3.2节知道了段头中包含着源端口号和目的端口号的信息，现在我们终于可以一睹UDP数据段的段头的芳容了！下图给出了UDP数据段的段结构，鉴于我们已经了解过前两个字段——源端口字段和目标端口字段。我们直接来学习后两个字段，长度字段(length field) 标识当前UDP数据段的长度（段头加数据）。校验和字段(checksum field) 是接收主机用于检测传输过程中，段有没有发生错误。在UDP检错前，其实在网络层中IP头也会进行一些校验和的检错，我们之后会学习到。<br>
<img alt="Pasted image 20240710003357.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240710003357.png"><br><br>UDP的校验和为传输层提供了一种简单的检错机制，用于检查在源到目的传输过程中数据段是否受到噪音干扰。如果在传输过程中出现干扰或数据丢失，接收端的传输层可以通过校验和来判断数据段是否正确。如果数据不正确，接收端会直接丢弃该数据段。下面我们来看看校验和是如何发挥作用的。<br><br>在计算校验和之前，先要明确一件事：我们在计算UDP Checksum 之前，我们要在UDP报文段的头部前加入一个伪头部(Pseudo header)。<br>
<img alt="Pasted image 20240710191219.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240710191219.png"><br>
校验和的计算过程其实很简单，其过程如下：<br>
<br>从“伪头部”开始，按每16位当作一个数，逐次求和，最终得出一个32位的数；
<br>如果这个32位的数的高16位不为0，则进行“回卷”操作。
<br>重复第2步直到高16位为0。
<br>最终，将低16位取反，得到校验和，填入checksum字段中
<br>简单举个例子，我们要将数据从 IP source:192.168.2.1，Port src:8080传递到IP dest:192.168.2.2，Port source:9090。这里的8位协议字段(protocol)是17，表示UDP协议。再假设我们要传4字节的数据字段（0x55aa）。<br>
小端方式表示的UDP segment如下：<br>
Pseudo Header:<br><br>UDP Header:<br><br>Segment Body:<br><br>	 0000 0010 0000 0001      Pseudo Header Starts HERE
	+1100 0000 1010 1000
	————————————————————
	 1100 0010 1010 1001(SUM)
	+0000 0010 0000 0010
	————————————————————
	 1100 0100 1010 1011(SUM)
	+1100 0000 1010 1000
	————————————————————
   1 1000 0101 0101 0011(SUM)
	+0001 0001 0000 0000 +1
    ————————————————————
	 1001 0110 0101 0100(SUM)
	+0000 0000 0000 0100
	————————————————————
	 1001 0110 0101 1000(SUM)
	+0001 1111 1001 0000      UDP Header Starts HERE
	————————————————————
	 1011 0101 1110 1000(SUM)
	+0010 0011 1000 0010
	————————————————————
	 1101 1001 0110 1010(SUM)
	+0000 0100 0000 0000
	————————————————————
	 1101 1101 0110 1010(SUM)
	+0101 0101 1010 1010      UDP Body Starts HERE
	————————————————————
   1 0011 0011 0001 0100(SUM)
    +0001 0010 1000 0011 +1
    ————————————————————
     0100 0101 1001 1000
    ^
    ————————————————————
     1011 1010 0110 0111(CHECKSUM) 
<br>在接收端，传输层会将UDP segment中每16位相加并加上进位，最终与CHECKSUM相或，若结果不是0xFFFF（即全1）说明报文段出错，应舍弃。<br>尽管报文段在传播过程中会有链路和设备对段文信息进行检错，但只要过程中有一个链路(link)不提供这种可靠的保证，那么这一报文段的可靠性就存疑。再者，即使路由器检错没有问题，段文存储在buffer中还是可能造成错位。因此，我们需要在传输层上实现纠错机制。这也是系统设计中对 end-end principle 的典例。<br>还有就是，UDP 并不实现纠错机制。当 UDP 检测到段文错误，根据实现上的不同，可能会直接舍弃错误的报文段，如果要采纳一个不完全准确的报文段可能还会警告应用。下节课，我们将学习可靠数据传输应遵循的原则。<br><br>传递一些文本数据或者浏览网页时，一点微小的变动就可能使传递的整个报文变为不可读的垃圾。因此，数据传输过程中的可靠性保证就成了网络工程师所绝对关注的事情。为了这种数据的可靠，应用层、传输层、甚至数据链路层都有相应的协议来实现数据传输过程中的可靠性。<br>在下图中，我们将提供可靠性服务的下层抽象成一个 reliable channel。这个抽象出的信道会向上层应用提供：（1）无数据位反转、（2）数据不会丢失、（3）数据按发送顺序接收。这也是可靠性数据传输协议为实现可靠性要做的事情。虽然传输层是可靠的，但是IP不提供可靠性（尽力而为）。而且在端到端的传输链路中即便大部分的链路都是可靠的，只要有一条链路使用了不可靠的协议，那么整条链路就是不可靠的。TCP向上层应用提供的可靠信道其实是基于下层不可靠的抽象信道之上的，看似是一个不可能完成的任务，我们将在后续学习中逐步了解这种可靠性是如何实现的。TCP 需要在这种滩涂地上建高楼属实不容易。<br>下面我们看 3.8(b) 当发生进程发送报文(packets)时，它会调用rdt_sent()，将报文可靠的传输到接收进程上。在接收端，传输层会调用rdt_rcv为上层提供可靠的报文，之后调用deliver_data向上层应用传输报文。之后的小结中，我们用 "packet" 代替 "segment"，这是因为这种可靠性的理论是面向整个计算机网络的，不单单为传输层独有。<br>
<img alt="Pasted image 20240712160221.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240712160221.png"><br>
在本节中，我们只考虑 单向数据传输(unidirectional data transfer) 的情况，也就是数据只有发送方发给接收方。而 双向数据传输(bidirectional data transfer)，也只是单工的 verse visa 。尽管我们考虑的单向数据传播，但在TCP协议在发送和接收两端仍然需要双向的报文传输来回交换数据之外的控制信息（control packets）。在交换报文时，收发两端都会调用udt_send()通过不可靠的信道发送报文。<br><br><br>在 rdt1.0 中，我们暂且不考虑传输层下层信道的可靠性问题。下面，我们罗列出了 rdt1.0 的发送端(Figure 3.9a)和接收端(Figure 3.9b)双方的有限状态机(finite-state machine) 的模型操作定义。<br>
在图中，我们看到，无论是接收端还是发送端，它们都只有一种状态(state)，一个事件(event) ，每个事件后对应两个动作(action)，动作完成后转换(transition)到原有状态。<br>在发送端，FSM从虚线箭头处初始化发送端的状态，之后等待来自上层应用发送信息报文。一旦有上层应用的报文传来，触发事件rdt_send(data)并执行动作packet=make_pkt(data)、udt_send(packet)，完成后返回到初始状态。<br>
在接收端，同样先初始化接收端的状态，等待下层网络发来的信息报文。一旦报文到来，触发事件rdt_rcv(packet)并执行动作extract(packet,data)和deliver_data(data)将报文通过socket送到应用进程上。之后返回到初始状态。<br>
<img alt="Pasted image 20240715175100.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240715175100.png"><br>
从这个例子中，数据报文总是从发送方传播到接收方，有了下层信道的可靠性保证，接收端完全不需要给发送方反馈任何信息（前提假设下层信道完全可靠）。<br><br>为了更贴合实际情况，我们在 rdt2.0 中引入位错误(bit error)。我们知道给传输层提供服务的下层网络不是可靠的，在报文的传输(transmission)、传播(propagation)和缓存(buffer)都可能会导致报文中出现位错误。现在我们依然假设 不会出现丢失 的情况。<br>传输层该如何实现在这种信道下的可靠性保证？在我们打电话时，当别人说完一句话后，我们会有肯定回应和不确定回应的方式，在我们不确定对方说了什么时，我们可以要求对方再说一遍。在这种信道上实现的可靠性的方式也类似。Message-dictation protocol 会让接收端用positive acknowledgments ("OK") 和 negative acknowledgments ("Please repeat") 的控制报文使发送端知道哪个报文出错了。最后发送端将出错的报文重传。这种可靠数据传输协议也叫 ARQ(Automatic Repeat reQuest) protocols。<br>要实现自动重传请求(ARQ)协议，就必须引入以下三个机制：<br>
<br>Error detection：我们最起码要有检错机制来知道有位错误出现了，之后才能根据重传出现错误的报文。先前学了UDP的校验和，我们知道额外添加字段（checksum）就能实现简单的检错了。
<br>Receiver feedback：因为接发双方之间可能相隔上千公里，只有接收方给回馈才能让发送方知道并提供数据报文的重传。接收端会根据收到的报文返回 positive(ACK) 和 negative(NAK) acknowledgments。由于只有两个状态，我们用一位就可以表示清除。
<br>Retransmission：发送端根据反馈重新传输过程出错的报文。
<br>下图我们展示 rdt2.0 收发两端的有限状态机模型。在 rdt2.0 中，发送端的FSM有两个状态：（1）等待来自上层应用的发送信息报文；（2）等待来自接收端反馈控制报文。接收端的FSM仍然只有那一个状态。<br>在发送端，FSM先完成等待上层应用数据状态的初始化，一旦触发发送数据的事件rdt_send(data)就会产生相应动作（sndpkt=make_pkt(data,checksum)、udt_send(sndpkt)）。之后，发送端会停止发送报文并转变状态到等待接收端发来控制报文的状态。也因此，rdt2.0 这种协议叫做 stop-and-wait protocol。当发送端接收到来自接收端的控制报文后，如果收到 NAK 信号，就启动重传，如果收到 ACK 信号，发送端回到初始位置并等待下一次的数据发送。<br>在接收端，FSM先完成等待发送端数据状态的初始化。之后，当接收方收到来自发送方的数据，接收方会先校验 checksum 是否无误，如果无误就将数据传给上层应用并返回 ACK 的反馈，如果 checksum 检验后不一致，就会丢弃当前数据报并反馈 NAK 的报文。<br>
<img alt="Pasted image 20240715220352.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240715220352.png"><br>
rdt2.0 看似已经很完善了，但是我们仍然没有考虑到反馈过程中 ACK 或 NAK 若是出现位错误该怎么办？我们考虑以下三种解决方案：<br>
<br>引入新的询问报文：如果发送方不清楚接收方发来的反馈报文是什么，发送方可引入一个发送方到接收方的报文类型来给接收方说明对当前的反馈报文存疑。但要是这个报文也出现位错了呢？
<br>增加足够多的校验和位：通过增加足够多的校验和位，发送方不但可以检错，也可以纠错。但是如果传输过程中发生了 packet loss 就完蛋了。
<br>重复报文传输(Duplicate packets)：发送方在收到存在位错误的反馈报文时再发一遍当前数据包。但这样可能引入新的问题——接收方应如何处理重复的报文？
<br>而被大多数据传输协议所采用的方法是在数据包前面加入一个新字段——序列号(Sequence number)。现在，通过判断 序列号，接收方就知道收到的包是不是重传的。对于停等协议来说，1bit 的序列号就够了。1 bit 只能表示两位的状态。因此，我们用模2运算来表示包的先后顺序（前提假设下层网络的传输不会造成丢包），比如，对于0而言，1就表示下一个数据包的序列号，由于 module-2 运算，(1+1)/2结果余数0，这时序号0的数据报又变成了序号1的下一个数据包。（但注意：虽然序列号相同，但是数据包是不同的）<br>下面，我们来将接收端和发送端的两个 FSM 按部就班地解读一下。发送端等待并收到应用进程的第0号报文，将报文传输给接收端并等待接收端的控制报文。接收方发来控制报文后，判断如果发来的是 NAK 或者控制报文有位错误，就启动重传机制并继续等待。接收方再次发来的控制报文没有为错误且信号位ACK，这时的发送端转换状态并等待应用进程发来第1号报文。<br>
<img alt="Pasted image 20240715234126.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240715234126.png"><br>
在接收端，当收到第0号报文，接收端会检测位错误和序列号是否满足条件，若报文有位错误，则反馈 NAK 信号，如果没有位错误但序列号和当前等待接收的序列号不同则返回 ACK 信号，告诉发送端发重了。<br><img alt="Pasted image 20240715234140.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240715234140.png"><br>
rdt2.2 和 rdt2.1 最大的区别就是将报文nNAK信号和报文(n-1)的ACK信号放在一块检测。之前在rdt2.1中，接收方收到发送方的报文后会检查两个部分——报文有位错误？和报文发重了？然后根据这两个部分发送不同的反馈报文。但是在rdt2.2中，接收方将这些放在一起判断，并将判断结果放在一个反馈报文中返回给接收方。<br>
<img alt="Pasted image 20240715235048.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240715235048.png"><br>
<img alt="Pasted image 20240715235100.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240715235100.png"><br><br>我们再考虑丢包的情况进去，现在，我们不得不考虑：（1）怎么检测数据包的丢失；（2）数据包丢失之后该怎么办。考虑到这种新情况，我们需要在协议中引入一种新的机制来应对丢包。在这个机制中，我们只考虑让发送端来检测和恢复丢失的数据包。<br>假设在数据传输的过程中，发送方的数据包或者接收方的 ACK 信号由于重重原因丢了。这时，发送方在会在一个设定的时间猛惊醒，这么长时间，数据包肯定是丢失了吧，随后重传(retransmit)数据包。至于这个时间多长合适呢？发送方发送数据包后，它至少需要一倍的往返延时时间收到 ACK 信号（还要包括中转路由器中的时间和接收方对这些数据的处理时间）。但是这种时间在现实中的网络环境是很难测量的。而做最坏延迟情况又会使发送方启动重传之前等待很长时间。所以要等多久启动重传由发送方决定。<br>在发送方确定一个重传时间后，只要它在这个事件内没有收到 ACK/NAK 等信号，发送方就重传。我们可能会想到，如果发送方的数据包没丢只是现在没有收到 ACK 信号怎么办？这样，在发送方-接收方信道中引入了重复的数据包(duplicate data packets)。对于这种情况的处理我们在 rdt2.2 中已经学过（序列号），这里不再赘述。<br>从发送方的角度看，重传(Retransmission) 好像一副万能药。数据包传输过程中丢失、接收方的ACK信号丢失、ACK信号过度延迟等都可以用重传解决。这种基于一个时间重传的机制需要一个 定时器(Countdown timer) 在到时间后叫醒发送方重传数据包。因而，发送方需要（1）每次发送数据包都要重设时间；（2）相应计数器的中断，重传数据包；（3）收到 ACK 信号后停止计数。<br>下图展示了发送方rdf3.0的FSM。In Figure 3.16, time moves forward from the top of the diagram toward the bottom of the diagram; note that a receive time for a packet is necessarily later than the send time for a packet as a result of transmission and propagation delays.<br>
Because packet sequence numbers alternate between 0 and 1, protocol rdt3.0 is sometimes known as the alternating-bit protocol. We have now assembled the key elements of a data transfer protocol.<br>
<img alt="Pasted image 20240718000203.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240718000203.png"><br>
<img alt="Pasted image 20240715235100.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240715235100.png"><br>
终于，经过完善，我们的传输层协议可以实现可靠的数据传输（不用担心信道中会发送位错误还是丢包）<br>
<img alt="Pasted image 20240718003101.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240718003101.png"><br><br>在上小结的内容中，虽然我们完成的 rdt3.0 可以实现一个可靠传输协议的功能性，但这种基于停等协议的传输层协议的性能太弱了。<br>
<img alt="Pasted image 20240718003522.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240718003522.png"><br>
为直观理解停等协议带来的性能影响，我们假设现在有如上图所示的两台主机分布在美国的东西海岸，假设传播介质中的传播速度是光速，那大概需要30毫秒的时延。假设现在我们的传输率  是 1Gbps，数据包的大小  是1000 bytes（8000 bits），传输完这8000bits需要：考虑到传播时延，整个数据包从开始传输到收到 ACK 信号总共需要 。由于30ms的时间都是传播所用的废物时间，所以这时的利用率(utilization) 为:只有 不到万分之三 这个利用率是很低的，几乎不占用网络资源。发送方在30.008毫秒内只能发送一个1000bytes的数据包（1 Gbps带宽可用的情况下只用了267 Kbps）。而且我们忽略了下层协议的处理时间和重传丢包等情况，加上这些，效率会更低。<br>
<img alt="Pasted image 20240718014251.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240718014251.png"><br>
要提高停等传输的效率，我们可以将数据包做的很大，但是会导致严重的网络拥塞，而且一旦丢包，重传的代价会很大。另一种方案就是在不确定接收方是否收到数据包，收到数据包后是否有错误，而接连发送多个数据包，这样不仅合理利用了网络带宽，还避免了拥塞问题的发生。我们称后一种方法为流水线传输(pipelining) 在可靠数据传输中实验流水线有如下要求：<br>
<br>序列号必须是增大的（不包括重传情况）而且每个传输数据包的序列号必须唯一。
<br>协议中的收发两端的实现中需要有一个buffer来存放这些连续传输的数据包。发送方buffer必需装得下还没有获得确认信号的数据。
<br>序列号和buffer将在后面请求重传时用到。我们之后会学习两种带纠错机制的流水线传输协议——回退N帧协议(Go-Back-N) 和 选择重传协议(Selective Repeat)<br>
<img alt="Pasted image 20240718014358.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240718014358.png">
<br><br>在上小节的学习中，我们学到停等协议下可靠数据传输协议是如何实现的，在小节末，我们通过例子直观感受到了停等协议对带宽利用的低下。这小节及下小节，我们就来着眼看看流水线传输方式实现的两个可靠数据传输协议。这小节我们来学习 回退N帧协议(Go-Back-N)。<br>下图展示了一个GBN协议中序列号，这是发送方的视图。我们用 base 表示为目前发送buffer中等待 ACK 信号时间最长的数据包的序列号。我们在buffer中划一个窗口，窗口大小设置为 base 及往后的 N 个数据包。定义 nextseqnum 为下一个要发送数据包的序列号。通过这两个定义的序列号，我们现在可以将buffer中所有的数据包（序列号）如下分组：<br>
<br>\[0, base-1]用来表示发送后已经收到 ACK 信号的数据包（序列号）；
<br>\[base, nextseqnum-1]表示发送了，但是没有收到接收方反馈信号的数据包（序列号）；
<br>\[nextseqnum, base+N-1]表示收到的应用层数据包，但是没有发送的数据包（序列号）；<br>

<br>最后，base+N往后的那些序列号分成一组，它们需要等前面 base 得到 ACK 信号后，base、nextseqnum 才会向后挪。<br>
<img alt="Pasted image 20240720004907.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240720004907.png"><br>
通过分组，我们了解到窗口大小 (N) 是不变的，而且窗口会随着GBN的运转而往后滑动。由于这种滑动，GBN协议也叫&nbsp;sliding-window protocol。但是我们还要注意，这个窗口大小 (N) 并不是无限大的，(N) 不仅仅受到发送端缓冲区大小的制约，还受到序列号位数和拥塞控制的影响。
<br>现实中，数据包的序列号是包含在数据包头的一个定长字段。如果序列号位数为  ，那么序列号的范围就是[0,-1]。它也最多只能表示个序列号，由于序列号是循环使用的，序列号达到 (-1) 后，下一个序列号将回到 0。这就是为什么我们需要采用模 () 计算。我们需要采用模计算。(将模()想想成一个环，这个环起点和终点都是00……000，但是终点前一个数11……111加1就又会回到起点了)之前实现的 rdt3.0 中，我们使用的mod 2，序列号只能是0和1。而TCP的序列号字段很大，有 32-bit，因而，我们可以在TCP的传输中用序列号表示字节流中的字节数而不是数据包（不然重传代价可能会很大）。<br>下面的两个图描述了使用GBN协议收发两端的有限状态机模型。在使用GBN后，当报文发生错误后发送方并不用等待来自接收方的 NAK 信号，当发送方没有接收到 ACK 信号且超时后发送方重传相关数据即可。在这个 extended FSM 中，新增加了 base 和 nextseqnum 的变量，下面我们看看发送方都要做出那些反应。<br>
<br>Invocation from above.<br>
在rdt_send(data)开始发送数据前，发送端系统会先判断窗口是不是满的。如果窗口满了，那么发送方会将数据返回到上层应用，告诉应用现在发不了数据（在实际实现中，发送方更可能会将数据缓冲（但不立即发送），或者使用同步机制（例如信号量或标志），以便只有在发送窗口未满时，上层才会调用&nbsp;rdt_send()）。如果没满，发送方就会创建并发送数据包并更新变量 base 和 nextseqnum。
<br>Receipt of an ACK.<br>
在GBN协议中，从接收方发来的 ACK 信号会被视为一种 累计确认(Cumulative ack)，也就是当接收方发来对序列号为n的 ACK 确认报文时，代表序列号小于n的所有报文都是没有问题的。收到确认后，发送方就可以将窗口向前滑动，继续发送新数据。
<br>A timeout event.<br>
GBN对超时处理的方式就是它名字（Go-Back-N）的由来。当超时事件（序列号为N的数据包规定时间内没有收到 ACK 信号）发生，发送方就会先重启定时器，然后将序列号 N 往后的所有报文重发一遍，。如果在重发过程中有新的ACK信号到达，定时器会相应地调整。
<br><img alt="Pasted image 20240720033306.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240720033306.png"><br>
GBN协议发送方的FSM也十分简单，如果发送方的数据包按序正确到达，它就回馈对这些报文的 ACK 信号（某个最近一次数据包序列的ACK）并将信号传送到上层应用。同理，如果已经收到并传送过序列号k的数据包，那就意味着序列号小于k的数据包都已经被传送过了。这种累计确认(Cumlative acknowledgment)在GBN协议中十分常见。<br>从刚才起，可能我们就会有疑问，底层网络并不提供按序到达的保证，那么传输层向上层应用提供的按序到达的保证从何谈起呢？当前接收方需要收到序列号 n 的数据包，但如果网络先传给它序列号 n+1 的数据包该怎么办？发生这种情况，GBN协议的接收方会直接丢弃所有的乱序数据包。<br>假设接收方会将序列号 n+1 数据包正确后将这个数据包缓存起来，将序列号 n 的数据包递交给应用后在按顺序传输缓存的第 n+1 个数据包。但如果序列号 n 的数据包丢失了呢？GBN的超时重传机制会将序列号 n 往后的所有数据包都重传，缓存的第 n+1 个数据包就没有用武之地了。直接丢弃第 n+1 个数据包反而简化了接收方的缓冲处理。这样做也有缺点——后续重传的数据包可能继续丢失或损坏，从而需要更多的重传。<br>
<img alt="Pasted image 20240720033322.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240720033322.png"><br>
下图展示了当窗口大小为4时的GBN协议运行时的样子。由于这种窗口的限制，序列号范围只能从0到3，在发送完三号数据包后就等待来自接收端的 ACK 信号。收到正确的 ACK 信号后，窗口就会往后滑动发送新的数据包（pkt4 和 pkt5，由于系统是mod 4的，所以pkt4 和 pkt5实际等价于 pkt0 和 pkt1）。 在接收端，由于 pkt2 的丢失，往后的 pkt3、pkt4、pkt5 都要重传。<br>
<img alt="Pasted image 20240720042336.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240720042336.png"><br>
在现实的协议栈(protocol stack)中，对GBN协议的实现实际上和我们图3.20 的FSM非常相似。在这种 基于事件编程(event-base programming) 中，各个过程都是被协议栈中的其他过程（或中断）所调用起来的。在发送端，这种事件可能是：<br>
<br>上层应用实体唤起 rdt_send(), 
<br>定时中断
<br>有数据包到达时的下层实体调用 rdt_rcv() 
<br>通过本节的学习，对我们后续TCP的理解也会很有帮助。GBN协议几乎包含了研究TCP可靠数据传输组件时会遇到的所有技术。包括使用序列号、累积确认、校验和以及超时/重传操作。<br><br>在上节课中的GBN协议中，我们解决了停等协议中的资源利用率低下问题。但是GBN协议也会有性能方面的问题。更确切地说，在窗口大小和带宽都足够大时，全部重传问题不大，但在网络带宽较小时，GBN协议可能会导致网络拥塞，并且对接收方和发送方的时间效率都不友好（发送方会重传大量数据，接收方无法提前缓存损坏或丢失的数据包）。在这些前提下，选择性的重传好像是一个更好的选择。<br>在选择性重传（Selective-Repeat protocol） 中，当发送方的某个数据包没有收到ACK信号时，它只需要重新发送该数据包，这样信道就不会被无用的数据包占用。<br>这种按需重传要求接收方逐一检查数据包并回发ACK信号，这就要求接收方缓存相关的数据包，并在排序后将其交给应用层。下面展示了 SR 发送方和接收方的视图。这里，窗口大小N继续用作限制一次性发送数据包的最大数量，避免拥塞。<br>
<img alt="屏幕截图 2024-07-21 161530.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/屏幕截图-2024-07-21-161530.png"><br><br>发送方的一生会处理以下三种事件(events)，还有对这三种事件的处理方式(action)如下：<br>
<br>Data received from above<br>
当发送方收到上层应用传来的数据，SR发送方就会检查 nextseqnum 的大小。如果序列号在发送方的窗口内，传输层就会封装并发送数据；不然就先缓存或者让应用待会再传。
<br>Timeout<br>
和GBN中一样，SR发送方也会有应对数据包丢失的定时器。但由于选择重传的缘故，每个数据包都要有单独的逻辑定时器(logical timer)，这些逻辑定时器都会在一个物理定时器中实现。
<br>ACK received<br>
一旦发送方收到某个数据包的 ACK 信号，它就会对这个数据包进行标记（Already ACK'd）。如果这个数据包的序列号是 send_base，窗口就会向前滑动到下一个标记为 Sent, not yet ACK'd 的数据包处。
<br><br>接收方要处理的事件和处理方式如下：<br>
<br>Packet with sequence number in [rcv_base, rcv_base+N-1] is correctly received<br>
这种情况下，序列号落在接收方窗口内，接收方收到数据包后随即反馈 ACK 信号。要是这个数据包之前没有收到就缓存起来。如果数据包的序列号等于 rcv_base，就将之后连着的数据包一同送到应用上层，同时滑动接收方窗口。
<br>Packet with sequence number in[rcv_base-N, rcv_base-1]is correctly received.<br>
如果发生这种情况，肯定是接收方的 ACK 反馈报文丢失或出错了。这种情况下接收方必须赶紧打包发送这个数据包的 ACK 信号报文(re-acknowledgment)，不然可能出现传输停止的情况，毕竟发送窗口就那么大。
<br>Otherwise<br>
如果接收方没有收到或者收到了错误的数据包，接收方什么都不用操心，安心等待发送方重传就好。
<br>对于第二种接收方的事件处理的情形我们在下面的图中予以更直观的展示。为方便理解，下图中的窗口大小只有4个序列号。一旦发送方没有收到序列号为2的 ACK 报文，发送方的窗口就会卡在这里。这也就是我们为什么强调接收方在收到数据包序列号在接收窗口前时，就必须发送 re-ack 信号，不然发送方就一直卡在这里了。<br>
<img alt="Pasted image 20240721225159.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240721225159.png"><br><br>从上面的例子我们能学到，发送方和接收方的同步非常重要。接着上面 Figure 3.26的例子继续，但我们的窗口大变为3。回忆之前了解过的模运算(modular arithmetic)，假如我们的系统是mod-4系统，不能够表示除了序列号范围0、1、2、3以外的数字。在mod-4系统中，我们要怎么才能够知道发送方发来的数据包是新的还是重传的？我们通过下面两个例子来了解一下这种情况。<br>在第一个例子（Figure 3.27a）中，接收方收到数据包后窗口向后挪动，由于我们窗口大小是3，一次性能够传输3个数据包。在接收方收到数据后返回这3个数据包的 ACK 报文，如果这三个 ACK 报文丢了怎么办？在发送方，超时后又开始重传这三个数据包，等 pkt0 到接收方时它会以为这是新的0号数据包。而第二个例子中，pkt0、pkt1、pkt2都正常传输接收并返回 ACK 数据包。随后传输pkt3、pkt0和pkt1，这次的pkt3在传播过程中丢失了，但后面传输的pkt0是新数据。<br>怎么辨别呢？在窗口大小等于3时没有办法知道收到的pkt0到底是重传还是新的报文。但是如果我们将窗口大小改为2或者1，那就很容易辨别后面传输的数据包属于哪种情况。因此在SR协议中的窗口大小必须小于等于序列号数的一半。<br>
<img alt="Pasted image 20240722010246.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240722010246.png"><br>
关于可靠数据传输协议的实现我们已经了解许多，我们在下表中回顾这些rdt的机制，所有的所有都使我们有能力看见"the big picture"。<br>
<img alt="Pasted image 20240722021917.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240722021917.png"><br>
Let’s conclude our discussion of reliable data transfer protocols by considering one remaining assumption in our underlying channel model. Recall that we have assumed that packets cannot be reordered within the channel between the sender and receiver. This is generally a reasonable assumption when the sender and receiver are connected by a single physical wire. However, when the “channel” connecting the two is a network, packet reordering can occur. One manifestation of packet reordering is that old copies of a packet with a sequence or acknowledgment number of x can appear, even though neither the sender’s nor the receiver’s win dow contains x. With packet reordering, the channel can be thought of as essen tially buffering packets and spontaneously emitting these packets at any point in the future. Because sequence numbers may be reused, some care must be taken to guard against such duplicate packets. The approach taken in practice is to ensure that a sequence number is not reused until the sender is “sure” that any previously sent packets with sequence number x are no longer in the network. This is done by assuming that a packet cannot “live” in the network for longer than some fixed maximum amount of time. A maximum packet lifetime of approximately three minutes is assumed in the TCP extensions for high-speed networks [RFC 7323]. [Sunshine 1978] describes a method for using sequence numbers such that reorder ing problems can be completely avoided.<br><br>
VINTON CERF, ROBERT KAHN, AND TCP/IP
在20世纪70年代初，分组交换网络开始普及，ARPAnet（互联网的前身）只是众多网络中的一个。每个网络都有自己的协议。两位研究员，Vinton Cerf 和 Robert Kahn，认识到互联这些网络的重要性，并发明了一种跨网络协议，称为 TCP/IP，即传输控制协议/互联网协议。虽然 Cerf 和 Kahn 最初将该协议视为一个整体，但后来将其分为两个部分，分别是 TCP 和 IP，它们独立运行。Cerf 和 Kahn 于1974年5月在《IEEE通信技术》上发表了一篇关于 TCP/IP 的论文 [Cerf 1974]。
TCP/IP 协议是当今互联网的基础，它在个人电脑、工作站、智能手机和平板电脑出现之前，在以太网、电缆和 DSL、WiFi 以及其他接入网络技术普及之前，在网络、社交媒体和流媒体视频出现之前就已经被设计出来了。Cerf 和 Kahn 认识到需要一种网络协议，一方面为尚未定义的应用程序提供广泛支持，另一方面允许任意主机和链路层协议互操作。
2004年，Cerf 和 Kahn 因“在互联网上的开创性工作，包括设计和实现互联网的基本通信协议 TCP/IP，以及在网络领域的启发性领导”而获得了被誉为“计算机界诺贝尔奖”的 ACM 图灵奖。
<br><br>从第一章开始，我们就提到了TCP是面向连接的(connection-oriented)，这是因为在应用进程向另一个应用进程发送数据前，两个进程需要先“握手(handshake)”。在握手的过程中，客户端和服务器会互相发送一些初始数据包(preliminary segments)，如：SYN、SYN-ACK、ACK。通过这些初始数据包的交换，客户端和服务器都可以确定一些确保数据传输的关键通信参数，如：初始序列号、窗口大小、确认号(ACK)。<br>TCP的“连接(Connection)”并不是在线路交换网络(circuit switched network)中那种端到端的 TDM 或 FDM 线路。这里的“连接”是一种逻辑概念，这种状态只有通信端系统上才知道，中间节点（路由器等）是看不见连接的，它们只能看到数据报(datagram)的传输。<br>TCP连接为客户端/服务器双方提供全双工的服务(full-duplex service)：也就是在TCP连接中，进程A向进程B发送数据的同时进程B也可以给进程A发送数据。除此之外，TCP的连接也永远是点对点(point-to-point) 的，也就是TCP的连接局限于一个接收方和一个发送方。一个发送方多个接收方这种“多播(multicasting)”的情形不会出现。<br>那TCP连接建立的过程是怎么样的？我们之前提到过初始化连接的是 客户进程(client process)，另一个进程就是 服务器进程(server p'r)。在 2.7 节的 TCP 客户端编程课中，我们把连接服务器的代码放在 if 判断语句中了。这里的serv_addr是一个结构体，包含服务器的 IP 地址和端口号。<br>if (connect(sock, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) &lt; 0)
<br>当客户进程执行这段代码后，客户端 TCP 就会开始初始化建立与服务器 TCP 的连接。现在我们只需要知道连接的建立是客户端和服务器互发初始数据段实现的，而 SYN 、SYN-ACK 是不带负载的，也就是没有应用层的数据，在第三个数据段 ACK 会带一点负载。正是由于连接的建立过程是通过这三个报文段的发送与接收建立起来的，因此这个过程往往被称为三次握手(three-way handshake)。<br>一旦 TCP 连接建立，两个应用进程就可以互发数据了。现在我们考虑客户端是怎么给服务器发送数据的。沿用发快递的例子，应用进程（房子）将数据（快递件）通过 socket（门）交给传输层（快递员，房子之外的地方）。在将快递件送给快递员之前，要先确保驿站还有放快递的空位（发送缓冲区(send buffer)）。发送缓冲区在三次握手期间就设置准备好了（预约发快递，驿站会确定是否可发）。如果可以，应用进程（房子）就会把数据（快递件）源源不断的送给传输层（驿站），在传输层添加头部信息后（包裹信息），再送给网络层（快递公司），由网络层负责将数据传输到目的地。TCP 规范并不规定 TCP 需要什么时候才能将缓冲区中的段送给网络层。<br>
<img alt="Pasted image 20240725192031.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240725192031.png"><br>
每一次最大传输多大的数据收到最大段大小(MSS) 的限制。MSS的大小又收到最大传输单元(MTU) 的限制。这很好理解因为在网络中的数据是层层封装之后以类似“包裹”一样传输的，而链路层的帧最大多大，MSS 就理所当然的等于 MTU（通常是1500字节）减去 TCP/IP 的头部长度（通常是40字节）也就是1460字节的大小。以太网和 PPP 链路层协议中都规定 MTU 大小为1500字节，因而 MSS 典型值就是1460字节了。当然了，路径 MTU (path MTU) 会受到路径中最小链路层帧大小的限制。<br>NOTE：在这里，MSS (Maximum Segment Size) 指的是应用层传下来数据的大小，并不包含 TCP/IP 的头字段。<br>TCP 通过加入头字段的方式将数据封装成 TCP 报文段，然后传下去到网络层封装成 IP 数据报，之后把 IP 数据报发向网络。当接收方的传输层收到 TCP 报文段后，这些段就会先放在 TCP 接收缓冲区中。应用就从这些缓冲区中读取数据流。每个主机都会有自己的发送缓冲区和接收缓冲区。<br><br>和 UDP 一样，TCP 报文段也是由头部字段和数据字段构成的。报文段的头部字段大小是固定的（通常为20字节）剩下的数据字段就是从上层应用传下来的数据。上小结我们了解的 MSS 就表示数据字段最大的字节数。如果我们要传输一张很大的照片，通常我们会将图像文件分割成不大于 MSS 的数据库(chunks)，最后一个数据块往往比 MSS 小。而在一些交互式应用上，数据块的大小可能会远远小于 MSS，比方说像 Telnet 或 ssh 这样的远程登陆应用中，当用户在终端中输入一个字符时，这个字符会立即被封装成一个 TCP 段发送出去。TCP 数据段的数据字段通常只有 1 字节，如此，一整个 TCP 段就只有 21 字节，头字段占了20/21。<br>下图我们展示了 TCP 段的段结构，和 UDP 一样，段头都有源和目的端口号，用于数据在应用层和传输层之间multiplexing/demultiplexing。还包括了和 UDP 一样的校验和字段。除此之外，TCP 还包括一些额外的字段：<br>
<br>32位的序列号(sequence number) 字段 和 32位的确认号(acknowledgment number) 字段。它们用来实现可靠数据传输的服务。
<br>16位的接收窗口(receive window) 字段用来流量控制。
<br>4位的头部长度(header length) 字段，也叫数据偏移(data offset)，以32位字(word)为单位指定 TCP 头部的长度（最大 60 字节）。由于 TCP 选项字段的存在，TCP 头部的长度可以是可变的。（通常情况下，选项字段是空的，因此典型的 TCP 头部长度为 20 字节。）
<br>选项字段(options field) 的长度是可变的，用于在发送方和接收方协商最大段大小（MSS）或作为高速网络中使用的窗口缩放因子。此外，还定义了时间戳选项(time-stamping option)。
<br>控制位(flag field) 包括6个bit位，有URG、ACK、PSH、RST、SYN、FIN。

<br>CWR 和 ECE 位用于拥塞控制，我们之后会有专门的小节介绍 TCP 的拥塞控制。
<br>URG（Urgent）：紧急指针有效。表示数据段中有紧急数据，接收方应优先处理。
<br>ACK（Acknowledgment）：确认序号有效。表示确认接收到的数据，通常在数据传输过程中每个数据段都会设置这个位。
<br>PSH（Push）：推送数据。表示接收方应立即将数据推送给应用层，而不是在缓冲区中等待。
<br>RST（Reset）：重置连接。表示连接出现问题，需要重新建立连接。
<br>SYN（Synchronize）：同步序号。用于建立连接的初始同步过程，通常在三次握手的前两次握手中使用。
<br>FIN（Finish）：结束连接。表示发送方已经完成数据传输，要求关闭连接。


<br>紧急指针(urgent data pointer) 字段，共16个字段指示紧急数据的结束位置。<br>
<img alt="Pasted image 20240726044658.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240726044658.png"><br>
在现实中，我们很少使用 TCP 的 PSH（Push）、URG（Urgent）标志位和紧急指针。在此介绍只是为了整个段构成的完整性。
<br><br>序列号和确认号是 TCP 最重要的两个字段，这两个字段保障了 TCP 可靠数据传输的实现。在上节课中我们也讨论过相关的 rdt 实现。现在，我们就来看看 TCP 到底在这两个字段里面塞了什么。<br>
<img alt="Pasted image 20240727043719.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240727043719.png"><br>
如上图，TCP 将数据视为一种无结构有序的字节流。和我们想象的可能不同，TCP 用序列号并不用于段的编号，而是数据流中对各个字节所编号。每个段第一个字节的序列号就代表了这个段的序列号。因而，序列号的编号是只针对数据字段的。上图的文件包含了500 000字节的数据流，而每个 MSS 1000字节，因此我们有500个数据段，第一个段的编号就是0，第二个段的编号为1000，以此类推。这样段的编号就会作为序列号字段插在头部字段(header field)中。<br>OK，现在我们来学习另外的确认序列号(acknowledgment numbers)。回忆一下，我们说 TCP 是全双工(full-duplex)的，在接收方（Host B）接收数据段的同时向发送方（Host A）反馈段的接收情况。每个数据段都会对应唯一的序列号，Host B 在正确收到数据段后会向 Host A 发送序列号 + 1的 ACK 信号段文。举个例子，在 1st 段文（0-999）被 Host B 收到之后，Host B 会发送序列号为1000的 ACK 段。TCP 提供累计确认(cumulative acknowledgments) 的机制，如果 ACK 段中序列号是1000，就表示序列号小于1000的字节均已收到，等待序列号1000往上的数据。<br>在 TCP 的 RFC 相关文档中其实并没有规定 TCP 连接中的主机收到乱序的段该怎么办。结合我们之前讲过的，我们有两种办法：<br>
（1）丢弃乱序的数据段；<br>
（2）将乱序的数据段放在一个接收缓冲区中，等待丢失的数据段(missing bytes)来填满空隙。<br>
尽管第一种方法简单且减少接收主机的部件设计，但由于第二种方案在网络带宽利用的更加高效，因此在现实中多采用第二种方案。<br>在图3.30中，我们假设初始序列号为0。实际上，TCP连接的双方会随机选择一个初始序列号。这么做是为了减少这样一种可能性：两个主机的连接已经终止了，但是先前的某个数据段还留存在网络之中，这个数据段就可能被之后同一对主机间新创建的连接当成有效的数据段（并且新连接恰好使用了与旧连接相同的端口号）<br><br>Telnet 是在 RCF 854 文档中规定的应用层协议。Telnet 跑在 TCP 协议上，可以用在任意一对主机上的远程登录。但由于 Telnet 连接并不加密，很多人会选择 SSH 协议。<br>假设我们现在有两个主机 Host A 和 Host B，其中 Host A 是客户端，初始化 Telnet 会话， Host B 是服务器。在 Telnet 上，Host A 键入的每个字符都会封装成一个 TCP 数据段发给远程主机；然后远程主机会回发每个字符的拷贝，显示到用户的屏幕上。这种”回发(echo back)“机制保证每个字符在远程主机上收到后都得到了处理。<br>假设用户输入了一个字母’C'，那客户端服务器之间的数据段传输是怎么样的？从传输开始到结束，客户端和服务器总共发了三个数据段，在TCP连接建立完毕后，客户端等待服务器端送来79号字节，服务器等待客户端的42号字节。双方对此心知肚明，因此客户端发送第一个报文段时会将42号序列号的字节发给服务器（包含 ASCII 的 'C"），并将服务器索要79号序列号的字节。<br>之后，服务器会在序列号为79的字节将字母 'C'  通过TCP报文回发给客户端，并请求客户端的43号报文（告诉客户端序列号42前面的数据都收到啦）。在服务器向客户端发送的TCP数据段中，我们可以发现这个数据段Seq=79, ACK=43, data='C'实际上发挥了两个作用——（1）ACK=43，收到前面的数据啦；（2）对数据 'C' 的回发。在同一个数据段中实现了对前面发送数据的确认，这种技术叫捎带确认(piggybacking)。<br>最后一个段只有一个作用——客户端对服务器发送信息的确认（ACKed）。这个数据段没有数据字段（这个 acknowledgment 就不是客户端-服务器数据字段的捎带确认了）。我们注意到这个数据段并没有数据字段但是仍然有序列号，这是因为TCP就是这样要求的。<br>
<img alt="Pasted image 20240727055138.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240727055138.png"><br><br>TCP和我们前面设计的 rdt 协议一样，都使用超时重传(timeout/retransmit) 机制来弥补那些已经丢失的段。尽管看起来很简单，但是我们不得不考虑在超时中的这个“时”是怎么来的？在此之前，我们得先知道往返时延(RTT) 多大，之后根据 RTT 确定多长时间重传一次。<br><br>现在，我们开始学习在 TCP 是怎么预估发送方-接收方之间的往返时间RTT的。我们用SampleRTT来表示数据段从传输层发送出去到接收到 ACK 报文段之间这么长的时间。SampleRTT在 TCP 的实现上通常表示目前还没收到 ACK 报文的这报文段发送后已经过了SampleRTT的时间。还有，TCP 不会记录重传段的SampleRTT，只记录发送一次的报文段。<br>显然的是，报文段传输路径拥塞度不同，SampleRTT值也会随之浮动变化，由此产生的SampleRTT时间我们通常称作非典型的(Atypical)。要想预估到更稳定的往返时间，我们就需要将每个段的SampleRTT来平均一下，获得的时间我们叫EstimatedRTT。我们通常用下面的公式计算：经过大量实验和应用，实验人员证明  的 α 值能够在大多数情况下提供稳定且准确的 RTT 估计。因而也将 1/8 的 alpha 值写进了 [RFC 6298]。这样，上面的公式就变成了：我们在这里计算的 EstimatedRTT 是 SampleRTT 的加权平均值，我们给当前的 SampleRTT0.125的权重，这样算得的EstimatedRTT就更好反应目前接收双方之间节点的拥塞度。在统计学中，这种平均被称为 exponential weighted moving average (EWMA)。下图展示gaia.cs.umass.edu和fantasia.eurecom.fr之间 TCP 连接的 RTT。我们看到EstimatedRTT比SampleRTT更加平滑。<br>
<img alt="Pasted image 20240811181317.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240811181317.png"><br>
然除了 RTT 的预估，RTT 的多变性也是我们要关注的。 在[RFC 6298]中同样定义了 RTT 变动，用DevRTT表示。用下列的公式计算：我们用DevRTT表示SampleRTT和EstimatedRTT之间的 EWMA 差异。DevRTT越小就说明网络越稳定，反之，网络则不稳定。对 β 的推荐值是0.25。<br>
PRINCIPLES IN PRACTICE
*TCP 通过使用积极确认和定时器来提供可靠的数据传输，这与我们在第 3.4 节中研究的方法非常相似。TCP 确认已正确接收的数据，然后在认为数据段或其相应的确认丢失或损坏时重新传输这些数据段。某些版本的 TCP 还具有隐式 NAK 机制——通过 TCP 的快速重传机制，接收到某个数据段的三个重复 ACK 被视为该数据段后续数据段的隐式 NAK，从而在超时之前触发该数据段的重传。TCP 使用序列号使接收方能够识别丢失或重复的数据段。就像我们的可靠数据传输协议 rdt3.0 一样，TCP 本身不判断某个数据段或 ACK 报文是否丢失、损坏或延迟过长。在发送方，TCP 的响应都会是一样的：重新传输相关的数据段。 
TCP 还使用流水线技术，允许发送方在任何给定时间内有多个已传输但尚未确认的数据段。我们之前看到，当数据段大小与往返延迟的比率较小时，流水线技术可以大大提高会话的吞吐量。发送方可以拥有的未确认数据段的具体数量由 TCP 的流量控制和拥塞控制机制决定。TCP 的流量控制将在本节末尾讨论；TCP 的拥塞控制将在第 3.7 节讨论。目前，我们只需要知道 TCP 发送方使用了流水线技术。*
<br><br>好了，现在我们知道怎么算得EstimatedRTT和DevRTT，很显然，我们所要的重传间隔得大于等于EstimatedRTT，但是不要大太多。而且我们想的重传间隔最好跟网络的拥塞变化要息息相关。当网络一时间更加拥塞了，我们需要调整重传间隔让它变得更大。这样我们就会得到下面式子：在[RFC 6298]中，建议初始的超时间隔为 1 秒。当发生超时时，TCP 会将当前的超时间隔值加倍。这是为了避免在接下来的数据段即将被确认时发生过早的超时。通过加倍超时间隔，可以减少不必要的重传，从而提高传输效率。一旦接收到数据段并更新了&nbsp;EstimatedRTT（估计的往返时间），TCP 会重新计算超时间隔。新的超时间隔将基于更新后的&nbsp;EstimatedRTT&nbsp;计算。<br><br>我们提到过网络层的 IP 协议是不可靠的，IP 不保证传输过程中数据报的按序到达和完整性。而传输层建立在网络层之上，所有传输层的数据报会遇到到达时的乱序、不完整、丢失等各类问题。因而对于传输层提供可靠性的 TCP，需要在 IP 尽力而为的非可靠服务上提供可靠数据传输服务，也就是说接收端接收的字节流要和发送方发送字节流一致。其中很大一部分的原则我们都在 3.4 rdt 那一节学习过。<br>还需要注意的是，虽然我们之前提到的超时重传为每个数据段都配备一个定时器时刻检测间隔时间（rdt）。但是尽管后面还可能有许多未收到 ACK 的数据段，TCP 定时器管理也只使用了 一个 重传定时器（跟踪新的最早发送但还没有确认的数据段）。<br>知道关于定时器的相关知识，现在我们逐步讨论一下 TCP 所提供的可靠数据传输服务。我们首先看一下 TCP 发送方只使用超时重传机制恢复丢失段的简化描述；之后介绍一个更完整的 TCP 发送方模型，该模型不仅使用超时机制，还使用重复确认（duplicate acknowledgments） 来从丢失的数据段中恢复。<br>我们用下面高度简化的 TCP 伪代码描述一下三个主要的事件及其处理。<br>/*假设暂且不受TCP拥塞控制的约束，且传递节点单一*/

NextSeqNum = InitialSeqNumber
SendBase = InitialSeqNumber

loop(forever){
	
	switch(event)
	
		event: data receive from application above
			create TCP segment with sequence number NextSeqNum
			if(timer current not running)
				start timer
			pass segment to IP
			NextSeqNum=NextSeqNum+length(data) 
			break;
		event: timer timeout 
			retransmit not-yet-acknowledged segment with smallest sequence number
			start timer
			break;
		event: ACK received, with ACK field value of y 
			if (y &gt; SendBase) { 
				SendBase=y 
				if (there are currently any not-yet-acknowledged segments) 
					start timer 
			} 	
			break;

}/*end of loop*/
<br>我们一件一件描述上面对发送方的三大事件。<br>
<br>收到应用层传来的数据包：封装来自应用层的数据包并发送给 IP。在此之间，TCP 会检测计时器是否在工作，如果没有就启动定时器。
<br>定时器超时：从未得到确认报文的最小的那个序列号开始重传。
<br>收到确认号为 y 的 ACK 数据段：如果 y 的大小大于 SendBase，就将滑动窗口，将 y 赋予 SendBase。然后如果检测到还有未得到确认的报文，就重启定时器。
<br><br>虽然我们刚刚只是给出了 TCP rdt 的简化版本，但其中也不乏一些微妙之处。在图3.34中，Host A给Host B发送了包含 8 字节数据序列号为 92 的数据段，并期望收到来自Host B包含确认号 100 的确认字段。但是第一次Host B传输 ACK 报文段的时候段丢失了，Host A的计时器在一段时间间隔中没有收到来自Host B的 ACK 信号，就启动重传，之后成功收到Host B传来的响应报文段。<br>
<img alt="Pasted image 20240812102024.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240812102024.png"><br>
但在下图3.35中，没有数据段的丢失，但是Host B的 ACK 响应没有在超时间隔内传到Host A，因而Host A启动重传。重传后在间隔内收到Host B传来对两个数据段的确认，因为对两个数据段都进行了确认，Host A也就不需要重传第二个数据段了。<br>
<img alt="Pasted image 20240812120639.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240812120639.png"><br>
在下图3.36的第三种情形下，我们看到在 Host B 回传对两个数据段的确认时丢失了第一个响应报文。但是由于Host A收到第二个响应报文（ACK=120）因此并不会启动重传，因为 120 的确认号对前面的字节序列进行了累计确认。<br>
<img alt="Pasted image 20240812120931.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240812120931.png"><br><br>现在我们做一些现实性的改变。在现实应用中，TCP 的重传时间并不是一成不变的，没多一次重传，TCP 都会设置重传时间为原先的两倍。比方说刚开始的超时间隔是 0.75 秒，如果时间内没有收到 ACK 确认段，TCP 就会启动重传并设置超时间隔为 1.5 秒，然后 3 秒。但如果如果在此期间接收到新的数据（定时器未工作）或 ACK 确认，超时间隔就会通过最新的 EstimatedRTT 和 DevRTT 重新计算。<br>这种超时间隔设置翻倍的改变是我们后面学习 TCP 拥塞控制的前提。因为定时器超时最可能是因为网络拥塞问题造成的。一次性太多数据包同时到达某一路由器队列就可能造成路由器的丢包或过久的排队时延。试想，网络状况本来就不太理想的情况下还频繁地发起重传，拥塞就会更加严重，但增加重传间隔就会在网络状况改善时能够迅速调整超时间隔。这种思想也会在我们 Chapter 6 中学习 CSMA/CD 时用到。<br><br>当然，超时间隔翻倍也有一个坏处，即超时间隔会变得很长。会出现每次丢包都会让重传的时间间隔翻倍，这样就增加了端到端的延时。但发送方可以通过检测重复的 ACK 来发现数据包丢失，而不必等待超时事件的发生。接收方通过重复 ACK(duplicate ACK) 告诉发送方还有还有哪一序列号的报文没有收到。发送方在收到多个重复ACK后（一般认为是3个）会认为某个数据段丢失，并立即重传该数据段。<br>下图我们总结了 TCP 接收方的ACK生成策略。一共有 4 种情况导致接收方生成ACK：<br>
<br>接收方收到按序到达的数据段，且所有数据都已经被确认。

<br>接收方做法：延迟确认(Delayed ACK)，即接收方不会立即发送ACK，而是等待最多500ms，看看还有没有下一个按序到达的数据段。


<br>接收方收到按序到达的数据段，并伴随一个按顺序到达尚未确认的数据段。

<br>接收方做法：立即发送累计确认ACK，对这两个按顺序到达的数据段进行确认。


<br>接收方收到乱序数据段并检测到前面数据段之间存在字节序列号的gap。

<br>立即发送重复ACK，期待收到的下一个收到字节序列号为gap的下沿。


<br>接收方收到填充gap的数据段。<br>
- 立即回发ACK信号。<br>
<img alt="Pasted image 20240812144354.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240812144354.png">
<br><br>那么 TCP 采用的是 GBN 协议还是 SR 协议呢？我们之前说过，TCP 对报文的确认是累积性确认的，接收方并不会按个确认那些乱序但准确到达的数据段。发送方也只需要在那些未收到确认的序列号中维护最小的那个(SendBase)，另外<br>维护下一个要发送字节的序列号(NextSeqNum)就可以了。截至这里，TCP 看起来好像是一个 GBN 的协议。但是TCP 和 GBN 还有许多不同之处。因为 TCP 的实现需要缓存那些收到的无误的数据段。（GBN会丢掉那些乱序的数据段）<br>假想一下，发送方要发送序列号从 1, 2, 3,......, N 的数据段，若传输期间没有丢包或corrupted bits，那么无事发生。但是如果数据包 n&lt;N 在传输过程中丢失了，那么两种回传协议就会大不同。GBN 协议下的传输层协议会把 n, n+1, n+2,......, N全部重传一遍，这会极大的增加网络拥塞。<br>我们前面提到，在 TCP 接收方收到数据段后并不会立即发送 ACK 数据段，而是等待500ms看看还有没有新到达的数据段，以便一同累计确认。TCP 发送方在开始序列号 n 的报文段重传前如果接收到序列号为n+1数据段的确认就会因为累计确认的关系滑动发送窗口。<br>TCP 也被叫做是 选择性确认(Selective ACKnowledgment) 的协议。TCP 允许接收方选择性地确认乱序数据段，而不是仅仅累计确认最后一个按顺序正确接收的数据段。TCP的错误恢复机制结合了GBN和SR协议的特点。虽然TCP使用累积确认（类似于GBN），但它也实现了选择性重传（类似于.SR），使得TCP在处理数据段丢失时更加高效。<br>]]></description><link>https://congzhi.wiki/computer-networking-a-top-down-approach/chapter-3-transport-layer.html</link><guid isPermaLink="false">Computer Networking A Top-Down Approach/Chapter 3 Transport Layer.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Wed, 12 Mar 2025 16:24:26 GMT</pubDate><enclosure url="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240705151453.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240705151453.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Computer Networking A Top-Down Approach]]></title><description><![CDATA[ 
 <br><br><br>原计划对 Computer Networking: A Top-Down Approach 整本书进行翻译，翻译了三章翻译不动了。目前已弃坑......<br><br><br>三章的入口罗列在下：<br>Computer Networking: A Top-Down Approach

<br><a data-href="Chapter 1 Computer Networks and the Internet" href="https://congzhi.wiki/computer-networking-a-top-down-approach/chapter-1-computer-networks-and-the-internet.html" class="internal-link" target="_self" rel="noopener nofollow">Chapter 1 Computer Networks and the Internet</a>
<br><a data-href="Chapter 2 Application Layer" href="https://congzhi.wiki/computer-networking-a-top-down-approach/chapter-2-application-layer.html" class="internal-link" target="_self" rel="noopener nofollow">Chapter 2 Application Layer</a>
<br><a data-href="Chapter 3 Transport Layer" href="https://congzhi.wiki/computer-networking-a-top-down-approach/chapter-3-transport-layer.html" class="internal-link" target="_self" rel="noopener nofollow">Chapter 3 Transport Layer</a>
<br><a data-href="SMTP" href="https://congzhi.wiki/computer-networking-a-top-down-approach/smtp.html" class="internal-link" target="_self" rel="noopener nofollow">SMTP</a>

]]></description><link>https://congzhi.wiki/computer-networking-a-top-down-approach/computer-networking-a-top-down-approach.html</link><guid isPermaLink="false">Computer Networking A Top-Down Approach/Computer Networking A Top-Down Approach.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 21:59:38 GMT</pubDate></item><item><title><![CDATA[SMTP]]></title><description><![CDATA[ 
 <br>在linux中完成SMTP对目标的email地址进行发邮件的操作，一切都配置成功，邮件能够发出并被收到，但是问题在于发出的massage body不显示的问题。<br>du@du-virtual-machine:~$ telnet smtp.qq.com 25
Trying 183.47.101.192...
Connected to smtp.qq.com.
Escape character is '^]'.
220 newxmesmtplogicsvrsza15-1.qq.com XMail Esmtp QQ Mail Server.
HELO qq.com
250-newxmesmtplogicsvrsza15-1.qq.com-30.163.159.208-81411193
250-SIZE 73400320
250 OK
AUTH LOGIN
334 ############
####################
334 ############
####################
235 Authentication successful
MAIL FROM:&lt;1395508263@qq.com&gt;
250 OK
RCPT TO:&lt;1395508263@qq.com&gt;
250 OK
DATA
354 End data with &lt;CR&gt;&lt;LF&gt;.&lt;CR&gt;&lt;LF&gt;.
From:"CongZhi"&lt;1395508263@qq.com&gt;
nihao,this is test one,the first email I send on linux  shell.I wish this could be seen!
.
250 OK: queued as.
QUIT
221 Bye.
Connection closed by foreign host.
<br><img alt="Pasted image 20240608075456.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240608075456.png"><br>问题解决：form...to...<br>From:"CongZhi"&lt;1395508263@qq.com&gt;
To:&lt;1395508263@qq.com&gt;
Subject: Test Email

nihao,this is test one,the first email I send on linux shell.I wish this could be seen!
.
<br><img alt="Pasted image 20240608080032.png" src="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240608080032.png">]]></description><link>https://congzhi.wiki/computer-networking-a-top-down-approach/smtp.html</link><guid isPermaLink="false">Computer Networking A Top-Down Approach/SMTP.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 22:00:39 GMT</pubDate><enclosure url="https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240608075456.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/computer-networking-a-top-down-approach/pics/pasted-image-20240608075456.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1. Introduction to the OS]]></title><description><![CDATA[ 
 <br><br><br>如今，计算机系统无处不在，而操作系统在计算机系统中处于核心位置，简单地了解计算机系统为我们后面学习操作系统这个”房间中的大象“十分必要。<br>计算机系统是一个宏观的概念，计算机系统由硬件(hardware) 和软件(software) 共同构成，二者相辅相成。硬件提供了基础设施，软件则利用硬件为我们创造丰富多彩的应用体验。和操作系统的关系是什么？我们现在可以先下一个定义：操作系统是管理软硬件资源，为应用程序提供服务的程序。也就是说操作系统是一种管理软件和硬件的系统软件（resource manager）。<br><br>假如没有电，你所能看到的一大块铁壳子就是计算机的硬件。没有软件的加持，硬件对于我们很多人来说就是一块废铁。而没有硬件的支撑，软件又会犹如空中楼阁。换句话说，软件赋予了硬件更大的价值，而硬件又为软件提供了发挥价值的平台。<br><br>在计算机组成的课程中，我们学到，计算机的五大部件：运算器、控制器、存储器、输入部件和输出部件。即要想组成一台图灵完备的计算机，我们至少需要：<br>
<br>CPU：包括 ALU、CU 和一众寄存器，CU控制着包括 ALU 和其他部件进行各种操作。
<br>Memory：由成千上万个记忆单元组成，用来存储各种指令和数据。
<br>Inputs：输入部件，提供数据和命令供 CPU 运算。
<br>Outputs：输出部件，输出 CPU 处理后的结果。
<br>抽象的概念是上层对下层复杂性的隐藏，整个计算机系统都是一层一层的抽象。CPU也是对数以亿计的门电路进行的抽象封装，CPU的引脚就是封装后的接口。尽管经过了封装，但裸机依然难用，因为我们总不可能将每个CPU的针脚都和一个开关/灯泡相连。咋办？<br><img alt="Pasted image 20240921032501.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240921032501.png"><br>上图展示了一台计算机的主板，没有安装CPU和内存条。但我们从这些插槽能够窥见整个计算机是如何被组织起来的（bus did all the works）。科技的发展使得主板可以变得很小很漂亮，但假想一下，没有软件（包括操作系统），我们该怎么使用这台裸机？<br><br>当代计算机几乎都遵循以存储器为中心的冯诺依曼体系结构，将计算机分为五大部件——存储器、运算器、控制器、输入部件和输出部件。其中，控制器（CU）负责协调和控制其他四个部件完成各自的任务。因此，计算机的工作流程实际上是由控制器指挥其他部件按顺序执行指令。一个指令处理的完整流程包括输入、存储、计算和输出。<br><br>计算机需要处理（计算）数据，五大部件中负责将外部信息输入到计算机系统中的是输入设备。常见的输入设备包括键盘、鼠标、扫描仪等。此外，现代计算机还包括触摸屏、语音识别系统和摄像头等高级输入设备，用于更加多样化和直观的用户交互。<br><br>在数据被处理前，输入的数据需要先被放到一个地方。这个地方就是我们一般说的主存储器/内存(Main Memory)，所有需要被处理的数据都会事先被放到主存中。<br>除了主存外，系统中一般也需要包含辅助存储器(Storage)。主存储器速度快但容量小，主要用于临时数据的存储和快速访问。辅助存储器容量大但速度较慢，用于长期数据的存储。<br><br>当CPU要处理某些数据时，它会从cache或memory中读取并处理这些数据。在某些特定情况下，系统还会在硬盘中寻找相关的数据。<br>除了CPU，GPU(Graphics Processing Unit) 在一些高并行计算的应用场景中有其不可替代的优势。如图像处理、深度学习等。<br><br>当数据处理完成之后，我们想得到处理后的结果。这时，系统就会让输出设备将计算机处理后的信息输出给用户。常见的输出设备包括显示器、打印机、扬声器等。<br><br>软件是运行在硬件上的一系列程序和数据的集合。软件告诉计算机硬件需要先这样，在那样...。我们前面说，硬件提供了计算机系统的基础设施。但仅靠硬件，我们使用计算机将会十分不便，因为和直接操作裸机差不多。<br>为了解决这个问题，人们发明了操作系统，它帮助我们管理计算机的硬件资源并为上层应用提供服务，也间接地管理了软件资源。有了OS，它会帮我们运行软件，我们只需要告诉操作系统要运行哪个程序就可以了。<br><br>计算机自发明之初就一直为人们的生活提供着便利，各式各样的计算机软件更是层出不穷。我们的生活中充斥着让人感到新奇和兴奋的应用软件，当我们想让计算机帮我们自己做事情时，我们就需要把自己的想法告诉计算机，这就要求我们编写一个软件让计算机运行。而这一切是如何完成的？<br>计算机系统是建立在一层层的抽象之上的。计算机很笨，无法理解人类抽象的思维，因此，我们需要将我们的想法用计算机能够理解的方式传达给它（我们下节课会介绍）。当程序编写好后，我们会将穿好孔的纸带交给穿孔纸带机(punch tape machine)让计算机读取这些孔的方式来存储数据或进行输出么？当然不了，现代的操作系统为我们提供了许多便利。<br>当应用程序编写好之后，我们只需要将编写好的程序交给操作系统，操作系统就会代为我们将二进制的机器指令交给硬件执行，执行完毕后为用户返回结果。操作系统提供了对硬件资源的抽象和管理，使用户不再需要直接与计算机硬件对接，替代了人工与裸机硬件的交互。操作系统通过驱动程序和系统调用接口，屏蔽了硬件的复杂性，使应用程序可以通过操作系统提供的标准化的接口访问硬件资源。简化了应用程序开发，也提高了系统的稳定性和安全性。<br><img alt="Pasted image 20241123001548.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241123001548.jpg"><br>程序在机器上运行时不能直接使用硬件部件，主要有两方面的原因。一是失去了上层的抽象，应用程序很难去真正使用这些部件。还有就是为了系统的安全性，防止应用程序直接操作硬件导致系统崩溃或数据损坏。当应用程序真正想要访问系统资源时，应用程序就需要向操作系统提出相关的请求，让操作系统代为完成。这个”请求“我们称之为系统调用(system call)，我们后续会逐步学习到。<br><br><br>当我们想要创建自己的软件时，我们需要将想法告诉计算机。计算机是无法理解人类的语言的，计算机能够理解的只有特定架构下的01指令。我们说抽象是将原本细节化的东西进行封装，那么从高级语言到机器语言的过程其实就是一个逆抽象的过程（一条高级语言指令可能对应很多条机器语言指令）。毕竟计算机很笨嘛，只能按照特定的方式处理和执行指令。<br><br>机器语言就是机器能够直接识别和执行的指令，机器语言和处理器的架构息息相关。对于不同的机器，使用的机器语言和汇编语言是不同的。这是由指令集架构ISA(Instruction Set Architecture) 所决定的（如x86、ARM、RISC-V、MIPS等）。见<a data-href="ISA, Instructions and CPU" href="https://congzhi.wiki/some-notes/isa,-instructions-and-cpu.html" class="internal-link" target="_self" rel="noopener nofollow">ISA, Instructions and CPU</a>。<br>尽管汇编和机器码一一对应，但这就是一次封装和抽象。相比于机器码，汇编的可读性要强很多。以下，我们展示两种采用不同思想的指令集（CISC 和 RISC）的x86架构和ARM架构下对内存中的数进行+2的加法操作。虽然很繁琐，但相比机器码总算是顺眼多了。<br>;CISC类型的x86架构:
; 假设edi寄存器包含了目标内存地址
add dword [edi], 2
<br>;RISC类型的ARM架构: ARM架构的指令集通常不允许直接对内存执行算术运算
; 假设r0寄存器包含了目标内存地址
ldr r1, [r0]
add r1, r1, #2
str r1, [r0]
<br><br>高级语言是汇编的又一层封装和抽象。高级语言增加了代码在不同平台上的可移植性，屏蔽了底层细节，使得同一段代码可以在不同架构的机器下运行。高级语言通过编译器编译成特定平台的汇编语言，再由特定平台的汇编器将汇编代码转换成机器码供计算机读取。<br>Unix系统最初就是用汇编语言编写的，然而汇编语言是machine-specific的，不支持不同平台的移植。代码的可移植性一直是计算机科学夜以继日想要解决的问题。虽然第一个高级语言 FORTRAN 的出现代表着编程语言有了更高层次的抽象，但最开始仍未解决可移植性问题。即你可能需要在不同的平台上写不同的程序。<br>C语言的出现改变了这一局面。C语言设计的初衷之一就是为了实现代码的可移植性。它通过提供一个接近底层硬件的抽象层，使得程序员可以编写在不同硬件平台上运行的代码，而不需要对每个平台进行大量的修改。<br><br>如今，我们的生活中充斥着各种各样的LLMs，它们好似一个know-it-all，能够回答世间万物。可预见的未来，我们是否能看到AI帮我们编程呢？<br><br><br>指令执行周期，又称指令周期。通常由取指令、指令解码、执行、结果写回 四部分组成。在指令周期中，通常要用到以下几个寄存器：PC寄存器、MAR寄存器、MDR寄存器、IR寄存器。（MDR寄存器 = MBR寄存器）<br><br>以X+Y加法指令为例，其指令执行周期如下：<br>
<img alt="Pasted image 20240405005008.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240405005008.png"><br><br>控制单元(CU)负责从内存中获取下一条要执行的指令。它通过程序计数器(PC)得到当前指令的地址，从内存中读取指令，将指令加载到指令寄存器(IR)中。完成这一操作后CU会更新PC中的值（进行PC + 1的操作），以指向下一条要执行指令的地址。<br>Fetch顺序：PC(In charge of CU)-&gt;MAR-&gt;(MEMORY)-&gt;MDR-&gt;IR-&gt;(Instruction executes)<br><br>在指令被加载到IR后，由控制单元解码指令，确定它是一条加法指令，并识别出操作数位于寄存器A和寄存器B。此阶段确定了需要执行的具体操作及涉及的数据。<br><br>根据CU的控制信号，ALU执行实际加法操作。它从寄存器s读取值，执行加法操作并将结果暂存。<br><br>在加法操作完成后，CU指示将ALU的计算结果写回寄存器。（有的指令并不需要写回）<br><br><br>
All problems in computer science can be solved by another level of indirection.
<br><br>前两课我们就隐隐约约在强调抽象这个概念了，抽象是计算机科学大厦得以建立的根本。我们在第一课说CPU是门电路的抽象，主板通过针脚和CPU、内存相连又对这些硬件进行了抽象，操作系统通过HAL层对整个计算机硬件进行了抽象等等等等。通过不断的抽象化隐藏复杂性的同时只展示最关键的信息（也就是接口），使得更高层的应用人员可以忽略底层细节，专注于最重要的事情。<br><br>这里不给出接口的定义。我们需要明白的是：通过一步一步的抽象，我们能够看到更高维度的问题。抽象的意义就在于为上层裸露接口。便于我们更上一层的应用。接口可以是硬件与硬件之间的，比如主板上的各种端口，也可以是软件与软件之间的，比如程序之间用来交换数据的应用程序编程接口(Application Program Interface , API)。除此之外，还有硬件和软件之间的接口，即HAL。<br>顺便一提，ISA也可以看成一种接口。<br><br>当你使用电脑时，你使用的其实并不是一台“真正的机器”，而是为你管理机器的操作系统。你所看到精美的画面、流畅的操作无一不是操作系统为你提供的。无论是CPU、内存还是显示器外设，我们都能将其视为“资源”。这些资源并不好使用，没关系，操作系统会帮我们将这些物理资源虚拟并转换成通用的虚拟资源，据此，我们也称操作系统为“虚拟的机器”。<br>面向应用程序，操作系统通过设备驱动程序和硬件抽象层(HAL) 将硬件资源进行抽象，为应用程序提供API接口。使应用程序能够使用标准化的API调用（如system calls）来访问各种硬件资源(如CPU、内存、打印机、显示设备等)，而不需要知道硬件的具体实现细节。<br>面向用户，软件操作系统提供了用户接口（如 图形用户界面GUI 和 命令行界面CLI ），将复杂的系统操作抽象化成用户友好的命令和图形界面。用户可以通过点击图标、菜单和按钮或输入简单的命令来执行复杂的操作，无需了解背后的实现机制。<br><br><br><br>在本阶段的前面，我们不断地展示计算机和操作系统是如何进行一步步的抽象的。经过对下层的抽象虚拟化，操作系统能够为应用进程提供、分配并管理虚拟化后的硬件资源。在这种视角下，我们可以将操作系统称作资源管家(resource manager)。通过虚拟化物理内存，操作系统能使不同的应用进程共享同一块内存；甚至通过划分不同的时间片，我们还可以让不同的应用程序共享同一片CPU，这种特性就是并发。<br><br>并发是操作系统为我们带来的另一个礼物。并发实现在操作系统对 CPU 虚拟化之上，在操作系统眼中，CPU 是可以分配给应用进程的资源。为了公平，操作系统可以让运行中的每个进程都轮流地使用 CPU（例如每个进程每次使用 1 毫秒）。这样即使只有一个 CPU，在用户眼中也好像很多进程（任务）在同时运行。这种特性使得一台主机服务多个用户变为现实。<br>多任务处理(multitasking)就是并发的一种实现方式，它允许多个任务（进程或线程）在同一时间段内交替执行。操作系统通过快速切换任务，使得每个任务都能在短时间内获得 CPU 的使用权，从而在用户看来，多个任务似乎在同时进行。<br><br>异步操作是指在执行某个操作时，不需要等待该操作完成，而是可以继续执行其他操作。当异步操作完成时，会通过某种方式通知执行者。异步机制在操作系统中非常重要，尤其是在处理I/O操作。<br>操作系统通过中断和信号机制来实现异步操作。当某个I/O操作完成时，硬件会发送一个中断信号给CPU，CPU会暂停当前的任务，转而处理这个中断信号。处理完中断信号后，CPU会恢复之前的任务。这样，进程就不需要一直等待I/O操作的完成，而是可以在I/O操作完成时被通知。<br>异步操作不仅限于I/O操作，还可以应用于其他需要等待的操作，比如网络通信、定时任务等。通过异步操作，操作系统能够更高效地利用资源，提高系统的响应速度和吞吐量。<br><br>目前来看，主存中的主存都是易失性的，这种特性使得存储在主存中的程序和数据很容易由于掉电或死机的原因丢失掉。你半天的劳动成果就可能毁于一旦。而且每次都得重新手动将程序调入内存，更不用说早期的内存是非常金贵的。这些都将迫使我们寻找一个解决方案，将数据长久的储存起来。<br>虽然主存不是非易失性的，但是我们的确有些外设提供这种数据持久化存储的保障，比如早期的软盘驱动器(floppy disk drive, FDD)，还有现在流行的固态存储(solid-state drive, SSD) 等。由于我们将文件放在这些非易失性存储器中，因而和这些非易失性存储介质进行交互的操作系统子系统我们称为文件系统(File system)。<br><br><br><br><br><br>
Operating systems are those programs that interfaces the machine with the application programs. The main function of these systems is to dynamically allocate the shared resources to the executing programs.    - What Can Be Automated
<br>操作系统的四个特征是虚拟(virtualization)、异步(asynchronous operations)、并发(concurrency) 和共享(sharing)。虚拟是其他特征实现的基础，操作系统将底层硬件抽象成上层应用程序可以向操作系统申请的虚拟资源。不难理解操作系统通过资源的分配和回收就可以实现共享和并发。异步则与其他三者不同，异步机制使得CPU不需要和慢速I/O一直打交道，提高了CPU的运行效率。<br>通过上面的学习，我们应该能够明白操作系统的职责之所在。OS最基本的职责就是为我们提供一些抽象，让系统方便使用（user's view）。除此之外，操作系统还应该管理资源，让系统的性能得到最大的利用。操作系统还需要为应用程序提供保护，让进程彼此隔离防止恶意进程伤害系统上的其他进程（system's view）。 ]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/1.-introduction-to-the-os.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/1. Introduction to the OS.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Mon, 03 Mar 2025 12:14:15 GMT</pubDate><enclosure url="https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20240921032501.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20240921032501.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2. OS Development Stages]]></title><description><![CDATA[ 
 <br><br><br>在计算机发展的早期阶段，没有操作系统帮助管理计算机的各类资源，用户使用计算机需要直接与计算机的硬件进行交互进行操作。这时的计算机处于手工操作阶段。<br>在手工操作阶段，用户需要通过拨动开关和插拔电缆这种原始的方式来向计算机中输入数据。当用户想要存放数据或指令时，也需要设置一系列开关的状态(通常1表示开，0表示关)。计算机完成运算后，用户通常需要通过观察灯泡的亮灭，或纸带打孔来解读结果。<br><img alt="Pasted image 20240411000024.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240411000024.png"><br>著名的手工操作阶段计算机有：<br>
<br>ENIAC(1945)：通过一系列复杂的开关和插线板(Plugboards)来编程。
<br>IBM650(1954)：使用磁鼓来存储程序和数据，但用户仍然需要通过物理介质（如punchcard）来输入程序和数据。
<br><a data-tooltip-position="top" aria-label="https://wixette.github.io/8800-simulator/" rel="noopener nofollow" class="external-link" href="https://wixette.github.io/8800-simulator/" target="_blank">Altair 8800</a>：通过拨动面板上的开关来输入机器语言程序。
<br><img alt="Pasted image 20240410013933.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240410013933.png"><br>与现代的操作系统相比，手工操作系统几乎没有优点，带给我们的只有如下的一些缺点：<br>
<br>没有对底层硬件的封装，操作困难
<br>使用物理开关和线缆进行编程，可靠性差
<br>程序员使用二进制的机械语言进行编程，难以调试
<br>计算机 CPU 的速度仍然远远快与人工，这时的 CPU 大部分时间处于空闲(idle)状态。相比于计算机执行程序，大部分时间被用于机器代码的编程、punch card的输入输出。
<br><br><br>在手工操作阶段，计算机硬件不能被多个用户同时使用，导致用户必须依次排队提交并完成自己的计算作业。人们渴望能一位管理员(operator)来帮助他们批量地处理这些作业。最终，这种对管理员的需求促使人们开发了系统程序来自动完成这些任务，这便是软件操作系统概念的初步形态。<br>批处理系统(Batch Operating System，BOS) 将CPU的利用率提升了一大截，用户可以将要执行的任务一次性全部打包交给机器。之后，用户不需直接操作计算机硬件就能提交作业。可以将BOS视作一位管理员，它负责接收所有用户提交的作业。BOS会将需求相似的作业分组成批次，然后批量发送到计算机上执行。作业完成后，BOS负责将结果返回给用户。<br>
<img alt="Pasted image 20240410020645.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240410020645.png"><br>
OS/360 是1964年IBM为其当时全新的System/360大型计算机开发的批处理操作系统它标志着企业级计算和批处理操作系统的早期发展。OS/360的直接后续版本包括System/370的操作系统，然后是MVS(Multiple Virtual Storage)，最后发展为现代的 z/OS。<br>批处理系统的工作流程：<br>
<br>用户输入作业
<br>BOS接收作业
<br>BOS按批次将作业进行分组
<br>BOS将分组分批次作业送到计算机上运行
<br>BOS将结果返还给用户
<br>优点<br>
<br>不需要用户与硬件进行直接交互
<br>易于使用和维护
<br>资源使用高效<br>
缺点
<br>响应时间可能较长
<br>不便于交互
<br>调试困难
<br>BPOS通过operator将用户向机器提供的jobs进行排队分批，然后BPOS能够在用户不干预的情况下将用户提交的作业全部完成。虽然这样极大缩短了A作业完成后开始执行B作业的这段时间，但是对于jobs对I/O的访问时间，在CPU上停留的时间仍然是很小的一部分，尽管相比手工操作阶段提高了CPU的利用率，但CPU的利用率仍然差强人意。当作业使用外设的时候，CPU处于空闲状态，为了克服这些限制多道程序设计应运而生。这种技术允许多个作业在内存中同时存在。<br><br><br>在BPOS中，机器允许多个用户同时将任务(jobs)加载进任务队列(job queue)中，这时，系统把需求相似的任务分成不同批次(batch)然后按顺序送入CPU中运行。在任务执行过程中，任务不仅仅需要使用CPU，还会访问磁盘或外设。在任务访问磁盘或I/O时，CPU会处于空闲(idle)状态。这样会无故浪费很多CPU资源。<br>试想，如果允许内存加载多个作业，我们可以通过特定策略来提高资源的利用率。这就是多道程序设计的由来。在BPOS中，作业需要一个一个按顺序完成。但是Multiprogramming OS允许同时存在多个作业处于活动状态。当一个任务等待I/O时，操作系统可以调度另一个任务使用CPU。这样，即使某些任务在等待I/O操作，CPU也能保持忙碌状态，从而大大提高了效率和吞吐量。<br>
<img alt="Pasted image 20240912161341.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240912161341.png"><br>
多道程序系统其实就是容许多”道“程序同时存在于内存中，通过调度算法来使CPU尽量忙碌，提高CPU的利用率。在多道程序系统中，我们需要理解下面的概念：<br>
<br>“道数”：内存中存放作业的数量。
<br>技术支撑：中断、通道
<br>优点：<br>
<br>资源利用率更高
<br>响应时间变短<br>
缺点
<br>复杂性的提升
<br><br><br>
Multi-tasking is a logical extension of multiprogramming.
<br>多道程序设计是多任务系统的前身，多道程序设计解决了CPU利用率低下的问题，但毕竟人类需要直接与计算机交互。从而促使了多任务系统的诞生。<br>多任务操作系统是一种能够“同时”处理多个任务的操作系统。这种类型的操作系统通过高效地分配CPU时间和其他资源，使得用户几乎可以同时运行多个任务，这些任务共享共同的CPU、内存等资源。极大的提高了系统的响应时间和用户体验。<br><img alt="Pasted image 20240912162841.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240912162841.png"><br>Multitasking OS 也叫 time sharing systems (分时系统)。这种操作系统将CPU时间分成很小的片段，称为时间片(time slices) 或 时间量(quantum)，并将这些时间片轮流分配给各个任务，从而实现多任务的并发执行 。这种方法的关键在于时间片的长度通常非常短(通常是毫秒级别)，足够短到让用户无法感觉到任务之间的切换。多个任务或多个用户感觉都独占CPU和内存，而实际上他们是在分享CPU和内存。<br>公认的第一个分时操作系统是 1961 年 MIT 开发的CTSS(Compatible Time-Sharing System)。CTSS的开发标志着计算机技术的一个重要转折点，使得多个用户能够通过各自的终端同时使用同一台计。算机资源。这一概念彻底改变了计算机的使用方式，为后来的操作系统，如Multics(多路信息计算服务)，以及今天我们使用的现代多任务操作系统奠定了基础。]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/2.-os-development-stages.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/2. OS Development Stages.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Feb 2025 05:07:46 GMT</pubDate><enclosure url="https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20240411000024.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20240411000024.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3. Operating System Structures]]></title><description><![CDATA[ 
 <br><br><br>
The strategy for integrating different operating system components within the kernel can be thought of as an operating system structure.
<br><br>简单结构并不是一个 well-defined 的结构，体积小、功能简单局限是简单结构的特点。简单结构的接口和功能层次并没有很好的分开。它的设计目标就是为了激活和管理早期计算机的硬件资源。<br>简单结构的设计直接与硬件交互，减少了中间层。但这也意味着它们缺乏现代操作系统中常见的保护和安全机制。<br>以MS-DOS (Disk Operating System) 为例的简单结构 :  <br>
<br>
层次结构：

<br>不支持多线程、多任务、网络、硬件保护和虚拟内存高级功能；
<br>仅支持命令行接口CLI；
<br>虽然提供了一些API以访问硬件，但用户程序也可以直接访问硬件。


<br>
优点：

<br>由于用户程序和硬件之间较少的接口层次决定了该系统不错的运行性能；
<br>层次结构简单、功能局限使得OS开发相对容易。


<br>
缺点：

<br>缺乏数据保护机制，应用程序可以轻易访问并篡改系统中的数据；
<br>应用程序的错误可能使整个系统崩溃；

<img alt="Pasted image 20240501224716.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240501224716.png">

<br><br>在分层结构中，操作系统被划分成不同层次(Layer/Level)并使得各个层次完成其层级的功能而不必在意低层级是如何实现的。下图就是分层结构典型的实现方式。<br><img alt="Pasted image 20240501230701.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240501230701.png"><br>
其中，每一层级都为上层提供服务，即下层为上层提供接口，上层直接调用下层实现的功能接口。<br>
<br>最低层级第0层(Layer 0)是硬件层；
<br>第一层直接控制硬件，实现对硬件的管理功能；
<br>在第二层的模块功能开发中，若需要使用硬件，必须通过第一次所提供的接口；
<br>在第三层及以上的模块在开发时必须使用低一层提供的接口，直至第N层的用户接口层。
<br>
<br>
优点：

<br>分层结构简化了debug的过程，当错误发生时，我们可以很容易地定位到发生错误的层级；
<br>实现了数据的抽象和封装，每一层只需要知道低一层级所能够提供的服务，无需关注细节；
<br>通过限制对低层级的直接访问，增强了系统安全；
<br>结构分层次简化了层次拓展的过程且不影响其他层级。


<br>
缺点：

<br>性能开销： 每一层级间的通信都可能引入额外的调用开销。
<br>层间依赖： 尽管每层理论上只依赖于低一层，但在实际开发中，上层的设计往往难以完全脱离对下层详细实现的依赖，这可能导致上层在下层变更时进行调整，弱化了理想中的独立性。
<br>设计复杂： 正确地设计各层的功能和接口可能非常复杂，需要精确定义每一层的职责，避免功能重叠或漏洞。


<br>
分层结构(Layered Approach)的一个经典例子是THE操作系统(Technische Hogeschool Eindhoven Operating System )，它由荷兰科学家Edsger Dijkstra及其团队在1960年代未设计。THE操作系统是为了在教育中展示分层设计概念而创建的， 每层都只能执行特定的功能，并且只能使用更低层提供的功能。THE操作系统的分层如下：
第5层 - 用户界面<br>
↓    ↑<br>
第4层 - 文件系统<br>
↓    ↑<br>
第3层 - I/O缓冲管理<br>
↓    ↑<br>
第2层 - 内存管理<br>
↓    ↑<br>
第1层 - 操作系统核心，负责调度和通信<br>
↓    ↑<br>
第0层 - 硬件

<br><br>单体内核是一种传统的操作系统架构，其典型代表是早期Unix系统，始于20世纪60年代。在这种架构中，内核不仅包含基本的系统管理功能，还集成了设备驱动、文件系统管理等高级管理任务。其结构组成包括内核和系统程序两部分：<br>
<br>内核：工作在特权模式，负责时钟管理、中断管理、设备驱动、CPU切换及对进程、存储器和设备的管理。
<br>系统程序 ：运行在非特权模式，通过系统调用结构利用内核提供的服务。<br>
<img alt="Pasted image 20240925014738.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240925014738.png">
<br>
<br>
优点：

<br>简化设计与实现：所有内核功能都整合在同一个地址空间内，无需复杂的通信机制或额外的上下文切换，从而简化了系统设计并提高了执行效率。
<br>性能优势：由于各部分紧密集成，功能间调用的开销最小，从而在性能上具有优势。


<br>
缺点：

<br>系统稳定性问题：由于所有核心都集中在一个大的内核中，任何一个功能的失败都可能导致整个系统的崩溃。
<br>维护和扩展困难：随着内核功能的增加，其复杂度上升，这使得维护和添加新功能变得困难。(屎山代码)


<br>尽管单体内核因其结构庞大且复杂，但许多流行的操作系统如Unix、Linux、Windows、Android和HarmonyOS都采用了基于这种模式的混合结构。这些系统通过在单体内核基础上引入模块化和微内核元素，形成了所谓”混合内核“架构，以提高系统的灵活性和可维护性。<br><br>在20世纪80年代，卡内基梅隆大学的研究人员Richard Rashid发布了Mach操作系统，这是第一个采用微内核结构的操作系统。这种结构的操作系统将所有非必需部件从内核中剥离，仅保留诸如地址空间管理、进程调度和进程间通信等核心功能，而其他系统服务则在用户空间运行。 系统服务进程与用户进程之间通过消息机制（一种进程间通信方式, IPC）进行通信。<br>
<img alt="Pasted image 20240925014813.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240925014813.png"><br>
这种做法的 优点 在于便于扩展操作系统。所有的服务可以在用户空间中增加，而无需修改内核。即使需要对内核进行修改，由于微内核本身体积很小，所需的修改也相对较少。<br>微内核架构的 缺点 同样明显。由于大多数服务如文件系统和网络协议运行在用户空间，内核与这些服务之间的频繁上下文切换和消息传递显著增加了执行开销。微内核架构的性能通常低于单体内核架构，尤其在需要高频服务调用的场景下，性能差距更为明显。<br><br>在这种结构下，内核包含一组核心组件，并能在启动或运行时通过加载模块来引入额外的服务。这种设计常见于现代操作系统如Unix和Linux。核心思想是内核提供必要的基础服务，而其他可选服务则可以在运行时动态地以模块形式加载，实现动态链接。<br><img alt="Pasted image 20240924165346.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240924165346.png"><br>这种模块化设计允许系统在不重新编译整个内核的情况下，直接添加或更新功能。每当需要更改时，只需操作相关模块而非整个内核，从而简化了更新和维护过程，提高了系统的灵活性和扩展性。<br><br>现实应用中，很少有操作系统采用单一严格定义的结构。而是结合各个结构是优点，形成混合系统，以便解决性能、安全性、可用性的问题。<br>Windows/macOS：宏内核+微内核<br>
Linux：模块化+宏内核<br><img alt="Pasted image 20240501235413.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240501235413.png"><br><br>外核是一种十分激进的操作系统内核架构。旨在尽可能地减少对应用程序开发者施加的抽象层。与传统的操作系统内核相比，外核将资源保护和管理分离，允许应用进程直接管理硬件资源。外核首次由MIT的研究人员在1995年提出（ <a data-tooltip-position="top" aria-label="https://cs.nyu.edu/~mwalfish/classes/14fa/ref/engler95exokernel.pdf" rel="noopener nofollow" class="external-link" href="https://cs.nyu.edu/~mwalfish/classes/14fa/ref/engler95exokernel.pdf" target="_blank">engler95_exokernel.pdf</a>）。<br>最小化内核、高性能、灵活性高是外核的特点。它的设计理念是将操作系统内核的功能最小化，只提供最基本的硬件抽象层，允许应用程序直接管理硬件资源。这种设计与传统的操作系统内核（如Monolithic Kernel和Microkernel）有很大不同。<br>Exokernel的设计理念对虚拟机管理程序(hypervisors)有很大的启发。特别是Exokernel中的系统调用（syscalls）与虚拟机管理程序中的超调用(hypercalls)有很多相似之处。超调用是虚拟机与虚拟机管理程序之间的接口，用于管理虚拟化环境中的资源。<br><img alt="Pasted image 20240925015122.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240925015122.png">]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/3.-operating-system-structures.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/3. Operating System Structures.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Feb 2025 05:07:50 GMT</pubDate><enclosure url="https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20240501224716.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20240501224716.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[4. System Boots Up]]></title><description><![CDATA[ 
 <br><br><br>计算机的启动需要操作系统的支持，而操作系统通常放在非易失的辅存中。因此，我们在学习系统启动之前，先来了解一下最常见的辅存——磁盘的构成。BIOS的启动顺序如下：系统会先检查软盘驱动器，然后硬盘驱动器。之后是光盘驱动器、USB设备、最后是网络(PXE)。<br><br>在计算机中，计算机的存储结构通常是分层设计的。通过这些不同的层次使得计算机的存储同时具有高速度和大容量的特征。计算机的分层结构通常由以下几部分组成：<br>
<br>寄存器(Register) : 以字节为单位。速度最快，存储容量最小。也是最接近CPU的存储结构，是CPU内部的一部分。
<br>高速缓存(Cache) : 以KB-MB为单位。速度次之，位于寄存器和主存之间的存储结构。和寄存器一样基于SRAM技术。
<br>主存(Main Memory) : 主存通常以GB为计量单位。是计算机CPU可以直接读取的存储结构。计算机的取指令、译码、执行、写回就是建立在主存之上的，是不可或缺的存储结构。
<br>辅助存储器(Auxiliary Memory) : 如硬盘驱动器（HDD）和固态驱动器（SSD），它们的容量通常从几百GB到几TB不等。在辅助存储器中存储的数据是非易失的(Non-volatile)。
<br><img alt="memory hierarchy.png" src="https://congzhi.wiki/congzhi's-os-series/pics/memory-hierarchy.png"><br><br>本系列，我们主要讨论从磁盘启动的方式。<br><br>磁盘读写数据的方式非常简单。一个磁盘由多个盘片组成，数据存放在盘片 (Platter)&nbsp;表面的一圈圈同心圆上，这些同心圆称为磁道 (Track)。半径相同的磁道组成的圆柱被称为柱面 (Cylinder)。然而，单独使用磁道来存储信息并不实际，因为每个磁道的信息量太大。因此，我们需要进一步划分磁道。<br>我们将磁道按一定角度划分成若干扇形，这些扇形与磁道的相交面称为扇区 (Sector/Disk block)。为了管理的方便，有时候我们还会将多个扇区组合在一起形成一个簇 (Cluster)，扇区一遍是最小的数据存储单元。一般而言，扇区的大小为512字节。<br>早期的磁盘每个磁道的扇区数量都是一样的，这就意味着半径越小的磁道位密度越大。而现在扇区不再按以前的方式划分了，现在磁盘的位密度都是一样大的，半径越大的磁道存储的数据越多。这就意味着外面磁道的扇区数要大于里面磁道的扇区数。<br><img alt="Pasted image 20241214172755.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241214172755.jpg"><br><br>磁盘逻辑结构有两种：CHS模式和LBA模式。CHS(Cylinder-Head-Sector)是早期的硬盘数据寻址方式，直接反应硬盘的物理结构。数据的位置由柱面、磁头和扇区这三个参数确定。例如，数据存储在某个具体的柱面上，该柱面由特定的磁头访问，而数据具体位于该磁道上的某个扇区内。<br>另一种逻辑结构是LBA(Logical Block Addressing)。相比CHS，LBA可以很好地应对HDD和SSD这两种存储介质。LBA方式下，硬盘被视为一个连续的逻辑块序列，每个块包含固定数量的字节。每个逻辑块都有一个唯一的编。当系统需要访问硬盘上的数据时，它只需指定数据块的LBA编号即可。<br>CHS的磁头号和柱面号都是从0开始，而扇区号从1开始。LBA模式下，第1个扇区又是从0开始。它们有以下的对应法则：其中  表示磁盘中磁头的数量， 表示每个磁道上扇区的数量。<br><br>主引导记录是硬盘最开始的那个扇区(是1号还是0号取决于寻址方式)，MBR 对于整个 bootstrap 过程十分重要。其中有如下需要注意的点：<br>
<br>MBR是这个特殊扇区的名字。
<br>MBR中包含了一段小的代码，被称为启动代码(bootloader)。这段代码负责引导过程中加载操作系统。当计算机启动时，BIOS(基本输入输出系统)会首先读取并执行MBR中的启动代码。
<br>MBR的魔数(magic number)：在MBR的末尾，有一个特定的值(通常是 0x55AA)作为有效性标志。这个标志用来表示该MBR是有效的，可以被BIOS识别。
<br>一般地，MBR占用1个扇区512字节，即使里面的代码不足512字节，也要用0进行填充。
<br><br><br><br>BIOS 是计算机系统中非常基础且关键的部件，它是一个固件(firmware)，嵌入在计算机主板的一个芯片中。一旦计算机通电（或按下 reset 复位），CPU的PC寄存器就会写入 BIOS 中起始地址，即CPU执行的第一条指令来自 BIOS。BIOS 指令的地址是预定义的，有硬件电路完成，再计算机初始化的过程中就会把这个预定义的地址交给 PC 寄存器。<br><br>我们将传统的计算机启动方式和现代计算机启动方式区别开来。上述提到的 BIOS 属于传统 bootstrap 的范畴。而现代操作系统大多使用 UEFI。<br><br>Legacy Boot 使用 BIOS 作为固件接口，其启动流程包括加电、执行 BIOS 指令、电源自检 (POST)、加载主引导记录 (MBR)，然后加载 Bootloader，将操作系统内核加载到内存中，并最终初始化系统完成启动。这种方式依赖于MBR 分区表，而 MBR 对磁盘容量的支持较为有限（最大为 2TB），且分区数量较少（最多 4 个主分区）。BIOS 详细的启动流程如下：<br>
<br>加电：当计算机通电后，电源供应器（PSU）开始工作，向主板和其他组件提供电力。
<br>BIOS启动：CPU从预定义的地址开始执行第一条指令，这条指令位于BIOS（基本输入输出系统）中。BIOS是存储在主板上的固件。
<br>电源自检（POST）：BIOS执行电源自检（Power-On Self Test），检查硬件设备（如内存、键盘、显示器等）是否正常工作。如果检测到错误，BIOS会发出错误信号（如蜂鸣声）或显示错误信息。
<br>加载MBR：BIOS完成自检后，会寻找启动设备（如硬盘、SSD、光盘等）。找到启动设备后，BIOS会将主引导记录（MBR）加载到内存的&nbsp;0x7C00H&nbsp;处。MBR是硬盘的第一个扇区，包含启动加载程序（Bootloader）和分区表。
<br>执行Bootloader：MBR中的Bootloader代码接管控制权。Bootloader的任务是加载操作系统内核。它会读取硬盘上的操作系统内核文件，并将其加载到内存中。
<br>内核初始化：操作系统内核被加载到内存后，开始执行。内核会初始化操作系统的各个子系统（如内存管理、进程管理、文件系统等），并启动系统服务和驱动程序。
<br>启动完成：内核初始化完成后，操作系统进入用户模式，显示登录界面或桌面，系统启动过程结束。
<br><img alt="booting process.png" src="https://congzhi.wiki/congzhi's-os-series/pics/booting-process.png"><br><br>UEFI（统一可扩展固件接口）是现代操作系统的主流选择。UEFI 的启动流程和BIOS很相似，相当于 BIOS 的 plus pro 版本。UEFI 改进了 BIOS 的功能，还扩展了其启动流程，提供了更丰富的启动界面功能，包括鼠标和键盘操作，甚至还支持启动时的网络连接。<br>UEFI 采用 GUID 分区表 (GPT)，大幅提高了对磁盘容量（支持超过 2TB）和分区数量（最多 128 个或更多）的支持。此外，UEFI 还引入了安全启动机制，可校验引导加载器和操作系统的数字签名，增强系统的安全性，防止恶意软件的篡改。<br>相比 BIOS，UEFI 最重要的升级是支持 GUID 分区表，而 BIOS 支持的是 MBR。<br><br><br><br><br><br><br>GRUB 是一个开源的多引导加载器(Multiboot)，是计算机启动时运行的第一个软件程序。GRUB 常用于多操作系统环境中，它负责选择加载某个操作系统内核并将控制权转交给内核，内核随后初始化操作系统的其余部分。<br>GRUB(Grand Unified Bootloader)的历史始于1995年，最初旨在支持GNU Hurd操作系统。它由Erich Boleyn开始开发，为了解决PC启动方法的不兼容性问题，他设计了多引导规范。1999年，Gordon Matzigkeit 和 Yoshinori K. Okuji 将 GRUB 官方纳入 GNU 项目。<br><br>GRUB 2 是一个重要的后续版本，提供了更多的功能和改进，尽管带上了版本号，但大家通常还是简称为 GRUB。为了区别，将老的 GRUB 称为 GRUB legacy，版本号停留在2005年的 v0.97。相比 GRUB 2，GRUB legacy 缺乏对 UEFI 的支持。<br><br>在GRUB中，你可以选择不同的操作系统。GRUB界面是字符模式，一般长这个样子：<br><img alt="Pasted image 20240406183909.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240406183909.png"><br>我们通过阅读 GRUB legacy 源码片段，再深入了解一下 bootloader 的工作原理。<br>
<br>假设:启动盘中安装了Linux，GRUB被安装在启动盘的最前面几个扇区。
<br>电脑加电后，BIOS会找到MBR，将这个扇区的可执行指令加载到内存起始地址0x7C00处，这是一个事先约定好的地址。至此，GRUB的 stage1加载完毕，CPU开始执行0x7C00处的指令。
<br>/*stage1.s*/
	jmp after _BPB /*第一条指令*/
	...
	after _BPB:
	boot_drive_check:
		...
		testb $0x80, %dl /*通过测试dl寄存器是否为0x80来判断是否从硬盘启动*/
		...
		/*check if LBA is supported*/
		mov $0x41, %ah
		movw $0x55aa, %bx
		int $0x13
		/*
		BIOS中断号：0x13
		功能号：0x41
		参数：0x55aa
		功能：查询扩展的磁盘访问功能
		返回结果：如果成功且bx寄存器返回相同魔数0x55aa，则说明支持LBA
		*/
		...
	lba_mode:
	/*为启动盘加载stage2代码做准备工作，比如从磁盘起始扇区、扇区数等*/
		movl 0x10(%si), %ecx
		movw $ABS(disk_address_packet), %si
		movb $1, -1(%si)
		movl $ABS(stage2_sector), %ebx
		movw $0x0010, (%si)
		movw $1, %2(%si)
		movl %ebx, 8(%si)
		movw $STAGE1_BUFFERSEG, 6(%si)
		xorl %eax, %eax
		movw %ax, 4(%si)
		movl %eax, 12(%si)
		
		movb $0x42, %ah
		int $0x13
		...
		/*
		BIOS中断号：0x13
		功能号：0x42
		参数：%dl = 驱动器编号
			 %si = offset of disk address packet
			 (DiskAddressPacket这个结构包含了要读取的扇区数、内存中缓冲区地址以及起始扇区号)
		返回结果：读取成功%al寄存器设置为0x0，否则为错误代码
		*/
		
	stage2_address:
		.word 0x8000
		/*boot stage2*/
		jmp *(stage2_address)
<br>
<br>stage2 的代码数据加载在内存的0x8000，打开stage2部分的代码发现绝大部分是用C语言而非汇编，我们可以理解成stage1阶段已经设置了指令执行的基本环境，并且因为第二阶段的功能更为复杂，使用高级语言编写会降低开发难度。<br>
<img alt="Pasted image 20240827160217.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240827160217.png">
<br><br>MBR（主引导记录）位于内存地址 0x7C00 后的 512 字节，而不是从 0x0000 到 0x01FF 的原因是历史和兼容性的考虑。在早期的 IBM PC 中，使用的 8088 处理器在启动时会将MBR加载到 0x7C00 这个地址。这是因为 8088 处理器需要在内存的前面部分（0x0000～0x03FF）保留用于中断向量表。此外，操作系统需要尽可能多的连续内存空间，所以MBR被放置在内存的尾部，即 0x7C00 地址，这样可以为操作系统留出更多的内存空间。为了兼容 8088，后续的 CPU 继续使用这个地址。<br>简单来说，计算机启动时，BIOS 会检查硬件，然后根据指定的顺序检查引导设备的第一个扇区（即MBR），并将其加载到内存地址 0x7C00 。MBR随后将控制权交给操作系统。这个过程确保了操作系统能够获得足够的内存空间，并且与早期的硬件保持兼容。<a data-tooltip-position="top" aria-label="https://www.ruanyifeng.com/blog/2015/09/0x7c00.html" rel="noopener nofollow" class="external-link" href="https://www.ruanyifeng.com/blog/2015/09/0x7c00.html" target="_blank">为什么主引导记录的内存地址是0x7C00？</a><br><br><br>中断向量表（IVT）和BIOS的INT中断调用之间有直接的联系。在实模式下，BIOS利用IVT来处理中断请求。IVT是一个位于内存低地址的表，通常从0x00000开始，它包含了256个中断向量，每个向量指向一个中断服务例程（ISR）的地址。当中断发生时，CPU会使用中断号来索引IVT并跳转到相应的ISR执行中断处理。<br>BIOS提供了一系列预定义的中断服务例程，这些例程可以通过软件中断调用（如INT 0x13用于磁盘操作，INT 0x10用于视频服务等）来访问。这些中断服务例程是实模式下与硬件交互的基本方法，允许操作系统和其他程序在不直接操作硬件的情况下执行诸如读取磁盘、显示字符等操作。<br>在保护模式下，中断描述符表（IDT）取代了IVT，但BIOS的INT调用仍然可以在实模式下使用。在系统启动时，BIOS会设置IVT，并在需要时响应中断请求，直到操作系统接管并可能设置自己的中断处理机制。<br><br><br>实模式下内存低1MB的地址空间都有什么？<br><img alt="Pasted image 20240924013452.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240924013452.png"><br>
[Memory Map (x86) - 实模式内存映射](<a rel="noopener nofollow" class="external-link" href="https://wiki.osdev.org/Memory_Map_(x86)" target="_blank">https://wiki.osdev.org/Memory_Map_(x86)</a><br><br><br>磁盘分区表：硬盘上存储分区信息的一个结构，它告诉计算机磁盘上有那些分区以及每个分区的起始和结束位置。这个表对操作系统来说非常重要，因为它用来读取、识别和管理磁盘上的数据。有几种不同的分区表类型，常见的包括MBR（主引导记录）和 GPT（GUID分区表）。<br><br>MBR 位于硬盘的最开始部分，它包含了引导代码和分区表。MBR 的大小通常为 512 字节，其中的bootloader占据446字节，分区表占据 64 字节，最后两字节是魔数 0x55AA 。<br>
<br>分区表有4个表项，每个表项16字节。那么最多支持多少个分区？最多4个主分区：分别是C盘、D盘、E盘、F盘。
<br>但是一般可能会有3个主分区，1个扩展分区。这里请注意，主分区可以是4个、3个、2个或1个，但扩展分区在MBR下最多只能有1个。
<br>逻辑分区是包含在扩展分区里面，逻辑分区的数量不受限制。
<br><img alt="0212511f66bbc3e3312972413e91a87c.webp" src="https://congzhi.wiki/congzhi's-os-series/pics/0212511f66bbc3e3312972413e91a87c.webp"><br>每个分区表中包含了一个分区的属性数据，主要有：<br>
<br>启动指示器（1字节）、起始磁头（1字节）、起始扇区和柱面（2字节）、分区类型（1字节）、结束磁头（1字节）、结束扇区和柱面（2字节）、起始逻辑扇区（4字节）、分区内扇区总数（4字节）
<br>启动指示器中 0x80 表示活动分区
<br>分区类型标识有：ext4/fat/ntfs...
<br>高亮部分表示CHS模式寻址
<br>斜体加粗部分表示LBA模式寻址
<br>这种分区表的属性（逻辑扇区用4字节表示）决定每个分区最大容量为：
<br><br>与 MBR 相比，GPT 是一个更现代的分区方案，它支持大于 2TB 的磁盘，并且可以创建多达128个分区。GPT 位于磁盘的开始和结束部分，提供冗余，以防主 GPT 损坏。GPT 使用全局唯一标识符(GUID)来标识分区，这意味着每个分区的标识符在全世界范围内都是唯一的。大多数现代操作系统(例如 Windows 10、Linux、macOS )都支持 GPT。但是，使用 GPT 可能需要 UEFI 固件，而不是传统的 BIOS 。<br>
<br>保护MBR：位于磁盘的最开始，即第一个扇区(LBA 0)。保护MBR的目的是使不支持GPT的旧系统识别C磁盘，避免这些系统意外修改GPT磁盘。保护MBR占用1个扇区。如果系统支持GPT，则会忽略这个扇区。
<br>GPT头部：磁盘的第二个扇区(LBA 1)。包含有关GPT分区表的元数据，如其位置、大小和CRC校验码。GPT头部通常也只占用1个扇区。
<br>GPT分区表：跟在GPT头部之后，这是一系列分区条目，每个条目128字节。默认情况下，GPT为分区条目数组预留了128个条目，每个条目128字节，因此默认情况下分区表占用 16KB 。对于 512 字节扇区的磁盘，这将是 32 个扇区。
<br><img alt="Pasted image 20240724122510.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240724122510.jpg"><br>
GPT 每个分区条目 128 字节包含以下字段：分区类型 GUID (16字节)、起唯一分区 GUID (16字节)、起始 LBA (8字节)、结束 LBA (8字节)、属性标志(8字节)、分区名称(72字节)。这种分区表属性决定了 每个分区最大容量：。此外，在磁盘的最后面还会有一组GPT的备份。<br><br><br><br>现阶段，引导程序加载操作系统内核，内核启动的时候，会有两种比较常见的系统启动方式：<br>
<br>传统的 System V init 系统，也常称为 SysVinit
<br>新式的 systemd，即 system deamon 的缩写
<br><br>init 是一个守护进程(Deamon)，开机运行，关机结束。init 进程是进程号为1的进程（pid = 1），所有系统上运行的其他进程都是 init 进程所 fork() 出来的。若当 init 进程无法运行，则系统就不会允许有其他任何程序运行，这种状态也被称为 "system panic" 。<br>一般我们常把 init 和 SysVinit 所联系起来。但实际上根据不同的 linux distribution ，init进程可以是SysVinit、Upstart或Systemd。<br><br>systemd 是一种系统和服务管理器，旨在成为 Linux 系统的 init 系统的替代品。它提供了并行化启动服务、按需启动守护进程、按需挂载文件系统、快照和恢复系统状态等功能。<br>相比init必须一个进程接着一个串行的系统启动，systemd支持多线程并行的启动方式，提高系统的启动速度。除此之外，systemd使用依赖关系图来确定服务的启动顺序，增强了系统的稳定性，但也提高了复杂性。<br><br><img alt="Pasted image 20240820022709.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240820022709.png"><br>早期Linux系统开机的几个阶段：<br>
<br>
BIOS开机自检到加载内核阶段。

<br>这个阶段的内容在本章已经介绍过。
<br>Linux内核保存在/boot目录下。


<br>
启动 init 进程。

<br>运行/sbin/init，这是 linux 系统启动运行的第一个进程，PID 为1，又叫超级进程或根进程。
<br>init 进程负责产生其他所有的用户进程，所有的进程都被挂载到这个进程下，如果 init 进程退出，那么所有进程都会被强制杀死（即系统关机）。如果一个进程的父进程先于子进程退出，子进程就会变成孤儿进程，转而挂载到 init 进程下。


<br>
init 进程读取/etc/inittab文件。

<br>根据文件中设置的启动层级和执行项来启动对应的程序，inittab 文件头的部分如下：

# Default runlevel. The runlevels used by RHS are:
#   0 - halt (Do NOT set initdefault to this)
#   1 - Single user mode
#   2 - Multiuser, without NFS (The same as 3, if you do not have networking)
#   3 - Full multiuser mode
#   4 - unused
#   5 - X11
#   6 - reboot (Do NOT set initdefault to this)
# 
id:5:initdefault:


<br>0-6的文件中说明了不同的启动层级，以及设定的启动层级。3和5较为常见。

<br>0为关机；
<br>1为单用户模式（维护模式）；
<br>2为无网络的多用户模式；
<br>3为普通用户登陆的字符终端模式；
<br>5为带图形界面的用户终端模式；
<br>6为重启。<br>
其中我们看到，真正有用的地方只有id:5:initdefault:，表示 init 要启动的进程会完成操作系统5级的功能。




<br>
执行系统初始化脚本（/etc/rc.d/rc.sysinit）。

<br>这个初始化脚本是每个系统级别都要运行进行初始化。
<br>对linux系统一些必备的东西进行初始化，比如时钟，键盘，磁盘，文件系统等。其中/etc/inittab每一行代表一个执行项。
<br>执行项的格式如：id:runlevels:action:process<br>
id：表示该执行项的id，为符合命名规则的标识符<br>
runlevels：符合执行条件的运行层级，为0-6数字的组合<br>
action：启动进程的方式，有initdefault, wait, respawn等选项<br>
process：表示需要执行的进程


<br>
执行启动层级对应的脚本（/etc/rc*.d）。

<br>根据第3步中所选中不同的系统层级进行的专门的初始化，上面的例子中，/etc/inittab文件中记录的运行级别5。所以init进程执行/etc/rc5.d进程，进行5运行级别必要的操作。
<br>在早期，如果有系统级的进程想要设置为开机启动，就将启动该进程的命令放在该文件中。后面有了service系统，就不需要手动更改配置文件了。


<br>
启动终端

<br>rc 执行完毕后，系统环境已经设置完成，各种服务进程也已经启动。init开始启动终端程序。不同的运行级别启动不同类型的终端。然后执行 rc.local 文件。

1:2345:respawn:/sbin/mingetty tty1
2:2345:respawn:/sbin/mingetty tty2
3:2345:respawn:/sbin/mingetty tty3
4:2345:respawn:/sbin/mingetty tty4
5:2345:respawn:/sbin/mingetty tty5
6:2345:respawn:/sbin/mingetty tty6


<br>早期如果有什么用户级进程需要在系统启动时自动启动，就添加到rc.local文件中。之后有了service系统，就不需要手动更改配置文件了。


<br><br>在有些时候，我们用ps -ef查看系统上运行所有进程的信息时，我们会发现进程号为1的进程并不是systemd。这时我们打印一下/sbin/init的进程信息，会发现/sbin/init只是一个软链接文件，实际上指向的还是/lib/systemd/systemd文件。<br>du@DVM:/$ ps -ef | more
UID          PID    PPID  C STIME TTY          TIME CMD
root           1       0  0 16:19 ?        00:00:03 /sbin/init auto noprompt splash
du@DVM:/$ ls -l /sbin/init
lrwxrwxrwx 1 root root 20 11月 22  2023 /sbin/init -&gt; /lib/systemd/systemd
]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/4.-system-boots-up.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/4. System Boots Up.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 21 Mar 2025 09:37:47 GMT</pubDate><enclosure url="https://congzhi.wiki/congzhi&apos;s-os-series/pics/memory-hierarchy.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/congzhi&apos;s-os-series/pics/memory-hierarchy.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[5. Interruption]]></title><description><![CDATA[ 
 <br><br><br><br>早期由于8086/8088 CPU最大只能寻址1MB且指令长度为16位。为了兼容性，x86系列的CPU在计算机启动后的最开始都以<a data-tooltip-position="top" aria-label="https://wiki.osdev.org/Real_Mode" rel="noopener nofollow" class="external-link" href="https://wiki.osdev.org/Real_Mode" target="_blank"><strong></strong></a>实模式(Real Mode)运行。实模式下只能使用低1MB的RAM，而且默认的指令长度为16bits。<br>在实模式下，地址线直接映射物理内存地址。处理器不执行任何形式的内存管理和保护，如BIOS阶段的指令，没有我们后面介绍的特权级别一说，也没有特权指令、非特权指令之分。在实模式下，处理器会执行BIOS阶段的指令，初始化硬件和系统设置。<br>之后，Bootloader接管计算机并在适当时刻将处理器从实模式转变为 <a data-tooltip-position="top" aria-label="https://wiki.osdev.org/Protected_Mode" rel="noopener nofollow" class="external-link" href="https://wiki.osdev.org/Protected_Mode" target="_blank"><strong></strong></a>保护模式(Protected Mode) 这一转变使得系统可以访问更大的内存空间和执行更复杂的指令，也可以使用例如虚拟内存管理和内存保护机制这样的高级功能。所有的现代操作系统都运行在保护模式。<br><br>为了实现系统的安全性和稳定性，现代OS和处理器定义了两种处理器执行权限模式：用户模式和内核模式。 这种设计使得操作系统可以更好地管理硬件资源，防止用户程序对系统的核心部分进行未经授权的访问。<br><br>在用户模式下，程序只能执行有限的指令，不能直接对硬件和内核中的数据结构进行访问，这种指令被称为非特权指令(non-privileged instructions)。用户模式的限制防止用户程序对系统资源的滥用，保护了系统的安全和稳定。常见的非特权指令有：<br>
<br>算术和逻辑运算指令。
<br>数据传输指令，不涉及受保护资源的读写。
<br>简单的控制流指令(如条件跳转)
<br>某些系统调用指令，这些通过中断或异常机制，安全地请求操作系统提供服务。
<br><br>也叫Kernel mode。在内核模式下，操作系统内核对所有的硬件和软件资源具有完全的访问权限。内核可以执行任何指令，管理任何设备和系统资源。只能在内核模式下运行的指令就是特权指令(privileged instructions)，这些指令通常涉及对硬件资源的直接控制和管理。常见的特权指令有：<br>
<br>修改控制寄存器(如分页控制、内存管理)
<br>更改处理器的运行模式(如从用户模式切换到内核模式)
<br>直接访问I/O设备，
<br>启用或禁用中断，
<br>控制时间片、任务切换等。
<br><br>在保护模式下，内核和用户程序从此隔离。用户程序只能够执行一些特定的指令，称为非特权指令，而内核可以执行任何特权、非特权的指令。那系统（CPU）是如何知道谁是用户程序，谁是内核程序呢？<br>现代操作系统实现了4种不同的程序执行等级（CPU模式），称为 hierarchical protection domains，也叫 protection rings。实际上这四种不同的 rings 只使用了两种。其中，用户程序只能执行在 Ring 3，而内核程序执行在 Ring 0。CPU 通过 CS 寄存器的前两位来识别当前程序的特权级别，称为 CPL (Current Privilege Level) 位。<br><img alt="Pasted image 20250127044801.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20250127044801.png"><br>
在段描述符、门描述符中还有 DPL(Descriptor Privilege Level)用来表示描述符特权级。比如在中断门描述符每一项都有一个 DPL，用于控制中断请求的特权级别；系统调用所对应的门描述符也有一个 DPL，用于控制系统调用的特权级别。只有当 CPL ≤ DPL 时，才能访问该描述符。<br>后面我们在学习进程<a data-href="6. Processing The Processes" href="https://congzhi.wiki/congzhi's-os-series/6.-processing-the-processes.html" class="internal-link" target="_self" rel="noopener nofollow">6. Processing The Processes</a>阶段的时候，我们会了解到每个进程都会有内核区（在32位系统下虚拟内存为3GB-4GB），在内核区中的代码段描述符和数据段描述符等的DPL就会被设置为0，即只有CPL为0时才能访问这些代码和数据等。<br><br>我们对用户模式和内核模式进行了简单的了解，我们知道用户程序都运行在用户模式下（Ring 3），权限受限。而操作系统核心组件（如内存管理、进程调度、文件系统等）运行在内核模式下（Ring 0），在用户态的用户程序是无法直接对系统的核心组件进行篡改的。<br>为了确保系统的安全，我们需要保证系统的完整性。系统完整性即系统在运行过程中保持其预期的正确性和一致性，防止未经授权的修改和破坏。由于用户态和内核态的分离，对系统核心的操作都在内核态中进行，这种特性保护了系统的完整性和稳定性。<br>比方来说，在用户程序下，如果出现程序错误，往往只会导致程序崩溃，而不会影响整个系统的稳定性。通过内核模式的错误处理机制，操作系统可以捕获和处理这些错误，防止它们扩散到系统的其他部分，维护系统的整体完整性。而且用户程序是无法直接篡改系统的核心部件的，这也维护了系统的完整性。<br><br>策略(policy) 是指操作系统如何决定何时以及如何执行某些操作，例如进程调度、内存管理、资源分配等。策略规定了系统行为的高层规则，而机制(mechanism) 则是实现这些规则的具体方法。<br>操作系统在内核模式下执行具体的机制（如进程调度、内存管理），而策略（如调度策略、资源分配策略）则由操作系统的高层组件或管理员来决定。这种分离有助于系统的灵活性和可维护性，同时确保系统的完整性。<br><br><br>由于操作系统对底层硬件的保护和封装，用户程序是不能够直接操作计算机硬件的。如果用户程序想要使用系统资源怎么办呢？操作系统通过系统调用接口提供了一系列的机制，使得用户程序可以调用这些接口来请求操作系统执行特定的操作，操作系统完成后返回操作结果。<br>系统调用是操作系统提供给应用程序的一组接口，允许应用程序请求操作系统执行一些不能在用户模式下完成的操作。系统调用是应用程序与操作系统内核之间的桥梁。对于用户而言，使用系统调用和调用函数非常类似，唯一的不同就是系统调用工作在内核模式。<br>系统调用的作用就是提供了一种安全的方法，让用户空间的程序请求内核空间的服务。我们通常将执行文件操作、进程控制、网络通信等需要更高权限的操作进行封装，提供系统调用接口给用户程序去使用。<br>当应用程序需要执行一个系统调用时，它会通过特定的机制（如软中断）通知操作系统。操作系统接收到通知后，会从用户模式切换到内核模式，执行相应的内核函数。完成操作后，操作系统将结果返回给应用程序，并切换回用户模式。这就是系统调用的过程。<br>系统调用有什么好处呢？它可以让操作系统在满足请求之前检查请求的正确性，防止不安全的操作。同时，应用程序开发者不需要了解硬件的低级编程细节。此外，相同的系统调用通常上在相同的操作系统上的接口是一样的，使程序具有一定的可移植性。<br><br>我们用打开文件open()函数举例，假设我们有以下 C 程序：<br>#include &lt;stdio.h&gt;
#include &lt;fctrl.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;unistd.h&gt;

int main(){
/*用户态*/

	int fd = open("example.txt", O_RDWR, S_IRUSR | S_IWUSR);//Mode switching
	if(fd == -1){
		perror("fail to open file");
		return 1;
	}
	char buf[128];
	int size = read(fd, buf, sizeof(buf) - 1);//Mode switching
	if(size == -1){
		perror("fail to read");
		close(fd);//Mode switching
		return 1;
	}
	printf("Read form buf: %s", buf);//Mode switching
	close(fd);//Mode switching
	return 0;
}
<br>虽然这段代码不长，但是发生了4次系统调用，状态转换了8次。<br><br><br>Question： Why printf(); works in the user mode?<br>
<img alt="Pasted image 20240913230021.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240913230021.png"><br>
Answer： printf();函数运行在用户态是因为 C standard library(libc) 运行在用户态，而 printf();是作为标准库的一部分。好了，现在的问题转为为什么标准库运行在用户态了，在我们调用 printf(); 的时候首先 printf(); 函数会根据函数里面的参数将打印的字符串序列排好序。之后字符串会被放到一个buffer中，然后调用系统调用write()将buffer传给内核处理。内核将buffer里面的内容交给特定的输出设备然后回到用户态，打印结束。<br><br>假设我们有如下的代码，我们对其进行编译并使用strace命令进行系统调用跟踪，会发生什么？<br>#include&lt;stdio.h&gt;
int main(){
    printf("hello");
    return 0;
}
<br>我们发现当我们执行程序的时候，我们调用了非常多的系统调用，但是在最后面有这么一行：write(1, "hello", 5hello) = 5。表示printf函数实际上是使用write系统调用来向屏幕上打印 "hello" 字符串的，返回值为5，即打印了5个字符。<br>du@DVM:~/Desktop/DSA$ strace ./test 
execve("./test", ["./test"], 0x7ffdd5170160 /* 55 vars */) = 0
brk(NULL)                               = 0x570c55c3b000
arch_prctl(0x3001 /* ARCH_??? */, 0x7ffc25af5710) = -1 EINVAL (Invalid argument)
mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7cdffcdbc000
access("/etc/ld.so.preload", R_OK)      = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, "/etc/ld.so.cache", O_RDONLY|O_CLOEXEC) = 3
newfstatat(3, "", {st_mode=S_IFREG|0644, st_size=59619, ...}, AT_EMPTY_PATH) = 0
mmap(NULL, 59619, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7cdffcdad000
close(3)                                = 0
openat(AT_FDCWD, "/lib/x86_64-linux-gnu/libc.so.6", O_RDONLY|O_CLOEXEC) = 3
read(3, "\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0&gt;\0\1\0\0\0P\237\2\0\0\0\0\0"..., 832) = 832
pread64(3, "\6\0\0\0\4\0\0\0@\0\0\0\0\0\0\0@\0\0\0\0\0\0\0@\0\0\0\0\0\0\0"..., 784, 64) = 784
pread64(3, "\4\0\0\0 \0\0\0\5\0\0\0GNU\0\2\0\0\300\4\0\0\0\3\0\0\0\0\0\0\0"..., 48, 848) = 48
pread64(3, "\4\0\0\0\24\0\0\0\3\0\0\0GNU\0I\17\357\204\3$\f\221\2039x\324\224\323\236S"..., 68, 896) = 68
newfstatat(3, "", {st_mode=S_IFREG|0755, st_size=2220400, ...}, AT_EMPTY_PATH) = 0
pread64(3, "\6\0\0\0\4\0\0\0@\0\0\0\0\0\0\0@\0\0\0\0\0\0\0@\0\0\0\0\0\0\0"..., 784, 64) = 784
mmap(NULL, 2264656, PROT_READ, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7cdffca00000
mprotect(0x7cdffca28000, 2023424, PROT_NONE) = 0
mmap(0x7cdffca28000, 1658880, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x28000) = 0x7cdffca28000
mmap(0x7cdffcbbd000, 360448, PROT_READ, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1bd000) = 0x7cdffcbbd000
mmap(0x7cdffcc16000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x215000) = 0x7cdffcc16000
mmap(0x7cdffcc1c000, 52816, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7cdffcc1c000
close(3)                                = 0
mmap(NULL, 12288, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7cdffcdaa000
arch_prctl(ARCH_SET_FS, 0x7cdffcdaa740) = 0
set_tid_address(0x7cdffcdaaa10)         = 71252
set_robust_list(0x7cdffcdaaa20, 24)     = 0
rseq(0x7cdffcdab0e0, 0x20, 0, 0x53053053) = 0
mprotect(0x7cdffcc16000, 16384, PROT_READ) = 0
mprotect(0x570c55b39000, 4096, PROT_READ) = 0
mprotect(0x7cdffcdf6000, 8192, PROT_READ) = 0
prlimit64(0, RLIMIT_STACK, NULL, {rlim_cur=8192*1024, rlim_max=RLIM64_INFINITY}) = 0
munmap(0x7cdffcdad000, 59619)           = 0
newfstatat(1, "", {st_mode=S_IFCHR|0620, st_rdev=makedev(0x88, 0), ...}, AT_EMPTY_PATH) = 0
getrandom("\x81\x42\x61\xea\x7a\xbb\x01\x45", 8, GRND_NONBLOCK) = 8
brk(NULL)                               = 0x570c55c3b000
brk(0x570c55c5c000)                     = 0x570c55c5c000
write(1, "hello", 5hello)                    = 5
exit_group(0)                           = ?
+++ exited with 0 +++
<br>我们对上面的系统调用重新看一遍，为什么只是打印一个字符串确需要如此多的系统调用？这是因为操作系统需要处理许多底层任务来支持程序的运行，我们执行printf之前的加载并执行程序都需要操作系统的介入。<br><br><br><br><br>系统调用是一种特殊类型的软件中断，通过系统调用，用户空间的程序可以请求操作系统的服务。系统调用是现代操作系统的基础功能，它为用户程序可以安全地使用内核模式下才能执行的文件操作、进程控制、通讯等操作。<br>系统调用有多种的实现方式:<br>
<br>传统x86：在传统x86使用 int 0x80 的软件中断方式，其中 0x80 就是系统调用的中断向量号。
<br>现代x86：在现代的x86系统上，我们常用 syscall 指令来使用系统调用。 syscall 并不使用传统的中断向量表，而直接通过特定的 MSR(模型特定寄存器) 跳转到内核系统调用实现的入口点。
<br><br>当使用传统x86系统上的系统调用时，每个系统调用都会有唯一一个标识符，也就是系统调用号。系统调用号用于区分不同的系统调用。用户程序通常将系统调用号放在一个特定的寄存器（比如 eax 寄存器）中来指示希望执行哪个系统调用。随后内核通过查看这个寄存器来决定执行具体的ISR。<br>当使用现代64位的x86系统时，保存系统调用号和系统调用入口关系的数据结构就是系统调用表(syscall table)。<br><br>向openat这样的函数实际上是系统调用号的包装器。这些包装函数简化了系统调用的使用，允许程序员通过高级和更易使用的接口方式与操作系统交互。<br><br>我们用 open("filename", MODE) 库函数为例，我们在用户代码中被调用时只传入两个参数：文件名和打开文件的模式。在该函数执行时会触发模式切换并调用openat系统调用，不同的CPU架构实现方法不太一样，下面我们对比3种架构。<br>我们会看到，虽然实现的细节不同，但是它们系统调用指令和传递参数的方式都是类似的。<br><br>x86-32属于传统的x86系统，使用 int 0x80 来调用 Linux 内核。如下：<br>section .data
	filename db 'example.txt', 0	; 要打开的文件名，末尾有一个null字符
	filemode dw 0x0002		; O_RDONLY模式
section .text
	mov eax, 5				; open系统调用的编号是5
	mov ebx, filename		; 第一个参数
	mov ecx, filemode		; 第二个参数
	xor edx, edx			; 第三个参数
	int 0x80				; 执行系统调用
<br><br>到了x86-64位系统上，用系统调用表(syscall table) 来保存记录系统调用号和系统调用入口的关系。我们使用 syscall 来执行系统调用。我们忽略一些细节，相关调用实现如下：<br>section .data
	filename db 'example.txt', 0	; 要打开的文件名，末尾有一个null字符
section .text
	mov rax, 257			; openat的系统调用的编号
	mov rdi, -100			; AT_FDCWD，当前 工作目录
	mov rsi, filename		; 第一个参数
	mov rdx, O_RDONLY		; 第二个参数
	xor r10, r10			; 第三个参数
	syscall					; 执行系统调用
<br><br>.section .data
filename:
	.ascii "example.txt\0"
.text
	mov x0, -100
	ldr x1, =filename
	mov	x2, 0
	mov x3, 0
	mov x8, 56
	svc 0
<br><br><br><br><br><br>
Interrupts are interruption to CPU.
<br>系统调用是一种特殊的中断。所有中断的处理流程和系统调用的处理流程有很多相似的地方。现代计算机是中断驱动的，中断机制的存在使得计算机(OS)能够及时响应外部事件并作出反应，极大地提升了系统的效率和响应性。<br>如果没有中断机制，CPU将不得不采用轮询(Polling)方式逐个地检查每个设备的状态以确定其是否需要服务。这是一种主动响应机制，相比于被动响应的中断机制，轮询浪费了很大一部分计算资源。<br><br>中断(Interrupts) 是一个由硬件或软件发出的信号，当某个过程或事件需要立即处理时会使用中断来通知处理器。中断的目的是让处理器注意到更高优先级的任务并打断当前正在进行的指令流保存当前的状态，然后转而去执行特定的中断处理程序，最后再返回原指令流中继续执行，这就是 中断机制 。<br><br><br>根据中断信号的产生源可将中断分为硬件中断和软件中断两大类：<br>
<br>
Hardware Interrupt：

<br>
外部中断（External Interrupt）：来自CPU外部硬件或I/O设备的中断。

<br>
内部中断（Internal Interrupt）：CPU内部自已产生的中断，也称为异常(exception)。

<br>trap：程序执行时故意产生的中断 (syscall)，是一种自愿中断
<br>fault：执行指令引起的异常事件，是可恢复的错误而触发的中断 (page fault)
<br>abort：硬故障事件，是不可恢复的严重错误下触发的中断 




<br>
Software Interrupt：

<br>通常由程序通过调用中断指令(如int xxx)主动发出的中断。(int 0x80)


<br><br>
<br>
Hardware Interrupts :

<br>或直接称为中断，是由硬件设备唤起的中断类型。
<br>硬件中断是异步的，任何时刻都可能发生。


<br>
Traps :

<br>有时也称作软件中断(Software Interrupts)。
<br>由用户程序唤起，用来请求操作系统的帮助。


<br>
Exceptions :

<br>处理器内部自动生成，由于某些非法指令的执行。
<br>Faults : 可恢复的错误。（page fault）
<br>Aborts : 通常是不可恢复的错误。（divide by 0 exception）


<br><br><br><br><br><br><br>操作系统是如何区分处理各种中断信号的。每种中断信号都被赋予一个特定的编号，称为中断向量号。这个向量号是一个整数，它起到了关键的角色，让系统能够识别并对应到具体的中断处理程序(也叫“中断服务例程”)。<br>中断向量号的分配方式取决于中断的类型:<br>
<br>外部中断，如来自硬件设备的中断，其向量号通常是由设备驱动在运行时动态申请的。这确保了不同设备能够根据当前系统状态获得适当的中断处理。
<br>异常，如程序错误或非法操作，其向量号则是由CPU的架构标准所固定规定。这样做的目的是为了确保异常能够以一致的方式被处理，无论系统在什么状态下。
<br>软件中断，通常是由操作系统内核中的程序触发的，其向量号是由内核预设。软件中断允许操作系统内部组件或运行在用户模式下的程序请求内核提供服务。
<br>在32位的x86架构中，有256个中断号，从0到255，也就是int指令后面的数字最大是255。中断向量号的划分如下：<br>
<br>预定义的中断(0-31)：0-19号是由Intel定义的用于处理各种标准异常的中断号，比如除零错误(0)，通用保护故障(13)，页故障(14)等。20-31号保留给 Intel 未来使用。
<br>用户自定义的中断(32-255)：32-47号通常被用于外部硬件中断，这是基于IBM PC架构的8259可编程中断控制器的标准设置。这个范围被称为主片和从片的IRQs(中断请求)。48-255号可以由操作系统自定义使用，通常用于实现软件中断、系统调用(128号中断向量)等。
<br>我们在前面看到过，在下x86架构下的系统调用编号是0x80。我们可以说，系统调用是软件中断的特定形式，而软件中断又是中断的子集。<br><br>中断向量表(Interrupt Vector Table，IVT) 存储了每个中断向量号与其对应的 中断服务例程(Interrupt Service Routine, ISR) 的地址。当系统检测到一个中断信号时，它会通过这个信号的向量号在IVT中查找相应的服务例程地址，然后跳转到该地址执行中断处理程序。<br>在计算机的实模式中，像键盘输入和屏幕显示等BIOS服务都是通过预设的中断方式实现的，它使用了中断向量表来查询BIOS中断号对应的ISR地址。<br>当计算机转入保护模式， 中断描述符表(Interrupt Descriptor Table, IDT) 取代了IVT，成为新的中断管理核心。IDT 相较于 IVT，有以下优点(不完整)：<br>
<br>安全性:  IDT不仅包含ISR的地址，还包含了必要的权限和状态信息，如特权级(DPL)。这允许操作系统设计者实施更精细的控制，例如防止用户模式代码直接触发某些特权中断。
<br>灵活性 : IDT支持在运行时动态修改，它们可能根据运行时的需要动态地添加、修改或移除中断处理程序。
<br>性能：IDT结构为现代操作系统提供了执行中断处理的更高效方式。例如，通过中断门触发的中断处理可以自动关闭中断，这避免了在处理一个中断时被其他中断干扰的问题，增强了处理的效率和系统的稳定性。
<br><br>中断服务例程(Interrupt Service Routine, ISR) 是响应硬件或软件中断信号的一段特定程序代码。当某个事件(如输入/输出操作、时钟信号、硬件故障或其他外部事件)触发中断时，处理器会暂停当前正在执行的任务，转而执行与该中断关联的ISR。<br>
<img alt="Pasted image 20240423213215.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240423213215.png"><br><br><br>当系统在执行指令流的过程中，在完成第 i 条指令后，如果突然接收到一个中断信号或主动发起系统调用，此时系统需要暂停当前的任务去响应这个中断/调用请求。为了确保中断处理完毕后，程序能够无缝地返回到被中断的位置继续执行后续指令，系统必须在执行中断处理程序之前，保存必要的一些信息，即现场信息。<br><br>以x86-32位架构为例。（arch/x86/kernel/entry_32.S）<br>现场信息是指CPU中的一些寄存器的值，通过保存恢复这些寄存器的数值，程序就能够回到被中断位置继续执行指令。这其中有几个核心寄存器：<br>
<br>SS：栈段寄存器，指向当前栈所在的栈段地址。
<br>ESP：栈指针寄存器，指向栈顶。
<br>EFLAGS：包含了影响程序执行的多种状态标志，如零标志、符号标志、溢出标志等。
<br>CS：包含当前代码段的选择子(Selector)，即指定了代码段在内存中的位置。
<br>EIP：即PC寄存器，指向将要执行的下一条指令。
<br>那这些现场信息存放在哪里呢？只要程序暂停执行并在未来需要恢复，那么程序就需要把现场信息先存放到一个位置，这个位置就是内核栈。这些现场信息会被 push 到内核栈中。<br><br>一旦程序在用户态被中断，上面提到的五个最重要的寄存器由硬件 CPU 自动完成（这个操作是当即完成的），无需操作系统或中断处理程序进行任何干预。而进程的中断上下文不仅仅只有这五个寄存器。操作系统负责保存一些额外的现场信息内容（执行 ISR 时保存）。如：<br>
<br>通用寄存器(EAX, EBX, ECX, EDX, ESI, EDI, EBP)
<br>段寄存器选择子（DS, ES, ES, GS）
<br>如果有错误发生，硬件还会压入错误码。待操作系统处理。<br>此外，在 CPU 执行 ISR 时，还牵扯到 CPL 的变化。即在中断发生时 CPU 特权级别 CPL 是"user mode"， CPU 需要负责将 CPL 切换至 0，即"kernel mode"，才能接着执行 ISR。（中断门描述符检查 DPL ≥ CPL ）<br><br>如果程序在内核态中断，那么将不再需要保存 SS 寄存器和 ESP 寄存器。因为中断时指向的就是内核栈。另外的，内核态下的段寄存器（如DS、ES）一般也不需要保存。因为它们已经指向内核数据段。<br><br>每个线程都有自己的内核栈。当线程被中断时，CPU 就会转换到其内核栈将线程的上下文进行压栈保存。一般而言，内核栈大小为 8KB/16KB 。<br><br>以x86-32架构为例。<br>在&nbsp;iret&nbsp;指令执行前，中断服务例程（ISR）需手动恢复操作系统保存的寄存器。恢复顺序需与保存顺序严格相反（后进先出，LIFO）。<br>ISR的指令逻辑流程：<br>
<br>保存通用寄存器
<br>执行中断处理代码
<br>恢复通用寄存器
<br>使用iret返回（弹出硬件保存寄存器）
<br><br>中断服务例程的执行完成后，系统需要通过执行 iret 指令来从 ISR 返回到原来的程序执行流。iret 指令的作用不仅是精确和有序的，它还负责恢复之前由 CPU 自动保存到栈中的处理器状态，并实现特权级的适当切换。<br>如果返回到用户态（CPL 0-&gt;3），那么执行 iret 时寄存器会依次弹出 EIP、CS、EFLAGS、用户态 ESP、用户态 SS。然后恢复 CS 中 CPL 的特权级别为 3，CPU 自动换回用户态。<br><br>仅仅弹出 EIP、CS、EFLAGS。而且由于特权级别不变，不切换栈指针。<br><br><br><br>信号将在<a data-tooltip-position="top" aria-label="6.5 Inter-Process Communications" data-href="6.5 Inter-Process Communications" href="https://congzhi.wiki/congzhi's-os-series/6.5-inter-process-communications.html" class="internal-link" target="_self" rel="noopener nofollow">IPC</a>阶段中介绍。<br>学习Linux的信号机制(signaling mechanism)时，一时间将我的思绪拉回了中断。信号是什么？软中断是什么？软件中断又是什么？它们有何相同点？又有哪些是不同的？<br><br>
The signaling mechanism in the Linux kernel allows running applications to asynchronously notify the system when a new event occurs. Because of its nature, this signaling mechanism is generally known as software interrupts.
<br>信号在Linux操作系统中非常重要。信号是进程间通信的一种方式。对于内核而言，信号就是一个事件，操作系统内核将中断的处理结果以信号的方式传递给进程。随后进程根据处理的结果做出相应的动作。<br><br>我们常常用信号作为进程间通信IPC和异常处理的一种手段。虽然操作系统内核通常是大多数信号的来源，但下面我们仍列举一些其他的信号来源：<br>
<br>进程执行时产生的异常，如段错误(segmentation faults)
<br>硬件产生的信号，比如定时器产生的信号
<br>其他进程使用kill系统调用产生的信号
<br><br>我们下面简单介绍硬件中断和异常是如何产生信号的。之后小节我们用例子说明kill系统调用是怎么产生信号并终止特定进程的。<br><br>信号的本质就是软件层次对中断的模拟，是一种异步通信机制。每个信号都对应着不同的功能。举个例子（按下Ctrl + C）：<br>
<br>硬件中断：

<br>键盘控制器检测到&nbsp;Ctrl+C&nbsp;按键组合，并发送硬件中断信号给 CPU。
<br>CPU暂停当前正在执行的用户空间代码，保存现场并切换到内核态。


<br>中断处理：

<br>进入内核态：CPU开始执行与键盘中断相关的中断服务例程（ISR）。
<br>执行ISR：内核中的键盘ISR处理这个中断事件，识别出这是一个Ctrl+C按键事件。


<br>生成信号：

<br>生成SIGINT信号：内核生成一个SIGINT信号。（用于终止进程）
<br>给进程发送信号：内核将SIGINT信号发送到目标进程，并将信号记录在PCB的信号位图上。


<br>信号处理：

<br>检测信号：当进程恢复执行时，内核会检查该进程PCB的信号队列（信号位图）。
<br>处理信号：根据进程的信号处理设置，内核会执行相应的操作。默认SIGINT会终止进程。
<br>调用信号处理函数：如果进程有自定义的信号处理函数，内核会调用该函数来处理信号。


<br><br>假如我们有一个signal.c文件如下：<br>#include &lt;stdio.h&gt;
#include &lt;signal.h&gt;
#include &lt;stdlib.h&gt;
void divideByZeroHandler(int signum) {
    printf("Divide by zero exception occurred!\n");
    exit(1);
}
int main() {
    if (signal(SIGFPE, divideByZeroHandler) == SIG_ERR){
	    perror("Cannot register the handler");
	    return 1;
    }
    int dividend = 10;
    int divisor = 0;
    int result;
    printf("Attempting to divide %d by %d...\n", dividend, divisor);
    result = dividend / divisor;
    printf("Result: %d\n", result);
    return 0;
}
<br>我们知道，当除数为0时，结果会是一个异常。当这个异常发生时，进程就会中断。这时操作系统内核会把 SIGFPE（浮点异常） 发给进程。又由于我们设置了信号的服务程序signal(SIGFPE, divideByZeroHandler);，所以当进程收到信号，他就会打印输出信息并退出程序 error(1)。<br><br><br>信号由操作系统负责传递给指定进程，传递时机是：<br>
<br>从内核态返回用户态运行时：内核会检查待处理信号集合，如果有未阻塞的待处理信号操作系统会在返回用户态前递送信号，调用相应的信号处理函数。
<br>被调度运行时：在进程真正开始运行用户代码之前，递送未阻塞的信号。
<br>就绪态时：信号会被添加到进程的待处理信号集合中，但不会立即递送。
<br>等待态时：如果进程正在阻塞于某个系统调用(如read、sleep等)，信号的发生可能会导致系统调用被中断，提前返回用户态处理信号。
<br><br>进程收到信号后的处理方式有:<br>
<br>默认处理:操作系统定义的默认行为(终止、忽略等)
<br>忽略信号:进程选择不处理某些信号(部分信号不可忽略)自定义处理:进程注册信号处理函数，定义自己的处理方式。

<br>定义信号处理函数
<br>注册信号处理函数


<br><br>我们可以通过下面的命令来查看Linux中的所有类型的信号：<br>kill -l
<br>Linux系统中有62种信号，分为两类：非实时信号（1-31）和实时信号（34-64）。非实时信号包括常见的SIGINT（中断信号）、SIGTERM（终止信号）等，而实时信号用于更高精度的事件处理。<br><br>从上述信号的了解中，我们能够感受到，中断可以是信号的产生源。我们已经学过中断了，我们可以将中断定义为一种CPU和操作系统内核的交流方式。中断一旦发生，CPU 暂停当前任务并触发内核中的中断服务程序（ISR）。<br><br>
<br>
处理程序(Handler)：信号处理程序在用户空间代码中执行，而中断服务程序在内核空间中执行。信号处理程序用于处理进程接收到的特定信号，而中断服务程序用于处理硬件中断。

<br>
屏蔽(Mask)：信号屏蔽和中断屏蔽分别用于暂时阻止进程接收信号和处理硬件中断，以保护关键代码段的原子性执行

<br><br>系统调用(syscall)是一种软件中断，我们可以用系统调用来给特定的进程发送信号。如：<br>
<br>kill&nbsp;系统调用：用于向指定进程发送信号，可以通过进程ID（kill(PID)）来指定目标进程。
<br>raise&nbsp;系统调用：用于向自身进程发送信号，相当于调用&nbsp;kill(getpid(), sig)。
<br>alarm&nbsp;系统调用：设置一个定时器，当定时器到期时，会向进程发送&nbsp;SIGALRM&nbsp;信号。
<br>sigqueue&nbsp;系统调用：用于向指定进程发送信号，并可以附带一个值。
<br><br>提供kill系统调用，我们可以给特定的进程发送SIGINT信号来终止某个进程。如下：<br>#include &lt;sys/types.h&gt;
#include &lt;signal.h&gt; // An abstraction to raw syscall
#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;

int main() {
    pid_t pid = fork(); 
	
    if (pid == 0) {
        for (int i = 0; i &lt; 5; ++i) {
            printf("this is child process\n");
            sleep(1); 
        }
    } else if (pid &gt; 0) {
        printf("this is parent process\n");
        sleep(2); 
        printf("terminating child process now!\n");
        kill(pid, SIGINT);
    } else {
        perror("fork");
    }
	
    return 0;
}
<br>在这个例子中，父进程先是使用&nbsp;fork()&nbsp;创建一个子进程。子进程每秒打印一次 “this is child process”。父进程等待2秒后，使用&nbsp;kill(pid, SIGINT)&nbsp;向子进程发送&nbsp;SIGINT&nbsp;信号，终止子进程。我们还可以自己编写信号处理函数来处理输出我们想要的结果。<br>du@DVM:~/Desktop/CppCode$ ./kill 
this is child process
this is parent process
this is child process
this is child process
terminating child process now!
<br><br>中断的来源很多，softirq的种类也不少。内核的限制是不能超过32个，目前实际用到的有10个。包括高优先级tasklet、定时器、网络收发、块设备、普通tasklet、高精度定时器和RCU等。softIRQ主要用于处理高频率、低延迟的任务，如网络包处理和定时器等。<br>其中两个用来实现tasklet(HI_SOFTIRQ和TASKLET_SOFTIRQ)，两个用于网络的发送和接收操作(NET_TX_SOFTIRQ和NET_RX_SOFTIRQ)，一个用于调度器(SCHED_SOFTIRQ)，实现SMP系统上周期性的负载均衡。在启用高分辨率定时器时，还需要一个HRTIMER_SOFTIRQ。<br>为了有效地管理不同的softirq中断源，Linux采用的是一个名为softirq_vec[] 的数组，数组的大小由NR_SOFTIRQS&nbsp;表示，这是在编译时就确定了的，不能在系统运行过程中动态添加。每个数组元素代表一种softirq的种类，而数组里存放的内容则是其各自对应的执行函数。]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/5.-interruption.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/5. Interruption.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 21 Mar 2025 16:04:10 GMT</pubDate><enclosure url="https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20250127044801.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20250127044801.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[6. Processing The Processes]]></title><description><![CDATA[ 
 <br><br><br>1.1 节内容了解即可，你需要知道什么是程序段、ELF 文件是什么。<br><br>
A process is a program in execution.
<br>你对进程这个词可能会陌生，但是你一定不陌生程序和文件这两个词。我们知道程序可以运行在机器上，而文件则是以一定格式存放数据的地方。要生成一个进程，我们需要先将程序交给操作系统，让操作系统帮我们运行。我们把这样具有一定格式的程序文件称为可执行文件。<br><br>我们这里所说的程序并不是高级语言源程序。高级语言源程序是给人类看的，计算机并不认识这些 ASCII 字符代表什么含义。在使用 C 语言的情况下，我们需要预处理、编译、汇编、链接之后才能得到可执行文件。且在不同的操作系统中，使用的可执行文件格式可能是不同的。<br>在 Linux 系统中，最常见的可执行文件格式是 ELF(Executable and Linkable Format)。ELF 格式非常灵活，支持静态链接、动态链接、可重定位代码等多种特性。它不仅用于可执行文件，还用于共享库和核心转储文件。<br>而在Windows系统中，标准的可执行文件格式是 .exe ，这是 "executable" 的缩写，可能也是我们见的最多的可执行文件的格式。除了 .exe 格式，Windows 还使用其他格式，如 .dll（动态链接库）和 .sys（系统驱动程序）。<br><br>我们说文件是具有一定格式的数据集合。ELF 文件有两种视图：链接视图和可执行视图，前者指链接之前的 ELF 目标文件，后者是指链接完成之后的 ELF 目标文件。二者最主要的区别在于，链接前的 ELF 目标文件无法直接载入内存中执行；而通过链接，ELF 目标文件中的地址确定之后（虚拟地址），就可以载入内存中运行了。<br>在后续的小节中，我们用下面的程序做例子：<br>#include &lt;stdio.h&gt;

int main(){
	printf("hello, world\n");
}
<br>我们用命令将程序生成可重定位目标文件和可执行目标文件：<br>gcc -c hello.c -o hello.o
gcc hello.c -o hello
<br><br>在ELF文件的可重定位视图中，目标文件由ELF头、程序头表（可选）、节(Sections)、和节头表组成。节(section)是ELF文件中具有相同特征的最小可处理单位，链接时就是对相同的属性的节进行组合成段(segments)，最后按段进行加载。<br><br>ELF头位于ELF文件最开始的地方（偏移为0），包含了文件结构的说明信息。ELF64头信息在机器中的编码是01序列，我们可以通过readelf 这种工具软件来查看ELF中包含的信息。这里我们需要读取文件的头信息，我们用 readelf -h hello.o 来获取ELF的头包含什么信息。<br>du@DVM:~/Desktop$ readelf -h hello.o
ELF Header:
  Magic:   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 
  Class:                             ELF64
  Data:                              2's complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0
  Type:                              REL (Relocatable file)
  Machine:                           Advanced Micro Devices X86-64
  Version:                           0x1
  Entry point address:               0x0
  Start of program headers:          0 (bytes into file)
  Start of section headers:          600 (bytes into file)
  Flags:                             0x0
  Size of this header:               64 (bytes)
  Size of program headers:           0 (bytes)
  Number of program headers:         0
  Size of section headers:           64 (bytes)
  Number of section headers:         14
  Section header string table index: 13
<br>hello.o 是可重定位的目标文件，给出的是 ELF 的链接视图，所以装入的入口地址是 0x0。这时的程序是无法执行的。<br><br>程序头表主要在程序的加载阶段使用。链接阶段主要关注的是节和节头表。程序头表我们保留，在介绍。<br><br>我们前面在ELF头中其实都看到hello.o 中有多少个节头了。这些节头给出每个节的相关信息，如节的名称、节的起始地址、节的偏移等等。每个节承担不同的功能，我们很快就能根据这些信息从文件的二进值信息这找到我们写进去的数据了。<br>节头表是一个结构体，包含了每个节的信息。在ELF头中，我们看到一个节头的大小是64字节，节头的结构体定义如下：<br>typedef struct {
    uint32_t sh_name;      // 节名称的索引
    uint32_t sh_type;      // 节的类型
    uint64_t sh_flags;     // 节的标志(在虚拟空间中的访问属性)
    uint64_t sh_addr;      // 节的虚拟内存地址(链接视图无意义)
    uint64_t sh_offset;    // 节在文件中的偏移
    uint64_t sh_size;      // 节的大小
    uint32_t sh_link;      // 节的链接信息
    uint32_t sh_info;      // 链接信息
    uint64_t sh_addralign; // 对齐要求信息
    uint64_t sh_entsize;   // 节中条目的大小
} Elf64_Shdr;
<br>节头的结构体中的数据都是01序列，所以我们用 readelf -S 命令来获取节头表的信息：<br>du@DVM:~/Desktop$ readelf -S hello.o
There are 14 section headers, starting at offset 0x258:
Section Headers:
  [Nr] Name              Type             Address           Offset
       Size              EntSize          Flags  Link  Info  Align
       
  [ 0]                   NULL             0000000000000000  00000000
       0000000000000000  0000000000000000           0     0     0
  [ 1] .text             PROGBITS         0000000000000000  00000040
       000000000000001e  0000000000000000  AX       0     0     1
  [ 2] .rela.text        RELA             0000000000000000  00000198
       0000000000000030  0000000000000018   I      11     1     8
  [ 3] .data             PROGBITS         0000000000000000  0000005e
       0000000000000000  0000000000000000  WA       0     0     1
  [ 4] .bss              NOBITS           0000000000000000  0000005e
       0000000000000000  0000000000000000  WA       0     0     1
  [ 5] .rodata           PROGBITS         0000000000000000  0000005e
       000000000000000d  0000000000000000   A       0     0     1
  [ 6] .comment          PROGBITS         0000000000000000  0000006b
       000000000000002c  0000000000000001  MS       0     0     1
  [ 7] .note.GNU-stack   PROGBITS         0000000000000000  00000097
       0000000000000000  0000000000000000           0     0     1
  [ 8] .note.gnu.pr[...] NOTE             0000000000000000  00000098
       0000000000000020  0000000000000000   A       0     0     8
  [ 9] .eh_frame         PROGBITS         0000000000000000  000000b8
       0000000000000038  0000000000000000   A       0     0     8
  [10] .rela.eh_frame    RELA             0000000000000000  000001c8
       0000000000000018  0000000000000018   I      11     9     8
  [11] .symtab           SYMTAB           0000000000000000  000000f0
       0000000000000090  0000000000000018          12     4     8
  [12] .strtab           STRTAB           0000000000000000  00000180
       0000000000000013  0000000000000000           0     0     1
  [13] .shstrtab         STRTAB           0000000000000000  000001e0
       0000000000000074  0000000000000000           0     0     1
Key to Flags:
  W (write), A (alloc), X (execute), M (merge), S (strings), I (info),
  L (link order), O (extra OS processing required), G (group), T (TLS),
  C (compressed), x (unknown), o (OS specific), E (exclude),
  D (mbind), l (large), p (processor specific)
<br>现在，我们就能准确地从中知道每个节相对 base 的确切位置。但仍然迷惑的是为何所有节的地址字段都为 0x0000 ？这是因为当前 hello.o 并没有链接重定位生成可执行目标文件，所以对应的每个节的起始地址都为 0x0（因为这时的节地址是毫无意义的）。<br><br>通过节头表中的信息和ELF头的信息，我们就能绘制出 hello.o 文件结构：<br>+-------------------------+-------------------------+   0x000
| ELF Header              | 64 bytes (0x40)         |
+-------------------------+-------------------------+   0x040
| .text                   | 30 bytes (0x1e)         |
+-------------------------+-------------------------+   0x05e
| .data                   | 0 bytes                 |
+-------------------------+-------------------------+   0x05e
| .bss                    | 0 bytes                 |
+-------------------------+-------------------------+   0x05e
| .rodata                 | 13 bytes (0x0d)         |
+-------------------------+-------------------------+   0x06b
| .comment                | 44 bytes (0x2c)         |
+-------------------------+-------------------------+   0x097
| .note.GNU-stack         | 0 bytes                 |
+-------------------------+-------------------------+   0x097
+-------------------------+-------------------------+   0x098(0x97对齐)
| .note.gnu.property      | 32 bytes (0x20)         |
+-------------------------+-------------------------+   0x0b8
| .eh_frame               | 56 bytes (0x38)         |
+-------------------------+-------------------------+   0x0f0
| .symtab                 | 144 bytes (0x90)        |
+-------------------------+-------------------------+   0x180
| .strtab                 | 19 bytes (0x13)         |
+-------------------------+-------------------------+   0x193
+-------------------------+-------------------------+   0x198(0x193对齐)
| .rela.text              | 48 bytes (0x30)         |
+-------------------------+-------------------------+   0x1c8
| .rela.eh_frame          | 24 bytes (0x18)         |
+-------------------------+-------------------------+   0x1e0
| .shstrtab               | 116 bytes (0x74)        |
+-------------------------+-------------------------+   0x254(596 Bytes)
+-------------------------+-------------------------+   0x258(600 Bytes)
| Section Headers         | 896 bytes (14 * 64)     |
+-------------------------+-------------------------+   0x5d8(600+896 Bytes)
<br>通过结构信息，我们可以很清楚地看到文件从哪开始，从哪里结束。我们用 hexdump -C 以16进制和 ASCII 格式查看 hello.o 文件。我们看到，程序如我们预想的一样从 0x5d8 结束。查看 .rodata 节的位置，我们也如预料地看到了 hello,world. 这样12个字符。至此，关于 hello.o 的解读圆满结束！<br>du@DVM:~/Desktop$ hexdump -C hello.o
00000000  7f 45 4c 46 02 01 01 00  00 00 00 00 00 00 00 00  |.ELF............|
...
00000050  89 c7 e8 00 00 00 00 b8  00 00 00 00 5d c3 68 65  |............].he|
00000060  6c 6c 6f 2c 20 77 6f 72  6c 64 00 00 47 43 43 3a  |llo, world..GCC:|
...
000005d0  00 00 00 00 00 00 00 00                           |........|
000005d8
<br><br>既然本阶段和进程有关，我们就聚焦于ELF的可执行目标文件视图上。链接后，可重定位目标文件进行相同属性节合并成段。由于在程序加载时是按段为单位进行加载，所以可执行目标文件由ELF头、程序头表、段(Segments)、节、和节头表组成，新加入了段的概念。<br><br>我们先用命令 readelf -h 查看ELF头，看看与可重定位目标文件有什么不同。首先，最大的不同就是程序的入口地址不再是0了，还多了程序头表还有节的数量变多了。然后我们发现，在链接（重定位）过后，我们少了带重定位信息的节（如 .rela.text 、.rela.data 等）。<br>du@DVM:~/Desktop$ readelf -h hello
ELF Header:
  Magic:   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 
  Class:                             ELF64
  Data:                              2's complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0
  Type:                              DYN (Position-Independent Executable file)
  Machine:                           Advanced Micro Devices X86-64
  Version:                           0x1
  Entry point address:               0x1060
  Start of program headers:          64 (bytes into file)
  Start of section headers:          13976 (bytes into file)
  Flags:                             0x0
  Size of this header:               64 (bytes)
  Size of program headers:           56 (bytes)
  Number of program headers:         13
  Size of section headers:           64 (bytes)
  Number of section headers:         31
  Section header string table index: 30
<br><br>我们从ELF头中并没有找到什么关于段和段头表的信息，它们在哪里呢？这些信息就存储在程序头中。在ELF头中，我们能读取到程序头的大小和数量，每个程序头描述了一个段的信息。所以，一个个的程序头实际上就是一个个的段头。<br>和节头一样，段头也是一个结构体数组，段头表用于描述这些段的各种属性信息。从上面的ELF头信息中我们可以读出，程序有13个段头，每个段头有56个字节。<br>typedef struct {
    uint32_t p_type;   // 段的类型
    uint32_t p_flags;  // 段的权限标志
    uint64_t p_offset; // 段在文件中的偏移量
    uint64_t p_vaddr;  // 段在内存中的虚拟地址
    uint64_t p_paddr;  // 段在内存中的物理地址
    uint64_t p_filesz; // 段在文件中的大小
    uint64_t p_memsz;  // 段在内存中的大小
    uint64_t p_align;  // 段在内存中的对齐要求
} Elf64_Phdr;
<br>程序头表描述了从文件中加载的各个段(segment) 的属性和位置，这些信息对于系统加载器将程序加载到内存并执行至关重要。每个Program Header描述了一个或多个段(segment)，包括它们在文件中的位置和大小、应当被加载到内存中的位置、以及需要的内存权限(如只读、可读写等)。<br>我们用 readelf -l 读取段头表的信息：<br>du@DVM:~/Desktop$ readelf -l hello

Elf file type is DYN (Position-Independent Executable file)
Entry point 0x1060
There are 13 program headers, starting at offset 64

Program Headers:
  Type           Offset             VirtAddr           PhysAddr
                 FileSiz            MemSiz              Flags  Align
  PHDR           0x0000000000000040 0x0000000000000040 0x0000000000000040
                 0x00000000000002d8 0x00000000000002d8  R      0x8
  INTERP         0x0000000000000318 0x0000000000000318 0x0000000000000318
                 0x000000000000001c 0x000000000000001c  R      0x1
      [Requesting program interpreter: /lib64/ld-linux-x86-64.so.2]
  LOAD           0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000000628 0x0000000000000628  R      0x1000
  LOAD           0x0000000000001000 0x0000000000001000 0x0000000000001000
                 0x0000000000000175 0x0000000000000175  R E    0x1000
  LOAD           0x0000000000002000 0x0000000000002000 0x0000000000002000
                 0x00000000000000f4 0x00000000000000f4  R      0x1000
  LOAD           0x0000000000002db8 0x0000000000003db8 0x0000000000003db8
                 0x0000000000000258 0x0000000000000260  RW     0x1000
  DYNAMIC        0x0000000000002dc8 0x0000000000003dc8 0x0000000000003dc8
                 0x00000000000001f0 0x00000000000001f0  RW     0x8
  NOTE           0x0000000000000338 0x0000000000000338 0x0000000000000338
                 0x0000000000000030 0x0000000000000030  R      0x8
  NOTE           0x0000000000000368 0x0000000000000368 0x0000000000000368
                 0x0000000000000044 0x0000000000000044  R      0x4
  GNU_PROPERTY   0x0000000000000338 0x0000000000000338 0x0000000000000338
                 0x0000000000000030 0x0000000000000030  R      0x8
  GNU_EH_FRAME   0x0000000000002014 0x0000000000002014 0x0000000000002014
                 0x0000000000000034 0x0000000000000034  R      0x4
  GNU_STACK      0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000000000 0x0000000000000000  RW     0x10
  GNU_RELRO      0x0000000000002db8 0x0000000000003db8 0x0000000000003db8
                 0x0000000000000248 0x0000000000000248  R      0x1

 Section to Segment mapping:
  Segment Sections...
   00     
   01     .interp 
   02     .interp .note.gnu.property .note.gnu.build-id .note.ABI-tag .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rela.dyn .rela.plt 
   03     .init .plt .plt.got .plt.sec .text .fini 
   04     .rodata .eh_frame_hdr .eh_frame 
   05     .init_array .fini_array .dynamic .got .data .bss 
   06     .dynamic 
   07     .note.gnu.property 
   08     .note.gnu.build-id .note.ABI-tag 
   09     .note.gnu.property 
   10     .eh_frame_hdr 
   11     
   12     .init_array .fini_array .dynamic .got 
<br>通过 Section to Segment mapping 中的信息，我们能够知道各个段和其所包含的节之间的映射关系，哪个段由哪些节组成。并且通过段的类型能够知道哪些段是需要载入内存，与存储器进行映像的。通过这些段头的信息，和在上节课的操作一样，我们可以通过这些地址信息找到我们只读字符串的位置。<br>00002000  01 00 02 00 68 65 6c 6c  6f 2c 20 77 6f 72 6c 64  |....hello, world|
00002010  00 00 00 00 01 1b 03 3b  30 00 00 00 05 00 00 00  |.......;0.......|
<br><br>当 ELF 程序加载进内存时，我们就说一个新的进程诞生了。当我们请求操作系统运行一个程序(如ELF可执行文件)时，操作系统会完成以下步骤：<br>
<br>读取文件：操作系统读取存储在磁盘上的 ELF 可执行文件。
<br>创建进程：操作系统调用创建新进程的系统调用（如fork或exec），此时会分配并初始化PCB。PCB包含进程的基本信息，如进程ID、状态、优先级、程序计数器、寄存器信息等。
<br>解析Program Header Table：系统解析Program Header以确定文件的哪些部分需要被加载到内存，它们需要被加载到内存的什么位置，以及需要什么权限（只读、读写、执行）。
<br>内存分配：操作系统为程序的各个段分配内存。这通常涉及到为代码段、数据段和BSS段分配空间，同时也包括为动态链接库和程序运行时堆栈的初始化预留空间。
<br>加载到内存：将代码和数据从磁盘复制到内存中的预定位置。
<br>程序执行：操作系统将控制权交给程序，从其入口点开始执行。
<br><br>简单地说，进程是运行程序的一个实例。相比于程序（包括指令和数据），进程还包含进程状态以及执行所需要的各项资源。也因此，我们称程序是静态的，而进程是动态的。进程是操作系统资源分配调度的基本单位，每个进程也都有自己独立的虚拟内存区域和其他的资源。<br><br>当进程被创建，操作系统需要一个数据结构来跟踪并表示一个进程的信息和状态，我们通常将这个结构称作进程控制块。操作系统将进程的所有信息都存储在一个PCB中。在所有的现代操作系统中，每个进程都有一个与之对应的PCB，它用于存储关于该进程的全部信息，PCB 中包括:<br>
<br>进程标识符(Process Identifier, PID)：这是一个整型，用于区分系统中的各个进程。
<br>进程状态(State)：它表示进程当前的状态，如就绪(ready)、运行(running)、等待(waiting)或终止(terminated)等。
<br>程序计数器(Program Counter)：存储下一条要执行的指令的地址。
<br>CPU寄存器信息(Register Data)：保存进程执行状态需要的所有寄存器值，包括累加器、索引寄存器、栈指针等。
<br>CPU调度信息(Scheduling infos)：包括进程优先级、调度队列指针等，用于CPU调度决策。
<br>内存管理信息：包括指向进程页面表、内存限制、段表等的指针。
<br>会计信息(Accounting Infomation)：包括CPU使用时间、实际使用的时间和限制、进程创建的时间等。
<br>I/O 状态信息：包括分配给进程的I/O设备列表、打开文件列表等。
<br>......<br>
<img alt="Pasted image 20241110161041.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241110161041.png">
<br>PCB是操作系统内核中的一个重要数据结构，用于存储与一个特定进程相关的所有信息。通过这些信息，操作系统可以有效地管理和调度进程，确保多任务环境下的进程并发执行和资源分配的合理性。操作系统每次对进程的操作都对应着对PCB的更新。<br><br>在 Linux操作系统中，进程控制块在task_struct的C结构体中实现。task_struct结构体位于内核源代码目录中的&lt;include/linux/sched.h&gt;头文件中。这个结构体包含了表示进程所需的所有信息，包括进程的状态、调度和内存管理信息、打开文件的列表，以及指向进程的父进程、子进程和兄弟进程的指针。<br>其中的一些字段有：<br>long state;                     /* state of the process */   
struct sched entity se;         /* scheduling information */ 
struct task struct *parent;     /* this process’s parent */ 
struct list head children;      /* this process’s children */ 
struct files struct *files;     /* list of open files */ 
struct mm struct *mm;           /* address space */
<br>......<br><br>在进程运行时，它所看到的一切都是虚拟的。所有的地址空间都是操作系统提供给进程的抽象概念，使得每个进程看起来都拥有一段连续且私有的内存区域。这就是虚拟地址空间，这种机制使得进程在运行时似乎有独立且完整的内存控制，而实际上其物理内存可能是非连续的，甚至与其他进程共享。<br>也就是说，进程使用的地址都是虚拟地址，而不是真实的物理内存上的地址。虚拟地址并不直接映射到物理内存的实际地址上，而是通过内存管理单元(Memory Management Unit, MMU)进行地址转换。实际上，CPU使用的也是虚拟地址，要映射到物理内存上同样需要MMU的参与。<br><br>上个阶段，我们谈论到了用户模式和内核模式，还简单地谈到了内核栈。为了实现系统的安全性和稳定性，我们将进程的虚拟内存空间划分为用户空间和内核空间。在32位机器上，由于处理器最多一次性处理的地址为32位的二进制数，只能访问  的内存空间。因而，我们常用低 3GB 表示用户空间，用高 1GB 表示内核空间。<br>随着软件业的发展，软件占用的空间也越来越大。32 位的机器所能提供的 4GB 虚拟内存明显不够用。进而人们研发了新的 64 位计算机架构，解决了 32 位机器虚拟内存小的短板。 64 位机器的寻址的范围可比 32 位机器大得多了。 64 位机器下，高 16bits 用于区别用户空间和内核空间。只使用了低 48 位分别给进程的内核空间和用户空间进行编址。 64 位进程虚拟内存布局如下:<br>Start               End                  Size    Use
0x0000000000000000  0x0000ffffffffffff   256TB   user
0xffff000000000000  0xffffffffffffffff   256TB   kernel
<br>由上图，user space 的空间和 kernel space 两个地址空间各有256TB，合在一起才是一个完整的进程虚拟地址空间。64bits 地址的高16bits，即 0xffff 代表内核空间，0x0000 代表用户空间。<br><br>这部分空间是每个进程所独有的，用于存储进程运行所需的代码、数据、堆和栈等。应用程序是可见的只有用户空间的地址，应用程序在此范围内执行其代码和处理数据。运行在用户模式下的程序不能直接访问内核空间资源，这增强了系统的安全性。<br><br>内核空间是系统中所有进程共享的空间，用于运行操作系统的内核代码和处理核心任务，如设备管理、内存管理、进程调度等。内核空间对用户模式下的程序是不可见的，只能由运行在内核模式的操作系统代码访问。这部分通常保留较高的地址范围。<br>虽然内核空间在每个进程的地址空间中都是可见的，但普通用户程序不能直接读写或执行内核空间的代码或数据。当用户程序需要进行系统调用以请求操作系统的服务时，它将通过定义好的接口（如系统调用）切换到内核模式，此时才能执行内核代码。<br><br>进程虚拟内存空间布局是指进程在虚拟内存中的组织和分配方式。它决定了一个进程的各种内存区域如何在虚拟地址空间中排列。典型的进程内存布局主要包括以下几个主要部分：<br>
<br>文本段(Text Segment)：程序的二进制执行代码（r/x）。
<br>数据段(Data Segment)：初始化为非 0 过的全局变量和静态变量（r/w）。
<br>BSS段(Block Started by Symbol)：存放初始化为 0 / 未初始化的全局和静态变量（r/w）。
<br>只读数据段(Read-Only Data Segment)：存储着不可修改的数据字符串常量（r）。
<br>堆(Heap)：用于动态内存分配（使用malloc）。在BSS段后开始，向上增长。
<br>栈(Stack)：用于存储函数调用的返回地址、局部变量和参数。位于高地址，向下增长。
<br>环境变量(Environment Variables)：存储与进程相关的环境信息，如路径、用户信息等。
<br>命令行参数(Command Line Arguments)：存储进程启动时传递的参数。
<br>内核空间(Kernel Space)：包含操作系统内核和相关数据结构，用户进程不可见。
<br><img alt="Pasted image 20240928001613.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240928001613.png"><br><br>这小节，我们通过运行自己的测试程序来观察以下某些变量在进程内存布局的哪部分。我们用到的测试程序如下：<br>#include &lt;stdlib.h&gt;
int global_b; //Uninitialized global variable
int main(){
	static int static_c = 10;//static variable initializing
	char* local_d = "hi,world";
	void* p = malloc(100);
	static_c ++;
	free(p);
	return 0;
}
<br>为了保留更多的调试信息，在编译链接时加上-g参数，然后用gdb命令对可执行文件进行调试。需要到用到的gdb命令有：<br>
<br>list 命令打印代码
<br>break main 设置在 main 数处的断点。
<br>run 开始执行程序，直到达到断点。
<br>info proc mappings显示进程的内存映射，包括各个内存段的地址范围info locals 显示当前函数的局部变量。
<br>print &amp;local_d 打印局部变量 local_d 的地址。
<br>我们得到的进程内存布局如下：<br>Mapped address spaces:
Start Addr           End Addr       Size     Offset   Perms  objfile
0x555555554000     0x555555555000   0x1000    0x0     r--p   hiprocess
0x555555555000     0x555555556000   0x1000    0x1000  r-xp   hiprocess //text
0x555555556000     0x555555557000   0x1000    0x2000  r--p   hiprocess //rodata
0x555555557000     0x555555558000   0x1000    0x2000  r--p   hiprocess //rodata
0x555555558000     0x555555559000   0x1000    0x3000  rw-p   hiprocess //data &amp; bss
0x555555559000     0x55555557a000   0x21000     0x0   rw-p   [heap]
0x7ffff7c00000     0x7ffff7c28000   0x28000     0x0   r--p   libc.so.6
0x7ffff7c28000     0x7ffff7dbd000   0x195000 0x28000  r-xp   libc.so.6
0x7ffff7dbd000     0x7ffff7e15000   0x58000  0x1bd000 r--p   libc.so.6
0x7ffff7e15000     0x7ffff7e16000    0x1000  0x215000 ---p   libc.so.6
0x7ffff7e16000     0x7ffff7e1a000    0x4000  0x215000 r--p   libc.so.6
0x7ffff7e1a000     0x7ffff7e1c000    0x2000  0x219000 rw-p   libc.so.6
0x7ffff7e1c000     0x7ffff7e29000    0xd000      0x0  rw-p   
0x7ffff7fa9000     0x7ffff7fac000    0x3000      0x0  rw-p   
0x7ffff7fbb000     0x7ffff7fbd000    0x2000      0x0  rw-p   
0x7ffff7fbd000     0x7ffff7fc1000    0x4000      0x0  r--p   [vvar]
0x7ffff7fc1000     0x7ffff7fc3000    0x2000      0x0  r-xp   [vdso]
0x7ffff7fc3000     0x7ffff7fc5000    0x2000      0x0  r--p   ld-linux-x86-64.so.2
0x7ffff7fc5000     0x7ffff7fef000    0x2a000  0x2000  r-xp   ld-linux-x86-64.so.2
0x7ffff7fef000     0x7ffff7ffa000    0xb000   0x2c000 r--p   ld-linux-x86-64.so.2
0x7ffff7ffb000     0x7ffff7ffd000    0x2000   0x37000 r--p   ld-linux-x86-64.so.2
0x7ffff7ffd000     0x7ffff7fff000    0x2000   0x39000 rw-p   ld-linux-x86-64.so.2
0x7ffffffde000     0x7ffffffff000    0x21000     0x0  rw-p   [stack]
0xffffffffff600000 0xffffffffff601000 0x1000     0x0  --xp   [vsyscall]
<br>
<br>对照ELF进程内存布局的表，global_b全局变量和static_c静态变量的地址都位于data和bss段；
<br>char* local_d = "hi,world" 创建了一个指向字符串的指针变量，其中，字符串中的数据是read-only。因此，指针变量指向的数据位于rodata段。
<br>p指针和local_d的地址位于stack段，因为它们是个局部变量。
<br>p指针指向malloc函数动态内存分配的100个字节，其分配的内存位于heap段。
<br>(gdb) print &amp;static_c
$1 = (int *) 0x555555558010 &lt;static_c&gt;
(gdb) print &amp;local_d
$2 = (char **) 0x7fffffffdee0
(gdb) print &amp;global_b
$3 = (int *) 0x555555558018 &lt;global_b&gt;
(gdb) print &amp;p
$4 = (void **) 0x7fffffffdee8
(gdb) print p
$5 = (void *) 0x5555555592a0
(gdb) print local_d
$6 = 0x555555556004 "hi,world"
<br><br>对于进程来说，栈空间非常重要。我们知道局部变量的概念，但局部变量中的局部体现在哪里？对于学过高级语言的我们来说，在花括号“{ }”里面定义的变量就是局部变量了。这样理解当然没有问题，但是为什么会这样呢？<br><br>当一个函数被调用时，系统会为该函数在栈空间上分配一个栈帧(stack frame)，其中包含着所谓的局部变量、参数、返回地址和其他信息。栈是一个动态的概念，局部变量会随着栈帧的创建而被分配，当函数执行完毕、栈帧销毁时，这些局部变量也随之消失。<br><img alt="Pasted image 20240509165620.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240509165620.png"><br>这也为我们使用堆空间带来一些警示。堆内存的申请通常是在函数内进行的，当栈帧销毁时，记录堆内存的指针也将不复存在。如果你没有使用语言提供的自动内存释放工具，你就必须在栈帧销毁前释放内存。当然，也可以像接力比赛一样，将指针的地址传给下一个变量。<br><br>要查看进程的栈空间，我们还需要用到的 GNU Debugger ，在这次 DIY 的实验中，我们会用到下面的实验代码：<br>#include &lt;stdio.h&gt;
int global_g = 5;
int hello(){
	int local_h = 10;
	printf("hello\n");//breakpoint
	return 0;
}
void world(){

}
int main(){
	int local_i = 0;
	hello();
	world();


	return 0;//breakpoint
}
<br>我们会用到相关的gdb命令如下：<br>
<br>info frame：指令的缩写形式为 i f ，查看函数调用帧所有信息。
<br>info registers：查看寄存器的情况(除了浮点寄存器)。
<br>info register rbp：查看栈基地址寄存器值。(Base Pointer) | r 表示机器是64位
<br>info register rsp：查看栈顶地址寄存器值。(Stack Pointer)
<br>x/10x $sp：查看sp(stack pointer，栈顶)开始10个单位的数据(16进制)，每个单位是一个字(在64位机器中是8字节)
<br>next：n，步进step over
<br>step：s，步入step in
<br>disas/disass/disassemble：反汇编指令。有许多选项，如 /m, /r。
<br>我们用gdb查看变量的地址：<br>(gdb) print &amp;local_h
$5 = (int *) 0x7fffffffde0c
(gdb) info frame
Stack level 0, frame at 0x7fffffffde20:
 rip = 0x55555555515c in hello (stack.c:5); saved rip = 0x7fffffffde2f
 called by frame at 0x7fffffffde28
 source language c.
 Arglist at 0x7fffffffde10, args: 
 Locals at 0x7fffffffde10, Previous frame's sp is 0x7fffffffde20
 Saved registers:
  rbp at 0x7fffffffde10, rip at 0x7fffffffde18


(gdb) print &amp;local_i
$6 = (int *) 0x7fffffffdedc

(gdb) i f
Stack level 0, frame at 0x7fffffffdef0:
 rip = 0x5555555551a4 in main (stack.c:17); saved rip = 0x7ffff7c29d90
 source language c.
 Arglist at 0x7fffffffdee0, args: 
 Locals at 0x7fffffffdee0, Previous frame's sp is 0x7fffffffdef0
 Saved registers:
  rbp at 0x7fffffffdee0, rip at 0x7fffffffdee8
<br><br>每当一个函数被调用时，都会创建一个全新的栈帧。和系统调用/中断等一样，我们需要在栈帧销毁时回到原函数的下一条指令继续执行。这就需要保存类似的一系列的上下文信息。其中，一部分信息由调用函数（Caller）保存，另一部分信息由被调用函数（Callee）保存。<br>int add(int x, int y){
	return x + y;
}
int main(){
	int a = 32;
	int b = 64;
	int sum = add(a, b); // &lt;-- line 7
}
<br>函数调用发生在第七行。调用函数会先将参数 b 和 a 的值压栈。然后将下一条指令的返回地址给压栈。之后，调用函数还需要保存部分寄存器（可能被被调函数修改的易失寄存器，比如 EAX, ECX, EDX 等）。被调用函数会保存使用频率相对低的寄存器（EBX, EDI, ESI 等），另外还会将函数里的局部变量压栈。<br><br><br><br>一个进程的生命周期从创建(new) 个进程到进程的 终止(terminated)，一般会经历五种不同的状态：<br>
<br>新建态(New)
<br>就绪态(Ready)
<br>运行态(Running)
<br>等待态(Waiting)
<br>终止态(Terminated)
<br><br>当一个新的进程被创建时，该进程会首先进入新建态(new)，这是进程生命周期中的一个瞬间过程。在这个瞬间的状态中，操作系统会为进程创建一个PCB，初始化PCB和进程的状态，随后将指令指针指向指令入口地址。之后，进程会等待操作系统的许可，以进入就绪态(ready) 队列。<br>
<br>在桌面操作系统中，进程通常会被自动批准进入就绪态。
<br>RTOS中，为避免系统资源饱和，可能会对进程的准入进行延迟处理，以满足进程的时限要求。
<br>每个新进程的创建都会有一个父进程。一般情况下，引起进程创建的主要有三类事件：<br>（1）系统启动；<br>
（2）用户请求（exec()系统调用）；<br>
（3）其他进程复制（fork()系统调用）。<br><br>在<a data-href="4. System Boots Up" href="https://congzhi.wiki/congzhi's-os-series/4.-system-boots-up.html" class="internal-link" target="_self" rel="noopener nofollow">4. System Boots Up</a>的最后，我们简单了解了一下Linux这种类Unix系统是如何启动的。我们看到，在系统启动时，有些进程在“明处”，而有些进程在“暗处”。我们所能看到的实际上都是用户可见的进程（user-visible process），而还有很多进程是我们看不到的，它们时刻支持着系统的运行。对于这类进程，我们称之为守护进程(Daemon)。<br><br>进程fork()出来的进程是指一个正在运行的进程通过调用fork()系统调用来创建一个新的子进程。这个子进程是父进程的副本，拥有相同的代码和数据，但在操作系统中作为一个独立的进程运行。<br>#include &lt;unistd.h&gt;

pid_t fork();
/* 
Parameters: None.

Return value: 
	- On success: Returns the process ID (PID) of the child process to the parent process, and 0 to the child process.
	- On failure: Returns -1 and sets errno appropriately.
*/
<br>通过不同的返回值，我们可以区分父子进程并执行不同的branch逻辑代码。<br><br>用户请求创建的进程是指用户通过操作系统界面或命令行输入指令，要求系统启动某个应用程序或服务。例如，用户双击桌面上的图标或在命令行输入启动命令，这些操作都会触发进程的创建。下面是exec 系列函数的两个常见变体，用于替换子进程的地址空间，使其执行新的程序。<br>#include &lt;unistd.h&gt;

int execl(const char *path, const char *arg, ...);
/* 
Parameters:
	1. path: The path to the executable file.
	2. arg: The argument list, terminated by a NULL pointer.

Return value:
	- On success: Does not return, as the new program replaces the current process.
	- On failure: Returns -1 and sets errno appropriately.
*/
<br>int execv(const char *path, char *const argv[]);
/* 
Parameters:
	1. path: The path to the executable file.
	2. argv: An array of argument strings, terminated by a NULL pointer.

Return value:
	- On success: Does not return, as the new program replaces the current process.
	- On failure: Returns -1 and sets errno appropriately.
*/
<br>在这个过程中，每个进程都会有相应的父进程负责其创建过程。要启动某个应用程序时，会先使用fork系统调用来创建一个子进程，然后在子进程中使用exec系列系统调用（如execl、execv等）来加载并执行新的程序。<br><br>当进程执行完毕或由于某种原因被终止，进程就会进入终止态(terminated)。在这个状态下，操作系统会回收该进程所占用的资源。同样，进程进入终止态也有几种不同的原因，比如：<br>（1）Normal exit (voluntary)；<br>
（2）Error exit (voluntary)；<br>
（3）Fatal error (involuntary)；<br>
（4）Killed by another process (involuntary)<br>进程终止后，操作系统会收集进程的一些信息（会计信息等）并移除进程的PCB。<br><br>正常退出是指进程自愿完成其任务并退出。这通常发生在用户关闭应用程序或进程完成其预定任务时。例如用户关闭一个应用程序或编译器完成编译任务后退出。<br><br>错误退出是指进程遇到错误并自愿退出。例如，程序尝试访问无权限的目录时，可能会选择退出并返回错误代码。当遇到某种错误时，我们常常使用exit()系统调用来终止程序，参数数值表示了代码退出时的状态，以便后续的跟踪。<br>#include &lt;stdlib.h&gt;

void exit(int status);
/* 
Parameters:
	1. status: The exit status of the process. Typically, 0 indicates success, and non-zero indicates failure.

Return value: No return.
*/
<br>用exit()退出时，操作系统会在进程进入终止态前释放其持有的资源。<br><br>致命错误是指进程遇到无法恢复的错误并被操作系统强制终止。例如，发生段错误或除零错误时，操作系统会强制终止进程。<br><br>进程可能会被其他进程强制终止。这通常发生在用户通过任务管理器终止无响应的程序，或者父进程决定终止其子进程。<br><br>和函数结束时返回值一样，当进程终止也会返回一个“码”，这是一个整数值。表示进程在终止时的状态。这个代码用于指示进程是否成功执行或是否发生了错误。<br>
<br>成功执行：进程成功完成其任务，通常会返回一个值0。
<br>错误发生：进程执行遇到错误，通常返回一个非零值。不同的值用于代表不同类型的错误。
<br>在Linux中，退出码的范围往往是 0-255，这些退出码可以帮操作系统或用户了解进程的执行结果。根据退出码采取相应的措施。<br><br><br>我们说进程通常而言会有五种状态，其实我们提到的是进程的五态模型，包括新建态、就绪态、运行态、等待态和终止态。任何运行中的进程在生命周期中都可能经历这五种不同的状态。通过将进程划分为不同的状态，操作系统能够更方便的管理计算机资源，为进程分配所需要的资源。<br><br>在进程的五态模型中，除了我们之前介绍的新建态和终止态，进程往往还会出现就绪态、运行态和等待态(waiting)/阻塞态(blocked)/睡眠态(sleeping)。<br>当进程具备可执行的条件，进程就会进入就绪态。这时，进程会等待被调度器分配CPU时间片来执行。同一时间，可能会有多个进程同时处于就绪态，以一定的顺序等待CPU的调度。为了管理这些就绪进程，操作系统会将这些进程放到一个链表实现的队列中来管理。<br>一旦就绪态的进程获得CPU时间片，开始执行代码，那么它就进入了运行态。运行态的进程可能会由于各种各样的情况重新进入就绪态或者进入阻塞态。<br>如果进程需要等待某个事件（如I/O操作的完成、资源的可用等）因而无法继续进行，进程就会被阻塞而进入等待队列。当事件发生（I/O操作已经完成）了，阻塞的进程会被唤醒，重新进入就绪态。<br><img alt="Pasted image 20250113004224.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20250113004224.jpg"><br>在五态模型下，进程的状态转变可能会出现以下情况：<br>
<br>NULL&nbsp;-&gt;&nbsp;New：新进程的创建。
<br>New&nbsp;-&gt;&nbsp;Ready：当进程创建完成后，系统将其放入就绪队列，等待调度器的调度。
<br>Ready&nbsp;-&gt;&nbsp;Running：操作系统的进程调度器选择就绪态进程，为其分配CPU资源。
<br>Ready&nbsp;-&gt;&nbsp;Exit：在被调度之前进程就被其他进程终止（可能是父进程）。
<br>Running&nbsp;-&gt;&nbsp;Ready：进程的时间片用完或由于其他调度策略导致进程失去CPU资源（被动）。
<br>Running&nbsp;-&gt;&nbsp;Blocked：进程等待某个事件的发生而自愿放弃CPU资源。
<br>Running&nbsp;-&gt;&nbsp;Exit：通常是进程正常退出，也可能是运行过程中发生错误或被终止。
<br>Blocked&nbsp;-&gt;&nbsp;Ready：阻塞进程接收到事件完成的信号，进入就绪态等待操作系统调度。
<br><br>为了方便管理，操作系统将不同状态的进程放入不同的队列当中进行管理，这个队列是链式的，方便进行PCB的插入和删除。以下是这些链式队列的大致结构。<br><img alt="Pasted image 20241130180123.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241130180123.jpg"><br>当进程被阻塞进入阻塞态时，操作系统会将阻塞的进程插入到阻塞队列中进行管理，根据不同原因的阻塞，阻塞队列可能有多个。<br><img alt="Pasted image 20241130182530.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241130182530.jpg"><br><br>在五态模型中，我们的视角一直局限于主存。然而，当主存资源耗尽时，我们可以将一些暂时用不到的进程交换（swap）到二级存储器（外存）中，从而腾出更多的资源留给系统中的其他进程，同时也能在一定程度上避免死锁的发生。这就是为什么我们引入七态模型。<br><br>在引入七态模型后，我们增加了两个新的状态：Suspended Ready(就绪挂起) 和&nbsp;Suspend Blocked (阻塞挂起)。这两个状态使得操作系统能够更高效地管理主存和外存资源。<br>当进程资源被交换到外存中时，我们就称进程被挂起了。在七态模型中，我们就引入了两种挂起态，即进程可以在就绪态被挂起(Suspended ready)，也可以在阻塞态被挂起(Suspended blocked)。<br><img alt="Pasted image 20241018163535.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241018163535.png"><br><br><br><br>在之前学习中断时，我们介绍了中断上下文的保存。当时，我们所关心的进程生命周期为：进程创建 -&gt; 使用一些系统调用 -&gt; 进程结束。而且系统一时间只能运行一个进程，并不考虑程序的并发执行和进程阻塞等其他因素。因此，中断上下文往往很简单，只包含一些寄存器，因为系统调用结束后回到用户态继续执行时所需的上下文信息很少。<br>然而，CPU从头到尾一次只运行一个程序显然是不能接受的。这样不仅会导致用户体验变差，CPU的利用率也可能很低。为了解决这种情况，人们提出了多道程序设计的理念，使得当一个进程等待I/O时，调度器会调度其他进程到CPU上运行。为了使系统更用户友好，我们可以让系统内的应用轮流地各执行1ms，使用户感觉所有进程都在同时运行。这就是分时多任务系统的理念。<br>在之后的阶段中，我们会介绍很多CPU调度的相关策略。为了使CPU的利用率和系统响应速度更好，操作系统需要选择特定的调度策略对系统内的进程进行调度。CPU调度决定了在任意时间点，哪个进程应该获得CPU的使用权。只要CPU调度发生了，必然牵扯到不同进程的状态转换，只要状态转换了，系统就需要保存进程的上下文信息。<br><br>我们之前提到了，任何对进程的操作最终都会反映在PCB的修改上。当一个进程由于某些原因从运行态上转换成其他状态时，为了保证进程在被暂停后能够恢复并正确继续执行，我们需要保存进程内部（PCB）的一些状态信息。这个信息就是进程上下文。进程上下文通常包括：<br>
<br>CPU寄存器的状态：这包括通用寄存器(如AX，BX，CX等)、程序计数器PC、堆栈指针BP，SP、指令寄存器IBR、状态寄存器(如EFLAGS)等。
<br>进程的内存状态：这包括代码本身(CS)、相关的数据、堆栈以及文件描述符等资源。
<br>进程的特定控制信息：如进程ID、进程的优先级、进程的账户信息、进程的调度状态等。
<br>进程切换时状态时，硬件会自动保存一些上下文（PC寄存器），操作系统会保存剩下的上下文。<br><br>当OS需要调度一个进程切换到另一个进程时，它会保存进程的上下文，并恢复下一个要运行进程的上下文。这个保存和恢复的过程被称为上下文切换。<br><img alt="Pasted image 20241130023834.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241130023834.jpg"><br><br>进程切换开销是上下文切换中所耗费的系统开销，如上图进程P1执行前后的空闲时间段，这段空闲时间段完全被进程切换所占用。在分时系统中，进程的切换开销往往是调度器选择时间片长度的重要考量因素。使得CPU在处理进程间切换的时间占整个CPU运行时间的比重在一个合理的范围上。<br><br>一般情况下，导致进程上下文切换的情况有以下三种：<br>
<br>Interrupts
<br>Multitasking
<br>User/Kernel switch
<br>Interrupts:&nbsp;中断是硬件或软件发出的信号，表明需要处理器立即注意的事件。当CPU接收到中断信号时会暂停当前执行的进程(或线程)，保存其状态，并切换到一个专门的中断处理程序来响应和处理这个事件。处理完中断后，操作系统可以选择:<br>
<br>恢复被中断的进程的执行。（系统调用这类简单的中断可以只保存中断上下文）
<br>切换到另一个进程，特别是在中断处理期间如果有更高优先级的进程变为就绪状态的情况。
<br>Multitasking:&nbsp;多任务处理是操作系统为了更高效地利用处理器资源而进行的进程调度。操作系统会根据特定的调度策略，决定何时将正在运行的进程切换出处理器，以及何时让新的进程或线程占用处理器资源。上下文切换的需求通常来源于以下两种情形：主动和被动，这部分将在进程的状态及转换部分解释。<br>Kernel/User Switch:&nbsp;This trigger is used when the OS needed to switch between the&nbsp;<a data-tooltip-position="top" aria-label="https://www.geeksforgeeks.org/difference-between-user-mode-and-kernel-mode/" rel="noopener nofollow" class="external-link" href="https://www.geeksforgeeks.org/difference-between-user-mode-and-kernel-mode/" target="_blank">user mode and kernel mode</a>.When switching between user mode and kernel/user mode is necessary, operating systems use the kernel/user switch.<br><br>本节课的开始，我们说引起进程创建的主要有系统启动、用户请求和其他进程复制的三类事件。那实际情况如何，n个进程是如何变到n+1个进程的？这些就是我们本小节拓展所要解释的，同时更详细地探索这些系统调用实际上都做了什么。<br><br>在<a data-href="4. System Boots Up" href="https://congzhi.wiki/congzhi's-os-series/4.-system-boots-up.html" class="internal-link" target="_self" rel="noopener nofollow">4. System Boots Up</a>中，我们最后简单地提了一嘴，在Linux中，进程号为1的进程是所有进程的祖先进程，init（或systemd）进程是系统启动时由内核创建的第一个进程。之后它会作为父进程启动一些守护进程和用户进程。然后再由这些用户进程生成自己的子进程，这些过程就是通过fork()系统调用完成的。<br><br>在前面，我们查看了fork()系统调用和exec()系列系统调用的一些函数原型。当父进程用fork()系统调用生成子进程时，一个虚拟内存映像完全一样的子进程就会被创建出来。fork()函数很特别，它有两个返回值，用于区分父子进程。我们可以用不同的返回值来执行不同的逻辑。<br><img alt="Pasted image 20241130023659.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241130023659.jpg"><br>虽然我们说子进程的内存空间是父进程的拷贝，但是实际上操作系统并不会真的原封不动地复制整个进程内存空间。这时因为操作系统用到了写时复制的技术，我们在内存管理的章节中会学到。<br><br>子进程创建好了之后，我们可以继续使用父进程的代码逻辑。但大多数时候，我们都想让子进程执行其他的程序，这时候就会用exec()系列的系统调用把当前的进程内存空间进行替换。下面的两个程序就展示了这两种截然不同的子进程执行逻辑。<br>// fork.c

#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/wait.h&gt; 

int main(){
	int ret = fork();
	if(ret == 0){
		printf("This is child process.\n");
	}
	else{
		printf("This is parent process.\n");
		wait(NULL);
	}
	return 0;
}
<br>// fork.c

#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/wait.h&gt; 

int main() {
    int ret = fork();
    if (ret == 0) {
        char *args[] = { NULL }; 
        execv("./hello", args);
    } else {
        wait(NULL); 
    }
    return 0;
}
<br>上面的例子中，我们用 fork() 和 execv() 系统调用来创建一个子进程，并在子进程中执行一个新的程序。在子进程中，使用 execv() 系统调用执行新的程序 ./hello。execv() 替换当前进程的地址空间，使其执行新的程序。而在父进程中，我们调用wait()系统调用，等待子进程结束，避免出现僵尸进程。<br>当我们使用strace -f ./fork时，我们会看到程序实际上用到了两个execve()和一个clone()系统调用。第一个execve()用于将当前进程替换为 ./fork 程序；接下来，通过 clone() 实现父进程内存空间的复制（fork() 库函数实际上是对 clone() 系统调用的封装）；在子进程中，execv 系统调用被用来执行新的程序 ./hello。<br>execve("./fork", ["./fork"], 0x7ffeae4313f8 /* 55 vars */) = 0
...
clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLDstrace: Process 20909 attached
, child_tidptr=0x72b7e9c79a10) = 20909
...
[pid 20909] execve("./hello", [], 0x7fffaaac2478 /* 55 vars */) = 0
...
[pid 20909] exit_group(0)               = ?
[pid 20909] +++ exited with 0 +++
&lt;... wait4 resumed&gt;NULL, 0, NULL)       = 20909
--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=20909, si_uid=1000, si_status=0, si_utime=0, si_stime=0} ---
exit_group(0)                           = ?
+++ exited with 0 +++
<br>在第二种执行逻辑中，其实有一步有些许的多余。我们先是克隆父进程的内存映像，接着对其进行替换。那我们为什么不在最开始的时候就创建一个新的子进程，避免不必要的内存复制操作。而且 Linux 并不保证fork()之后父/子进程执行的先后性。<br><br>posix_spawn 提供了一个更高级的接口，简化了进程创建和执行的过程。posix_spawn 使用 clone3 系统调用来创建一个新的子进程。与 fork 不同，posix_spawn 不会复制父进程的内存空间，而是直接创建一个新的进程，并立即执行指定的程序。它的函数原型如下：<br>#include &lt;spawn.h&gt;

int posix_spawn(pid_t *restrict pid, const char *restrict path,
                const posix_spawn_file_actions_t *file_actions,
                const posix_spawnattr_t *restrict attrp,
                char *const argv[restrict],
                char *const envp[restrict]);
/* 
Parameters:
	1. pid: A pointer to a variable where the process ID of the child process will be stored.
	2. path: The path to the program to be executed.
	3. file_actions: A pointer to a posix_spawn_file_actions_t structure that specifies file actions to be performed in the child process before executing the program. Can be NULL.
	4. attrp: A pointer to a posix_spawnattr_t structure that specifies attributes for the child process. Can be NULL.
	5. argv: An array of argument strings passed to the new program. The array must be terminated by a NULL pointer.
	6. envp: An array of environment strings passed to the new program. The array must be terminated by a NULL pointer.

Return value:
	- On success: Returns 0 and stores the process ID of the child process in the variable pointed to by pid.
	- On failure: Returns an error number (positive integer) and sets errno appropriately.
*/
<br><br>测试代码如下，这段代码和我们前面fork.c的作用相同：<br>// spawn.c

#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/wait.h&gt;
#include &lt;spawn.h&gt;
#include &lt;stdlib.h&gt;

extern char **environ;

int main() {
    pid_t pid;
    char *args[] = { "./hello", NULL };

    int status = posix_spawn(&amp;pid, "./hello", NULL, NULL, args, environ);
    if (status == 0) {
        printf("Child process created with PID: %d\n", pid);
        waitpid(pid, NULL, 0); 
    } else {
        perror("posix_spawn failed: ");
    }
    return 0;
}
<br><br>我们不再这里示例strace -f ./spawn了，我们想一想相比于fork()，posix_spawn()带给我们哪些好处。看看上面的代码，你可能已经发现一个最直接的好处，即posix_spawn 将进程创建和程序执行结合在一个调用中，简化了代码逻辑，减少了开发者犯错的可能。<br>通过 posix_spawn_file_actions_t 和 posix_spawnattr_t 结构体，可以在创建新进程时指定文件操作和进程属性，减少了额外的系统调用。<br>此外，在使用posix_spawn()时，使用的clone()系统调用实际上会有CLONE_VM和CLONE_VFORK这两个字段。CLONE_VM表示子进程将与父进程共享同一个内存空间，但是不会共享内核资源（文件描述符、信号处理）；CLONE_VFORK表示在子进程调用execve()或_exit()之前，父进程会被挂起。<br><br>我们在上面看到，fork()和posix_spawn()都用到了不同类型的clone()来生成一个子进程。clone()为我们提供了细粒度的操作，我们可以用clone()完成很多有趣的操作。甚至上线程都是用类似的clone3()系统调用完成的。clone()的函数原型如下：<br>#include &lt;sched.h&gt;

int clone(int (*fn)(void *), void *child_stack, int flags, void *arg, ...);
/* 
Parameters:
	1. fn: A pointer to the function to be executed by the child process. This function takes a single argument of type void* and returns an int.
	2. child_stack: A pointer to the stack space for the child process. The stack grows downwards, so this should point to the end of the allocated stack space.
	3. flags: A bitmask of flags that control the behavior of the child process. Common flags include:
		- CLONE_VM
		- CLONE_FS
		- CLONE_FILES
		- CLONE_SIGHAND
		- CLONE_PARENT
		- CLONE_THREAD
		- CLONE_VFORK
	4. arg: A pointer to the argument to be passed to the function fn.

Return value:
	- On success: Returns the process ID (PID) of the child process.
	- On failure: Returns -1 and sets errno appropriately.
*/
<br><br>clone3()是clone()的改进，相比于后者，clone3()有许多优势，如：更灵活的参数传递、可扩展性更佳等。clone3()的函数原型如下：<br>#include &lt;sched.h&gt;

int clone3(struct clone_args *cl_args, size_t size);
/* 
Parameters:
	1. cl_args: A pointer to a struct clone_args, which contains various fields to specify the behavior and properties of the child process.
	2. size: The size of the struct clone_args structure.

Return value:
	- On success: Returns the process ID (PID) of the child process.
	- On failure: Returns -1 and sets errno appropriately.
*/
<br>struct clone_args {
    uint64_t flags;
    int64_t pidfd;
    uint64_t child_tid;
    uint64_t parent_tid;
    uint64_t exit_signal;
    uint64_t stack;
    uint64_t stack_size;
    uint64_t tls;
    uint64_t set_tid;
    uint64_t set_tid_size;
    uint64_t cgroup;
};
/* struct clone_args fields:
- flags: A bitmask of flags that control the behavior of the child process. Common flags include CLONE_VM, CLONE_FS, CLONE_FILES, CLONE_SIGHAND, CLONE_PARENT, CLONE_THREAD, CLONE_VFORK, CLONE_SYSVSEM, CLONE_SETTLS, CLONE_PARENT_SETTID, and CLONE_CHILD_CLEARTID.
- pidfd: A file descriptor that refers to the PID of the child process.
- child_tid: A pointer to a location where the child process's thread ID will be stored.
- parent_tid: A pointer to a location where the parent process's thread ID will be stored.
- exit_signal: The signal to be sent to the parent when the child exits.
- stack: A pointer to the stack space for the child process.
- stack_size: The size of the stack space.
- tls: A pointer to the thread-local storage (TLS) area.
- set_tid: A pointer to an array of TIDs to be set in the child.
- set_tid_size: The number of TIDs in the set_tid array.
- cgroup: A file descriptor referring to the cgroup to which the child process should be added.
*/
<br><br>clone()和clone3()拥有基本相同的flags，用这些不同的flags，我们就可以完成各种各样有趣的事情。常见的flags和相关的释义如下：<br>/* Common flags:
- CLONE_VM: The child process shares the same memory space as the parent process.
- CLONE_FS: The child process shares the same file system information as the parent process.
- CLONE_FILES: The child process shares the same file descriptors as the parent process.
- CLONE_SIGHAND: The child process shares the same signal handlers as the parent process.
- CLONE_PARENT: The child process has the same parent process as the calling process.
- CLONE_THREAD: The child process is placed in the same thread group as the calling process.
- CLONE_VFORK: The parent process is suspended until the child process calls execve() or _exit().
- CLONE_SYSVSEM: The child process shares System V semaphore adjustments with the parent process.
- CLONE_SETTLS: The child process uses the TLS (Thread-Local Storage) area specified in the tls field.
- CLONE_PARENT_SETTID: The child's TID is set in the parent_tid field in the parent process.
- CLONE_CHILD_SETTID: The child's TID is set in the child_tid field in the child process.
- CLONE_CHILD_CLEARTID: The child process's TID is cleared in the child_tid field when the child exits.
- CLONE_UNTRACED: The child process is not traced by the parent process.
*/
<br><br>#define _GNU_SOURCE
#include &lt;sched.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/wait.h&gt;
#include &lt;linux/sched.h&gt;
#include &lt;sys/syscall.h&gt;

struct clone_args {
    uint64_t flags;
    int64_t pidfd;
    uint64_t child_tid;
    uint64_t parent_tid;
    uint64_t exit_signal;
    uint64_t stack;
    uint64_t stack_size;
    uint64_t tls;
    uint64_t set_tid;
    uint64_t set_tid_size;
    uint64_t cgroup;
};

extern char **environ;

int main() {
    pid_t pid;
    char *args[] = { "./hello", NULL };
    struct clone_args cl_args = {
        .flags = CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND | CLONE_PARENT_SETTID | CLONE_CHILD_CLEARTID,
        .pidfd = 0,
        .child_tid = 0,
        .parent_tid = 0,
        .exit_signal = SIGCHLD,
        .stack = 0,
        .stack_size = 0,
        .tls = 0,
        .set_tid = 0,
        .set_tid_size = 0,
        .cgroup = 0
    };

    pid = syscall(SYS_clone3, &amp;cl_args, sizeof(cl_args));
    if (pid == -1) {
        perror("clone3 failed");
        exit(EXIT_FAILURE);
    }

    if (pid == 0) {
        // Child process
        execve("./hello", args, environ);
        perror("execve failed");
        exit(EXIT_FAILURE);
    } else {
        // Parent process
        printf("Child process created with PID: %d\n", pid);
        waitpid(pid, NULL, 0);
    }
    return 0;
}
<br><br><br><br><br><br>在Linux下，所有的进程都是以树形结构组织起来的。所有的进程都有其父进程（除了根进程&nbsp;init或&nbsp;systemd）。在bash命令行下，你可以用pstree命令来查看这样的树形结构,以获得所有进程及其父子关系的信息。同时，用ps命令可以查看当前系统下进程的各种信息。<br><img alt="Pasted image 20241018191021.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241018191021.jpg"><br>在命令行下，一条命令实际上是由当前的&nbsp;bash&nbsp;创建一个进程，后面的参数是传给这个进程的参数。比如&nbsp;ps、gcc&nbsp;等。而平时我们经常使用&nbsp;./hello&nbsp;来执行程序，为什么&nbsp;ps&nbsp;这些命令行命令不需要&nbsp;./&nbsp;呢？这是因为这些命令的路径问题。<br>命令行中的&nbsp;ps、gcc&nbsp;等命令通常位于系统的 环境变量&nbsp;PATH&nbsp;指定的目录中，例如&nbsp;/usr/bin、/bin&nbsp;等。bash&nbsp;会在&nbsp;PATH&nbsp;环境变量指定的目录中查找命令，所以直接输入命令名即可执行。<br>而&nbsp;./hello&nbsp;表示在当前目录下查找并执行&nbsp;hello&nbsp;程序，./&nbsp;显式指定了当前目录。如果没有在&nbsp;PATH&nbsp;中包含当前目录，就需要使用&nbsp;./&nbsp;来运行当前目录中的程序。<br><br><br>进程组是操作系统中用于管理和组织进程的一种机制。一个进程组由一个或多个进程组成，这些进程可以相互协作完成某些任务。进程组的主要目的是为了方便信号的发送和管理。当我们用shell执行命令时，进程组就会被创建。<br>sleep 100 # a proc group with only 1 process.

echo "Hello, World!" &gt; temp.txt &amp; cat temp.txt # a proc group with 2 processes.
<br>在Linux和Unix系统中，每个进程都有一个进程组ID，并且有其组标识符PGID。进程组中的所有进程共享同一个PGID。通常而言，fork()父进程和子进程在一个进程组中，进程组的ID是组长的ID。我们可以通过getpgid(pid_t pid)来获取指定进程的进程组ID。<br>子进程除了加入父进程的进程组外，还可以创建或加入其他的进程组。我们通过setpgid(pid_t pid, pid_t pgid)来设置指定进程的进程组ID，如果pid参数为0，则使用调用者的进程id，如果pgid是0，则由pid指定的进程id作为进程组id。比如setpgid(0, 0);就表示创建一个当前进程为进程组长的进程组。<br>进程组的一个常见用途是信号处理。信号会被发生给进程组的全体成员。当用户在终端中按下Ctrl+C时，系统会向前台进程组发送一个中断信号（SIGINT），终止该进程组中的所有进程。此外，进程组还会由于作业控制，因为在shell中，一个进程组通常被看作为一个作业(job)。<br>例如，以下代码展示了如何创建一个新的进程组并将子进程加入该进程组：<br>#include &lt;unistd.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main() {
    pid_t pid = fork();

    if (pid == -1) {
        // fork failed
        perror("fork");
        exit(EXIT_FAILURE);
    } else if (pid == 0) {
        // Child process
        setpgid(0, 0); // Create a new process group with the child process as the leader
        printf("Child process: PID = %d, PGID = %d\n", getpid(), getpgid(0));
        // Child process code here
    } else {
        // Parent process
        printf("Parent process: PID = %d, PGID = %d\n", getpid(), getpgid(0));
        // Parent process code here
    }

    return 0;
}
<br>在这个示例中，子进程通过setpgid(0, 0)创建了一个新的进程组，并将自己设置为该进程组的组长。父进程和子进程的进程组ID可以通过getpgid(0)获取。<br><br>#include &lt;unistd.h&gt;
#include &lt;sys/types.h&gt;

pid_t getpgid(pid_t pid);
/* 
Parameters:
	1. pid: Process ID of the target process. If pid is 0, getpgid() returns the PGID of the calling process.

Return value:
	- On success, returns the PGID of the specified process.
	- On failure, returns -1 and sets errno to indicate the error.
*/
<br>int setpgid(pid_t pid, pid_t pgid);
/* 
Parameters:
	1. pid: Process ID of the target process. If pid is 0, setpgid() sets the PGID of the calling process.
	2. pgid: Process Group ID to be assigned. If pgid is 0, the PGID is set to the PID of the process specified by pid.

Return value:
	- On success, returns 0.
	- On failure, returns -1 and sets errno to indicate the error.
*/
<br><br>几个进程组又可以组成一个会话。会话中的所有进程都拥有相同的会话ID，会话ID是session leader的进程组ID，保存在task_struct中的session成员中。一个会话中有一个前台进程组，剩下的都作为后台进程组存在。<br><img alt="Pasted image 20250128013013.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20250128013013.png"><br>
前台任务会阻塞当前会话，而后台任务不会阻塞当前会话。我们可以在shell命令后面加入&amp;来将进程组作为后台任务运行。只有前台进程组中的进程可以读写终端，而后台进程组中的进程只能写终端，不能读终端。<br>sleep 5
# You cannot do anything before 5s passed.

sleep 5 &amp; # background proc group
# You can do anything here.
<br>此外，当你使用ctrl+C发生终止信号（下节课会了解到）时，信号只会发送给前台进程组的所有进程，而后台进程组中的进程不会受影响。<br><br>#include &lt;unistd.h&gt;
#include &lt;sys/types.h&gt;

pid_t getpgrp(void);
/* 
Parameters: None.

Return value:
	- On success, returns the PGID of the calling process.
	- On failure, returns -1 and sets errno to indicate the error.
*/
<br>int setpgrp(void);
/* 
Parameters: None.

Return value:
	- On success, returns 0.
	- On failure, returns -1 and sets errno to indicate the error.
*/
<br>pid_t getsid(pid_t pid);
/* 
Parameters:
	1. pid: Process ID of the target process. If pid is 0, getsid() returns the SID of the calling process.

Return value:
	- On success, returns the SID of the specified process.
	- On failure, returns -1 and sets errno to indicate the error.
*/
<br>pid_t setsid(void);
/* 
Parameters: None.

Return value:
	- On success, returns the SID of the calling process.
	- On failure, returns -1 and sets errno to indicate the error.
*/
<br>pid_t tcgetpgrp(int fd);
/* 
Parameters:
	1. fd: File descriptor of the terminal.

Return value:
	- On success, returns the PGID of the foreground process group associated with the terminal.
	- On failure, returns -1 and sets errno to indicate the error.
*/
<br>int tcsetpgrp(int fd, pid_t pgrp);
/* 
Parameters:
	1. fd: File descriptor of the terminal.
	2. pgrp: Process Group ID to be set as the foreground process group.

Return value:
	- On success, returns 0.
	- On failure, returns -1 and sets errno to indicate the error.
*/
<br>pid_t tcgetsid(int fd);
/* 
Parameters:
	1. fd: File descriptor of the terminal.

Return value:
	- On success, returns the SID of the session leader for the terminal.
	- On failure, returns -1 and sets errno to indicate the error.
*/
<br><br>终端用于绑定一个会话，作为其控制台使用。<br><br><br>如果父进程先于子进程结束终止，那么子进程就会变成孤儿进程。孤儿进程会被进程号为1的进程（init和systemd）接管，成为它们的子进程。孤儿进程并不会对系统造成直接的危害，操作系统会在孤儿进程运行完毕之后回收进程资源。但是，我们仍然有义务给孤儿进程一些关爱。<br><img alt="Pasted image 20241018205838.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241018205838.png"><br>虽然init进程会接管孤儿进程，但是大量的孤儿进程会增加init进程的负担。而且孤儿进程可能会使调试变得复杂。为了更美好的明天，我们应尽量避免孤儿进程的产生。如果孤儿进程并不关键，我们可以用kill -SIGKILL [PID]杀死孤儿进程。(ꈨຶꎁꈨຶ)۶”<br><br>当子进程先于父进程终止但父进程尚未调用&nbsp;wait()&nbsp;系统调用时，子进程会变成僵尸进程。僵尸进程保留在系统中，直到父进程读取其退出状态。如果父进程终止前没有读取其状态，僵尸进程占用的进程表项资源就会一直被其霸占。特别是在发生&nbsp;fork&nbsp;bomb&nbsp;的情况下，这种情况会变得尤为危险，因为进程表项的数量是有限的（通常为&nbsp;65536&nbsp;项）。<br><img alt="Pasted image 20241018203144.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241018203144.png"><br><br>wait()系统调用会阻塞父进程，知道任意一个子进程终止。当子进程终止，wait()会返回子进程的PID，子进程的退出状态会被存储到父进程提供的地址中。<br>#include &lt;sys/types.h&gt;
#include &lt;sys/wait.h&gt;

pid_t wait();
/* 
Parameters: None.

Return value:
	- On success: Returns the process ID (PID) of the terminated child process.
	- On failure: Returns -1 and sets errno appropriately.
*/
<br>pid_t waitpid(pid_t pid, int *status, int options);
/* 
Parameters:
	1. pid: The process ID of the child process to wait for. If pid is -1, wait for any child process.
	2. status: Pointer to an integer where the exit status of the child process will be stored.
	3. options: Options to modify the behavior of waitpid (e.g., WNOHANG).

Return value:
	- On success: Returns the process ID (PID) of the terminated child process.
	- On failure: Returns -1 and sets errno appropriately.
*/
<br><img alt="Pasted image 20241018204321.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241018204321.png"><br>当子进程用exit()系统调用终止执行后，内核会给父进程发送一个SIGCHLD信号，理想情况下，父进程应当读取子进程的信息并删除子进程的进程表项(process entry)。所以其实每个子进程执行结束都会变成僵尸进程，保留最小退出信息。<br><img alt="Pasted image 20241018205735.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241018205735.png"><br><br>下面是一个fork炸弹，尽管在运行时不会产生僵尸进程，但是进程会源源不断地产生子进程，子进程又会源源不断的产生子进程，不一会儿你就会发现系统卡死了。这时，系统资源耗尽，无法再启动新进程，现有的进程可能会很慢甚至无法响应。<br>#include &lt;unistd.h&gt;
int main()
{
   while(1) 
      fork();    
   return 0;
}
<br><img alt="Pasted image 20241018202903.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241018202903.png"><br><br>通过对上面的fork炸弹做一些修改，你可以用top命令来直观地查看该进程所产生的僵尸进程。这个例子中的子进程将不会再产生子进程，因而不会产生上面进程数量的指数爆炸，更加安全一些。每隔一秒，父进程就会fork一次，子进程会迅速结束并变成僵尸进程。<br>#include &lt;sys/types.h&gt;
#include &lt;sys/wait.h&gt;
#include &lt;unistd.h&gt;
#include &lt;stdio.h&gt;

int main() {
	while(1){
	    pid_t pid = fork();
	    if (pid == 0) {
	        _exit(0);
	    } else {
		    // wait(NULL);
		    // printf("Child cleanup!\n");
	        printf("A zombie is made.\n");
		    sleep(1);
	    }
	}
    return 0;
}
<br>我们前面说过，僵尸进程会占用系统的进程表项资源，而且这种资源是有限的。当所有PIDs都被僵尸进程霸占后，我们将不能够再创建新进程。在这种极端的情况下，我们只能够重启系统了。那如何解决这些僵尸进程呢？<br>最好的解决方案当然是编写正确的程序，确保子进程退出后父进程读取其进程表项。然而，犯错有时是难免的。在这个例子中，我们可以直接终止父进程，这样 init 进程会接管并清理掉这些僵尸进程。然而在实际中，我们并不能直接关闭服务器（用户还等着服务器提供服务呢），因此需要手动清理偶尔产生的僵尸进程。在学习信号时我们会讲到。<br><br><br>这里我们简单了解一下信号，为如何用信号处理僵尸进程做铺垫。作为进程间通信的一部分，我们将在进程间通信中详细探讨信号。<br><br>每个发送给进程的信号都有相应默认的处理程序(handler)。如果进程自己没有为特定信号注册相应的处理程序，那么收到信号时，就会执行默认的处理程序。下面举例了一些常用的 POSIX.1-1990 标准下的信号：<br><br><br>如果进程想选择特立独行，想要接收到信号之后执行自定义的处理程序，对于大多数信号而言，这样是可行的，这样可以在信号触发时执行特定的逻辑。例如，当按下 Ctrl+C (SIGINT 信号) 时，进程可以执行一些清理操作或记录日志，而不仅仅是简单地终止进程。<br>对于任何事件发生的信号，信号都必须被响应处理，那怕在处理程序中什么都不做。此外，我们有两个特殊的信号 SIGKILL 和 SIGSTOP 不可以被捕获、阻塞或忽略。SIGKILL 信号用于强制终止进程，而 SIGSTOP 信号用于停止进程的执行。无论进程如何设置信号处理程序，这两个信号都会被内核直接处理，以确保系统能够对不响应的进程进行强制干预。<br><br>在命令行界面，我们常用 kill [PID] 命令来杀掉一个 PID 进程号的进程。通常情况下，使用 kill 8080 这样的命令会向8080号进程发送一个 SIGHUP 的信号，默认情况下，这个进程就会被终止（当然你可以注册另外的处理程序来进行额外的善后工作）。<br>如果进程仍然阻塞，你可以用 kill -9 8080 来强制终止这个进程。这个 -9 参数就是向进程发送9号信号（SIGKILL），而默认下是1号信号（SIGHUP）。<br><br>在子进程退出时，父进程需要读取其进程表项以避免僵尸进程的出现。然而，尽管子进程终止后会像父进程发送SIGCHILD的信号，但是我们在上面看到，对于这个信号，默认的处理方式却是忽略。要避免僵尸进程的产生，我们的想法是在父进程收到子进程退出时发来的SIGCHILD信号后读取相应的进程表项。<br><br>我们用下面的函数注册信号的服务例程，其中signo是想要捕获的信号号，后面的sig_handler是对该信号的服务例程。<br>// This is a void handler
void sig_handler(int signo){
	/* Handle the signal in some way. */
}
// Register the handler
void (*signal(int signo, void(*sig_handler)(int))) (int);
<br><br>我们前面说过，要避免僵尸进程，我们就需要使父进程wait()子进程，但这一过程会阻塞父进程，这是我们不想要看到的。其实如果父进程结束，这些僵尸进程会被进程号为1的进程接管并自动释放资源，但是父进程可能是服务器，需要一直运行下去。<br>我们知道，当子进程运行结束，子进程就会给父进程发送SIGCHLD信号。我们可以让父进程捕捉这样的信号，然后在其中调用wait()系统调用，从而释放子进程的进程表项，即杀死僵尸进程：<br>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;sys/wait.h&gt;
#include &lt;signal.h&gt;
#include &lt;unistd.h&gt;

void SIGCHLD_handler(int signo) {
    while (waitpid(-1, NULL, WNOHANG) &gt; 0){
        printf("Released in SIGCHLD_handler!\n");
    }
}
int main() {
    signal(SIGCHLD, SIGCHLD_handler);
    while (1) {
        pid_t pid = fork();
        if (pid == 0) {
            printf("Hello from child process.\n");
            sleep(1);
            exit(0);
        } else if (pid &lt; 0) {
            perror("fork failed");
            exit(1);
        }
        //sleep(5); // Nonsense, program will wake up after handler being called.
    }
    return 0;
}
<br>运行程序后，打开另一个终端。用命令ps -aux | grep 'Z'查看当前系统下的僵尸进程，应当每隔1秒钟就多一个僵尸进程。当我们用ctrl+c给进程发送SIGINT终止进程时，你会看到这些僵尸进程的资源都被释放掉了。如果你想子程序退出后立即释放，就将上面的注释删掉。<br><br>sigaction是一个规范的、扩展性更好的信号处理框架。<br>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;sys/wait.h&gt;
#include &lt;signal.h&gt;
#include &lt;unistd.h&gt;

void SIGCHLD_handler(int signo) {
    while (waitpid(-1, NULL, WNOHANG) &gt; 0) {
        printf("Released in SIGCHLD_handler!\n");
    }
}
void SIGINT_handler(int signo) {
    while (waitpid(-1, NULL, WNOHANG) &gt; 0) {
        printf("Released in SIGINT_handler!\n");
    }
    exit(0);
}

int main() {
    struct sigaction sa;

    sa.sa_handler = SIGCHLD_handler;
    sigemptyset(&amp;sa.sa_mask);
    sa.sa_flags = SA_RESTART;
    sigaction(SIGCHLD, &amp;sa, NULL);

    sa.sa_handler = SIGINT_handler;
    sigemptyset(&amp;sa.sa_mask);
    sa.sa_flags = 0;
    sigaction(SIGINT, &amp;sa, NULL);

    while (1) {
        pid_t pid = fork();
        if (pid == 0) {
            printf("Hello from child process.\n");
            sleep(1);
            exit(0);
        } else if (pid &lt; 0) {
            perror("fork failed");
            exit(1);
        } else {
            printf("Child created!\n");
        }
        // sleep(5); // Nonsense, program will wake up after handler being called.
    }
    return 0;
}
]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/6.-processing-the-processes.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/6. Processing The Processes.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 21 Mar 2025 15:56:19 GMT</pubDate><enclosure url="https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20241110161041.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20241110161041.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[6.5 Inter-Process Communications]]></title><description><![CDATA[ 
 <br><br><br><br>人类需要沟通和交流，交流与合作共同建造了我们这个美好的世界。在原始村落时代，人类只能通过面对面交流进行协作，沟通范围局限在同村居民之间。电话的发明打破了物理距离的壁垒，使跨地域的实时沟通成为可能，极大地扩展了协作的边界。<br>对于进程也一样，在没有网络的时代，进程间通信只局限在一台主机上。随着网络基础设施的建设，我们已经进入了光纤入户(FTTH)的时代。进程间通信不再具有局限性，远距离的通信成为了可能。通过网络，分布在不同地理位置的进程可以互相通信，协同工作，共同完成复杂的任务。<br><br>我们有两类进程间通信，一类是同一台主机上的进程间通信，还有一类是不同主机之间的进程间通信。这两类进程间通信的主体思想都很简单，即发送方进程发送信息，接收方进程接收信息。<br>不管是哪种进程间通信，你都需要考虑收发过程的同步和互斥问题、同步性和异步性，我们本节不做介绍，相关内容将在后续的同步互斥篇章进行介绍。<br><br>对于同一台主机上的进程间通信，其核心思想是在内核或用户空间创建共享存储区域，其中一个进程W往里面写，另外一个进程R往外读。这种模型本质上就是生产者-消费者问题的实现，需要同步机制来保证缓冲区空、缓冲区满和竟态条件的问题。共享存储器可以用内核缓冲区(pipe) 或 用户内存空间(Shared memory, shm) 的方式来实现。<br>还有将数据放到磁盘中的IPC机制叫内存映射文件(Memory&nbsp;Mapped&nbsp;Files)。这种方法允许多个进程通过映射文件到共享内存的方式进行通信，并将数据持久化到磁盘上。<br>此外，信号也是一种进程间通信方式。与上面不同的是，信号本身并不携带信息(messages)，因而也被称为轻量级的进程间通信机制。信号主要用于通知进程发送某些事件，比如终止、中断和自定义事件等。<br><br>如果两个进程不在同一台主机上，我们就需要借助网络的力量，使用操作系统提供的Socket&nbsp;API向特定的主机发送消息报文。对于上层应用者来说，完全可以将Socket看作是邮递数据的“邮政公司”。我们将数据交给“邮政公司”（Socket&nbsp;API），它们会妥善处理一切。<br>通过Sockets，分布在不同主机上的进程可以建立连接，进行数据交换。这种方式广泛应用于网络应用、分布式系统和客户端-服务器模型中。<br><br><br>进程间通信总是伴随着不同的格式进行的，正如人类交流一样。讲话方（发送方）使用不同的语言不同（不同的格式），如果聆听方听不懂那种语言（没有对应的parser函数），这种交流便是没有意义的。在进程间通信中，尽管信息都是以0和1在计算机世界中传输的，但只要规定了一定的格式，接收双方达成一定共识（使用同一种格式），交流就可以达成。<br>常见的通信格式有JSON和XML，通过格式提供的约定，我们可以按照接收/发送之间的约定将信息进行包装(packet)和解码(parse)（也叫序列化和反序列化）。我们也可以使用官方所提供的库。<br><br>一旦涉及到信息的发送和接收，收发的顺序是需要有一定的约束的。<br><br>同步通信要求发送方和接收方在某一特定时间点上进行协同。比方如，发送方必须等待接收方准备好接收数据后再发送。这种方式的优点是确保数据的可靠传输，但可能会导致等待时间的增加。<br><br>异步则允许发送方和接收方无需协同、独立工作。发送方在发送数据后可以继续处理其他任务，而接收方在准备好接收数据时再进行处理。这种方式提高了系统的并发性和效率，但需要额外的机制来确保数据的一致性和完整性。<br><br><br>对于不同主机间的通信，虽然还有其他的方式，但我们主要借助 Socket API 来进行。尽管你可以用网络来交换进程之间的数据。但一般来说，socket 并不作为 IPC 的一部分。<br><br>Socket API的命名灵感来源于电源插座🔌(power socket)。当设备与电源插座连接时，插座允许设备连接并交换电流，当设备断开与电源插座的连接，电流的交换也随之结束。同样的道理，Socket API也允许不同的进程之间进行数据的交流。Socket API为上层应用封装屏蔽了下层传输层的细节。<br>我们知道，传输层提供两种通信范式：数据报(datagram) 和 连接流(connection stream)。TCP是面向连接的传输层协议，为上层的应用提供可靠传输(reliable transfer)服务。TCP保证数据完整有序的送达。常见的使用TCP作为传输层协议的应用层协议有FTP、SMTP和HTTP。<br>UDP是面向非连接的协议，它为上层应用提供不可靠的传输服务。由于UDP不需要建立连接，因此UDP不保证数据的完整性和顺序，但它的开销较小，传输速度较快。所以UDP比TCP更加简单高效。UDP常见于语音/视频通话和游戏中。<br><br>在Linux等类Unix的系统中，socket也被视为一种文件。所以你能复用部分标准的文件处理（read、write）来操作socket。但是socket提供了一些其他的语义抽象。这种抽象简化了编程接口，你可以用socket系统调用来创建一个socket。<br>socket()的函数原型如下：<br>#include &lt;sys/socket.h&gt;

int socket(int domain, int type, int protocol);
/* 
Parameters:
	1. Domain: address format; 
		- AF_INET: IPv4
		- AF_INET6: IPv6
		- AF_UNIX or AF_LOCAL: Unix domain sockets
		- AF_PACKET: Low-level packet interface
	    - AF_NETLINK: Kernel/user-space communication
	    - et cetera...
	2. Type: what kind of data;
		- SOCK_DGRAM: Datagram socket (UDP)
	    - SOCK_STREAM: Stream socket (TCP)
	    - SOCK_RAW: Original socket (IPPROTO_RAW)
	    - SOCK_SEQPACKET
	3. Protocol: how data is transported; 0 for type inference
		- IPPROTO_TCP: Used with SOCK_STREAM for TCP
	    - IPPROTO_UDP: Used with SOCK_DGRAM for UDP
	    - IPPROTO_ICMP: Used with SOCK_RAW for sending/recving ICMP packets
		- IPPROTO_SCTP
Return value: 
	- Return a socketfd on success.
	- -1 on failure.
*/
<br><br>socket()系统调用有三个参数，分别是domain, type 和 protocol。<br><br>这个参数定义了地址格式和通信范围，决定了socket的底层协议族。常见的有AF_INET, AF_INET6 和 AF_UNIX/AF_LOCAL。这里的AF_指的是Address Family。AF_INET 和 AF_INET6用于网络通信，其中一个用于IPv4，一个用于IPv6。它们的地址结构也是不一样的，分别是：struct sockaddr_in和struct sockaddr_in6。<br>AF_UNIX或者AF_LOCAL，则用于本地的进程间通信。因为它并不涉及网络通信，所以没有网络协议栈封包拆包所造成的开销。<br><br>这个参数定义了socket的类型，用于选择数据的传输方式和服务类型。我们关注SOCK_STREAM跟SOCK_DGRAM。前者，SOCK_STREAM定义socket的类型为可靠、有序和双向的面向连接的字节流（TCP），和SOCK_DGRAM，也就是将socket的类型定义为不可靠的无连接的数据报文。<br><br>这个参数明确地指定传输层使用何种网络协议。我们关注IPPROTO_TCP和IPPROTO_UDP。当你设置为0时，内核会根据前两个参数自动推导。<br><br>当组合非法或不兼容，就会返回-1并设置errno = EINVAL。<br><br>socket()函数中有许多参数，选择不同的参数，我们可以创建不同类型的socket。下面，我们将用IPv4创建一个TCP和一个UDP的传输协议的网络连接。<br><br>#include &lt;sys/socket.h&gt;
#include &lt;netinet/in.h&gt;

int main() {
    int sockfd = socket(AF_INET, SOCK_STREAM, 0);
    if (sockfd &lt; 0) {
        perror("TCP socket creation failed");
        return 1;
    }
    return 0;
}
<br><br>#include &lt;sys/socket.h&gt;
#include &lt;netinet/in.h&gt;

int main() {
    int sockfd = socket(AF_INET, SOCK_DGRAM, 0);
    if (sockfd &lt; 0) {
        perror("UDP socket creation failed");
        return 1;
    }
    return 0;
}
<br><br>socket创建好之后，我们就可以使用setsockopt&nbsp;函数通过各种选项来配置和调整套接字。这个函数允许你控制和修改套接字的行为，比如超时时间、缓冲区大小、重用地址、启用或禁用特定协议特性等。在后面的学习中，检测另一方是否还在发送报文就少不了setsockopt()。<br>int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen);
/* 
Parameters:
	1. sockfd: The file descriptor of the socket on which to set the option.
	2. level: The level at which the option is defined (e.g., SOL_SOCKET for socket-level options, IPPROTO_TCP for TCP options).
	3. optname: The option name to set.
	   - Under SOL_SOCKET level:
	     1. SO_RCVTIMEO: set receive timeout time.
	     2. SO_SNDTIMEO: set send timeout time.
	     3. SO_REUSEADDR: allow local address reuse.
	     4. SO_KEEPALIVE: keep connections alive by enabling periodic transmissions.
	     5. SO_RCVBUF: set the receive buffer size.
	     6. SO_SNDBUF: set the send buffer size.
	     7. SO_LINGER: linger on close if data is present.
	     8. SO_BROADCAST: permit sending of broadcast messages.
	     9. SO_ERROR: retrieve and clear the socket error status.
	     10. SO_OOBINLINE: leave received out-of-band data in the input stream.
	   - Under IPPROTO_TCP level:
	     1. TCP_NODELAY: disable Nagle's algorithm.
	     2. TCP_KEEPIDLE: set the idle time before keep-alive probes are sent.
	     3. TCP_KEEPINTVL: set the interval between keep-alive probes.
	     4. TCP_KEEPCNT: set the number of keep-alive probes to be sent.
	   - Under IPPROTO_IP level:
	     1. IP_TTL: set the IP time-to-live value.
	     2. IP_MULTICAST_TTL: set the multicast time-to-live value.
	     3. IP_MULTICAST_LOOP: control the loopback of multicast packets.
	     4. IP_ADD_MEMBERSHIP: join a multicast group.
	     5. IP_DROP_MEMBERSHIP: leave a multicast group.
	   - Under IPPROTO_IPV6 level:
	     1. IPV6_V6ONLY: restrict the socket to IPv6 communications only.
	     2. IPV6_MULTICAST_HOPS: set the multicast hop limit.
	     3. IPV6_MULTICAST_LOOP: control the loopback of multicast packets.
	     4. IPV6_JOIN_GROUP: join an IPv6 multicast group.
	     5. IPV6_LEAVE_GROUP: leave an IPv6 multicast group.
	4. optval: A pointer to the buffer containing the value for the option. This buffer contains the value to be set for the specified option.
	5. optlen: The size, in bytes, of the buffer pointed to by optval.

Return value:
	- On success: Returns 0.
	- On failure: Returns -1, and errno is set to indicate the error. You can use the perror function or strerror to print the error message.
*/
<br><br>我们在<a data-href="Endianness" href="https://congzhi.wiki/some-notes/endianness.html" class="internal-link" target="_self" rel="noopener nofollow">Endianness</a>中对大小端字节序进行了介绍。在网络传输中，为了避免两台计算机因为大小端问题产生的一系列问题，我们规定将大端序作为网络字节序。这样做不但统一了计算机网络的交流方式，也使得工程师抓包后方便阅读各种信息（大端序）。<br><br>在arpa/inet.h头文件中，提供了一些转换字节序的库函数。如果你不清楚你所用系统的字节序，建议加上这些转换函数来确保数据在网络上传输时的正确性：<br>#include &lt;arpa/inet.h&gt;

// Host TO Network Long/Short
uint32_t htonl(uint32_t hostlong); 
uint16_t htons(uint16_t hostshort); 

// Network TO Host Long/Short
uint32_t ntohl(uint32_t netlong); 
uint16_t ntohs(uint16_t netshort); 
<br><br>除此之外，arpa/inet.h头文件中还有将点分十进制（十六进制）与网络字节序数值进行转换的库函数。这些转换在设置或接收网络地址时非常有用。<br>#include &lt;arpa/inet.h&gt;
int inet_aton(const char *cp, struct in_addr *inp);
/* 
Parameters:
	1. cp: IP address in decimal form (as a string, e.g., "192.168.1.1")
	2. inp: Pointer to a struct in_addr where the function will store the network address

Return value: Returns 1 on success, 0 if the input is not a valid IP address.
*/
<br>// Internet Presentation TO Network
int inet_pton(int af, const char *src, void *dst);
/* 
Parameters:
	1. af: Address family (AF_INET for IPv4, AF_INET6 for IPv6)
	2. src: IP address in decimal form (as a string, e.g., "192.168.1.1")
	3. dst: Pointer to a buffer where the function will store the network address (usually a struct in_addr or struct in6_addr) 

Return value: Returns 1 on success, 0 if inputs is not a valid IP address, and -1 on error.
*/
<br>// Internet Network TO Presentation
const char *inet_ntop(int af, const void *src, char *dst, socklen_t size);
/* 
Parameters:
	1. af: Address family (AF_INET for IPv4, AF_INET6 for IPv6)
	2. src: Pointer to the network address structure (e.g., struct in_addr or struct in6_addr)
	3. dst: Pointer to a buffer where the function will store the IP address in decimal form (as a string)
	4. size: Size of the destination buffer 

Return value: 
	- Returns a pointer to the destination buffer `dst` on success. 
	- NULL on failure.
*/
<br><br><br>和发快递时你需要知道对方的地址信息一样，当我们在网络上传输报文时，你需要用一种约定好的格式来创建一个address structure。我们用&nbsp;sockaddr_in&nbsp;结构体来表示IPv4地址：<br>#include &lt;netinet/in.h&gt;
#include &lt;arpa/inet.h&gt;

struct sockaddr_in {
    sa_family_t sin_family; // Address Family
    in_port_t sin_port;     // Port number
    struct in_addr sin_addr; // IP address
};
struct in_addr {
    uint32_t s_addr; // 32-bit IPv4 address
};
<br><br>我们用addrinfo来表示IPv6的套接字的地址信息。这个结构体是一个通用的结构体，能够表示各种不同类型的地址。<br>struct addrinfo {
    int              ai_flags;
    int              ai_family;
    int              ai_socktype;
    int              ai_protocol;
    socklen_t        ai_addrlen;
    struct sockaddr *ai_addr;
    char            *ai_canonname;
    struct addrinfo *ai_next;
};
<br><br>此外，我们还有sockaddr_un结构体用于表示Unix domain sockets:<br>#include &lt;sys/un.h&gt;

struct sockaddr_un {
    sa_family_t sun_family; // Address Family (AF_UNIX)
    char sun_path[108];     // Path name
};
<br><br>每当主机上有运行一个程序，那个程序就会注册一个端口号以便标识程序的入口。计算机上有多个端口（一般为 65536 个），通过这些端口，数据可以准确的发送道正确的进程处。向邮递员用门牌号来发件送件一样，网络通信也需要这些端口号来接收数据。<br><br>在定义并初始化IPv4/IPv6的套接字结构体时，我们需要把人类可读的字符串转换成机器可读的IP地址格式以便路由器和其他网络设备能够进行正常的处理和数据包路由。<br>我们前面在<a data-tooltip-position="top" aria-label="6.5 Inter-Process Communications > 2.2.4.2 Decimal Presentation and Network Byte Order Address Conversion" data-href="6.5 Inter-Process Communications#2.2.4.2 Decimal Presentation and Network Byte Order Address Conversion" href="https://congzhi.wiki/congzhi's-os-series/6.5-inter-process-communications.html#2.2.4.2_Decimal_Presentation_and_Network_Byte_Order_Address_Conversion" class="internal-link" target="_self" rel="noopener nofollow">这里</a>讨论了一点IP地址和Sting互相转换的库函数。其中inet_aton用于将IPv4地址从点分十进制字符转换成二进制格式。而后者inet_pton是更通用的函数，支持IPv4和IPv6的地址转换。<br><br>网络地址定义好之后，我们需要按照特定的顺序来初始化&nbsp;sockaddr_in&nbsp;结构体的各个字段。<br>#include &lt;stdio.h&gt;
#include &lt;string.h&gt; // for memset
#include &lt;netinet/in.h&gt;
#include &lt;arpa/inet.h&gt;

int main() {
    struct sockaddr_in addr;
    memset(&amp;addr, 0, sizeof(addr)); // Clear the addr structure
    addr.sin_family = AF_INET; // Use IPv4.
    addr.sin_port = htons(8080); // Indicate the port number.
    addr.sin_addr.s_addr = inet_addr("192.168.1.1"); // inet_addr(INADDR_ANY); 
    // or inet_pton(AF_INET, "192.128.1.1", &amp;addr.sin_addr); // Recommended
    printf("Address: %s, Port: %d\n", inet_ntoa(addr.sin_addr), ntohs(addr.sin_port));
    return 0;
}
<br><br>这个函数的主要作用是将主机名（如"example.com"）或服务名（如&nbsp;"http"）转换为可以用于创建套接字的地址信息。通常是客户端用来获取服务器端的网络地址信息来创建想要的套接字。得到服务器的地址，客户端就可以与服务器建立连接。<br>#include &lt;sys/types.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;netdb.h&gt;

int getaddrinfo(const char *node,    // e.g. "www,example.com" or IP
				const char *service, // e.g. "http" or port number
				const struct addrinfo *hints,
				struct addrinfo **res);

/* 
Parameters:
	1. node: hostname or IP address
	2. service: protocol or port number
	3. hints: used to restrict the kind of connection you want
	4. res: pointer to be updated with the result

Return value: 
	- Returns 0 on success, and update the pointer res points to. 
	- Else on error.
*/
<br>当我们使用getaddrinfo时，会返回结构体addrinfo，通过其中的ai_addr字段，我们可以得到指向的sockaddr_in结构体。如下：<br>struct addrinfo hints, *res;
getaddrinfo("example.com", "http", &amp;hints, &amp;res);

struct sockaddr_in *ipv4 = (struct sockaddr_in *)res-&gt;ai_addr;
<br><br>我们将主机上的不同的进程用端口号进行标识，在网络的进程间通信中，我们只要知道主机的地址（即IP地址）和端口号，我们就能和那个“远方的”进程进行通信。在网络通信中，客户端要做到实际上远不及服务器端做的多。客户端要做的，就是打招呼（connect()）并说话（socket通信）。<br><br>下面，我们看看客户端是如何通过connect()来与服务器打招呼的，以下是其函数原型：<br>int connect(int sockfd, struct sockaddr *addr, socklen_t len);
/* Blocking the thread by default.
Parameters:
	1. sockfd: The file descriptor for the socket to be connected. This is the integer value returned by the socket() function.
	2. addr: A pointer to a struct sockaddr, which contains the address of the target host. This can be cast to a pointer of specific address types, like sockaddr_in for IPv4 or sockaddr_in6 for IPv6.
	3. len: The size, in bytes, of the address structure pointed to by addr. Typically, this will be sizeof(struct sockaddr_in) or sizeof(struct sockaddr_in6).

Return value:
	- On success: Returns 0.
	- On failure: Returns -1, and errno is set to indicate the error. You can use the perror function or strerror to print the error message.
*/
<br><br>在之前，我们学过了getaddrinfo函数，通过这个函数，我们就可以得到服务器的网络地址。在客户端眼中，我们就知道了服务器叫什么名字了。知道了网络地址，我们就可以通过connect函数来与服务器建立连接，为之后的交流做好铺垫。<br>struct addrinfo hints;
struct addrinfo *res;
int sockfd;

memset(&amp;hints, 0, sizeof(hints));
hints.ai_family = AF_INET;
hints.ai_socktype = SOCK_STREAM;

getaddrinfo("www.example.com", "80", &amp;hints, &amp;res);
sockfd = socket(res-&gt;ai_family, res-&gt;ai_socktype, res-&gt;ai_protocol);

int status = connect(sockfd, res-&gt;ai_addr, res-&gt;ai_addrlen);
<br>在这个例子中，如果返回值status为 0 就表示服务器收到了我们的连接请求并成功建立连接。<br><br>在网络通信中，服务器的职责可比客户端大得多。要和服务器打招呼，客户端可不需要知道自己的名字是什么，操作系统会自动为客户端分配一个临时的端口号。而服务器可不一样，因为要时时刻刻监听来自客户端的连接请求。服务器必须显式调用bind()将套接字绑定到特定的端口号上。（毕竟要是你的名字要是随机的，客户端对建立连接将毫无头绪）<br>绑定完成之后，服务器开始运行并需要持续监听来自外界的连接请求，以便对客户端进行服务。当服务器监听到来自客户端的连接请求之后，客户端会接受并建立一个专门的套接字来于这个特定的客户端进行通讯。<br><br>bind()函数用来让进程与一个特定的端口号进行绑定的函数。<br>int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
/* 
Parameters:
	1. sockfd: The file descriptor of the socket to be bound. This is the integer value returned by the socket() function.
	2. addr: A pointer to a struct sockaddr, which contains the address to bind to the socket. This can be cast to a pointer of specific address types, like sockaddr_in for IPv4 or sockaddr_in6 for IPv6.
	3. addrlen: The size, in bytes, of the address structure pointed to by addr. Typically, this will be sizeof(struct sockaddr_in) or sizeof(struct sockaddr_in6).

Return value:
	- On success: Returns 0.
	- On failure: Returns -1, and errno is set to indicate the error. You can use the perror function or strerror to print the error message.
*/
<br>例子1：<br>#include &lt;sys/socket.h&gt;
#include &lt;netinet/in.h&gt;
#include &lt;arpa/inet.h&gt;
#include &lt;unistd.h&gt;
#include &lt;cstring&gt;
#include &lt;iostream&gt;

int main() {
    int sockfd;
    struct sockaddr_in server_addr;

    sockfd = socket(AF_INET, SOCK_STREAM, 0);
    if (sockfd == -1) {
        perror("socket");
        return 1;
    }

    memset(&amp;server_addr, 0, sizeof(server_addr));
    server_addr.sin_family = AF_INET;
    server_addr.sin_port = htons(8080);
    server_addr.sin_addr.s_addr = INADDR_ANY;

    if (bind(sockfd, (struct sockaddr *)&amp;server_addr, sizeof(server_addr)) == -1) {
        perror("bind");
        close(sockfd);
        return 1;
    }

    // Other code...
    close(sockfd);
    return 0;
}
<br>客户端进程的bind()并不是必要的，为什么？<br><br>listen()&nbsp;函数用于将套接字设置为被动模式，以便接受传入的连接请求。listen()系统调用会创建一个容量为backlog的队列保存未处理的客户端请求。我们会人为地设置一个backlog。当客户端与服务器的连接数等于这个数字时，客户端的连接将被服务器拒绝。<br>int listen(int sockfd, int backlog);
/* 
Parameters:
	1. sockfd: The file descriptor of the socket that will be put into a listening state. This is the integer value returned by the socket() function.
	2. backlog: The maximum length to which the queue of pending connections may grow. Typically a small positive integer.

Return value:
	- On success: Returns 0.
	- On failure: Returns -1, and errno is set to indicate the error. You can use the perror function or strerror to print the error message.
*/
<br>例子2：<br>// Assume the bind() function has been called

if (listen(sockfd, 10) == -1) {
    perror("listen");
    close(sockfd);
    return 1;
}

// Other code...
close(sockfd);
return 0;
<br><br>accept()&nbsp;函数用于接受传入的连接请求，从监听套接字队列中提取第一个连接请求，并为新的连接创建一个新的套接字。accept是一个阻塞调用(blocking call)，当调用accept时，客户端对服务器的监听将会被阻塞。也就是说，每一次服务器只能接受一个客户端的连接。<br>int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);
/* 
Parameters:
	1. sockfd: The file descriptor of the listening socket. This is the integer value returned by the socket() function and used by the bind() and listen() functions.
	2. addr: A pointer to a struct sockaddr, which will be filled with the address of the connecting entity. Can be cast to a pointer of specific address types, like sockaddr_in for IPv4 or sockaddr_in6 for IPv6.
	3. addrlen: A pointer to a socklen_t, which on input contains the size of addr, and on output contains the size of the address returned.

Return value:
	- On success: Returns a new file descriptor for the accepted socket.
	- On failure: Returns -1, and errno is set to indicate the error. You can use the perror function or strerror to print the error message.
*/
<br>例子3：<br>    // Assume bind() and listen() functions have been called

    sin_size = sizeof(struct sockaddr_in);
    new_fd = accept(sockfd, (struct sockaddr *)&amp;client_addr, &amp;sin_size);
    if (new_fd == -1) {
        perror("accept");
        close(sockfd);
        return 1;
    }

    std::cout &lt;&lt; "Connection accepted" &lt;&lt; std::endl;

    // Other code...
    close(new_fd);
    close(sockfd);
    return 0;
}
<br>如果你不关心客户端是谁，你可以将accept()后面的字段设置成NULL。届时，服务器就不需要存储客户端的这些信息了，简化了代码。<br>int new_fd = accept(sockfd, NULL, NULL);
<br>上面的例子中accept获得的新的文件描述符new_fd代表了与客户端的连接。你可以使用这个套接字进行接收和发送数据，而不需要手动维护客户端的地址信息。<br><br>当连接建立、一切准备就绪之后，通信就可以开始了。在TCP的网络通信中，我们主要使用send()和recv()两个函数来发送和接收信息。<br>因为套接字也可以看成是一种特殊的文件，所以你也可以使用最底层的read()和write()系统调用来接收和发送网络信息。在使用read()时，你需要通过循环一直接收数据，因为你不知道要接收多少数据。在write()时，你也需要使用循环来确保所有数据都能够发出去（缓存满）。<br><br>send()&nbsp;函数用于通过套接字发送数据。它将指定缓冲区中的数据发送到与套接字关联的另一端。send()操作是阻塞的，即如果套接字发送缓冲区已满，send()&nbsp;调用将阻塞，直到有足够的缓冲空间为止。<br>int send(int sockfd, const void* msg, int length, int flags);
/* 
Parameters
	1. sockfd: Socket to send the data to
	2. msg: Bytes of data to be sent
	3. length: Size of the message
	4. flags: Options, giving in 0 will suffice, common flags are:
	    - MSG_CONFIRM: Tell the link layer that the packet was received.
	    - MSG_DONTWAIT: Enable non-blocking operation.
	    - MSG_OOB: Send out-of-band data.
	    - MSG_PEEK: Peek at the incoming message.
	    - MSG_WAITALL: Wait for the full request or error.
	    - MSG_NOSIGNAL: Do not generate SIGPIPE.
	    - MSG_MORE: Sender will send more data.

Return value: number of bytes sent, returns -1 if something went wrong
*/
<br><br>recv()&nbsp;函数用于通过套接字接收数据。它会从指定的套接字接收数据并将其存储在缓冲区中。与&nbsp;send()&nbsp;类似，recv()也是阻塞的，即如果没有可用数据，recv()&nbsp;将阻塞程序，直到数据到达。<br>int recv(int sockfd, void* buffer, int length, int flags);
/* 
Parameters
	1. sockfd: Where to receive data from
	2. buffer: Where the data goes
	3. length: The maximum size of the buffer
	4. flags: Flags can also be 0 here, common flags are:
	    - MSG_CONFIRM: Tell the link layer that the packet was received.
	    - MSG_DONTWAIT: Enable non-blocking operation.
	    - MSG_OOB: Receive out-of-band data.
	    - MSG_PEEK: Peek at the incoming message.
	    - MSG_WAITALL: Wait for the full request or error.
	    - MSG_NOSIGNAL: Do not generate SIGPIPE.

Return value: 
	- Returns the number of bytes actually read into the buffer on success.
	- Returns 0 if the connection has been closed.
	- Returns -1 on error.
*/
<br><br>知道另一方是否还在发送报文并不容易。但是我们有一些机制来检测对方是否仍然在传输数据。我们的想法是，当一端发送了报文，一段时间后仍未接受到向本端发来的响应报文就断开连接。用这种方法防止程序一直阻塞下去。<br>这里，我们主要通过通过setsockopt设置超时时间、启用Keep-Alive等各种套接字属性。<br><br>TCP协议本身支持&nbsp;Keep-Alive&nbsp;机制，用于检测空闲连接是否仍然活跃。通过在协议层面发送探测报文并等待响应，可以判断连接的状态。可以使用setsockopt函数在应用程序中启用这项功能。<br>int enable_tcp_keepalive(int sockfd) {
	// Enable keep-alive.
    int optval = 1;
    setsockopt(sockfd, SOL_SOCKET, SO_KEEPALIVE, &amp;optval, sizeof(optval));

    int keepidle = 60; // 空闲时间（秒）
    int keepinterval = 10; // 探测报文发送间隔（秒）
    int keepcount = 3; // 最大重试次数

    setsockopt(sockfd, IPPROTO_TCP, TCP_KEEPIDLE, &amp;keepidle, sizeof(keepidle));
    setsockopt(sockfd, IPPROTO_TCP, TCP_KEEPINTVL, &amp;keepinterval, sizeof(keepinterval));
    setsockopt(sockfd, IPPROTO_TCP, TCP_KEEPCNT, &amp;keepcount, sizeof(keepcount));

    return 0;
}
<br>上面的例子中，我们启用了TCP所提供的Keep-alive机制。之后，我们还设置了其余几项参数：<br>
<br>keepidle：表示如果连接在keepidel秒内没有任何活动，开始发送Keep-Alive探测报文。
<br>keepinterval：表示每隔多少秒发送一次探测报文，直到收到对方的响应或达到最大重试次数。
<br>keepcount：表示在未收到对方响应时，最多发送keepcount次探测报文。如果在尝试这么多次后仍未收到响应，就认为连接已断开。
<br><br>通过设置接收超时时间，可以在指定时间内没有接收到数据时断开连接。这种方法对突发性传输较为有效，但可能会误判传输较慢的情形。<br>#include &lt;sys/types.h&gt;
int set_recv_timeout(int sockfd, int seconds) {
    struct timeval timeout;
    timeout.tv_sec = seconds;
    timeout.tv_usec = 0;

    if (setsockopt(sockfd, SOL_SOCKET, SO_RCVTIMEO, &amp;timeout, sizeof(timeout)) &lt; 0) {
        perror("setsockopt");
        return -1;
    }
    return 0;
}
<br><br>通过定期发送心跳包（短的空数据包）来确认连接是否保持。对方收到心跳包时，需要回复一个确认包。如果没有收到确认包，可以认为连接已经断开。心跳检测需要客户端和服务器两端共同配合。在客户端，同样需要处理心跳消息，并回复服务器发送的心跳包。<br>// server-side code
while (1) {
    const char *heartbeat = "HEARTBEAT";
    send(sockfd, heartbeat, strlen(heartbeat), 0);

    char buffer[1024];
    int bytes_received = recv(sockfd, buffer, sizeof(buffer), 0);
    if (bytes_received &lt; 0) {
        if (errno == EWOULDBLOCK || errno == EAGAIN) {
            printf("Receive timeout, no data received\n");
        } else {
            perror("recv");
            break;
        }
    } else {
        printf("Received heartbeat response: %.*s\n", bytes_received, buffer);
    }
    sleep(5);
}
// client side code
// ...
<br>这个例子仍需完善，因为没有结合超时机制，如果另一方一直不发送响应报文就会使得recv()调用无限期阻塞下去。<br><br>Sending and Receiving Struct Type. XML and JSON are popular format for information transfer.<br><br>不同于TCP，UDP是粗鲁的、没有教养的，因为UDP忽略了打招呼的过程。同时，UDP不保证数据包到达的完整性，因而UDP被称为无连接的、轻量级的通信协议。<br><br>sendto&nbsp;函数用于在无连接（如UDP）套接字上发送数据报（datagram）。<br>int sendto(int sockfd, const void *msg, size_t len, int flags, const struct sockaddr *dest_addr, socklen_t addrlen);
/* 
Parameters:
	1. sockfd: The socket file descriptor.
	2. msg: A pointer to the buffer containing the message to be sent.
	3. len: The length of the message in bytes.
	4. flags: Options to modify the behavior of the function.
	5. dest_addr: A pointer to the struct sockaddr containing the destination address.
	6. addrlen: The size of the destination address structure.

Return value:
	- On success: Returns the number of bytes sent.
	- On failure: Returns -1, and errno is set to indicate the error. You can use the perror function or strerror to print the error message.
*/
<br><br>recvfrom&nbsp;函数用于在无连接（如UDP）套接字上接收数据报（datagram）。<br>int recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen);
/* 
Parameters:
	1. sockfd: The socket file descriptor.
	2. buf: A pointer to the buffer where the received message will be stored.
	3. len: The length of the buffer.
	4. flags: Options to modify the behavior of the function.
	5. src_addr: A pointer to the struct sockaddr where the source address will be stored. Can be NULL.
	6. addrlen: A pointer to a socklen_t object which will contain the size of the source address structure.

Return value:
	- On success: Returns the number of bytes received.
	- On failure: Returns -1, and errno is set to indicate the error. You can use the perror function or strerror to print the error message.
*/
<br><br>This part will be discussed in the <a data-href="14. Asynchronous IO" href="https://congzhi.wiki/congzhi's-os-series/14.-asynchronous-io.html" class="internal-link" target="_self" rel="noopener nofollow">14. Asynchronous IO</a>.<br><br>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;curl/curl.h&gt;

int main(void) {
    CURL *curl;
    CURLcode res;

    curl_global_init(CURL_GLOBAL_DEFAULT);
    curl = curl_easy_init();
    if(curl) {
        curl_easy_setopt(curl, CURLOPT_URL, "http://example.com");
        curl_easy_setopt(curl, CURLOPT_FOLLOWLOCATION, 1L);
        res = curl_easy_perform(curl);
        if(res != CURLE_OK) {
            fprintf(stderr, "curl_easy_perform() failed: %s\n", curl_easy_strerror(res));
        }
        curl_easy_cleanup(curl);
    }
    curl_global_cleanup();
    return 0;
}
<br><br><br>size_t read_callback(char* buffer, size_t size, size_t nitems, void *inputdata);

// size_t: represents a size and can be treated like an integer
// buffer: the area where you are going to put the data to send
// nitems: the number of items
// return value: the number of bytes successfully put there, 0 signals EOF

<br><br>size_t write_callback(char *ptr, size_t size, size_t nmemb, void *userdata);

// size_t: represents a size and can be treated like an integer
// ptr: points to whatever data we have received
// nmemb: the size of the data
// size: always 1
// userdata: arbitrary structure we get to pass directly to this punction
// return value: number of bytes processed
<br><br>CURLcode curl_easy_setopt(CURL *handle, CURLOPT_READFUNCTION, read_callback);
CURLcode curl_easy_setopt(CURL *handle, CURLOPT_READDATA, void *pointer);

CURLcode curl_easy_setopt(CURL *handle, CURLOPT_WRITEFUNCTION, write_callback);
CURLcode curl_easy_setopt(CURL *handle, CURLOPT_WRITEDATA, void *pointer);
<br><br><br><br>当我们用管道机制进行进程间通信时，操作系统会在内核空间中划分额外的内核空间用于数据共享。Pipe是单向传输的（像水管一样），一个管道的数据只能向一个方向流动（写端到读端），所用如果你想实现全双工则需要两个管道。管道有两种实现机制：pipe()和mkfifo()。<br><img alt="Pasted image 20241130023253.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241130023253.jpg"><br>Pipe一般上是循环队列，管道缓冲区的大小（Linux上）通常是4KB-64KB之间。管道以字节流的方式通信，发送方每一次发送都会将消息分为很多个小块（一字节）之后将字节块放入队列中，然后接收方会一个字节一个字节的接收数据。pipe的系统调用提供同步机制（阻塞锁），如果缓冲区已满或为空时，写操作和读操作都会被阻塞，直到数据读出/写入。对于命名和匿名管道而言都是如此。<br><br>在类Unix的系统中，你可以用pipe()系统调用函数来创建用于进程间通信的匿名管道。匿名管道只能在有血缘关系的进程之间使用。匿名管道的创建函数如下：<br>#include &lt;unistd.h&gt;

pipe(int pipefd[2]);
// pipefd[0] is the read-end
// pipefd[1] is the write-end
<br><br>下面，我们举个创建匿名管道的例子：<br>#include &lt;sys/types.h&gt;
#include &lt;unistd.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;

int i = 100;
const char* str = "hello world";
char rdBuf[32];

int main(int argc, char const *argv[])
{
	int pipefd[2];
	if(pipe(pipefd) == -1){
		perror("pipe create fail");
		return -1;
	}
	if (fork() == 0){
		printf("this is child process\n");
		memset(readBuf, 0, 32);
		if (read(pipefd[0], rdBuf, 32) == -1){
			perror("read fail");
			return -1;
		}
		printf("I have read the character string: %s\n",rd);
		close(pipefd[0]);
	}
	else{
		printf("this is parent process\n");
		sleep(2);
		if (write(pipefd[1], str, strlen(str)) == -1){
			perror("write fail");
			return -1;
		}
		close(pipefd[1]);
	}
	return 0;
}
<br>参数pipefd是一个包含两个整型元素的数组，用来存放管道的读写文件描述符。<br>
<br>pipefd[0]是管道的读端，read(pipefd[0], buffer, sizeof(buffer))从管道中读出并写到buffer中。
<br>pipefd[1]是管道的写端，write(pipefd[1]), message, strlen(message) + 1) 将message中的数据写到管道里面。<br>
当pipe系统调用成功，返回0，失败返回-1并设置errno。
<br>只要任一端的文件描述符没有被关闭，pipe就会接着存在，也就是说只有我们close()pipe的两端之后，pipe才会被清理掉。<br><br>管道是一个特殊的文件类型，本质还是文件。我们用open函数打开磁盘文件的操作会将文件描述符(file descriptor, fd)存放在进程的虚拟空间中。在匿名管道的学习中，我们对这种管道“文件”并不敏感，因为匿名管道的文件描述符虽然产生了，但却是一直存放在进程的虚存中对内核空间的内存进行操作，本质上不进行对磁盘IO的操作，所以我们也就看不到相关的文件。<br>而fifo命名管道就有所不同了，创建命名管道的同时在也会在文件系统上创建一个fifo文件。这个文件是有名称的，任何进程只要知道这个名称，就可以通过该名称打开fifo文件从而与另一端进行通信。所以命名管道允许在多个不同进程之间传输数据。（fifo文件充当管道入口的作用）<br>命名管道在创建后会一直存在（持久性），直至显示删除，那怕没有进程使用。命名进程创建好后，对该管道的操作就和操作文件一样，使用open、read、write等系统调用来使用管道进行通信。由于命名管道不支持文件定位操作，且遵守先进先出的原则，所以命名管道也被称为 FIFO special file。<br><br>#include &lt;iostream&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;cstring&gt;

//写端

const char* pipe_name = "tmp";
const char* str = "hello world";
char readBuf[32];
memset(readBuf, 0, 32);
if (mkfifo(pipe_name, 0644) == -1){
	perror("mkfifo func error");
	return -1;
}
int fifo_Writefd = open(pipe_name, O_WRONLY);
if(fifo_Writefd == -1){
	perror("open fifofd error");
	return -1;
}
if(write(fifo_Writefd, str, strlen(str)) == -1)(
	perror("write func error");
	return -1;
)
close(fifo_Writefd);

//读端

const char* pipe_name = "tmp";
int fifo_Readfd = open(pipe_name, O_RDONLY);
if(fifo_Readfd == -1){
	perror("open fifofd error");
	return -1;
}
if(read(fifo_Readfd, readBuf, 32) == -1)(
	perror("write func error");
	return -1;
)
std::cout &lt;&lt; readBuf &lt;&lt; std::endl;
close(fifo_Readfd);
if(unlink(pipe_name) == -1){
	perror("unlink func error");
	return -1;
}
<br><br><br>在上面的命名管道小节中，我们其实提到了，在适用系统调用pipe()创建管道的文件描述符时，我们实际上并不用到磁盘。虽然我们进行了文件操作，但是这些操作都是在内存的内核区中进行的，并不会涉及实际的“对文件操作”。<br>所以，匿名管道(pipe)是用于有亲缘关系进程之间通信的一种方式。匿名管道是临时存在于内存中的，当所有相关进程终止或关闭管道文件描述符（读端和写端）后，匿名管道自动销毁。在对匿名管道操作时，我们并不需要调用unlink系统调用函数删除文件。<br><br>在非亲缘关系进程之间通信时，我们使用mkfifo命令创建命名管道(fifo)，fifo是一个有名字的特殊文件。当A进程创建了这个fifo，由于它具有文件名属性，因此B进程可以通过文件路径、文件名等属性对这个文件进行访问，通过访问fifo文件，B进程可以知道内核缓冲区的哪一部分作为管道使用。这就是fifo实现非亲缘关系进程通信的基本原理。<br>如果进程A使用mkfifo命令首次创建FIFO文件时，会在文件系统中创建一个相应的inode记录（首次访问文件系统）。之后用open()系统调用打开管道时，会读取inode表项以获取文件相关元数据，（第二次访问文件系统）。由于此前系统已经缓存了文件的inode，这时进程B通过系统上的inode记录打开FIFO文件并创建合适的fd就不再需要访问文件系统了。<br>请注意，这里说的使用I/O并不是说管道传输的数据会先放到磁盘上，这样太慢了。我们说使用I/O是指使用命名管道时会在文件系统（磁盘）上创建一个FIFO文件。这个文件的创建是使用I/O的。<br><br>共享内存的进程间通信机制划分出了一段内存用于共享，与管道不同的是，通常而言共享内存的方式能够划分的内存更大（通常管道分配4KB-64KB），而且共享内存段(shm)位于用户空间。<br><br>POSIX&nbsp;标准强调统一性和可移植性，所以POSIX的标准利用文件系统接口（文件描述符）来操作shm，也简化了系统的实现和使用。通常与mmap()结合使用，常用到的系统调用有：<br>
<br>shm_open：通过shm_open函数创建或打开一个共享内存对象，并返回一个文件描述符shm_fd。这个文件描述符将用于后续的共享内存操作，就像操作一个普通文件一样。
<br>ftruncate：使用ftruncate函数设置共享内存对象的大小。这一步确保共享内存对象有足够的空间来存储数据。
<br>mmap：通过mmap函数将共享内存对象映射到进程的地址空间，并返回这段内存的起始地址（*ptr）。这个过程使得你可以像操作普通内存一样操作共享内存。
<br>使用memcpy或strcpy：一旦共享内存被映射到地址空间，你可以使用标准的内存操作函数（如memcpy或strcpy）来操作这段内存。这个过程与操作普通内存没有区别。
<br>close(shm_fd)：在使用完共享内存后，通过close函数关闭共享内存对象的文件描述符。这个步骤类似于关闭文件，表示不再需要访问该共享内存对象。
<br>shm_unlink：最后，使用shm_unlink函数删除共享内存对象。这一步类似于删除文件，释放掉不再需要的共享内存对象。
<br><br>shm_open&nbsp;用于创建或打开一个共享内存对象，并返回一个文件描述符用于后续的内存操作。创建时会在文件系统（通常是/dev/shm）中显示一个对应的文件条目。<br>#include &lt;sys/mman.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;sys/stat.h&gt;

int shm_open(const char *name, int oflag, mode_t mode);
/* 
Parameters:
	1. name: The name of the shared memory object.
	2. oflag: The open flags (e.g., O_CREAT, O_RDWR).
	3. mode: The permission mode of the shared memory object (e.g., 0666).

Return value: Returns a file descriptor on success, -1 on failure and sets errno appropriately.
*/
<br><br>ftruncate&nbsp;用于设置共享内存段的大小，确保其有足够的空间来存储数据。由于在内存中页框的大小通常是4KB，所以在我们设置共享内存段大小时通常设置为4096的倍数。<br>int ftruncate(int fd, off_t length);
/* 
Parameters:
	1. fd: The file descriptor of the shared memory object.
	2. length: The size to set for the shared memory object in bytes.

Return value: Returns 0 on success, -1 on failure and sets errno appropriately.
*/
<br><br>close&nbsp;用于关闭共享内存对象的文件描述符，类似于关闭文件。<br>int close(int fd);
/* 
Parameters:
	1. fd: The file descriptor to close.

Return value: Returns 0 on success, -1 on failure and sets errno appropriately.
*/
<br><br>shm_unlink&nbsp;用于删除共享内存对象，类似于删除文件，释放不再需要的共享内存。对于POSIX共享内存，如果未调用shm_unlink函数来删除共享内存对象，那么它会继续驻留在系统内存中，直到系统重启或显式删除。<br>int shm_unlink(const char *name);
/* 
Parameters:
	1. name: The name of the shared memory object.

Return value: Returns 0 on success, -1 on failure and sets errno appropriately.
*/
<br>如果在shm_unlink之前没有close共享内存对象，该函数会标记这段共享内存，当所有进程都关闭描述符后，系统会清理资源（届时删除共享内存段）。<br><br>我们下面用代码简单演示一下POSIX中shm的创建（打开）、设置大小、关闭、删除shmfd的一系列操作。这里请注意，设置shm大小我们交给写进程来设置：<br>#include &lt;iostream&gt;
#include &lt;cstring&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/mman.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;fcntl.h&gt;

//Write process
const char* shm_name = "my_shm";
const char* str = "hello world";

int main(int argc, char const *argv[])
{
	int shm_fd = shm_open(shm_name, O_CREAT | O_RDWR, 0666);
	if (shm_fd == -1){
		perror("shm_open");
		exit(EXIT_FAILURE);
	}
	
	if (ftruncate(shm_fd, 4096) == -1) {
        perror("ftruncate");
        close(shm_fd);
        exit(EXIT_FAILURE);
    }

    void *ptr = mmap(0, 4096, PROT_WRITE, MAP_SHARED, shm_fd, 0);
    if (ptr == MAP_FAILED){
    	perror("mmap");
    	close(shm_fd);
    	exit(EXIT_FAILURE);
    }

	memcpy(ptr, str, strlen(str));
	close(shm_fd);

	std::cout &lt;&lt; "Character string's been sent" &lt;&lt; std::endl;
	return 0;
}

//Read process
const char* shm_name = "my_shm";
char rdBuf[32];

int main(int argc, char const *argv[])
{
	int rdshm_fd = shm_open(shm_name, O_RDONLY, 0666);

	void *ptr = mm(0, 4096, PROT_READ, MAP_SHARED, rdshm_fd, 0);
	if (ptr == MAP_FAILED){
    	perror("mmap");
    	close(rdshm_fd);
    	exit(EXIT_FAILURE);
    }
	std::cout &lt;&lt; "Read from shared memory: " &lt;&lt; (char*)ptr &lt;&lt;std::endl;

	close(rdshm_fd);
	shm_unlink(shm_name);
	return 0;
}
<br><br>既然在POSIX下万物皆文件，而且我们用shm_open系统调用会返回一个文件句柄，那么我们应该能在磁盘中找到相关的共享内存文件吧？没错，确实会如此。当我们执行下面一行代码int shm_fd = shm_open(shm_name, O_CREAT | O_RDWR, 0666);后，我们查看/dev/shm，应当可以看到相关的文件。运行后查看目录：<br>du@du-virtual-machine:~/Desktop/OS$ ls /dev/shm
my_shm
<br>实际上，共享内存在传递信息之前通过打开文件对象my_shm返回一个文件的描述符shm_fd。有了这个文件描述符，进程就可以对特定的共享内存段中进行读写操作（也就相当于fd实际上是共享内存段的索引）。写端进程在修改这部分内存时，数据会在内存中被更新，实现了数据在不同进程间的交换。结合信号量可以实现同步分次读写。<br><br>System V使用不同于POSIX标准的IPC机制，&nbsp;System&nbsp;V下的shm并不依赖文件系统持久存储（不同于POSIX中使用文件描述符和路径名管理共享内存段），而是通过特定的标识符（shmid）来管理。System&nbsp;V共享内存并不会持久化存储在文件系统中，而是存储在内存中，用于进程间的快速通信。相比于万物皆文件的POSIX而言效率和性能更好。<br>在System V的shm方式中，我们主要用到四个系统调用shmget、shmat、shmdt和shmctl。这四个系统调用的含义分别是：<br>
<br>shmget获取(get)一个新的共享内存段(shm)，并返回唯一的标识符(shmid)用于后续的操作。
<br>shmat将创建的shm附加(attach)到进程的地址空间。
<br>shmdt从进程的地址空间中将shm分离(detach)出来。
<br>shmctl用于控制和操作shm，通常用来删除内存段。
<br><br>System&nbsp;V的共享内存通过标识符（shmid）来管理，这些标识符通过shmget和ftok等函数生成。要创建新的或获取存在的共享内存段的引用，我们需要使用shmget系统调用，它的函数原型是：<br>#include &lt;sys/types.h&gt;
#include &lt;sys/ipc.h&gt;
#include &lt;sys/shm.h&gt;

int shmget(key_t key, size_t size, int shmflg);
/* 
Parameters:
	1. key: A unique identifier for the shared memory segment. This can either be the result of an ftok() call or the constant IPC_PRIVATE.
	2. size: Indicates the size of the shared memory segment in bytes.
	3. shmflg: Access permissions (UNIX standards, e.g., 0600). Optional flags include:
	   - IPC_CREAT: Create a new segment if it does not exist.
	   - IPC_EXCL: Fail if the segment already exists.

Return value: Returns the shared memory segment identifier (shmid), which is an integer.
*/
<br>要获得对一段共享内存段的唯一标识（键值），我们需要用到ftok函数。其函数原型如下：<br>#include &lt;sys/types.h&gt;
#include &lt;sys/ipc.h&gt;

key_t ftok(const char *pathname, int proj_id);
/* 
Parameters:
	1. pathname: A pointer to the path of an existing and accessible file.
	2. proj_id: A project identifier. This is usually a single character.

Return value: Returns a key of type key_t, which can be used to identify a shared memory segment, message queue, or semaphore.
*/
<br>如果没有相关文件，我们可以创建一个空文件来生成键值。（open系统调用）<br><br>当共享内存段存在之后，我们就可以将其附加到我们的进程空间中了。附加完成之后，进程就可以通过指针对这段空间进行操作，从而实现与其他进程之间的通信。其函数原型如下：<br>void* shmat(int shmid, const void* shmaddr, int shmflg);
/* 
Parameters:
	1. shmid: ID of the shared memory segment.
	2. shmaddr: Address at which to attach the shared memory segment (always use NULL to allow the system to choose the address).
	3. shmflg: Flags for the operation (e.g., SHM_RDONLY to attach in read-only mode).

Return value: Standard C pointer with the address of the shared memory.
*/
<br><br>使用完成共享内存段之后，我们需要用detach系统调用将其与进程内存空间进行分离。这个系统调用非常简单，只有一个参数：<br>int shmdt(const void* shmaddr);
/* 
Parameters:
	1. shmaddr: The address returned by the attach call.

Return value: 0 for success and -1 for error.
*/
<br>虽然很简单，但是请不要忽视其重要性。虽然进程终止后操作系统也会帮我们进行资源管理，但是有时我们需要进程一直运行，这时，如果不进行shmdt就会导致shm一直驻留到内存中。<br><br>我们用shmctl来删除共享内存段，这个函数能做的不仅仅是删除，但这里我们仅仅关注其删除的功能。下面是这个函数的原型：<br>int shmctl(int shmid, int cmd, struct shmid_ds *buf);
/* 
Parameters:
	1. shmid: Shared memory segment ID.
	2. cmd: Command to perform on the shared memory segment. For deletion, use IPC_RMID(ReMove ID).
	3. buf: Pointer to a struct shmid_ds, used for control commands that require or return data, not needed for IPC_RMID(in this case, just set to NULL).

Return value: Returns 0 on success, -1 on failure and sets errno appropriately.
*/
<br>System V的shm使用引用计数(reference count)来管理其生命周期。当进程通过shmat附加共享内存时，引用计数增加。当进程通过shmdt分离共享内存段时，引用计数减少。只要引用计数不为0，我们调用shmctl删除共享内存段时这个共享内存段并不会立刻被删除，内核会将其标记为”待删除“状态，直到引用计数归零。<br><br>除了管道和共享内存，消息队列也是一种常见的IPC机制。消息队列和管道有些相似，它们都是一种内核对象、以先进先出的方式对消息进程处理（默认情况）。但它们处理的对象不同。管道传递的消息是以字节流的方式进行传输的，而消息队列中传递的消息具有消息类型信息（包含着消息类型和消息体）。<br>而且在消息队列中，我们可以通过消息类型进行筛选和优先级处理，而管道不具备这种能力。消息队列允许你根据不同的消息类型有选择地读取消息，从而实现更细粒度的控制。而管道只能按照数据到达的顺序逐个读取，无法跳过或优先处理特定的数据。<br>由于消息具有类型信息，而且消息队列可以作为进程间通信的中间人存储消息，从而解耦合进程之间的同步问题，即进程可以独立地执行任务，而不必频繁地等待或与其他进程直接同步。所以消息队列常用于生产者-消费者模型中，生产者进程将数据发送到消息队列后可以立即继续生成新的数据，不必等待消费者进程处理完毕。<br><br>#include &lt;mqueue.h&gt;

mqd_t mq_open(const char *name, int oflag, ...);
/* 
Parameters:
	1. name: Name of the message queue.
	2. oflag: Flags for the operation (e.g., O_CREAT to create the queue if it doesn't exist).
	3. ...: Optional mode and attributes (used when creating the queue).

Return value: Message queue descriptor (mqd_t) on success, (mqd_t)-1 on failure and sets errno appropriately.
*/
<br>int mq_send(mqd_t mqdes, const char *msg_ptr, size_t msg_len, unsigned int msg_prio);
/* 
Parameters:
	1. mqdes: Message queue descriptor.
	2. msg_ptr: Pointer to the message to be sent.
	3. msg_len: Size of the message in bytes.
	4. msg_prio: Priority of the message.

Return value: 0 on success, -1 on failure and sets errno appropriately.
*/
<br>ssize_t mq_receive(mqd_t mqdes, char *msg_ptr, size_t msg_len, unsigned int *msg_prio);
/* 
Parameters:
	1. mqdes: Message queue descriptor.
	2. msg_ptr: Pointer to the buffer where the received message will be stored.
	3. msg_len: Size of the message buffer in bytes.
	4. msg_prio: Pointer to store the message priority (optional).

Return value: Number of bytes received on success, -1 on failure and sets errno appropriately.
*/
<br>int mq_close(mqd_t mqdes);
/* 
Parameters:
	1. mqdes: Message queue descriptor.

Return value: 0 on success, -1 on failure and sets errno appropriately.
*/
<br>int mq_unlink(const char *name);
/* 
Parameters:
	1. name: Name of the message queue.

Return value: 0 on success, -1 on failure and sets errno appropriately.
*/
<br><br>#include &lt;sys/types.h&gt;
#include &lt;sys/ipc.h&gt;
#include &lt;sys/msg.h&gt;

int msgget(key_t key, int msgflg);
/* 
Parameters:
	1. key: Unique key to identify the message queue.
	2. msgflg: Flags for the operation (e.g., IPC_CREAT to create the queue if it doesn't exist).

Return value: Message queue identifier (msgid) on success, -1 on failure and sets errno appropriately.
*/
<br>int msgsnd(int msqid, const void *msgp, size_t msgsz, int msgflg);
/* 
Parameters:
	1. msqid: Message queue identifier.
	2. msgp: Pointer to the message to be sent.
	3. msgsz: Size of the message in bytes.
	4. msgflg: Message flags to alter default behavior (e.g., IPC_NOWAIT).

Return value: 0 on success, -1 on failure and sets errno appropriately.
*/
<br>ssize_t msgrcv(int msqid, void *msgp, size_t msgsz, long msgtyp, int msgflg);
/* 
Parameters:
	1. msqid: Message queue identifier.
	2. msgp: Pointer to the buffer where the received message will be stored.
	3. msgsz: Size of the message buffer in bytes.
	4. msgtyp: Type of message to be received.
	5. msgflg: Message flags to alter default behavior (e.g., IPC_NOWAIT).

Return value: Number of bytes received on success, -1 on failure and sets errno appropriately.
*/
<br>int msgctl(int msqid, int cmd, struct msqid_ds *buf);
/* 
Parameters:
	1. msqid: Message queue identifier.
	2. cmd: Command to perform on the message queue (e.g., IPC_RMID to remove the queue).
	3. buf: Pointer to a struct msqid_ds, used for control commands that require or return data.

Return value: 0 on success, -1 on failure and sets errno appropriately.
*/
<br><br><br>对比POSIX和System&nbsp;V下的共享内存，POSIX的共享内存通过shm_open系统调用在文件系统中创建一个共享内存文件，之后通过这个文件描述符对共享内存段进行管理。相比之下，在SystemV中的共享内存机制使用标识符（shmid）管理，不依赖于文件系统进行索引。<br>相同点在于，这两种标准都使用文件系统的信息作为共享内存段标识符的生成依据，尽管方式不同（POSIX是直接依赖，System&nbsp;V是间接依赖）。而且不论是POSIX还是System&nbsp;V，实际的数据都是存储在用户群的内存中。<br><br>POSIX标准下的shm，管道的使用场景更加specific。管道具有先进先出的特性，而且有内核维护其缓冲区，所以管道不需要显式地同步机制，但是大小较为局限（通常为4KB-64KB）。相比之下，共享内存需要信号量或互斥锁等同步机制来防止数据竞争。<br>还与共享内存不同的是，管道是一种流式传输信息的通信工具，因为这种字节流传递方式，所以从管道中传输的数据不能有复杂的类型（如结构体）。而共享内存则提供了更多的灵活性和更高的性能，共享内存可以存储和访问如结构体等复杂的数据结构。<br>此外，内核态到用户态的切换开销也是我们需要考虑的。虽然内核保证了数据传输的安全性，但是频繁的切换使得管道的性能不及共享内存高。<br><br>管道和消息队列很相似，在数据传输的顺序上，它们都是以FIFO的顺序进行传输的。但是消息队列相比指向更加灵活，因为消息队列通过链表结构存放信息并传输数据。这就造就了消息队列一些管道不支持的特性，例如：消息带有类型标识符，能够标识消息的类型和优先级。这样，消息就可以根据特定的类型和优先级被消息接收方所接收。（链表结构的便利）<br>管道的同步机制比较简单，生产者进程写入数据后，消费者进程读取数据，过程由内核自动管理，但缺乏显式的同步控制。而消息队列支持显式同步，通过msgsnd和msgrcv系统调用，提供进程间更灵活的同步与调度机制。<br><br><br>一般我们可能并不会将内存映射文件 mmap 机制作为一种进程间通信的方式去使用。但它确实可以提供信息在不同进程间的通信的功能。我们下面就一起来看看它的功能。<br>进程映射文件，你从名字上就能知道和文件脱不了干系。它的主要作用就是将文件映射到进程的虚拟地址空间，使得进程可以直接通过内存地址访问文件内容，而不需要 read/write。即访问内存就等价于访问文件（操作系统会自动处理缺页和回写）。我们先了解了解文件是如何打开的。<br><br>详细请参阅<a data-href="13. File Systems" href="https://congzhi.wiki/congzhi's-os-series/13.-file-systems.html" class="internal-link" target="_self" rel="noopener nofollow">13. File Systems</a>，这里仅作概述。<br>操作系统内维护了一张打开文件表&nbsp;(Open&nbsp;File&nbsp;Table,&nbsp;OFT)，其中包含许多表项，我们称之为&nbsp;OFD&nbsp;(Open&nbsp;File Description)。当你使用 open("example.txt", O_RDONLY) 打开某一文件时，实际上你只是将文件表项被加载进了内存。打开文件表项包含该文件的元数据和控制信息，通过这些信息，你就可以知道如何在磁盘中寻得文件内容了。<br>当某个进程要打开文件时，系统会首先在打开文件表中查找相关表项，如果找到了相应的表项，就说明我们不需要从磁盘加载文件打开表项了。即使内容可能并没有被加载进内存，但这时我们也说该文件已经打开。（一般来说，只有需要用到内容的时候才会把文件内容从磁盘上加载进内存，即"lazy approach"）<br>对于只读文件产生的条目，我们不用担心多程序并发带来的同步互斥问题。但当有进程写操作时，我们就需要留意同步互斥访问文件资源的问题。<br><br>当文件打开之后，我们就可以用 mmap() 系统调用建立从文件到进程虚拟内存空间之间的映射。由于访问 IO 很耗时间，所以这时候，文件内容仍然不会加载进内存，在第一次访问映射后的地址空间时才会（缺页中断-&gt;加载文件内容）。我用一张图来简单的形容一下：<br>在进程通过 open() 系统调用知道文件的源信息后，我们就可以用 mmap 将文件的前 4KB 内容映射到进程的虚拟地址空间中。这时仅仅建立虚拟地址到文件的虚拟映射。当程序要读/写文件时，由于缺页，这时系统分配 4KB 物理内存并建立虚拟地址到物理内存地址的映射，并将文件内容从磁盘加载到内存中。（图应该是 0-4095 字节）<br>
<img alt="mmap.png" src="https://congzhi.wiki/congzhi's-os-series/pics/mmap.png"><br><br>现在，我们知道了内存映射是将一个文件映射到进程的地址空间。进而实现文件磁盘和进程虚拟空间中一段虚拟地址的一一对应关系。这种对应关系会保存在虚拟存储空间的文件映射与匿名映射区中，这段区域位于堆和栈之间。<br>mmap函数的函数原型如下：<br>#include &lt;sys/mman.h&gt;

void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);
/* 
Parameters:
	1. addr: Starting address for the new mapping. Typically set to NULL to let the kernel choose the address.
	2. length: Length of the mapping in bytes. Must be a multiple of the system's page size.
	3. prot: Desired memory protection of the mapping. This can be a combination of the following:
	   - PROT_READ: Pages can be read.
	   - PROT_WRITE: Pages can be written.
	   - PROT_EXEC: Pages can be executed.
	   - PROT_NONE: Pages cannot be accessed.
	4. flags: Flags that determine the nature of the mapping. Common flags include:
       - MAP_SHARED: Write updates to the mapping are visible to other processes mapping the same region, and also reflected in the underlying file.
       - MAP_PRIVATE: Changes to the mapping are private to the process and not visible to other processes. Changes are not reflected in the underlying file (copy-on-write).
       - MAP_ANONYMOUS: Mapping is not backed by any file; the fd parameter is ignored (should be -1).
       - MAP_FIXED: Forces the mapping to use exactly the address specified in addr. Be cautious as it may overwrite existing mappings.
       - MAP_FIXED_NOREPLACE: Similar to MAP_FIXED, but will fail with EINVAL if the specified address is already occupied.
       - MAP_POPULATE: Populates page tables for the mapping immediately instead of waiting for lazy access.
       - MAP_NORESERVE: Prevents reserving swap space for the mapping. If physical memory runs out, the process may be terminated.
       - MAP_LOCKED: Locks the mapping in memory, preventing it from being swapped out.
       - MAP_HUGETLB: Uses huge pages for the mapping to reduce TLB (Translation Lookaside Buffer) overhead.
       - MAP_UNINITIALIZED: Allocates uninitialized memory. Unsafe and supported only on specific architectures.
	5. fd: File descriptor of the file to be mapped. Ignored if MAP_ANONYMOUS is set.
	6. offset: Offset in the file where the mapping starts. Typically set to 0.

Return value: Returns a pointer to the mapped area on success, or MAP_FAILED on failure. The errno variable is set to indicate the error.
*/
<br><br>如果你想要修改映射区域的保护权限，我们可以使用 mprotect 系统调用，其函数原型如下：<br>#include &lt;sys/mman.h&gt;

int mprotect(void* address, size_t length, int prot);
/* 
Parameters:
	1. address: Starting address of the memory region to be protected.
	2. length: Length of the memory region in bytes.
	3. prot: Desired protection of the memory region. It can be a combination of the following:
	   - PROT_READ: Pages can be read.
	   - PROT_WRITE: Pages can be written.
	   - PROT_EXEC: Pages can be executed.
	   - PROT_NONE: Pages cannot be accessed.
   
Return value: Returns 0 on success, -1 on failure and sets errno to indicate the error.
*/
<br><br>msync&nbsp;函数用于同步内存映射区域与其底层存储之间的内容。通过msync，我们可以确保内存中进行的修改能够被写回到映射的文件上，保持数据的一致性。通常而言，我们在对内存映射区域进行写操作之后使用msync确保数据的持久保存。<br>#include &lt;sys/mman.h&gt;

int msync(void* address, size_t length, int flags);
/* 
Parameters:
	1. address: Starting address of the memory region to be synchronized.
	2. length: Length of the memory region to be synchronized.
	3. flags: Flags that determine the synchronization behavior. Common flags include:
	   - MS_SYNC: Perform synchronous writes(blocking).
	   - MS_ASYNC: Perform asynchronous writes.
	   - MS_INVALIDATE: Invalidate all cached data.

Return value: Returns 0 on success, -1 on failure and sets errno to indicate the error.
*/
<br><br>munmap 系统调用用于解除一个映射关系，将之前通过 mmap 映射的内存区域释放回操作系统。它的函数原型如下：<br>int munmap(void *addr, size_t length);
/* 
Parameters:
	1. addr: Starting address of the memory region to be unmapped. This should be the address returned by a previous call to mmap.
	2. length: Length of the memory region to be unmapped. Must be the same length as that specified in the original mmap call.

Return value: Returns 0 on success, -1 on failure and sets errno to indicate the error.
*/
<br><br>了解了内存映射文件是什么。你应该能想得到如果两个进程都将同一个文件映射到自己的虚拟内存空间，实现基本的同步互斥。那么就可以实现进程间的通信。这当然没有问题，但是这也太扯了，非常无聊。我们不想和文件打交道。<br>如果你细心，你可能会对 mmap() 系统调用的 flags 项感兴趣：MAP_PRIVATE、MAP_SHARED 和 MAP_ANONYMOUS。它们什么意思？我们一项一项解释。<br><br>MAP_PRIVATE 提供一种只有进程内部私有这段虚拟内存的映射关系。<br>而 MAP_SHARED 提供多线程共享同一物理资源。<br><br>当你使用 MAP_ANONMYMOUS 时，虚拟内存将不会和任何文件产生映射关系，而是在访问的时候系统会分配物理内存并建立虚拟内存到物理内存上的映射。<br>你可能了解过，当库函数 malloc 申请堆内存时，申请内存小于 128KB 时（一般而言），底层会调用 sbrk() 系统调用。当申请的堆内存大于 128KB 时，底层会调用 mmap()。你可能会奇怪为什么堆内存的申请会和内存映射文件产生联系，即便没有任何文件参与。而到这里，你可能就明白是怎么回事了。<br>实际上，进程启动的时候，就会用 malloc 申请内存段空间（数据段、代码段等）。这些在程序运行的整个生命周期都不会改变的内存就相当于：<br>void *mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_FIXED | MAP_ANONYMOUS, -1, 0);
// Size must be a multiple of the system's page size. (4n * KB)
<br>一般情况下，你使用 malloc 申请大块内存时，底层调用的 mmap 实际上相当于：<br>void *mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
// Size must be a multiple of the system's page size. (4n * KB)
<br>如果配合 MAP_SHARED 我们就可以实现类似 shm 共享内存的进程间通信了。但是这种进程间通信仅仅存在于父子进程或其他有亲缘关系的进程之间。但这里你需要知道 mmap() 映射的大小应为系统页大小的倍数。（页大小一般为 4KB ，也有 16KB 等的）<br><br>下面我们让父进程在”共享内存“中写 Hello, kid，然后让子进程读。我们不设置复杂的同步互斥机制，先让子进程阻塞一秒。这里请注意，fork()系统调用会将父进程所有的资源都复制一份，所以当我们关闭文件描述符的时候应当关闭两次，而不是一次。<br>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;sys/mman.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/wait.h&gt;

#define MY_SHM_SIZE 4096

int main(){
    // 1. create my shared memory
    char *my_shm = mmap(NULL, MY_SHM_SIZE,
                    PROT_READ | PROT_WRITE,
                    MAP_ANONYMOUS | MAP_SHARED,
                    -1, 0);

    if(my_shm == MAP_FAILED){
        perror("mmap failed");
        exit(EXIT_FAILURE);
    }

    // 2. write-in
    strcpy(my_shm, "Hello, kid");

    // 3. fork
    pid_t pid = fork();
    if(pid == -1){
        perror("fork failed");
        exit(EXIT_FAILURE);
    }

    if(pid == 0){
        sleep(1);
        printf("Child received: %s\n", my_shm);
        exit(EXIT_SUCCESS);

    }else{
        wait(NULL);
    }

    // 4. unmapping
    if(munmap(my_shm, MY_SHM_SIZE) == -1){
        perror("munmap failed");
    }
    return 0;
}
<br><br><br>在上个阶段的最后，我们看了看如何用信号处理僵尸进程的问题。我们通过注册SIGCHILD信号的处理程序来捕获子进程终止的信号，从而避免僵尸进程的产生。信号机制作为一种轻量级的进程间通信方式，我们本节课来详细探讨探讨相关的细节。<br><br>在<a data-tooltip-position="top" aria-label="5. Interruption" data-href="5. Interruption" href="https://congzhi.wiki/congzhi's-os-series/5.-interruption.html" class="internal-link" target="_self" rel="noopener nofollow">Interruption</a>的阶段中，我们了解了内核是如何处理异常的。当程序执行过程中发生异常时，内核会接管并执行相应的异常处理例程(exception handler)。因为异常的处理程序都在内核中，用户程序对异常的发生是毫不知情的。比方说缺页中断。<br><a data-tooltip-position="top" aria-label="https://www.man7.org/linux/man-pages/man7/signal.7.html" rel="noopener nofollow" class="external-link" href="https://www.man7.org/linux/man-pages/man7/signal.7.html" target="_blank">信号机制</a>在软件层面上模拟了硬件中断。信号提供了一种机制来通知用户进程发生了何种异常，以便用户程序能够根据自身情况做出响应。回想在用信号处理僵尸进程时，我们自己定义的handler实际上是放在用户区的，而中断通常会在内核空间中执行。此外，信号的触发和处理机制和中断并不相同。（信号的嵌套是被允许的。）<br>Linux中共有64种信号，其中1-34属于非实时信号，而35-64属于实时信号，用于实时系统。<br>$ kill -l
 1) SIGHUP	 2) SIGINT	 3) SIGQUIT	 4) SIGILL	 5) SIGTRAP
 6) SIGABRT	 7) SIGBUS	 8) SIGFPE	 9) SIGKILL	10) SIGUSR1
11) SIGSEGV	12) SIGUSR2	13) SIGPIPE	14) SIGALRM	15) SIGTERM
16) SIGSTKFLT	17) SIGCHLD	18) SIGCONT	19) SIGSTOP	20) SIGTSTP
21) SIGTTIN	22) SIGTTOU	23) SIGURG	24) SIGXCPU	25) SIGXFSZ
26) SIGVTALRM	27) SIGPROF	28) SIGWINCH	29) SIGIO	30) SIGPWR
31) SIGSYS	34) SIGRTMIN	35) SIGRTMIN+1	36) SIGRTMIN+2	37) SIGRTMIN+3
38) SIGRTMIN+4	39) SIGRTMIN+5	40) SIGRTMIN+6	41) SIGRTMIN+7	42) SIGRTMIN+8
43) SIGRTMIN+9	44) SIGRTMIN+10	45) SIGRTMIN+11	46) SIGRTMIN+12	47) SIGRTMIN+13
48) SIGRTMIN+14	49) SIGRTMIN+15	50) SIGRTMAX-14	51) SIGRTMAX-13	52) SIGRTMAX-12
53) SIGRTMAX-11	54) SIGRTMAX-10	55) SIGRTMAX-9	56) SIGRTMAX-8	57) SIGRTMAX-7
58) SIGRTMAX-6	59) SIGRTMAX-5	60) SIGRTMAX-4	61) SIGRTMAX-3	62) SIGRTMAX-2
63) SIGRTMAX-1	64) SIGRTMAX
<br>在上个阶段的最后，我们还简单地了解了信号的 default action，然而对于大部分信号而言，进程可以对特定的信号进行忽略或设置自己的信号处理程序。<br><br><br>学完进程，我们现在知道每个进程会对应一个 task_struct 结构体，其中，就有很多与信号相关的数据结构。对于信号的管理，我们有 signal_struct 结构体、sighand_struct、信号集 sigset_t 和用于记录当前挂起信号的 sigpending 结构体。<br>struct task_struct{
// ...
	// 指向一个signal_struct结构体的指针。用于管理与进程相关的信号信息。
	struct signal_struct *signal; 
	// 指向一个sighand_struct结构体。用于管理信号服务例程。	
	struct sighand_struct *sighand; 
	// 用于表示当前被阻塞的信号。其中sigset_t是一个64位的位掩码。
	sigset_t blocked;
	// sigpending用于表示当前挂起的信号。
	struct sigpending pending;
// ...
}
<br><img alt="Pasted image 20250128190859.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20250128190859.png"><br><br>在 task_struct 中，我们看到每个进程私有的挂起信号 sigpending。而在 signal_struct 中，我们还有一个存放进程组共享挂起信号的数据结构 shared_pending。在学习<a data-tooltip-position="top" aria-label="6. Processing The Processes > 3.2.1 Process Group" data-href="6. Processing The Processes#3.2.1 Process Group" href="https://congzhi.wiki/congzhi's-os-series/6.-processing-the-processes.html#3.2.1_Process_Group" class="internal-link" target="_self" rel="noopener nofollow">进程组</a>时提到，信号的处理可以以进程组为单位进行。当信号发出时，信号会被存放在 shared_pending 结构体中。<br>signal_struct的结构体原型如下：<br>struct signal_struct {
    atomic_t sigcnt;
    atomic_t live;
    int nr_threads;
    struct list_head thread_head;
    struct sigpending shared_pending;
    struct sigpending group_exit_pending;
    int group_exit_code;
    unsigned int flags;
    struct rcu_head rcu;
};
/* 
Parameters:
	1. sigcnt: Atomic counter for the number of signals.
	2. live: Atomic counter for the number of live processes in the signal group.
	3. nr_threads: Number of threads in the signal group.
	4. thread_head: List head for the threads in the signal group.
	5. shared_pending: Shared pending signals for the signal group.
	6. group_exit_pending: Pending signals for group exit.
	7. group_exit_code: Exit code for the group exit.
	8. flags: Flags for the signal group.
	9. rcu: RCU head for the signal group.
*/
<br><br>sigset_t 实际上是一个位掩码(bitmask)，用于表示一组信号。在许多操作系统中，sigset_t 是一个 64 位的 unsigned long 数据类型，每一位代表一个信号。由于我们有 64 种信号，因此每一位可以表示一个信号的状态。当我们发送某个信号时，就将 sigset_t 的那一位置为 1。<br>信号的轻量型就体现在这种使用位操作来管理和操作信号集的方式。<br><br>sighand_struct是信号处理程序的结构体，其中包括三个参数。我们需要关注的是struct k_sigaction action[64];。从数组的大小就能看来，其对应Linux中支持的64种信号，根据数组编号的不同，记录着不同信号的处理方式（actions）。<br>结构体k_sigaction的原型如下：<br>struct k_sigaction {
    struct sigaction sa;
    unsigned long sa_flags;
    void (*sa_restorer)(void);
    __sigaction_handler_t sa_handler;
    sigset_t sa_mask;
};
/* 
Parameters:
	1. sa: User-defined signal handler structure, containing the signal handling function and signal mask.
	2. sa_flags: Signal handling flags, used to control the behavior of signal handling.
	3. sa_restorer: Restorer function pointer, used to restore the execution environment after the signal handler returns.
	4. sa_handler: User-defined signal handler function pointer.
	5. sa_mask: Signal mask, used to block certain signals during the execution of the signal handler.
*/
<br>其中的struct sigaction就是用于定义信号处理程序的结构体。其参数包含信号处理函数、信号掩码和控制标志等。下面是struct sigaction的结构体原型：<br>struct sigaction {
    void (*sa_handler)(int);
    void (*sa_sigaction)(int, siginfo_t *, void *);
    sigset_t sa_mask;
    int sa_flags;
    void (*sa_restorer)(void);
};
/* 
Parameters:
	1. sa_handler: Signal handling function pointer, which is called when the signal is received.
	2. sa_sigaction: Alternative signal handling function pointer, used when the SA_SIGINFO flag is set.
	3. sa_mask: Signal mask, used to block certain signals during the execution of the signal handler.
	4. sa_flags: Signal handling flags, used to control the behavior of signal handling.
	5. sa_restorer: Restorer function pointer, used to restore the execution environment after the signal handler returns.
*/
<br>这里面，sa_handler是指向信号处理函数的函数指针，当收到信号时调用。这里我们可以使用预定义的常量SIG_DFL（默认信号处理）或者SIG_IGN（忽略信号）来设置这个字段。<br><br>信号可以被阻塞屏蔽(blocked)，被屏蔽信号不会立即被传递给进程的信号处理程序。这些信号会被保留，直到它被解除屏蔽后才会被处理。屏蔽进程用于阻止某些信号的干扰，以确保进程在关键操作期间不会被信号中断。在屏蔽期间到来的信号并不会被处理，我们称之为信号的挂起(pending)。每个线程都会有自己的挂起信号集(pending signal set)，集合中的信号表示不是0就是1（表示被挂起，需要被处理）,一个信号无论有被挂起多少次，最终只会被处理一次。进程的信号挂起集合是有线程屏蔽集合合并生成的。fork(2)创建好的子进程会初始化自己的集合。<br>进程可以使用sigprocmask(2)来操作信号的屏蔽，作用于下辖所有的线程。在多线程的环境中，使用 pthread_sigmask(2) 可以确保信号屏蔽设置仅影响当前线程。fork但子进程会继承父进程对信号的屏蔽，在execve(2)后仍然会保留。<br><br>如果我们什么都不做，不同的信号会表现出不同的默认操作。根据信号的不同，不同的信号有以下五种不同的 default action：<br><br>一个进程可以使用signal(2)或sigaction(2)来改变信号的默认处理方式。当一个信号被传送给进程时，对于大多数信号，进程可以自行决定是按照默认方式处理呢、还是忽视掉这个信号、亦或是使用一个自定义的函数来处理信号。进程的处理方式是一个per-process的事情，这就意味着同一进程中的不同线程对于相同信号的处理方法是一样的。fork()后，子进程的信号处理和父进程相同，在execve(2)后改变。<br><br>信号有很多不同的类型，分别代表着不同事件的发生。信号可以由内核、其他进程或自身进程发送，用于通知进程发生了某些事件。当一个进程向另一个进程发送信号时，会经由内核将信号传递给目标进程，内核起到中介的作用。<br><br>Send a signal, raise a flag，信号非常小，一般不携带数据信息，所以当我们说信号是轻量级的进程间通信。当进程发送一个信号时，内核会在目标进程的信号队列（signal pending set）中添加该信号，并在适当的时候将其传递给目标进程。信号可能被阻塞，这就意味着信号暂时不会被处理。若未阻塞信号，目标进程接收到信号后，会在适当的实际用预先设定的信号处理程序来处理该信号。<br>根据不同的系统调用接口，信号会被发送给进程组（killpg()）、进程（kill(), sigqueue(), pid_send_signal()）或是线程（raise(), pthread_kill(), tgkill()）。当信号发送给线程时，特定的线程会在未阻塞相关信号时对其进行处理。当发送给进程时，本着阻塞不绝对就是绝对不阻塞的原则，内核会任意挑选一个未对特点信号进行阻塞的线程来处理相关的信号服务例程。<br><br>我们有两个系统调用 pause() 和 sigsuspend() 来挂起线程的执行，直到有信号被捕获。<br>pause() 系统调用会挂起执行，捕获任何信号都会让线程接着执行。<br>sigsuspend() 也会挂起线程，但不同的是，sigsuspend() 会临时改变信号屏蔽字，并且只会在未被屏蔽的信号被捕获时才恢复线程的执行。这使得 sigsuspend() 更灵活，因为你能控制在等待时哪些信号是屏蔽的，哪些信号是可处理的。<br><br><br>当发生从内核态到用户态的转变（系统调用返回、发生线程的调度）时，内核会检查是否有未阻塞的挂起信号。如果进程自己注册了相关的信号服务例程，那么一旦发生从内核态到用户态的转变，就会发生：<br>
<br>挂起信号集合中的相关位清零（信号从集合中移除）。
<br>如果信号处理函数是使用sigaction系统调用注册的，并且指定了SA_ONSTACK标志。内核会为信号处理函数加载一个单独的信号栈（默认信号的服务例程在进程的栈空间中建立栈帧）。
<br>和中断类似的，执行handler前，我们还要将一些上下文信息保存到一个栈帧里，便于信号处理完毕后恢复继续执行。
<br>之后，内核会为信号处理程序构建一个栈帧，设置PC为指向信号处理程序函数的第一条指令。
<br>内核将控制权交给用户空间，信号处理程序开始处理。完成后将控制权交给signal trampoline。
<br>signal trampoline调用sigreturn(2)，这个系统调用和恢复上下文，继续执行有关。
<br>从内核的角度来看，信号处理程序代码的执行与任何其他用户空间代码的执行完全相同。也就是说，内核不会记录任何特殊的状态信息来指示线程当前正在执行信号处理程序。所有必要的状态信息都保存在用户空间的寄存器和用户空间栈中。嵌套信号处理程序的调用深度仅受用户空间栈的限制（以及合理的软件设计）。<br><br>#include &lt;signal.h&gt;

void (*signal(int sig, void (*handler)(int)))(int);
/* 
Parameters:
	1. sig: The signal number to be handled. Common signals include SIGINT, SIGTERM, SIGKILL, etc.
	2. handler: A pointer to the signal handling function. This function takes a single argument of type int (the signal number) and returns void.
		- SIG_IGN: Ignore the signal.
		- SIG_DFL: Treat signal as its default manner.
		- Your own handler.

Return value:
	- On success: Returns the previous signal handler.
	- On failure: Returns SIG_ERR and sets errno appropriately.
*/
<br><br>null 信号（信号值为 0）是 Unix-like 系统中的一个特殊信号。在前面，我们看到记录信号的结构 sigset_t 只有 64 位。所以 null 信号实际上不存在，他没有任何 default action，它唯一的作用就是测试。用于检测进程是否存在或测试用户权限。<br>if (kill(pid, 0) == 0) {
    // the process exists and we have promission to send a signal
} else {
    // the process is non-existing, or we don't have much promission
}
]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/6.5-inter-process-communications.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/6.5 Inter-Process Communications.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Mar 2025 06:06:36 GMT</pubDate><enclosure url="https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20241130023253.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20241130023253.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[7. Thread and Concurrency]]></title><description><![CDATA[ 
 <br><br><br><br>没有线程的时候，在一个 HTTP 的服务器上，每一个客户端的连接都将对应一个进程的创建。在高并发的场景下，每秒都可能有成百上千个客户端需要建立与服务器的链接，频繁创建并销毁进程带来的开销可能是服务器不可承受之重。此外，进程间通信也会为系统带来不小的开销。<br>那么，我们是否有更好地方法来降低系统开销，实现一种机制来避免进程复制或切换所给我们带来的系统开销呢？在剖析进程时，我们发现进程中有很多部件，而执行程序是在栈区中执行的。为了减少进程操作开销，人们将进程中负责执行程序的部分称为线程，线程所需要的资源都共享进程的。从而，我们可以在服务器进程中，用多线程的方式同时服务多个客户端，减少了进程开销。<br><img alt="Pasted image 20241204003952.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241204003952.jpg"><br>线程是执行线程的简写，它是一系列顺序任务流，这些任务流可被CPU调度。由于线程的调度和操作相比进程系统开销要小很多，所以现在的操作系统使用线程作为CPU调度的基本单位，即线程是最小的可调度单位。而进程，作为资源管理的基本单位，可以被看作是线程的容器。<br><br>为了让这个最小的可调度单位能够正常的工作，我们需要给线程分配必要的资源。每个线程都需要独立的 TCB ，包括寄存器组、PC寄存器和堆栈指针等。此外，还需要给每个线程分配栈空间以确保能够调度执行。这些线程会共享同一个进程中的代码段、数据段和文件等资源。由于线程的轻量，我们也称其为轻量级进程(Light-weight process)，这样的轻量型为减少系统开销帮了不少忙。<br><img alt="Pasted image 20241203215622.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241203215622.jpg"><br>由于线程所占用的资源很少，所以创建和销毁线程要比进程快得多（10×），而且上下文切换的时间也更快。又因为所有线程共享进程的资源，所以同一进程中线程间交流并不需要IPC。要使程序运行起来，一个进程就至少需要有一个线程，叫做主线程(main thread)。<br>此外，线程间共享进程资源还为我们带来另一个好处——高缓存命中率（关于缓存亲和性的内容将在<a data-tooltip-position="top" aria-label="8. CPU Scheduling > 第三课 Multiple-Processor Scheduling" data-href="8. CPU Scheduling#第三课 Multiple-Processor Scheduling" href="https://congzhi.wiki/congzhi's-os-series/8.-cpu-scheduling.html#第三课_Multiple-Processor_Scheduling" class="internal-link" target="_self" rel="noopener nofollow">CPU调度</a>阶段中学习到）。由于线程的轻量型，线程切换通常不需要将一些上下文重新加载到缓存中，所以缓存命中率高。<br><br><br>线程和进程一样有各种各样的状态，操作系统为了对线程进行管理和调度，在线程创建的时候会为线程创建一个TCB来存放线程执行相关的信息。TCB数据结构中的数据通常包括：<br>
<br>线程ID：用于唯一标识系统内的线程；
<br>线程状态：如运行、等待、就绪等；
<br>寄存器内容：保存线程的上下文信息，确保线程能够恢复执行；
<br>优先级：用于调度策略；
<br>线程特定的数据：每个线程私有的数据区；
<br>指向PCB的指针；
<br>指向不同内存区域的指针：text,data,heap and stack；
<br>资源信息指针。
<br>...
<br>为了使线程执行相独立，线程的栈空间和上下文信息是线程独享的，与其他线程相独立。虽然线程TCB中有指向资源的指针，但这些资源都是共享的，线程并不作为资源的管理者。<br>在Linux中，进程和线程都使用task_struct数据结构来描述它们的状态和信息。但同一进程内的线程间共享进程内的地址空间和资源。我们也有线程组的概念，同一进程内的主线程和其他线程组成一个线程组，组号tgid即为主线程的线程标识符。<br><br>和进程一样，每个独立的线程也都有自己的状态。我们之前介绍的进程模型有七种状态，线程也有自己的五态模型。由于线程并不是资源的调度单位，我们不用考虑线程在内存上的换入和换出，因此在线程模型中不会看到挂起态。线程的五态有：new、ready、running、waiting、terminate。<br>线程的状态和进程的状态息息相关，如果进程因等待I/O操作或其他资源而阻塞，那么所有线程也会进入阻塞状态。当进程处于就绪状态时，虽然它的线程已经准备好运行，但进程没有被调度到CPU上，因此所有线程暂时不能使用CPU资源。这就是进程被称为最基本的资源调度单位的原因。<br>如果所有的线程都被阻塞，而进程处在就绪态呢？由与进程的运行需要依托至少一个线程的可运行状态，所有即使进程能够获取资源也不可以执行任何任务。<br><br>线程上下文切换是操作系统从一个线程的执行状态切换到另一个线程的执行状态的过程。这个过程的过程和进程上下文切换的过程类似。与进程的上下文切换相比，线程的上下文信息更小，所以切换效率更高。<br><br>在同一进程下，由于线程之间共享进程资源，其上下文切换通常不涉及存储块的交换，所以线程切换的局部性更好（保留缓存内容，可能不需要刷新MMU）。<br><br>我们刚才比较同一进程内的线程切换，由于进程内的线程共享了大部分进程资源，因而开销相对较低。而跨进程的线程切换则不太一样了。由于跨进程的线程没有共享的进程资源，而且进程与进程之间的内存空间和安全环境的完全隔离，所以跨进程间的线程切换的系统开销要大得多。<br><br>在<a data-tooltip-position="top" aria-label="5. Interruption > 第七课 Interrupt Context" data-href="5. Interruption#第七课 Interrupt Context" href="https://congzhi.wiki/congzhi's-os-series/5.-interruption.html#第七课_Interrupt_Context" class="internal-link" target="_self" rel="noopener nofollow">阶段-5</a>，我们接触到了内核栈，我们用内核栈来存储中断上下文。那问题来了，进程的上下文 PCB 和线程的上下文 TCB 在哪里存储呢（task_struct in Linux）？它们在内核堆中存储。内核堆和用户进程的堆空间一样，是一种动态内核数据结构。<br>我们没有接触 CPU 调度的内容。简单起见，你需要理解——当线程切换时，内核需要负责保存当前线程的 TCB 并恢复调度线程的 TCB 。由于这一过程在内核中进行，所以硬件和系统会先将中断上下文保存到内核栈中。然后操作系统保存剩余的上下文（TCB）到内核堆，调度程序选择一个线程，恢复其 TCB 并通过 iret 返回用户态或内核态执行。<br><br>线程的这种轻量型可以带给我们很多好处，但也能够给程序的执行带去不少的烦恼。下面，我们将比较线程和进程在各个方面上的不同，然我们得以对两者有更好的理解。<br><br>在它们的创建方式上，我们讨论进程fork()的创建方式。在POSIX thread库中，线程通过pthread_create()来创建。由于进程是资源调度的基本单位，所以在进程创建的过程中，除了创建一个主线程之外，还要将父进程的所有资源映像拷贝到进程自己的内存空间中。相比之下，线程不需要进行资源的完整复制，而是共享同一进程的资源，因而线程的创建更小。<br>由于线程共享进程中的资源，因而线程的内存开销和切换开销要小很多。你可以将进程和线程理解为大石头和小石头，操作系统搬小石头肯定更加地容易。在数据的共享上，进程会使用繁琐的IPC机制，在同一进程内的线程不需要考虑这些，因为它们的资源是共享的。<br><br>事事都有其两面性，看过线程光鲜亮丽的一部分，我们接下来学习线程阴暗的一面。相比进程之间彼此隔离，由于线程间资源共享可能导致一系列问题。比如不当的调度导致的资源竞和死锁问题。我们说线程栈是独立的，但不像进程空间那样隔离。理论上，一个线程可能访问另一个线程的栈空间，这是非常危险的。可能导致程序的崩溃。<br><br>在前面，我们说多个线程可能属于一个进程，这些线程共享进程中的数据。这种数据共享是多线程编程带给我们的一个好处。但在某些情况下，每个线程可能需要自己的某些数据副本。我们将这种数据称为线程局部存储。<br>一个线程的TLS仅对这一个线程可见，这破坏了一定的共享性，但会带来很多好处（比如避免可能导致的资源竞争和死锁问题）。为了在线程的生存周期内可用，TLS通常声明为静态的。在C语言和C++中，可以使用 __thread (编译器提供)或 thread_local (C++11)来声明TLS变量。<br>如果我们想为一个线程分配一个唯一的标识符，我们可以这样声明：<br>#include &lt;stdio.h&gt;
#include &lt;pthread.h&gt;

__thread int threadID = 0;

void* printThreadID(void* arg) {
    threadID = (int)(long)arg;
    printf("Thread ID: %d\n", threadID);
    return NULL;
}

int main() {
    pthread_t t1, t2, t3;

    pthread_create(&amp;t1, NULL, printThreadID, (void*)(long)1);
    pthread_create(&amp;t2, NULL, printThreadID, (void*)(long)2);
    pthread_create(&amp;t3, NULL, printThreadID, (void*)(long)3);
    
    pthread_join(t1, NULL);
    pthread_join(t2, NULL);
    pthread_join(t3, NULL);

    return 0;
}
<br>#include &lt;iostream&gt;
#include &lt;thread&gt;

thread_local int threadID = 0;

void printThreadID(int id) {
    threadID = id;
    std::cout &lt;&lt; "Thread ID: " &lt;&lt; threadID &lt;&lt; std::endl;
}

int main() {
    std::thread t1(printThreadID, 1);
    std::thread t2(printThreadID, 2);
    std::thread t3(printThreadID, 3);

    t1.join();
    t2.join();
    t3.join();

    return 0;
}
<br><br><br>以上，我们了解了内核级线程(kernel level threads)，内核级线程是由操作系统直接管理的线程。每个内核级的线程都有自己的TLB，线程的数据结构由操作系统内核管理，存储在内核空间。除了内核级线程，我们还有用户级线程(user-level threads) 的概念。<br><img alt="Pasted image 20241204011034.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241204011034.jpg"><br>内核级线程和用户级线程都有自己的线程资源（栈、上下文信息等），但是内核级线程是被操作系统管理的，而用户级线程被用户空间的程序所管理，内核并不需要知晓用户机进程的存在。<br><br>用户级线程的突然出现让我们猝不及防，用户级线程是对内核级线程的模拟。在前面学习的线程中，我们说（内核级）线程是CPU基本的调度单位，这里的线程实际上就是内核级线程。用户级线程是在用户空间创建的，也就是说内核空间中并不会创建相关的TLB。TLB相当于线程的操纵句柄，因而系统没有办法对用户级线程进行调度。<br>由于内核并不会记录ULTs的资源和上下文，所以ULTs并不能参与CPU的调度。ULTs的运行建立在运行在CPU的KLTs之上。虽然看上去ULTs好像并不大方便高效，但这种线程事实上能够带给我们许多好处，如：ULTs的操作都是在用户态进行的，所以ULTs的系统调用和上下文切换的开销可以非常低。ULTs的创建、切换等操作并不需要内核的帮助，速度可以相较KLTs快很多。<br>但是这种线程的缺点也显而易见，多个ULTs运行在一个KLT上，没有实际线程的并发，性能可能并不够好。如果一个KLT对应多个ULTs，每个ULT可能只会获得1/n的线程性能。下面，我们将介绍三种用户级线程和内核级线程的设计模型：多对一模型、一对一模型、多对多模型。<br><br>多对一模型中，一个KLT上要支持多个ULTs的执行。我们前面提到过，ULTs的切换开销很低，所以这种模型中的上下文切换非常快。但由于这种模型只有一个KLT，这就意味着一时间在这些ULTs只能有一个在CPU上执行。即使在多核处理器上，并行在这种模型上是不可能实现的。<br><img alt="Pasted image 20241204011053.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241204011053.jpg"><br>而且，如果某个时刻其中一个ULT调用了阻塞的系统调用（使用I/O），那么唯一的那个内核级线程将会阻塞。进而，整个进程会被阻塞，剩下的那些用户级线程就也随之阻塞。一个ULT的阻塞导致了所有ULTs的阻塞。<br><br>在一对一模型中，每个ULT都对应着一个KLT，每个ULT事实上变成了一个独立的调度单位（因为ULT的线程操作就对应着KLT的线程操作）。这种模型和我们学习的线程是对应的。使用一对一模型后，我们就不必担心一个ULT的阻塞导致整个进程阻塞的事件发生。而且，使用一对一模型后，这些ULTs可以在多处理器上并发地运行。<br><img alt="Pasted image 20241204011045.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241204011045.jpg"><br>由于这种模型的一一对应，我们实际上失去了ULTs给我们带来的好处。我们不能再享受到多用户级线程带来的快速上下文切换速度；当你创建一个用户级线程后，你还需要使用系统调用来创建另一个支持ULT的系统级线程。而且，我们失去了线程调度的灵活性，因为所有的调度将在内核的调度器下完成。<br>尽管有这么些缺点，现在的许多操作系统仍然采用一对一的模型。一方面这种模型较好实现，而且多核处理器也能够有较好的性能来支持庞大数量的内核级线程数量。<br><br>在多对多模型上，N 个用户级线程被小于或等于N的内核级线程所支持。相比上两种模型，多对多模型更加灵活，性能看上去也更好。在多对多模型中，ULT 可以不再绑定到特定的 KLT 上了。我们可以在用户级的线程库中实现一些机制，使得当某个 KLT 被阻塞，其余的ULT可以迁移到其他的 KLTs 上。当然，这就意味着可怜的 cache 命中率。<br><img alt="Pasted image 20241204011100.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241204011100.jpg"><br>红利吃尽代价总是要偿还的，这种模型实现起来更为复杂，而且用户级线程的线程库调度的效率可能并不如内核调度更加有效，还有更大的开发和维护成本。FreeBSD5支持M:N的线程模型，到 FreeBSD7 时默认只使用 1:1 模型，并从 FreeBSD8 完全放弃了M:N模型。<br><br><img alt="Pasted image 20241204011158.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241204011158.jpg"><br><br>我们已经了解了不同的线程模型，那么用户态线程库中创建的线程是如何变成可调度的内核线程的呢？对于多对多或两级线程模型的系统实现中，系统通常会假如一个中间层，叫LWP。对于用户线程库来说，LWP相当于一个虚拟的处理器，应用程序可以在其上调度用户线程运行。每个LWP都会附加到一个内核线程上，操作系统调度内核线程在物理处理器上运行。如果一个内核线程阻塞（例如等待I/O操作完成），LWP也会阻塞。紧接着，附加到LWP的用户级线程也会阻塞。<br>一个应用可能要好几个LWP才能确保程序的高效运行。假设一个在单处理器上运行的CPU密集型应用程序。在这种情况下，一次只能运行一个线程，因此一个LWP就足够了。然而，一个I/O密集型应用程序可能需要多个LWP来执行。即为每个并发阻塞的系统调用都需要一个LWP。例如，我们有五个不同的读文件请求，但我们只有四个LWP，那么第五个请求就必须等其中一个LWP从内核返回。<br>用于用户线程库和内核之间通信的方案称为调度激活。其工作原理如下：内核为应用程序提供一组虚拟处理器（LWP），应用程序可以将用户线程调度到可用的虚拟处理器上。此外，内核必须通知应用程序某些事件，这些事件被称为上行调用（Upcall）。上行调用由线程库通过上行调用处理程序处理，上行调用处理程序必须在虚拟处理器上运行。当用户线程即将被阻塞时，上行调用就会被触发，通知应用程序保存阻塞线程的状态，并调度其他线程运行。当阻塞事件结束时，内核再次触发上行调用，通知应用程序恢复之前阻塞的线程。<br><img alt="Pasted image 20250113014249.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20250113014249.jpg"><br>在一对一线程模型中，每个用户级线程对应一个内核级线程，因此不需要轻量级进程作为中间层。在这种模型中，用户级线程直接映射到内核级线程，操作系统内核负责调度和管理这些线程。<br><br>POSIX thread（pthread）区别于不同的系统实现，可以是用户级线程也可以是内核级线程；<br>Windows threads是内核级线程；<br>Java thread API会使用宿主机上的线程，宿主机上实现上面类型的线程，Java线程就是什么类型的；<br><br>到这里，我们已经了解过了进程，对线程也有了一定的理解。我们对比了进程和线程上下文切换开销。由于线程的轻量型，我们将线程作为CPU调度的基本单位，而进程作为资源管理的基本单位。<br><br><br>要实现并发，系统就需要是分时的。分时系统将CPU时间分为一段一段的CPU时间片。我们通快速的切换任务。当时间片越来越小时，在宏观上用户和程序就会就会感觉像是独占了CPU。这就是分时的概念，程序在微观上交替执行，宏观上”同时“执行。<br><img alt="Pasted image 20241203220443.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241203220443.jpg"><br><br>在现实中，我们有三种不同类型的并发：进程的并发、线程的并发和I/O复用。前两者是最好理解的，我们比较了进程和线程的优劣，对于进程的并发来说，每个进程都有自己独立的虚拟空间和资源，隔离性高，可以提供更好的安全性和稳定性；而进程切换的开销使得进程并发可能会影响系统资源。<br>线程的并发则减少了进程切换带来的系统开销，线程切换时仅仅保留执行时所需要的少量资源，其他的资源都由进程进行管理。而且线程减少了进程间通信的使用。然而，线程之间互相影响增加了并发控制的复杂性，稳定性相对差一点。<br>I/O复用我们将在学习完I/O系统后单独开一个阶段学习。I/O复用指的是多个I/O操作”同时“被单个进程/线程”同时“所处理，而不需要为每个I/O操作创建一个独立的进程/线程。常见的I/O复用技术有select、poll和epoll。<br><br>提到了并发，与之对应地，我们往往会想到并行的概念。并行我们很好理解，同时地做很多件事。初学者常会将这两个概念搞混，因为在宏观上，它们提供的效果太类似了。只要你的视角转向微观，你就会明白它们的不同。<br>并发是”同时“做多件事，但并行是同时做多件事。他们在宏观上好似都拥有同时，但在微观上只有并行是同时做的。并发关注结构，而并行关注执行，并发提供了解决问题的结构方法，可能支持并行化(多核)，但也不必然(单核)。<br><img alt="Pasted image 20241203220449.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241203220449.jpg"><br><br>并发为我们带来许多优点，我们现在可以在单处理器上允许多个程序，实现微观上虽然是交替执行，但宏观上”并行“执行的特点。这种特性提升了CPU的利用率，从而带给我们更好的性能表现。<br>缺点同样显而易见，调度器需要瞻前顾后，增加了系统调度的复杂性，多个进程可能会相互作用，互相争夺资源，所以避免并发线程导致 inconsistent states 是我们需要关心的一大问题。除此之外，频繁调度所产生的上下文切换开销也是我们要关心的。<br><br><br>POSIX 线程库提供了许多系统调用用于管理线程和线程属性。我们下面一步一步的来介绍这些系统调用。本阶段，我们着重于学习线程管理和线程属性相关的 POSIX 线程库中的系统调用。<br><br>pthread 是 POSIX 标准线程的缩写，它的标准定义在 IEEE 1003.1c 中，规范了 UNIX 系统中的线程行为。这些规范促成了代码在不同平台上（类 Unix）的可移植性。常用管理线程相关系统调用有：<br>#include &lt;pthread.h&gt;

pthread_create();           // Create a new thread
pthread_exit();             // Terminate the calling thread
pthread_join();             // Wait for a specific thread to exit
pthread_detach();           // Detach a thread
pthread_yield();            // Yield the processor to another thread
pthread_cancel();           // Send a cancellation request to a thread
pthread_testcancel();       // Test for pending cancellation requests
<br>常用的线程属性相关的系统调用有：<br>#include &lt;pthread.h&gt;

pthread_attr_init();        // Initialize thread attributes object
pthread_attr_destroy();     // Destroy thread attributes object
pthread_attr_setdetachstate(); // Set the detach state attribute
pthread_attr_getdetachstate(); // Get the detach state attribute
pthread_attr_setstacksize();   // Set the stack size attribute
pthread_attr_getstacksize();   // Get the stack size attribute
pthread_attr_setstackaddr();   // Set the stack address attribute
pthread_attr_getstackaddr();   // Get the stack address attribute
pthread_attr_setscope();       // Set the contention scope attribute
pthread_attr_getscope();       // Get the contention scope attribute
pthread_attr_setschedparam();  // Set the scheduling parameters attribute
pthread_attr_getschedparam();  // Get the scheduling parameters attribute
<br><br>我们先从管理 POSIX thread 的相关系统调用上学起。我们先来看线程创建的系统调用。<br><br>当要创建一个新的线程时，我们会用到pthread_create系统调用，其函数原型如下：<br>int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg);
/* 
Parameters:
	1. thread: Pointer to a pthread_t variable that will hold the thread ID.
	2. attr: Pointer to a pthread_attr_t structure that specifies thread attributes (can be NULL for default attributes).
	3. start_routine: Function pointer to the function to be executed by the thread.
	4. arg: Argument to be passed to the start_routine function.

Return value: Returns 0 on success, non-zero on failure.
*/
<br>这个函数有 4 个参数，需要接受一个 pthread_t 类型的线程类型变量、一个 pthread_attr_t 类型的线程属性、指向一个可调用对象的函数指针和需要传递的参数。本小节我们不需要关注第二个参数，线程属性是为了更小粒度的控制线程，我们留在下小节介绍。<br><br>在创建线程时，通过设置start_routine的函数指针，我们可以让创建好的线程去执行相关的start&nbsp;routine。在编写start_routine函数时，我们需要遵循以下规则：<br>void *(*start_routine) (void *)
/* Rules to obey:
Return value must be a (void*) pointer.
Parameter only can be one void* type pointer, can be a function pointer or else.
*/
<br>下面展示如何使用pthread_create创建一个线程并打印 "Hello from thread!\\n" ：<br>#include &lt;stdio.h&gt;
#include &lt;pthread.h&gt;

void* printHello(void* arg) { // This is a start routine
    printf("Hello from thread!\n");
    return NULL;
}

int main() {
    pthread_t thread; // To store the thread ID

    if (pthread_create(&amp;thread, NULL, printHello, NULL) != 0) {
        perror("Failed to create thread");
        return 1;
    }
    if (pthread_join(thread, NULL) != 0) {
        perror("Failed to join thread");
        return 1;
    }
    printf("Hello from main!\n");
    return 0;
}
<br>当调用 pthread_create 后，新的线程将会创建并开始执行 start_routine 参数所指向的函数。创建完成之后，我们可以用pthread_t类型的变量来操作特定的线程。通过pthread_t变量，我们可以进行线程的管理和控制，比如调用pthread_join等操作来等待线程结束。<br><br>当我们需要等待一个线程结束时，就会用到pthread_join()系统调用。pthread_join()会阻塞主线程（或其他线程）等待指定线程完成后再继续执行，它的函数原型如下：<br>int pthread_join(pthread_t thread, void **retval);
/* 
Parameters:
	1. thread: Thread ID of the thread to wait for.
	2. retval: Pointer to a location where the thread's return value will be stored (can be NULL if not needed).

Return value: Returns 0 on success, non-zero on failure.
*/
<br>为什么一个线程要等待另一个线程呢（主要是主线程等待子线程）？和我们前面学习过的进程 wait() 系统调用类似。主线程需要 pthread_join() 来读取返回值并回收子线程的资源。避免资源泄漏。<br>而且如果主线程没有等待子线程完成或者没有将子线程分离，主线程先行退出，那么所有未分离的子线程会被强制退出。这时，操作系统会强制性地回收子线程所占有的资源，可能导致数据完整性问题并带来同步问题。这里，你需要关心的问题是资源没有得到正确的释放。<br><br>线程有创建就有终止，当我们使用pthread_exit()系统调用时，线程就会终止执行并返回一个值给调用者。函数原型如下：<br>void pthread_exit(void *retval);
/* 
Parameters:
	1. retval: Pointer to the return value of the thread.

This function does not return.
*/
<br>pthread_exit()&nbsp;可以确保线程在退出时正确清理资源（pthread_cleanup_push），并将返回值传递给任何等待它的线程，例如通过&nbsp;pthread_join()&nbsp;函数等待的线程。<br>#include &lt;pthread.h&gt;
#include &lt;stdio.h&gt;

// Function to be executed by the thread
void* thread_function(void* arg) {
    int *ret_val = (int*)malloc(sizeof(int));
    *ret_val = 42; // Set the return value to 42
    pthread_exit((void*)ret_val); // Exit the thread and return the value
}

int main() {
    pthread_t thread;
    int result;
    void *retval;

    // Create a new thread
    result = pthread_create(&amp;thread, NULL, thread_function, NULL);
    if (result != 0) {
        // Handle error
        return -1;
    }

    // Wait for the specific thread to exit and get the return value
    result = pthread_join(thread, &amp;retval);
    if (result != 0) {
        // Handle error
        return -1;
    }

    // Print the return value
    printf("Thread returned value: %d\n", *(int*)retval);

    // Free the allocated memory
    free(retval);

    return 0;
}
<br><br>我们用pthread_detach&nbsp;系统调用将线程设置为分离状态，使线程结束时资源能被自动回收。要设置守护线程等后台线程就需要将线程设置为分离状态。它的函数原型如下：<br>int pthread_detach(pthread_t thread);
/* 
Parameters:
	1. thread: Thread ID of the thread to detach.

Return value: Returns 0 on success, non-zero on failure.
*/
<br>我们前面提到，主线程的退出会导致所有未分离线程的强制退出。而当线程被设置为分离状态后，主线程的退出就不会再影响分离后线程的运行了，这时分离的子线程会在后台继续运行，并在完成后由操作系统自动释放资源（当所有子线程完成后，操作系统会终止整个进程并回收资源）。<br><br>当有需要让线程让出 CPU 给其他线程时，就会用到 pthread_yield 系统调用。需要注意的是，这个出让是系统层面上的。其函数原型如下：<br>int pthread_yield(void);
/* Explanation:
This function yields the processor to another thread.

Return value: Returns 0 on success, non-zero on failure.
*/
<br>pthread_yield()会让线程主动放弃 CPU 。当线程调用pthread_yield()后，它将处于就绪状态，并让操作系统的调度程序选择运行其他就绪线程。一旦其他线程完成或被调度程序切换，原线程可以重新获得CPU时间并继续执行。<br><br>在前面，我们学习了线程会共享进程的地址空间、进程的一系列资源。但是要使得线程能够正常运行，线程还需要拥有自己独立的 TCB、寄存器组和栈空间。前面的两个由操作系统帮我们管理，作为程序员，你可以在创建子线程时规定一些线程的属性信息。包括：<br>
<br>栈大小(stack size)：定义线程的栈大小空间，确保线程运行过程中不会发生栈溢出。你可以通过pthread_attr_setstacksize函数设置栈大小。
<br>调度参数(scheduling parameters)：设置线程的优先级，以决定线程的执行顺序。可以通过pthread_attr_setschedparam函数设置调度参数。
<br>线程状态(thread state)：可以设置线程是分离状态还是可连接状态。分离状态的线程在终止后会自动释放资源，而可连接状态的线程需要通过pthread_join来回收资源。可以通过pthread_attr_setdetachstate函数设置线程状态。
<br><br>在上小结 pthread_create() 中，我们见到了存放线程属性的结构 thread_attr_t 。所有关于线程属性的系统调用都是围绕着这个结构所展开的。简化版的结构体原型如下：<br>typedef struct {
    int detachstate;          // Thread detach state (PTHREAD_CREATE_JOINABLE or PTHREAD_CREATE_DETACHED)
    int scope;                // Contention scope (PTHREAD_SCOPE_SYSTEM or PTHREAD_SCOPE_PROCESS)
    size_t stacksize;         // Thread stack size
    void *stackaddr;          // Thread stack address
    
    struct sched_param schedparam; // Scheduling parameters (priority, etc.)
    // Other fields specific to the implementation
} pthread_attr_t;
<br>下面是一个例子：<br>#include &lt;pthread.h&gt;
#include &lt;stdio.h&gt;

// Thread start routine
void* startRoutine(void* arg) {
    // Thread work here
    return NULL;
}

int main() {
    pthread_attr_t attr;
    pthread_t thread;
    int result;

    // Initialize the thread attributes object
    pthread_attr_init(&amp;attr);

    // Specific settings for thread attributes
    // Example: set the detach state
    pthread_attr_setdetachstate(&amp;attr, PTHREAD_CREATE_JOINABLE);

    // Create a thread with the specified attributes
    result = pthread_create(&amp;thread, &amp;attr, startRoutine, NULL);
    if (result != 0) {
        perror("Failed to create thread");
        return 1;
    }

    /*
    Do something here
    */

    // Wait for the thread to terminate
    result = pthread_join(thread, NULL);
    if (result != 0) {
        perror("Failed to join thread");
        return 1;
    }
    // Destroy the thread attributes object
    pthread_attr_destroy(&amp;attr);

    return 0;
}
<br><br>pthread_attr_init函数用于初始化一个线程属性对象，使其具有默认属性。初始化为默认属性有许多好处，我们希望避免未初始化属性导致的不确定行为，减少潜在的错误，提高查询的可靠性。pthread_attr_init系统调用完成后，我们就可以设置特定化一些的线程属性。<br>系统调用的原型如下：<br>int pthread_attr_init(pthread_attr_t *attr);
/* 
Parameters:
	1. attr: Pointer to a pthread_attr_t structure to be initialized.

Return value: Returns 0 on success, non-zero on failure.
*/
<br>默认属性一般如下：<br>Thread attributes: 
	- Detach state = PTHREAD_CREATE_JOINABLE 
	- Scope = PTHREAD_SCOPE_SYSTEM 
	- Inherit scheduler = PTHREAD_INHERIT_SCHED 
	- Scheduling policy = SCHED_OTHER 
	- Scheduling priority = 0 
	- Guard size = 4096 bytes 
	- Stack address = 0x40196000 
	- Stack size = 0x201000 bytes
<br><br>pthread_attr_destroy&nbsp;用于销毁一个线程属性对象并释放其占用的资源。函数原型如下：<br>int pthread_attr_destroy(pthread_attr_t *attr);
/* 
Parameters:
	1. attr: Pointer to a pthread_attr_t structure to be destroyed.

Return value: Returns 0 on success, non-zero on failure.
*/
<br><br>#include &lt;pthread.h&gt;

int pthread_attr_setdetachstate(pthread_attr_t *attr, int detachstate);
/* 
Parameters:
	1. attr: Pointer to the thread attributes object.
	2. detachstate: Detach state to be set (PTHREAD_CREATE_JOINABLE or PTHREAD_CREATE_DETACHED).

Return value: Returns 0 on success, non-zero on failure.
*/
<br>int pthread_attr_getdetachstate(const pthread_attr_t *attr, int *detachstate);
/* 
Parameters:
	1. attr: Pointer to the thread attributes object.
	2. detachstate: Pointer to an integer where the detach state will be stored.

Return value: Returns 0 on success, non-zero on failure.
*/
<br>int pthread_attr_setstacksize(pthread_attr_t *attr, size_t stacksize);
/* 
Parameters:
	1. attr: Pointer to the thread attributes object.
	2. stacksize: Stack size to be set.

Return value: Returns 0 on success, non-zero on failure.
*/
<br>int pthread_attr_getstacksize(const pthread_attr_t *attr, size_t *stacksize);
/* 
Parameters:
	1. attr: Pointer to the thread attributes object.
	2. stacksize: Pointer to a size_t where the stack size will be stored.

Return value: Returns 0 on success, non-zero on failure.
*/
<br>int pthread_attr_setstackaddr(pthread_attr_t *attr, void *stackaddr);
/* 
Parameters:
	1. attr: Pointer to the thread attributes object.
	2. stackaddr: Stack address to be set.

Return value: Returns 0 on success, non-zero on failure.
*/
<br>int pthread_attr_getstackaddr(const pthread_attr_t *attr, void **stackaddr);
/* 
Parameters:
	1. attr: Pointer to the thread attributes object.
	2. stackaddr: Pointer to a void* where the stack address will be stored.

Return value: Returns 0 on success, non-zero on failure.
*/
<br>int pthread_attr_setscope(pthread_attr_t *attr, int scope);
/* 
Parameters:
	1. attr: Pointer to the thread attributes object.
	2. scope: Contention scope to be set (PTHREAD_SCOPE_SYSTEM or PTHREAD_SCOPE_PROCESS).

Return value: Returns 0 on success, non-zero on failure.
*/
<br>int pthread_attr_getscope(const pthread_attr_t *attr, int *scope);
/* 
Parameters:
	1. attr: Pointer to the thread attributes object.
	2. scope: Pointer to an integer where the contention scope will be stored.

Return value: Returns 0 on success, non-zero on failure.
*/
<br><br>线程取消是一种机制，允许线程在完成其工作之前被另一个线程终止掉。其中，我们将要取消的线程叫做 target 。要取消某一线程，我们需要先用 pthread_cancel 发送取消请求给目标线程。之后，目标线程一般会在取消点检查取消请求，检查到取消请求后终止线程。（延迟取消）<br>线程可以设置自己的取消状态和取消类型，来决定如何相应取消请求。取消类型有：<br>
<br>异步取消(Asynchronous Cancellation)：线程可以随时被取消。（风险较大）
<br>延迟取消(Deferred Cancellation)：线程在到达取消点时检查取消请求。
<br><br>线程可以使用&nbsp;pthread_setcanceltype&nbsp;系统调用来设置自己的取消类型<br>int pthread_setcanceltype(int type, int *oldtype);
/* 
Parameters:
	1. type: Specifies the new cancelability type for the thread. It can be one of the following:
	   - PTHREAD_CANCEL_DEFERRED: The thread will respond to cancellation requests at cancellation points (default).
	   - PTHREAD_CANCEL_ASYNCHRONOUS: The thread will respond to cancellation requests immediately.
	2. oldtype: Pointer to an integer where the previous cancelability type will be stored. Can be NULL if the previous type is not needed.

Return value: Returns 0 on success, non-zero on failure.
*/
<br><br>我们用&nbsp;pthread_cancel&nbsp;系统调用取消一个正在运行的线程。与 pthread_exit 不同的是， pthread_cancel 通常是其他线程调用。<br>int pthread_cancel(pthread_t thread);
/* 
Parameters:
	1. thread: Thread ID of the thread to be canceled.

Return value: Returns 0 on success, non-zero on failure.
*/
<br><br>pthread_testcancel&nbsp;系统调用可以在调用线程中创建一个取消点，使线程能够响应取消请求。<br>void pthread_testcancel(void);
/* 
Explanation: This function creates a cancellation point in the calling thread. If a cancellation request is pending, the thread will be canceled.

This function does not return a value.
*/
<br><br>我们常常使用pthread_testcancel作为取消点来检查是否有取消请求，当检测到请求时，目标线程就会终止线程。然而，pthread 中的库函数还会作为潜在取消点(Potential&nbsp;Cancellation&nbsp;Points)。<br>潜在取消点指的是线程在执行这些操作时，可以检查并响应取消请求的地方。这些点通常是在系统调用或库函数内部，它们也会检查是否有取消请求，以确保线程能够及时响应取消请求。常见的潜在取消点有：<br>
<br>pthread_join：等待线程终止。如果在等待过程中收到取消请求，当前线程会响应并退出。
<br>pthread_testcancel：显式检查取消请求的位置。插入此调用可以设置明确的取消点。
<br>pthread_cond_wait：等待条件变量。如果在等待过程中收到取消请求，线程会响应取消。
<br>read&nbsp;和&nbsp;write：许多I/O操作，如文件读写，也会作为取消点。
<br>sleep：休眠函数在终止时也会检查取消请求。
<br><br>我们主要使用 pthread_cancel 系统调用来发送取消请求，这是 POSIX 标准中提供的线程取消机制。通过 pthread_cancel ，可以发送取消请求并使目标线程在取消点检查和相应取消请求。下面是一个简单的例子：<br>#include &lt;stdio.h&gt;
#include &lt;pthread.h&gt;

void* startRoutine(void* arg) {
    while (1) {
        printf("Thread running\n");
        pthread_testcancel(); // Set a cancellation point, check for cancel request
        sleep(1);
    }
    pthread_exit(NULL);
}

int main() {
    pthread_t thread;

    pthread_create(&amp;thread, NULL, startRoutine, NULL);
    sleep(3); // Blocking for 3s before send cancellation.
    pthread_cancel(thread); // Send cancellation.
    pthread_join(thread, NULL);
    printf("Main thread ends\n");
    return 0;
}
<br><br>如果取消线程的时候线程仍然占有资源怎么办？为了避免资源泄漏，我们可以用下面的系统调用来设置一个 cleanup 句柄。确保每次线程取消时都会调用 cleanup&nbsp;routine 来清理线程，释放资源。<br>#include &lt;pthread.h&gt;

// Register cleanup handler with argument.
void pthread_cleanup_push(void (*routine)(void*), void *argument);
/*
1. routine: Pointer to the cleanup handler function.
2. argument: Argument to be passed to the cleanup handler function.
*/
<br>// Run if execute is non-zero.
void pthread_cleanup_pop(int execute);
/*
1. execute: If non-zero, the cleanup handler is executed.
*/
<br>注意，pthread_cleanup_push&nbsp;和&nbsp;pthread_cleanup_pop&nbsp;必须在同一作用域下成对使用。如果使用了一个，就必须使用另一个。如果没有一个，那么两个都不要出现。<br><br>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;pthread.h&gt;
#include &lt;unistd.h&gt;

void cleanupHandler(void *array) {
	void** a = (void**) array;
	if(*a != NULL){
	    free(*a);
	    printf("Array cleaned up.\n");
	}
}

void* startRoutine(void* arg) {
    int* array = (int*)malloc(sizeof(int) * 10); // 先分配内存
    pthread_cleanup_push(cleanupHandler, (void*)&amp;array); 

    while (1) {
        printf("Thread running\n");
        pthread_testcancel();
        sleep(1);
    }

    pthread_cleanup_pop(1); // To pair
    pthread_exit(NULL);
}

int main() {
    pthread_t thread;
    pthread_create(&amp;thread, NULL, startRoutine, NULL);
    sleep(3);
    pthread_cancel(thread);
    pthread_join(thread, NULL);
    printf("Main thread ends\n");
    return 0;
}
<br>void** a = (void**) array;的必要性：使用(void**)提供了指针的间接访问，通过传递&nbsp;void*&nbsp;参数到清理函数，如果需要修改或检查传入的内存指针指向的内容，可以将其转换为&nbsp;void**。通过类型转换确保指针类型匹配，使得我们能够访问并释放原指针指向的内存。<br>如果cancellation在pthread_cleanup_push(cleanupHandler, array);之前就发生了怎么办？我们可以用下面的方法：<br>int* array = NULL;
pthread_cleanup_push(cleanupHandler, &amp;array); 
array = (int*)malloc(sizeof(int) * 10);
<br><br><br><br>在上一个阶段的结尾，我们简要讨论了多核处理器的调度问题。对于大多数系统来说，多核处理器和优化调度确实能够显著加快系统的运行速度。想象一下，如果有100个人在排队吃面条，显然两家面馆一起营业的效率会比只有一家面馆要高一倍。<br><br><br><br>This depends on the nature of the task (n&lt;core number and in an ideal scenario)<br>Fully parallelized: n*Threads = n*Speed<br>
Partitally parallelized: n*Threads = N*Speed (1&lt;N&lt;n)<br>
Cannot be parallelized: n*Threads = 1*Speed<br><br>阿姆达尔定律(Amdahl's&nbsp;Law) 是计算机科学中的一个公式，用来预测系统在添加多个处理器后的最大可能加速比。阿姆达尔定律表达了一个程序中可以被并行化的部分和不能被并行化的部分，以及在添加更多处理器后系统性能的提升受限于那部分不可并行的计算。<br><br><br>
<br>&nbsp;是使用&nbsp;n&nbsp;个处理器时的加速比。
<br> 是可以并行化的程序部分比例。
<br>&nbsp;是不能并行化的程序部分比例。
<br>&nbsp;是处理器数量。
<br><br><br><br><br>上述课程的学习完毕后，我们应当对线程有了一定了解了。简单来说，线程就是进程的执行流，执行流是什么我们马上会介绍。还记得我们进程番外篇学习的 IPC 机制么？通过IPC，我们创建多个进程共同解决一个问题，但这样做除了资源的浪费，还不得不考虑进程间通信带来的开销。但是引入线程后，上述两个我们最关系的问题迎刃而解。<br>在多核处理器的背景下，创建多个线程的好处是显而易见的——节省资源。线程虽然有独立的TCB，但是线程没有独立的进程虚拟地址空间。这就为线程带来很多相对进程而言的优点，这也是为什么线程能够打赢进程。当项目的代码量很大的时候，fork()创建的子进程的代码区会浪费很大一部分珍贵的内存空间，本质上还是父子进程共享”同一段“代码。但使用线程后，双引号就可以去掉了。<br>而且相比进程，线程为我们带来的优点有：<br>
<br>对线程的操作更快（创建、切换、销毁等）；
<br>TCB 更轻量；
<br>线程间数据直接共享，免去繁琐的 IPC 操作。<br>
但是有优点就会有缺点，比如：
<br>因为进程之间彼此隔离，因而进程的稳定性更好。
<br><br>在理解栈空间之前，我们可以先去看看进程代码是如何执行的——详见 《<a data-href="进程的一生——从出生到死亡 (Abandoned)" href="https://congzhi.wiki/some-notes/进程的一生——从出生到死亡-(abandoned).html" class="internal-link" target="_self" rel="noopener nofollow">进程的一生——从出生到死亡 (Abandoned)</a>》。知道了进程的执行逻辑之后，我们会注意到进程虚拟空间中 “栈” 这个名词的分量。栈是一个很重要的概念，代码的功能是在函数中执行的，而函数的执行依赖在栈空间中创造的一个个栈帧来实现。因此程序的执行和栈空间密不可分，即栈空间就是独立的运行上下文。<br>当一个进程拥有多个线程时，每个线程共享代码段、数据段等资源。每个线程创建的时候操作系统会为这个线程分配单独的栈空间资源。比如，一个线程的栈空间从A到B，另一个线程的栈空间从B到C（A&lt;B&lt;C），以此类推。每个线程的代码在各自的栈空间内运行。<br>我们可以用下面的代码来进行线程栈空间的初始化。<br>#include &lt;thread&gt;
#include &lt;iostream&gt;

void m_Func(){
}

int main(){
    std::size_t stack_size = 1024*1024; // 1MB
    std::thread t(std::thread(func), std::move(stack_size));
    t.join();
    return 0;
}
<br>我们说线程之间数据共享，其实不仅仅是指数据段中的数据。理论上如果知道其他线程栈中局部变量在栈帧中的位置，也可以对这些数据进行操作。因此，线程中的资源是高度共享的。如果线程甲创建的栈帧覆盖线程乙的栈空间，就有可能导致进程的终止。（Threads share all segments except the stack, but a thread can still access the stack of another thread.）<br><br>在当下的日常生活中，无论是手机、电脑、工作站或是服务器都采用多核处理器架构。这是因为相比于执着地将单核登峰造极（在单核心上堆料），多加一个核心性价比要来的更好。由此，多核处理器成为了绝对的主流。但核心也不是越多越好的，要发挥多核处理器的性能优势，不仅仅需要操作系统合理的调度，同样也需要我们开发人员编写多线程的程序以供操作系统调度。<br><br>在Windows操作系统中，线程是进程的基本执行单元。每个进程可以包含一个或多个线程，这些线程共享进程的资源（如内存空间、文件句柄等）。当用户创建一个线程时，Windows会在内核中创建一个对应的内核级线程。Windows采用我们前面所说的1:1线程模型，即每个用户级线程对应一个内核级线程。这种模型的优点是线程管理和调度由操作系统内核负责，简化了开发者的工作。<br>在Windows中，同一台主机上，不同进程中的线程ID可能会重复，因为线程ID在进程内是唯一的。<br><br>在Linux操作系统中，线程和进程的概念则更加模糊。Linux使用轻量级进程(Lightweight Process, LWP)来实现线程，每个线程在内核中都是一个task。Linux通过pthread_create()或clone()系统调用创建线程，clone()允许创建一个共享资源的task（线程）。每个task都有一个唯一的struct task_struct数据结构，用于管理和调度。与Windows不同，Linux的线程模型更灵活，可以通过clone()的参数指定共享哪些资源。<br>在Linux中，所有属于同一进程的线程共享相同的线程组ID（TGID），这个TGID实际上就是进程的PID。而由于进程和线程都是为task，每个任务都有唯一的TID。所以同一台主机上的所有的线程ID都是唯一的。<br><br>C++11的多线程库提供了一组标准的API，用于创建和管理线程、同步线程操作等。这些API包括std::thread、std::mutex、std::condition_variable等。由于这些API是基于pthread标准设计的，因此它们在不同操作系统上的实现是相似的。<br><br>Windows操作系统本身提供了丰富的线程API，如CreateThread、WaitForSingleObject等。C++11的多线程库在Windows上实现时，底层会调用这些Windows API。由于Windows采用1:1线程模型，因此每个C++创建的线程都会对应一个内核级线程。<br>Linux操作系统主要使用pthread库来实现多线程。C++11的多线程库在Linux上实现时，底层调用了pthread API，如pthread_create、pthread_join等。Linux的线程模型基于轻量级进程（LWP），C++程序中创建的每个线程都会对应一个task_struct。<br><br>当程序加载进内存，内核会创建该程序的主线程，其 start routine 的入口在 main() 的开始。在 main() 这个主线程下，我们可以使用 thread 类创建多个子线程。过程如下：<br>#include &lt;iostream&gt;
#include &lt;thread&gt;
static int i = 0;
void hello() {
	i++;
	std::cout &lt;&lt; "Hello there! I am No." &lt;&lt; i &lt;&lt; std::endl;
}
int main() {

	std::thread thread_1(hello);
	std::thread thread_2(hello);
	std::thread thread_3(hello);
	std::thread thread_4(hello);
	std::thread thread_5(hello);
	std::thread thread_6(hello);
	std::thread thread_7(hello);
	std::thread thread_8(hello);
	std::thread thread_9(hello);
	std::thread thread_10(hello);

	return 0;
}
<br>通过thread类就可以创建线程类对象，我们需要给thread类的构造函数传递可调用对象的参数，这里使用函数作为参数。但这个程序会出现bug，这是因为：<br>
<br>主线程没有等待子线程而先行退出；
<br>并没有实现对共享变量i的互斥访问。
<br>因而会导致如下的问题出现：<br><img alt="Pasted image 20240905160146.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240905160146.png"><br>du@DVM:~/Desktop$ ./thread 
Hello there! I am No.5
Hello there! I am No.5
Hello there! I am No.6
terminate called without an active exception
Hello there! I am No.7
Aborted (core dumped)
<br><br>程序执行对应着新进程的创建，在进程中，main函数就是主线程，而在主线程执行时，我们可以创建另外的线程，让这些线程并行独立执行。我们需要注意的是，如果主线程在子线程完成之前结束，程序会调用std::terminate，导致所有未完成的子线程被强制终止，从而引发abort()。<br><br>为了避免主线程先于子线程结束，我们用join()函数来阻塞主线程等待子线程结束后再返回。join()确保主线程在子线程结束后回收其资源，避免资源泄漏。<br>#include &lt;iostream&gt;
#include &lt;thread&gt;
static int i = 0;
void hello() {
	i++;
	std::cout &lt;&lt; "Hello there! I am No." &lt;&lt; i &lt;&lt; std::endl;
}
int main() {

	std::thread thread_1(hello);
	std::thread thread_2(hello);
	std::thread thread_3(hello);
	std::thread thread_4(hello);
	std::thread thread_5(hello);
	thread_1.join();
	thread_2.join();
	thread_3.join();
	thread_4.join();
	thread_5.join();
	std::cout &lt;&lt; "Main thread say byebye!" &lt;&lt; std::endl;
	return 0;
}
<br>运行结果如下：<br>Hello there! I am No.2
Hello there! I am No.5
Hello there! I am No.5
Hello there! I am No.5
Hello there! I am No.5
Main thread say byebye!
<br>join()函数适用于需要确保子线程完成其任务后再继续主线程工作的情况。<br><br>另一种情况是我们想让子线程与主线程分离，主线程从此无法控制子线程，子线程被C++的运行库接管。主进程不需要等待子线程结束在退出，运行库会在这些子线程运行结束后自动清理资源。由此，detach()函数适用于不需要等待子线程完成的任务，例如后台任务或守护线程。<br>#include &lt;iostream&gt;
#include &lt;thread&gt;
static int i = 0;
void hello() {
	i++;
	std::cout &lt;&lt; "Hello there! I am No." &lt;&lt; i &lt;&lt; std::endl;
}
int main() {

	std::thread thread_1(hello);
	std::thread thread_2(hello);
	std::thread thread_3(hello);
	std::thread thread_4(hello);
	std::thread thread_5(hello);
	thread_1.detach();
	thread_2.detach();
	thread_3.detach();
	thread_4.detach();
	thread_5.detach();
	std::cout &lt;&lt; "Main thread say byebye!" &lt;&lt; std::endl;
	return 0;
}
<br>运行结果如下：<br>Main thread say byebye!
Hello there! I am No.1
<br>我们看到主线程早早就结束了，有的子线程甚至还来不及在屏幕上向我们打招呼。<br><br>有三种方式在在子线程中传递参数：1. 值传递；2. 引用传递；3. 指针传递。一般来说使用 detach() 函数时尽量不要传递指针，还不要使用隐式类型转换。<br><br>普通类型在传递子线程函数参数时，我们可以直接使用值传递。当我们使用值传递时，函数收到的是变量的副本，也就是说，函数内部的变量和元素的变量是两个独立的变量了，修改函数内部的变量并不会影响到原始的变量。所以，当使用值传递时，主线程可以放心的退出。<br><br>在C++的 std::thread 中，直接传递引用参数需要使用 std::ref 来包装引用，否则 std::thread 会尝试复制参数，这会导致编译错误或未定义行为。示例如下：<br>#include &lt;iostream&gt;
#include &lt;thread&gt;

void hello(int&amp; i) {
//void hello(const int i){
    i++;
    std::cout &lt;&lt; "Hello there! I am No." &lt;&lt; i &lt;&lt; std::endl;
}

int main() {
    int i = 0;

    std::thread thread_1(hello, std::ref(i));
//  std::thread thread_1(hello, i);
    thread_1.join(); 

    std::cout &lt;&lt; "Main thread: i = " &lt;&lt; i &lt;&lt; std::endl;
    return 0;
}
<br>使用普通的引用传递会调用一次复制构造函数，导致函数无法对引用对象进行修改，于是我们有std::ref，它可以使子线程在传递参数时不再调用复制构造函数。<br><br>每个函数的调用和返回都是伴随着栈内存中栈帧的创建和销毁。如果函数内申请了一段堆内存空间，我们就需要在函数返回之前（栈帧销毁前）将这段堆内存给释放掉，因为栈内存是堆内存的唯一寻址方式。所以，当主线程退出而子线程仍在运行且访问传递的指针时，就可能会导致指针悬挂的问题（因为内存已经释放掉了）。<br>再者，多个线程同时访问指针指向的数据。期间若是涉及到了数据的写操作，我们还不得不考虑数据一致性的问题，可能需要额外的同步机制来确保数据的安全问题。<br>在现代C++中，我们可以使用智能指针来避免内存释放的问题，但是数据一致性还是我们需要考虑的。下面是使用std::shared_ptr的示例，即使主线程退出，我们仍然可以正确管理内存。<br>#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;memory&gt;
#include &lt;chrono&gt;

void hello(std::shared_ptr&lt;int&gt; ptr) {
    (*ptr)++;
    std::cout &lt;&lt; "Hello there! I am No." &lt;&lt; *ptr &lt;&lt; std::endl;
}

int main() {
    auto ptr = std::make_shared&lt;int&gt;(0);

    std::thread thread_1(hello, ptr);
    std::thread thread_2(hello, ptr);
    std::thread thread_3(hello, ptr);
    std::thread thread_4(hello, ptr);
    std::thread thread_5(hello, ptr);

    thread_1.detach();
    thread_2.detach();
    thread_3.detach();
    thread_4.detach();
    thread_5.detach();

    std::this_thread::sleep_for(std::chrono::seconds(2)); // 确保子线程有时间完成

    std::cout &lt;&lt; "Main thread say byebye!" &lt;&lt; std::endl;
    return 0;
}
<br>运行结果如下：<br>Hello there! I am No.2
Hello there! I am No.5
Hello there! I am No.5
Hello there! I am No.5
Hello there! I am No.5
Main thread say byebye!
<br><br>你可能已经注意到，我们上面代码的运行结果并不符合我们所想象的那样。虽然我们用join()确保子线程运行完成，但是我们仍然看到这种情况：<br>Hello there! I am No.2
Hello there! I am No.5
Hello there! I am No.5
Hello there! I am No.5
Hello there! I am No.5
Main thread say byebye!
<br>这是由于操作系统的线程调度机制和竞态条件导致的。线程的执行顺序由操作系统的调度器决定，可能导致输出顺序的不确定性。为了解决这种问题，我们可以使用同步机制，如互斥锁（mutex）&nbsp;或&nbsp;条件变量(condition&nbsp;variable)，也可以将操作原子化(atomic operation)。我们将在下一阶段介绍这些技术。<br><br><br>
协程本身并不作为操作系统中的内容。协程是用户级的并发编程模型。这里仅作为补充。协程并不算新鲜词，Melvin Conway在1958年就提出了协程的概念，并应用于汇编程序中。
<br>协程并不算是操作系统的内容，因为它是在用户态实现的。引入协程的概念就是为了避免线程切换的开销，作为更小型的并发控制流，协程随即应运而生。因为协程是用户级别的并发编程模型，所以协程切换时不需要从用户态陷入内核态，系统内核对协程的存在也一无所知。<br>在本阶段，我们提到了内核调度的最小单位是内核级的线程。现代的操作系统中，一个用户级线程往往对应着一个内核级线程，当我们在用户空间创建一个用户空间线程之后，我们可以说我们创建了一个内核可以调用的真•线程。而协程往往在一个线程中运行，所以协程并不提高程序的性能。<br><br>协程和函数很类似，你可以说协程就是一个能暂停并继续执行的函数。当函数中出现co_await、co_yield或co_return的其中一项时，该函数就可被看作为一个协程。下图展示了函数和协程的调用过程。当函数被调用时，函数就会开始执行，直到遇到return或到达函数末尾。而协程可以执行一部分程序后挂起，等待再次调度。协程实现了在单个线程内的并发执行。<br><img alt="Pasted image 20250112233950.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20250112233950.png"><br>
由于协程在用户空间实现并发，我们可以控制代码的执行顺序，从而减少多任务调度造成的竞争问题（特别是cooperative multitasking）。由于协程在单个线程内运行，并且可以在执行过程中暂停和恢复，因此我们可以避免传统多线程编程中常见的竞争条件和锁定问题。在某些情况下，仍然需要使用同步机制来确保一致性。<br><br><br>为了实现协程从挂起恢复后继续运行，协程也需要保存上下文状态信息，这些上下文状态信息被存放在coroutine frame中。根据coroutine frame的实现方式，我们有两类协程：stackfull coroutine和stackless coroutine（C++20 使用的是 stackless coroutine）。Stackfull coroutine会将coroutine的数据和c-routine frame存放在stack中，而stackless coroutine的实现方式则会把coroutine存放在堆上。<br>这些上下文信息会有编译器代为我们管理。当协程的生命周期结束时，协程帧就会被销毁。<br><br>在C++中，我们有三个关键字：co_await、co_yield和co_return。这三个关键字得以让协程与外界进行交互。协程可以被暂停/挂起和恢复执行。其中，co_await和co_yield可以挂起协程，而co_return用于返回。它们有不同的行为，协程状态与这三个关键字也息息相关。<br><br>包含协程三个关键字之一的函数就可以被看作是一个协程。但需要注意的是，在C++中，当我们创建协程时，协程的返回类型必须是一个特定的类型，该类型需要包含一个名为promise_type的嵌套类型（和std::promise没关系）。所以下面返回类型为int的协程代码在编译时就会报错：<br>int foo() {std::suspend_always{};}
<br>promise_type是一个类对象（struct或class，而且必须名为promise_type），定义并控制协程的行为和生命周期管理。返回值类型就是对这个promise_type的包装，如下：<br>struct co_return {
    struct promise_type {
		// Something needs to be done here...
    };
};
co_return foo() {}
<br><br>在promise_type中，需要至少包含以下的方法get_return_object、initial_suspend、final_suspend、return_void（或return_value）和unhandled_exception。我们将一步一步的对这五个方法进行说明。最小的协程返回对象如下：<br>struct co_return {
    struct promise_type {
        co_return get_return_object() { return {}; }
        std::suspend_never initial_suspend() { return {}; }
        std::suspend_never final_suspend() noexcept { return {}; }
        void return_void() {}
        void unhandled_exception() { std::terminate(); }
    };
};
<br><br>这是最先开始执行的方法，get_return_object方法构造协程的返回类型（这里是co_return）并返回promise_type的父类型，也就是协程的返回类型。这里的return {};表示返回默认构造的co_return。<br><br>这个方法在协程开始执行之前被调用，返回一个可等待对象，决定协程是否在开始时挂起。这里，返回的可等待对象可以是std::suspend_never或std::suspend_always。我们这里使用前者，表示协程在开始时不会挂起，而是立即执行。return {};返回默认构造的std::suspend_never。<br>根据不同的启动方式，协程可以被分为Lazily started coroutines和eagerly started coroutines。我们例子中给出的是eagerly started coroutines，这些协程在创建时就会立即开始执行。如果我们在这里返回的可等待对象是std::suspend_always那么我们就会创建lazily started coroutine。<br><br>与 initial_suspend 类似，final_suspend 方法在协程结束时被调用，它同样返回一个可等待对象，决定协程是否在结束时挂起。这里我们使用 std::suspend_never 。 final_suspend 是一个 non-throwing method，这就是为什么通常使用 noexcept 关键字。<br><br>这两个方法用于处理协程的返回值。如果协程没有返回值，则使用return_void；如果协程返回值，则使用return_value。在例子中，我们不设置任何返回值，所以使用return_void。<br><br> unhandled_exception 方法用于协程中的异常处理，在协程中抛出未捕获的异常时被调用。在一些的例子中，我们不需要做任何的异常处理。例子中，我们使用 std::terminate() 来终止协程。<br><br>C++标准提供了两个常见的 awaiters，std::suspend_always 和 std::suspend_never。当使用 std::suspend_always 时，，协程会在遇到 co_await 时立即挂起。使用 std::suspend_never 时，协程会在遇到 co_await 时继续执行，不会挂起。<br><br><br>#include &lt;iostream&gt;
#include &lt;coroutine&gt;

struct co_return {
    struct promise_type {
        co_return get_return_object() { return {}; }
        std::suspend_never initial_suspend() { return {}; }
        std::suspend_never final_suspend() noexcept { return {}; }
        void return_void() {}
        void unhandled_exception() { std::terminate(); }
    };
};

co_return coroutine_foo() {
    std::cout &lt;&lt; "Hello ";
    co_await std::suspend_always{};
    std::cout &lt;&lt; "world!" &lt;&lt; std::endl;
}

int main() {
	co_return cofoo = coroutine_foo();
	cofoo();
    return 0;
}
<br><br>#include &lt;iostream&gt;
#include &lt;coroutine&gt;

struct co_return {
    struct promise_type {
        co_return get_return_object() { return co_return{std::coroutine_handle&lt;promise_type&gt;::form_promise(*this)}; }
        std::suspend_never initial_suspend() { return {}; }
        std::suspend_never final_suspend() noexcept { return {}; }
        void return_void() {}
        void unhandled_exception() { std::terminate(); }
    };
    std::coroutine_handle&lt;&gt; handle;
    co_return(std::coroutine_handle&lt;&gt; handle_): handle{handle_}{ }
    operator std::coroutine_handle&lt;promise_type&gt;() const {return handle_}
};

co_return coroutine_foo() {
    std::cout &lt;&lt; "1. Hello! \n";
    co_await std::suspend_always{};
    std::cout &lt;&lt; "2. Again! \n";
    co_awiat std::suspend_always{};
    std::cout &lt;&lt; "3. Another Hello! \n";
    co_awiat std::suspend_always{};
    std::cout &lt;&lt; "4. Another another Hello! \n";
}

int main() {
	co_return cofoo = coroutine_foo();
	cofoo.handle.resume();
	cofoo.handle(); // Calls std::coroutine_handle&lt;&gt;::operator();
	std::cout &lt;&lt; std::boolalpha &lt;&lt; cofoo.handle.done() &lt;&lt; std::endl; // Check if coroutine is executed.
	cofoo();
    return 0;
}
<br>学不明白。。。课程链接如下：<br><a data-tooltip-position="top" aria-label="https://www.youtube.com/playlist?list=PL2EnPlznFzmhKDBfE0lqMAWyr74LZsFVY" rel="noopener nofollow" class="external-link" href="https://www.youtube.com/playlist?list=PL2EnPlznFzmhKDBfE0lqMAWyr74LZsFVY" target="_blank">Coroutines</a>]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/7.-thread-and-concurrency.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/7. Thread and Concurrency.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 21 Mar 2025 16:42:43 GMT</pubDate><enclosure url="https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20241204003952.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20241204003952.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[8. CPU Scheduling]]></title><description><![CDATA[ 
 <br><br><br>当今的现代操作系统都调度内核级的线程，但许多资料仍然使用如“作业调度”或“进程调度”这样的名词。在本阶段的内容中，不区分相关名词的具体含义。无论是作业调度、进程调度还是线程调度，都是指操作系统在不同时间段内分配CPU资源给不同任务的过程。<br><br>在OS中，调度(Scheduling) 是指管理和分配计算机处理器给不同进程的过程。调度通常分为：长程调度(Long-term scheduling)、中程调度(Medium-term scheduling)、短程调度(Short-term scheduling) 和 I/O调度(I/O scheduling)。<br><img alt="Pasted image 20240528012310.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240528012310.png"><br><br>长程调度，或称高级调度(high-level scheduling) 和 作业调度(job scheduling)，决定了哪些作业(jobs)进入系统（内存）并加入到就绪队列准备运行。涉及到进程从new state到ready state的转换。通常在批处理系统中使用，用于控制系统的负载和作业的流入速度。长程调度的主要目标是保证系统资源的合理利用，避免系统的过载。<br>我们使用的PC中，长程调度并不常见。作为用户，我们可以决定去运行哪个程序。有时候可能会有per-user的限制（比如 100 processes/user）。除了批处理，长程调度在服务器中也很常见。当服务器满载时，新加入的客户端可能会收到服务器的提示信息（比如游戏服务器的排队提醒）。<br>在Android等移动操作系统上，进程调度可能会非常激进。当系统资源紧张时，操作系统会优先保证前台应用的运行，而将后台进程杀掉以释放内存和CPU资源。这种机制被称为“杀后台”。<br><br>中程调度，或称中级调度(mid-level scheduling)，负责进程在内存和外存之间的调度，如换入和换出。这种调度用于内存管理，以便内存不足时将不活跃的进程暂时换出，从而腾出内存空间给其他进程使用。中程调度的主要目标是优化内存使用，提高系统的整体性能。<br>相比于长程调度和短程调度，中程调度的频率很低，因为I/O操作很费时间。甚至在有的操作系统中，当内存不足时会强制终止任务的执行。（Android）<br><br>短程调度，或称低级调度(low-level scheduling) 和 CPU调度(CPU scheduling)。长程调度/中程调度可能很久才发生一次，单短程调度可是时时刻刻都在发生。短程调度就相当于是“我们现在要做什么？”。阻塞、运行、预备态都是在短程调度中发生的。在短程调度中，调度器(dispatcher)会使用一些调度算法管理选择哪个进程可以占用CPU。<br>在多任务操作系统中，（短程）调度器负责不断地将进程放在CPU中执行，以确保系统的高效运行。调度程序选择下一个要在CPU中运行的进程后，调度器就会执行相关的上下文切换，然后跳转到适当的内存位置执行相应的指令。<br>
<img alt="Pasted image 20250112184625.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20250112184625.png"><br>由调度器所消耗的时间成为调度延迟。这种延迟可能会变成系统的性能瓶颈，所以设计调度器时应当确保其时间复杂度尽可能的低。<br><br>详见I/O系统。<br><br>不同的CPU调度算法具有不同属性，一个特定算法的选择可能会对某一个或几个进程更有利。为了选择以应对特定情境的算法，我们需要考虑各个准则综合评估。这些准则包括：<br>
<br>CPU使用率(CPU utilization)<br>
CPU利用率是指CPU十几倍使用的事件百分比。对于一个实际系统，CPU利用率不宜太低，一般为40%（轻负载系统）到90%（重负载系统）。
<br>吞吐量(Throughput)<br>
吞吐量时系统一个单元时间内进程完成的数量。
<br>周转事件(Turnaround time)<br>
周转时间是进程从提交到完成的这段时间。周转时间是所有时间段之和，包括等待进入内存、就绪队列中的等待、CPU中执行和I/O执行。
<br>响应事件(Responce time)<br>
响应时间是指从提交请求到系统首次响应的时间(例如:当你进行键盘输入，从按下一个键到屏幕显示这个字符的时间)。对于交互式系统，低响应时间至关重要，因为它直接影响用户体验。调度策略应确保系统对用户请求的响应尽可能快。
<br>等待事件(Waiting time)<br>
等待时间是指一个进程在就绪队列中等待处理器分配所花费的时间。调度策略应尽量减少进程的等待时间，从而提高系统的整体性能。
<br>
<br>公平性(Fairness)<br>
公平性是指调度策略应确保所有进程得到公平的处理器时间，不应让某些进程长期得不到处理器资源。公平的调度策略可以防止饥饿现象(starvation)，即某些进程长时间等待却无法执行。
<br>
<br>优先级(Priority)<br>
某些系统中，进程可能具有不同的优先级。调度策略需要根据优先级分配处理器时间，确保高优先级进程能及时得到处理。这对于实时系统和需要紧急处理的任务尤为重要。
<br>折中与权衡(Trade-offs)<br>
在实际应用中，不同评估标准之间往往存在冲突。例如，优化周转时间可能会增加等待时间，或者提高吞吐量可能会降低公平性。因此，选择调度策略时需要在这些标准之间进行折中和权衡，以实现系统的最佳性能。
<br><br>在系统中运行的进程根据其行为模式可以被分为不同的类型。根据进程主要消耗CPU资源还是I/O资源，我们将进程分为CPU密集型和I/O密集型。此前，我们先明晰burst的概念。<br><br>CPU burst指的是进程在一段时间段内连续使用CPU。在这段时间里，进程主要执行使用CPU的计算任务，不进行I/O操作。<br>I/O burst就是进程在时间段内连续进程I/O操作，而不进行使用CPU的计算任务。<br><br>CPU密集型和I/O密集型进程的判断实际上就是通过CPU burst和I/O burst的相对时长判断的。CPU密集型进程的CPU burst时间较长，而I/O burst时间较短。而I/O密集型进程则相反。<br>由于I/O密集型进程因为所需要的CPU时间并不多，所以被称为短作业或短进程。类似的，CPU密集型进程也被称为长作业或长进程。<br><br><br><br>先来先服务算法是最简单的CPU调度算法。采用FCFS，OS的调度程序会按照进程进入就绪队列的先后顺序分配CPU时间。<br>若采用非抢占式(non-preemptive) 的先来先服务算法，每个进程会一直占用CPU知道执行结束或主动放弃，然后调度程序会选择就绪队列中的下一个进程继续执行。<br>因为FCFS可以通过FIFO队列的方式轻松实现，因而也称为FIFO算法。<br><br>
<br>FCFS算法是最易于理解和实现的调度算法，这是它最大的优点。
<br>此外，得益于先进先出的性质，FCFS算法是公平的。
<br>FCFS一般适用于批处理系统。
<br><br>
<br>由于算法非常简单，没有优化策略，所以FCFS的效率不高。
<br>等待时间和周转时间受进程顺序影响大，可能导致车队效应(convoy effect)。
<br>此外，由于后来的进程往往需要等待前面所有进程的结束，这会导致靠后进程的饥饿。
<br>（车队效应容易发生在IO密集型进程队列中。这类进程只用很短的时间在CPU上执行。如果有一个 CPU 密集型进程在队列的前面，它会占用 CPU 很长时间，导致后面的 I/O 密集型进程不得不等待。这会导致 CPU 和 I/O 设备的利用率降低，系统效率下降。）<br><br>RR调度算法是增加抢占的FCFS算法。它定义了一个较小的时间片(time slice) 或 时间量(time quantum) ，通常是10~100ns。将就绪队列作为循环队列，CPU调度器循环整个就绪队列，为每个进程分配不超过一个时间片的CPU。RR算法是专门为分时系统设计的，也是最常作为核心使用的调度算法。<br><br>
<br>简单、易于实现且对于就绪队列的每个进程都是公平的。
<br>CPU使用率高：若时间片大小合适，RR算法通常可以保持较高的CPU使用率。
<br><br>
<br>低吞吐量：由于每个进程都要以相同的时间片循环共享CPU资源，因此可能会导致比FCFS更小的吞吐量(下同)。
<br>高等待时间和高响应时间。
<br>在进程调度过程中有上下文切换(Context switching)，当时间片设置的过小时，频繁的上下文切换会占用大量CPU资源。
<br><br>虚拟轮转(Virtual Round Robin, VRR)是传统轮转调度（Round Robin, RR）的改进版本。虚拟轮转调度的主要目的是解决传统轮转调度在处理I/O密集型进程时的效率问题。<br>在传统轮转调度中，每个进程都会被分配一个固定的时间片，当时间片用完时，进程会被切换到队列的末尾。然而，这种方法对I/O密集型进程不太友好，因为这些进程通常会在时间片用完之前就进入等待I/O操作的状态，导致它们频繁地被切换，增加了系统的开销。<br>虚拟轮转调度通过引入一个虚拟队列(auxiliary queue)来解决这个问题。当一个进程进入等待I/O操作的状态时，它会被移到虚拟队列中，而不是直接切换到主队列的末尾。当I/O操作完成后，进程会被重新放回主队列的适当位置，以便尽快获得CPU的使用权。<br><br>最短优先调度算法将每个进程与下次CPU执行长度关联起来。当CPU空闲时，调度器会将CPU资源赋给最短CPU执行时间的进程。短作业优先算法可以是抢占式的，称为最短剩余时间优先(Shortest Remaining Time First)。通常情况下SJF特指非抢占式调度。<br>由于最短时间的进程总是先执行，所以系统的平均等待时间和平均周转时间总是最优的。但是最短优先算法不可避免的会导致长进程的饥饿。而且最短作业优先的策略很难实现，因为CPU无从开始时得知每个进程要使用多长的CPU时间，因此SJF是很难实现的。<br><br>
<br>SJF is an optimal algorithm, which uses the best way of CPU and I/O devices.
<br><br>
<br>算法很难实现。
<br>在执行过程中到达的更短进程得不到及时的响应。
<br>会导致长进程的饥饿。
<br><br>SRTF是最短作业优先的抢占式版。在这种算法下，最短剩余时间的进程总会先于其他进程执行。<br><br>
<br>吞吐量大：短进程会被即时响应。
<br>系统开销小：由于SRTF算法只在进程完成或添加新进程时才做出调度决策，因此系统的管理开销很小。
<br><br>
<br>算法很难实现。 
<br>会导致长进程的饥饿现象。
<br><br>优先级调度算法会根据每个进程的优先级来分配CPU时间。在这种调度算法中，每个进程都会被赋予一个优先级，CPU总是将资源分配给优先级最高的进程。<br>
<br>优先数(Priority)：描述进程重要性和紧急程度的一个属性。
<br>优先数(Priority number)：用于量化优先级的一个数值，一般而言，优先数越低，优先级越高。
<br>优先级调度算法有抢占式(preemptive)和非抢占式(non-preemptive)版本。
<br><br>相比于轮转调度算法，优先级调度算法显然不算是一个公平的算法，因为低优先级的进程往往需要忍受饥饿。但是我们可以通过老化的方法解决这个问题。<br>
<br>通常而言，系统会设置一个时间间隔。每经过一个时间间隔，系统就会随着时间的推移增加等待进程的优先级。
<br>系统需要平衡优先级提升和实际需求，确保高优先级进程的响应时间不会因为频繁提升低优先级进程的优先级而收到太大影响。
<br><br>除了动态提升进程的优先级外，还可以通过降低高优先级进程的优先级来防止饥饿问题。<br>
<br>时间片耗尽：当一个高优先级进程消耗完它被分配的时间片后，其优先级可能自动被降低。
<br>资源占用检测：如果一个进程在一定时间内占用了过多CPU时间，系统可能会动态调整其优先级。
<br><br>在高响应比优先算法中，调度器需要计算就绪队列中所有进程的响应比(Response ratio)，并选择响应比最高的进程分配CPU时间。响应比的计算公式是：W表示进程在就绪队列中的等待时间；<br>
S表示进程的预计服务时间（运行时间）。<br>我们可以看出，这种算法是对SJF算法的改进版，使得长进程经过一段时间的等待（W增加，RR变大）以可以获得CPU。HRRN算法综合等待时间和运行时间，防止长进程饥饿，提供较为公平的调度。通常情况下，该算法默认使用非抢占式。<br><br>多级队列调度算法将就绪队列中的不同进程按照类型划分成多个不同的队列中：<br>
<br>队列分类：按照进程的需求和行为特性，将进程分类到不同的队列中，例如按进程类型（交互式、批处理、系统级等）进行分类。
<br>优先级设置：在MLQ调度中，可以将每个队列设置为不同的优先级，一般的优先级排序为：
<br>调度策略：每个队列可以采用最适合其进程特性的调度策略。如，前台交互式进程通常采用RR策略，后台批处理进程则可能再用FCFS策略。
<br>调度执行顺序：调度器首先会检查高优先级的队列是否有可运行的进程，若没有，调度器才会检查下一优先级的队列。
<br>抢占和非抢占
<br><br><br>多级反馈队列调度算法综合了静态优先级和时间片轮转算法的特点，实现了动态调整进程优先级来优化CPU时间段分配。<br>
<br>进程队列：系统设置多个队列，每个队列具有不同的优先级。通常而言，优先级排序为
<br>调度策略：每个队列均采用时间片轮转算法，队列的优先级越低，队列分配的时间片越长。
<br>调度执行顺序：新就绪的进程首先进入最高优先级队列（）。如果进程在其时间片结束时未完成，则会被降至下一优先级队列（从移到）。如果进程在较低优先级队列中因等待I/O操作而被贬为组测状态，并在I/O完成后再次就绪，它则可能被提升回更高的优先级队列。
<br>抢占和非抢占
<br>Note：尽管多级队列调度算法和多级反馈队列调度算法都划分了很多队列对进程进行划分。但它们在进程调度上有着本质的区别。<br>
<br>在MLF中，进程一旦被分配到某个队列，就会在完成前一直待该队列中。这会必定的导致某些进程的饥饿。
<br>在MLFQ中，进程可以在不同的队列间”移动“。因而，采用MLFQ的OS可以根据进程长短动态地调整进程在长进程队列还是短进程队列。克服了SJF不能预测进程长短的缺点。保持CPU不空闲的前提下实现了较短进程优先，所以MLFQ的效率相较于MLQ要高。
<br><br>Garanteed scheduling的调度算法不同于前面注重于效率的多中调度算法，这种算法旨在确保每个用户公平地获得相等的CPU时间。比如系统内有 n 个用户，那么每个用户将获得 1/n 的CPU时间。或者 m 个进程，每个进程获得 1/m 的CPU时间。这种算法可能不是最高效的，但是相对公平的。<br>为了实现Guaranteed Scheduling，系统需要跟踪每个用户或进程所用的CPU时间。具体来说，系统会计算每个进程的实际CPU时间与预期CPU时间之间的差异。如果某个进程的实际CPU时间少于预期CPU时间，系统会优先分配更多的CPU时间给该进程，以确保公平性。<br><br>Lottery scheduling是一种随机化的调度算法。每个进程根据其优先级或需求在某种资源上获得一定数目的“彩票(lottery tickets)”。资源调度时，调度器会随机抽取一张彩票，持有该彩票的进程将获得资源。<br>在Lottery Scheduling中，假如某资源总彩票数量为 T，某个进程拥有 f 张该类型的彩票，那么这个进程获得该资源的概率大约为 f/T。当进程被创建或终止时，系统会调整彩票的数量，以确保资源分配的公平性。<br><br><br>当没有事情可做时，调度算法会调度什么呢？因为调度器并不能自己生成一个进程去运行，在这种情况下，调度器会加载idel task去运行。Idle Task 没有任何依赖关系（dependencies），即它不依赖于其他任务或资源来执行。由于无事可做的状态任何时候都可能发生，所以idel task不可以被阻塞，以确保随时都可以被加载。<br>在不同的系统里，idel task的实现可能是不同的，可以是重复地唤起调度器，也可能是做一些无意义的加法运算，或是执行一堆的NOP指令。当执行idle task时，CPU会被 halt/switch 到低功耗模式。它的主要目的是确保CPU始终有任务可执行，从而避免系统进入空闲状态。<br>这些无用功好像毫无意义，但是idel task还是有它的存在意义的：<br>
<br>防止了调度器无事可做，避免调度器返回状态异常。
<br>提供了任务运行时间的会计信息，以便我们能够知道系统处于空闲状态的时长。
<br><br>Priority Inversion 是一种调度问题，描述了一种高优先级进程等待低优先级进程释放资源的情形。当一个低优先级的任务持有一个高优先级任务所需的资源时，高优先级任务被迫等待，导致系统性能下降。这种情况通常发生在多任务操作系统中，尤其是在实时系统中。<br>想象这样一种情形，高优先级任务 、中优先级任务  和低优先级任务  。 作为一个高优先级的进程等待低优先级  所占有的信号量。而且  在临界区中，由此  进入阻塞状态。如果在此期间  开始运行，由于  的优先级高于 ，所以  会抢占CPU， 被阻塞，进一步延迟  的执行。这就是Priority Inversion。在实时系统中，这种高优先级进程必须尽快运行。我们需要寻找一种解决办法。<br><br>为了解决Priority Inversion问题，可以使用Priority Inheritance协议。当低优先级任务持有高优先级任务所需的资源时，低优先级任务会暂时继承高优先级任务的优先级，直到释放资源为止。这可以确保高优先级任务尽快获得所需资源，减少等待时间。<br><br>1997年，NASA的Mars Pathfinder探测器在火星上运行时，遇到了一个严重的问题：系统频繁重启，导致数据传输中断。这个问题的根源在于Priority Inversion。具体来说，火星车有这样三个任务：<br>
<br>低优先级任务：获取一个信号量，对information bus进行加锁。
<br>中优先级任务：处理通信（communication）。
<br>高优先级任务：需要使用information bus。
<br>当低优先级任务加锁时，高优先级任务进入阻塞状态。这时，中优先级任务开始运行，并抢占了CPU资源，从而低优先级任务也被阻塞，同时并不释放信号量。由于中优先级任务一直运行，高优先级任务一直得不到锁，系统会认为高优先级任务运行错误（task failure）。<br>高优先级作业一直被阻塞会让系统认为发生了严重的死锁。为了尽快恢复高优先级作业的运行，系统会进行Armageddon的死锁解决方案，即reboot。这就意味着一些数据的丢失。<br><br>和优先级继承的解决思路类似。优先级天花板会将为每个共享资源分配一个优先级天花板来防止低优先级任务阻塞高优先级任务。<br><br><br><br>当我们的视界迈入多处理器的时刻，我们的世界发生了巨变，同时，复杂度会迈上一个新的台阶。当前，我们可以考虑的多处理器系统主要有三类：<br>
<br>Distributed System：服务器多采用的处理器架构，系统中的处理器通过网络连接。
<br>Functionally Speciallized：处理器的功能特化。一个CPU用于图像处理，另一个用于数据处理。
<br>Tightly Coupled：系统中的处理器共享内存和资源，通常通过高速总线连接。
<br>本节课，我们聚焦于紧耦合型的系统，这也是当前个人PC上常见的多 die 多核心CPU的类型。<br><br>
简单起见，一般认为每个处理器只有一个核心。本文部分内容作为补充介绍多 die 多核心 CPU。
<br>在之前的讨论中，我们仅仅将讨论范围放在了单核心处理器(single-core processor) 的调度策略上面。然而，由于主频发展的瓶颈，要提高CPU的性能，我们需要增加CPU的核心数，即多核心处理器(multicore processor)。当下，多核心处理系统在大多数计算机上得到了广泛的应用，在服务器上，处理器的核心数甚至能够达到144核心（Intel Sierra Forest-SP）。<br>在单核系统中，所有的进行共享同一个处理单元，调度器只需要决定下一个要执行的进程是哪个。而在多核系统中，由于调度器需要在多个核心之间分配任务，调度复杂性大大增加。我们下面从三个方面举例其相比单处理器的复杂性：<br>
<br>并行性(Parallelism)：由于在单处理器系统中我们只有一个核心，所有进程必须串行执行，系统能够并发但没有并行。由于核心数的增加，多核系统能够在任务一占据核心0的同时任务一占据核心1同时执行。为系统带来了并行性。
<br>负载均衡(Loading Balancing)：在单核心处理器上，CPU资源十分珍贵，我们想让处理器时时刻刻都保持高负荷的状态。在多核心处理器中，我们需要考虑负载均衡，即如何将任务均匀地分配给各个核心。如何保证每个核心都运行在最佳的状态才是我们要关心的。
<br><img alt="Pasted image 20241003233336.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241003233336.png"><br>
3. 核心亲和性(Core Affinity)：在计算机组成的Memory hierarchy中，我们学习了Cache的分级。其中，每个核心都会对应一个L1 Cache和一个L2 Cache。这些缓冲中存储着最近在当前核心上运行过任务的数据和指令。如果进程频繁切换或混乱调度，就会造成每次核心的调度都会造成缓存失效，性能降低。<br><br>在并行计算中，粒度(granularity)，或“谷粒大小”（grain size)，描述了并行计算中任务的规模大小。系统能够进行并行任务的规模越大，粒度就越大。细粒度(fine-grained) 的任务通常较小，可以均匀地分配到多个处理器或核心上运行。粗粒度(coarse-grained) 的任务较大，不易均匀分配任务，可能导致负载不均衡。所以细粒度的任务一般部署在同一台主机上，而粗粒度的任务可以部署到多处理器系统或分布式系统上。<br>指令间隔(Instruction Interval) 指的是处理器执行指令之间的时间间隔。这种时间间隔包含了指令之间可能存在的等待时间、访存时间和同步通信所用的时间等。<br>粒度大小和指令间隔大小息息相关。一般来说，粒度越大，指令间隔就越大。下面是几种系统，其中粒度和指令间隔逐步增大：<br>
<br>
单处理器系统(Single Processor System)：

<br>粒度：最小
<br>指令间隔：通常较短，因单处理器执行所有任务，无需并行通信和同步。


<br>
功能特化的多处理器系统(Functionally Specialized Multiprocessor System)

<br>粒度：小
<br>指令间隔：适中，因特化处理器执行特定任务，但需要一些同步和通信。


<br>
多处理器系统(Multiprocessor System)

<br>粒度：中等
<br>指令间隔：适中，因多个处理器并行执行任务，需要更多的同步和通信。


<br>
功能特化的分布式系统(Functionally Specialized Distributed System)

<br>粒度：较大
<br>指令间隔：较大，因不同系统节点执行特化功能，需频繁通信和同步。


<br>
分布式系统(Distributed System)

<br>粒度：最大
<br>指令间隔：最大，因任务在不同节点分布，网络延迟和同步开销较大。


<br>细粒度由于任务较小，同步和通信往往只局限在同一台主机上的不同核心上，同步通信的开销较低，因此细粒度系统的指令间隔较小。粗粒度系统由于任务较大，通信和同步的开销较大，所以指令间隔可能非常大。<br><br><br>多核CPU？多CPU？如果你为这两个名词所困扰，我们不妨先了解一下CPU是如何制造的。高纯度硅经过切割之后我们得到一个个晶圆(wafer)，晶圆经过光刻等制造出许多个相同的电路图案，每个图案切割后我们就得到了一个die(裸片)。而die功能越复杂（面积越大），die的良品率就会越低。即die越大，成本越高，但是性能好。<br>如果我们有一个48核心CPU，我们该如何权衡利弊？我们可以将48个核心集成到一个die上封装成单die多核心CPU；还可以将48个核心分别集成在4个die上，每个die对应12个核心封装成多die多核心CPU。在第二种方案上，我们不额外考虑外围电路和总线的封装细节。第二种方案显然成本更小，也有很多实用性，每个die就对应着我们的一个处理器(CPU)。这也是多处理器调度的单位。<br><br>了解了CPU如何制造，现在，你应该能明白多处理器调度的实质其实就是多核心调度。但是这些核心被封装到了不同的die中了。这样带来的问题就是die内数据的传输是会快于die之间的数据传输的，而且多个die还要考虑总线冲突的问题。<br><img alt="Pasted image 20241004014342.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241004014342.png"><br>除此之外，在x86类型的系统上，L1和L2的cache是每个处理器一个的，而L3 cache是所有处理器共享的。当进程  在Core1上运行一段时间后跳到Core2上运行，这就会导致大量的cache层面的page fault（cache miss）。<br><br><br>非对称多处理器(Asymmetric Multi-Processing)：在AMP中，处理器的职责不对称。通常有一个主处理器负责系统调度和IO操作，其他从处理器则仅负责执行分配给它们的任务。主处理器在整个系统中占据主导地位，所有进程调度和系统调用都由它处理，从处理器则不直接参与调度决策。<br>
<br>硬件架构简单，主从职责分明。
<br>
<br>主处理器的性能可能成为瓶颈，扩展性不佳。
<br><br>对称多处理器(Symmetric Multi-Processing)：在SMP中，每个处理器共享同一个主存、IO设备以及操作系统，并且它们具有对等的访问权限。每个处理器都有同样的权利参与任务调度，并执行相同的操作。由于所有处理器可以访问共享的资源，调度器的任务是将进程公平地分配给各个处理器，使得系统负载均衡。<br>
<br>处理器平等共享资源，简化了设计。
<br>处理器之间需要共享内存和I/O总线，这可能会导致瓶颈。
<br>现代操作系统大多采用SMP结构，因为SMP系统能够更好地利用多核处理器的并行计算能力，并且更适合现代通用计算环境中的高并发和负载均衡需求，比如Linux、Windows、macOS等。而AMP更多用于嵌入式、实时系统等特定场景中。<br><br>非一致性内存访问(Non-Uniform Memory Access) 是一种多处理器内存架构，用于优化多处理器系统中的内存访问效率。在NUMA架构中，系统中的多个CPU被划分成不同的节点（Node），根据CPU和主存的链接方式，每个node访问不同内存区域的速度并不一致。根据这种差异，我们说每个节点有自己的本地内存和资源。<br>内存、IO和CPU的链接方式使得每个节点的CPU可以快速访问本地内存和IO，但访问其他节点的内存或IO会有较高的延迟。<br><img alt="Pasted image 20241004021149.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241004021149.png"><br>在NUMA系统上编写程序时，尽量将线程绑定到对应的CPU，并从该CPU的本地内存分配内存，以最大化性能。使用工具如numactl可以查看和设置NUMA相关的信息，优化程序的内存访问模式。<br><br><br>如果我们有4个处理器，如果其中一个处理器的利用率是 100% 而其他三个处理器无事可做，这种情况在我们看来是不理想的，因为所有任务都在一个处理器上运行可能会导致L1和L2 cache频繁的发生cache miss。<br>负载均衡就意味着系统的工作负载相对均衡，每个处理器的利用率都相当。相比于所有的处理器共享一个全局的任务队列，负载均衡在每个处理器有自己的私有任务队列的情况下更加重要。因为任务最初是分配到各个处理器的私有队列中的。如果某个处理器的队列过载，而另一个处理器的队列较空闲，那么负载就不再均衡。这时就需要通过负载均衡策略（如PUSH和PULL迁移）来重新分配任务，以确保所有处理器的负载均衡。<br>
<br>PUSH migration：当某个处理器的任务队列过载，调度器会主动将任务从这个处理器上PUSH到其他负载较轻的处理器上。PUSH migration是一种主动的负载均衡策略，适用于避免个别处理器过载的问题。
<br>PULL migration：当某个处理器负载过轻，处理器就会从其他负载中的处理器那里PULL任务。PULL migration是一种被动的负载均衡策略，用于确保处理器不闲置，始终保持忙碌状态。
<br><img alt="Pasted image 20250112055229.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20250112055229.png"><br><br>多处理器系统引入处理器亲和性策略使得进程尽可能在同一个处理器上连续运行。这可以最大限度地保持进程数据在处理器的本地缓存(Cache)中，减少由于进程迁移而导致的缓存未命中开销，以及减少处理器间的缓存一致性开销，从而提升系统性能。<br>
<br>硬亲和性(Hard Affinity)：规定进程只能在某个特定处理器上运行，调度器不会将其迁移到其他处理器。
<br>软亲和性(Soft Affinity)：尽量使进程在某个处理器上运行，但在特定情况下，调度器可以将其迁移到其他处理器。
<br>Linux中有关于两种处理器的亲和性的选项，我们可以使一个进程只在一个处理器上运行的同时让另一个进程尽量在另一个处理器上运行。<br><br>负载均衡调度是从全局视角进行的优化，期望进程能够自由地在不同的处理器之间迁移。然而这种频繁的迁移可能会导致缓存命中率直线下降的问题，降低缓存的利用效率。<br>另一方面，处理器亲和性注重局部的优化，期望进程尽可能地留在一个处理器上，以便提高缓存的命中率的同时也减少缓存的一致性问题。但这样可能带来处理器负载不均匀的问题。<br><br>超线程技术(Hyper-Threading Technology，HTT)是英特尔公司开发的一种技术，旨在提高处理器的并行处理能力。通过在每个物理处理器核心上创建多个逻辑处理器，超线程技术使得单个处理器能够同时处理多个线程，从而提高了处理器的利用率和整体性能。<br>超线程技术通过在一个物理核心上运行多个线程，可以在一个线程发生memory stall时，切换到另一个线程继续执行，从而减少处理器的空闲时间，提高处理器的利用率。这种技术在多任务处理和高并发应用中尤为有效，因为它能够更好地利用处理器资源，减少内存访问延迟对性能的影响。<br>我们知道CPU可以处理算数和逻辑运算，有了超线程技术，我们不再把CPU看作单一不可划分的资源。举个例子，我们有线程 1 和线程 2，我们通过超线程可以实现在线程 1 使用CPU算数运算的同时线程 2 使用逻辑运算。<br><img alt="hyper.webp" src="https://congzhi.wiki/congzhi's-os-series/pics/hyper.webp"><br><br><br><br>本课作为简单补充实时调度并对实时操作系统进行简短的介绍。简单来说，实时调度就是实时操作系统上进行的调度。那什么是实时系统？我们从它的实时性来源——墙上时钟时间来进行介绍。<br><br>对于实时操作系统而言，任务必须在严格的时间限制内完成。这个时间基准就是由墙上时钟时间来提供的。时间限制就意味着deadline，在实时系统中，对missing deadline没有任何容忍。如果任务没有在严格的截止时间前完成的话，就意味着系统故障。<br>常见的操作系统（如Windows、Linux、MacOS）并不能怎么匹配实时操作系统，主要原因在于它们对超时截止时间没有保证(guarantee)。这些操作系统设计的初衷是为了通用性和多任务处理，而不是为了满足严格的实时性要求。<br>在Windows上，即使你在任务管理器中将任务设置为实时优先级(Real-time priority)，系统也不保证任务能够在严格的时间限制内完成。这是因为Windows的调度机制并不是为硬实时任务设计的，系统中的其他因素（如内存管理、中断处理等）仍可能导致任务无法按时完成。<br>相比之下，实时操作系统(Real-Time Operating Systems, RTOS)专门设计用于满足实时性要求。它们具有更严格的调度机制和时间管理，以确保任务在规定的时间内完成。例如，RTOS会使用优先级调度、最早截止时间优先(EDF)等算法来确保任务按时完成，并处理硬实时任务的严格时间限制。<br><br>不同于前面调度中对“快”的追求，实时系统中安全和时效是最主要的（可预测性(Predictablity)）。最重要的任务必须尽早地完成，并且在相应的时间内完成。在实时系统中，对于不同的任务，我们有不同的解决方案。我们可以把实时任务分成这三种：<br>
<br>硬实时任务(Hard Real-Time Tasks)：硬实时对错过截止时间没有任何容忍度，任何延迟都会被视为系统失败。所以硬实时任务必须在严格的时间限制内完成，否则就会导致系统的故障。例如，对即将到来的导弹轨道进行计算拦截，即便延迟仅仅0.1秒钟，都可能相差数百米，这显然不是我们能够接受的。
<br>固实时任务(Firm Real-Time Tasks)：固实时任务也需要在截止时间内完成，但如果偶尔错过截止时间，系统不会立即出现故障。然而，错过截止时间会影响系统的性能和可靠性。例如，在线交易系统中，偶尔的延迟可能不会导致系统崩溃，但会影响用户体验。
<br>软实时任务(Soft Real-Time Tasks)：软实时任务在”时间限制“上的管理相对更松弛，允许在一定范围内的时间延迟。比如天气预报15分钟后下雨，但是现在已经下雨了，虽然带来的错误的信息，但是代价也许是我们能接受的。
<br>实时任务要求实时的可预测性，这就是为什么Java这类解释型语言不适宜作为实时系统中的工作语言。更何况Java虚拟机在进行垃圾回收(Garbage Collection, GC)时，JVM会暂停JVM中的所有应用程序线程执行，直到垃圾回收完成。这肯定不符合RTOS对可预测性的要求。<br><br>在实时系统中，实时失败(Real-Time Failure) 是指系统未能在规定的时间内完成任务，导致系统无法满足其时间约束。这种失败可能会导致严重的后果，特别是在硬实时系统中。<br><br>如果任务是硬实时的，我们有两种任务无法在截止时间内完成的场景：<br>
<br>调度太晚：例如，需要两小时完成的任务在距离截止时间还有一小时的时候才开始调度运行。
<br>任务执行中断：调度开始运行时，任务是可以完成的。但是由于某种原因（如高优先级的任务被调入），完成任务变得不太可能。
<br>第一种情况下，系统可能会拒绝任务的开始请求，或是永远也不会调度任务运行。因为没有必要在浪费CPU时间在一个不能按时完成的任务上面。第二种情况呢？有没有什么办法使得任务能按时完成的同时尽量减少对系统造成的影响？当然有，这就是我们为什么引入实时调度的原因。<br><br><br>实时系统在以下五个关键方面具有其独特性：<br>
<br>确定性(Determinism)
<br>响应性(Responsiveness)
<br>用户控制(User Control)
<br>可靠性(Reliability)
<br>故障软处理(Fail-Soft Operation)
<br><br>确定性预示着操作可预测，以确保任务能够在规定的时间内完成。完美的确定性(determinism)并不存在。在实时操作系统上，有时候我们只是希望得到一个保证，即不管怎么样，实时系统都能尽量确保任务按时完成。这种保证不一定是绝对的，但必须能够在大多数情况下满足系统的时间约束。<br>
尽管我们在实时系统上追求这种determinism，但是这并不意味这non-determinism是不好的。一个典型的例子就是caching，通过一些优秀的置换算法，cache可以大大提升系统的性能。在一些嵌入式系统上，可能并不会配备cache，通过单一的主存结构，实际上你可以得到更好的determinism。因为任何任务访问主存的时间都是相近的。<br><br>Responsiveness并不简单地指系统响应所需要的时间。determinism相当于告诉我们当任务发出请求之后，系统多久才能接收到请求，这需要规定在一个确切的值。而responsiveness指系统收到请求后开始响应事件(handle the event)的时间间隔。由于中断还可能被高优先级的任务中断嵌套，responsiveness并不仅仅涵盖从接收到请求到执行中断服务例程(interrupt handler)的时间，还要把执行到高优先级中断服务例程的时间加到一起。<br><br>Administrator control对于系统的影响是巨大的，毕竟每个系统最终的服务对象都是人嘛。在实时系统中，我们可以适当的增加系统的实时性（完全的硬实时系统），也可以减弱实时性的存在，如果操控得当，你得到的实时系统可能会类似于typical OS。<br>尽管我们的可操作空间很大，但由于操作对象是实时系统，有些地方是不能修改的。在实时系统中，我们可以使用以下两种策略：<br>
<br>不做修改，系统以原汁原味地方式提供操作。
<br>根据需要做适当的修改：作为administrator，我们确实能在系统上做很多修改。比如调整任务的优先级、实时类型（硬实时、固实时、软实时），甚至选择系统的调度策略。因为操作系统并不能判断哪个任务是实时的，哪个是general purposes的。
<br><br><br>不同于典型系统中调度影响性能不同，实时系统中，调度直接影响着系统的成与败。当你选择了一个很差的调度策略，系统可能会忽略掉高优先级任务的运行请求，系统出现故障，“保证”无法得到保证。通过这些方面的介绍，你可能也能感受到了任务调度在实时系统中的地位。<br>对于实时系统，我们要确保在规定时间内完成所有的硬实时任务，同时尽量完成尽可能多的软实时任务。不同调度算法的选择可能会导致系统中截然不同的任务完成情况。请记住，在实时系统中，保证重要任务的按时完成是首要任务，“效率”并不是我们首要考虑的。<br>在调度策略的选择上，所有的非抢占式调度算法都不能有效地发挥作用。一旦有硬实时任务未能按时完成，系统就会出现故障。同样，分时系统也不适用于实时系统，因为你不能让高优先级的任务等待低优先级任务的时间片完成。调度越是干脆利落，对实时于系统的稳定性和可靠性就越好。<br><br>在实时系统中，我们可以将执行的任务分成下面这四种：<br><br>望名生意，fixed-instance的任务只在固定的、预先定义的一段时间内运行。它们有固定的执行实例，通常用在那些特定时间执行操作的场景中，一般只会运行一次。比方说系统启动时初始化系统的任务、数据库的初始化等。<br><br>这些任务在固定的周期内重复执行。它们在每个周期结束时被重新调度，广泛用于定期检查、传感器数据采集等场景。例如，每隔一秒钟读取一次传感器数据。周期性任务有两个相关的属性： 和 。前者指的是周期，后者指最坏的运行时间<br>由此，我们可以得到下面的公式：这个公式用来计算系统的利用率，即所有任务的最坏运行时间与其周期的比值之和。我们需要保证 。因为一旦  ，那就以为着系统过载了，即系统内的周期性作业太多了。实时系统不能够保证每个任务都能在规定时间内完成。<br>那我们只要选择合适的调度策略，保证系统内  就好了么？事情还远远没有这么简单。因为系统内不仅仅只存在周期性任务，除了fixed-instance任务，我们仍然还要两类任务要去了解。<br><br>Aperiodic任务没有固定的执行周期，这些任务的触发是随机的，且没有最小的时间间隔限制。这就使得当一个aperiodic硬实时任务运行时，如果有更高优先级的硬实时任务到达，我们可能无法保证前一个aperiodic任务按时完成。<br>Aperiodic任务一般用于处理非周期性的事件，例如用户的请求或外部事件。任务的执行时间可能是不确定的，但仍需要在合理的时间范围内完成。如何调度这些任务，以及用什么顺序完成任务的调度，是值得我们思考的问题。<br><br>这些任务类似于aperiodic任务，但它们有最小的时间间隔限制(Minimum Inter-Arrival Time)。这意味着在任务之间必须保持一定的间隔时间（比如说  ）。这类任务通常用于处理偶发事件，如紧急报警或异常处理。<br><br>在正式的进入实时调度策略的学习之前，我们还需要思考一个问题。之前的学习中，我们能发现在实时系统中"deadline"到处都是，那怎么才能知道任务大概需要多长时间执行呢？不管在之前的学习中还是生活中，预知未来一直都是一个很困难的事情。但是在实时系统中，我们需要这样的事件来保证系统的determinism。<br><br>在周期性的任务小节中，我们见过这个公式：上面的  指的是最坏运行时间，怎么得到的？我们的日常生活中很多测试的软件，其中不乏有指令执行时间的测试工具和整个软件执行时长的测试工具，在日常中，我们有两种方法来预测这个worst case scenario time。<br>
<br>源代码分析(Source code analysis)
<br>实证测试(Empirical testing)
<br><br>软件要运行，就要按照其源码一行一行地执行。为了得到  ，源代码分析预测的方式就需要大致地知道所有的这些机器指令全部执行完毕需要多久。我们要得到最坏情况下的执行时间，当然也就要忽视一些机器和系统层面的优化，例如，忽略流水线(pipelining)和编译器优化等。<br>为了使得预测具有可行性，市面上有很多我们可以遵循的标准。例如，在 NASA/JPL 指南下：<br>
<br>代码中不可以出现递归和goto语句；
<br>如果代码出现循环语句，循环边界必须是固定的；
<br>在软件初始化之后，不允许再出现动态内存分配。
<br>虽然这些指南提供了一个框架来确保代码的可预测性和稳定性，但它们并不是绝对的规约。如果你能够有效地控制动态内存分配所带来的时间开销，那么在代码的任何位置使用malloc进行内存动态分配是可行的。（使用binary buddy system）<br>源代码分析通常适用于代码量较小的任务，因为在这种情况下，分析和预测每条指令的执行时间相对简单。然而，当代码量变得庞大和复杂时，源代码分析的难度会显著增加。这就像估算从宿舍走到食堂的时间和从宿舍走到家里的时间，显然这两者的复杂度不在一个层面。在这种情况下，我们可能需要另一种预测方法——实证测试。<br><br>除了源代码分析，我们还有另一种更简单和直接的办法：把程序从头到尾地跑一遍，看看执行时间有多长。这种办法就是实证测试。实证测试的预测方法除了能够应对绝大多数情况下的任务外，还能够简单地预估一下系统的性能，同样的任务，通过比较在不同机器上运行的时长，我们就可以大致得出两个系统的性能。<br>通过一遍遍地模拟任务在系统内的运行时长，我们可以统计这些信息来设置一个最坏运行时间。利用统计到的模拟运行时间，我们可以使用置信区间(confidence interval)的概念来设置最坏运行时间。例如，当我们模拟的运行时间 99% 的置信区间是 [10s, 20s]，我们就可以设置最坏运行时间为 21s 或 22s。<br><br><br>前面我们简单地提到了实时系统和典型操作系统的不同，了解了一下为什么非抢占和分时的调度算法都不在适用于实时系统，我们补充了timeline的相关概念和调度思想。在本节课中，我们将开始介绍单处理器和多处理器上的实时调度算法。<br><br>
没有最优的调度策略，有的是相对于某个环境下最优的调度策略。
<br><br>EDF，最早截止时间优先算法，算得上是学生们最熟悉也是世界上最常被人类应用的算法。毕竟有句话是这样说的：“DDL是第一生产力”。学生们的想法是不管三七二十一，哪个作业最先截止，就先完成哪个作业。即无论任务的优先级如何，哪个任务离它的时间期限最近，就率先完成哪个任务。<br>如果一个任务正在执行的同时另一个更急迫的任务到了，那正在运行的任务就会被挂起以运行新的那个任务。这就意味着有的periodic任务可能被aperiodic/sporadic的任务给抢占掉（urgent call is coming），对于一些硬实时任务可能不是非常友好，因为有的软实时任务离deadline可能更近。<br>在未过载的系统中，我们有能力完成所有的任务，软实时硬实时并无大碍，只要完成所有的任务就好。但是在过载的系统中，有的硬实时任务就可能被更紧急的软实时任务抢占CPU，从而造成系统故障。尽管系统设计者在设计系统时需要避免过载(overloading)的发生，但是在现实中我们不能指望系统永远步发生故障。为了避免过载带来的系统故障，我们需要做一些改变。<br><br>和我们之前提到过的优先级继承(priority inheritance)很像，为了避免软实时任务抢占硬实时任务的CPU，Deadline Interchange 允许在任务的截止时间之间进行交换，以优化任务的调度顺序，让优先级更高的硬实时任务优先进行调度。这种方法可以最大化系统资源的利用率的同时确保高优先级任务能够按时完成，减少系统过载带来的故障风险。<br><br>
Slack time is how long a task can wait before it must scheduled to meet a deadline.
<br>执行剩余时间算法(LSTF)，是我们要学习的另一种实时调度算法。和EDF有些类似，只是将离比较的时间从  换成了 。就相当于在ddl之前你还可以玩多长时间。Slack time的计算公式如下：举个例子，如果任务只需要执行10ms就能结束而距离deadline还有50ms，那么slack time就等于40ms。我们只要在40ms前执行这个任务就可以保证任务的完成。Slack time可以给我们指示哪个任务是目前应当尽早来做的（我们的目标是not missing any deadlines）。<br>LSTF其实就是在EDF的基础上进行了微调，他们的缺点是相同的，都没有对优先级进行考虑。我们提到过，这可能会使一些硬实时任务miss its deadline，从而导致系统的故障。<br><br>Rate-monotonic调度引入了优先级的概念，主要用于周期性任务的调度。任务优先级的确定基于任务的周期长度：周期越短的任务，优先级越高。RMS的优先级一旦确立，在运行时不会再改变。RMS适用于周期性任务的调度，但是并不算是最优的算法(not optimal)，在  时，系统依然可能出现故障。<br>例如我们有一下三个任务，他们的分别是：、、。在这种情况下，利用率应当为：而经分析发现，第三个任务将会运行异常（fail to meets its deadline）。而使用EDF算法调度就不会出现这种情况。那我们怎么保证所有被RMS调度的周期性任务能够按时完成呢？我们有以下公式：当所有任务的利用率乘积加1的结果小于等于2时，RMS可以保证所有任务按时完成。<br><br>这个算法是rate monotonic的变体，将deadline作为优先级的确定的依据。在DMS下，距离deadline最近的任务的优先级最高。<br><br>由于EDF（Earliest Deadline First）算法是最优算法，因此在实现调度器时，我们希望尽量向EDF靠拢。我们之前提到过，EDF调度器无法区分任务是软实时还是硬实时，这可能导致系统内任务不能预期完成。一种解决方法是让非周期性任务和软实时任务的优先级永远低于硬实时或固实时任务的优先级，但这种做法可能会导致任务间抢占可能会变得更加频繁、平均任务完成时间的增加，这对于调度算法来说，可能并不是我们想要的结果。<br><br>为了简化调度并优化这种解决方案，在实时系统的理论中，我们使用Polling Server来解决这一问题。polling server相当于一个携有多个非周期性任务的“容器”，polling server本身是一个有着固定执行时间的周期性硬实时任务。它会在固定的时间间隔内检查是否有非周期性任务需要处理，并在需要时分配资源进行处理。这种方法可以有效地将非周期性任务与周期性任务结合起来，保证系统的响应性和稳定性。<br>Polling server是aperiodic server的一种实现方式（periodic version）。我们举个现实中的例子，polling server就相当于午休时间，一般可能是12：00-2：00。你可以在这两小时中做你想做的任何事。相当于polling server在运行时调度一些非周期性的任务。在polling server运行的时间内，非周期性的软实时任务会被调度运行。通过定期分配处理时间给非周期性任务和软实时任务，确保它们能够及时得到处理，同时不会影响硬实时任务的调度。这种方法在保证系统整体性能的同时，减少了非周期性任务和软实时任务的等待时间。<br><br>我们还可以拥有多个server来服务各种各样类别的任务。相较于aperiodic server，multiple server可以进行更细粒度的任务管理。比如一个服务器处理硬实时任务，一个服务器处理非周期性任务等。<br><br>DDS是对polling server的进阶。在polling server中，当期限内全部的非周期性任务执行完毕了，server就会将剩余的时间片丢掉，立即结束本次周期。这就相当于午休时间没事儿做了就去工作了一样。而DDS会保留剩余的时间，以便同周期未来的某一时刻使用。还是午休的类比，如果在午休时间内没有事情做，可以把这段时间留到以后使用，比如下午或晚上。DDS这种安排方式既不浪费时间，又能在需要时迅速处理紧急任务。但是这种保留的时间仅限于今天（同周期内）。<br><br>比起polling server那样在一个周期内分配一大块空间的方式，DSS将这一大片时间分成多个小块(time chunks)，这样做有什么好处呢？我们以等公交为例，polling server相当于30分钟的前2分钟过去3趟公交车，DSS相当于每10分钟一趟公交。虽然平均下来两种方式都是10min/bus，但是第二种方式的公交车载人数往往更多。通过分散时间片，DSS能更均匀地分配资源和负载，避免资源的浪费和系统负载的突发。这类似于每10分钟来一趟公交，可以更均匀地分配乘客流量。<br>在实现上，DSS并不像公交车的例子那样严格地按照每趟10分钟的方式执行，而是相当于一种chunk credit的方式工作。具体来说，DSS 会为非周期性任务分配一个时间片信用额度。这些信用可以在任务需要时使用，而不是在固定时间间隔内强制执行。当一个非周期性任务到达时，如果DSS有足够的chunk credit，该任务会立即得到处理。如果credit unavailable，任务则会被延迟到下个周期。<br><br>又是时候从单处理器的世界中跳出来了，在本节中，我们介绍有关多核实时调度的相关知识。在本节里，我们先区分这两个概念：<br>
<br>Task（任务）：这是需要完成的工作或操作的描述。一个任务可以是任何需要处理的事情，比如计算一个复杂的数学公式、处理一段音频数据，或者控制一个设备。任务本身定义了应该做什么以及如何做，但不包括具体的执行实例。
<br>Job（作业）：这是一个任务的具体实例。每次任务被执行时，都会生成一个作业。比如，如果一个任务是每分钟读取一次传感器数据，那么每次读取操作就是一个作业。作业可以有不同的执行时间、资源需求和截止日期（deadline）。
<br>当我们的视角不再局限于单处理器，多处理器给我们带来了更好的性能。我们思考这几个问题：<br>
<br>抢占是否允许？
<br>作业的迁移(migration)是否允许？
<br>作业的并行化(parallelism)是否允许？
<br><br>多处理器能够一次性允许多个作业，那么抢占的算法还需要么？或者说是抢占是否允许呢？从典型操作系统的单处理器调度中，我们就学习到optimal algorithm是需要抢占式的调度的，而且在实时系统中，没有抢占有可能会造成某些作业影响硬实时任务的执行，我们当然需要抢占。<br><br>作业迁移是指将一个正在执行的作业从一个CPU迁移到另一个CPU。我们提到过，作业的迁移就意味着cache misses，对于CPU dedication scheduling approach（作业1在固定CPU1上完成，作业2固定在CPU2上完成。如：partitioned scheduling），作业的迁移就是不允许的。然而，完全不允许作业的迁移就可能会使得某个作业因为CPUx缺少CPU时间而不能在deadline前完成（其他的CPUy和CPUz可能空闲）。<br>对任务队列的管理上，我们有global scheduling和partitioned scheduling。前者是指所有CPU共享同一个任务队列，后者指每个CPU都有自己的任务队列。对于migration，global scheduling为了能够实现更好的负载均衡，调度器可以动态地将任务分配给最空闲的处理器。Partitioned scheduling则不允许job migration，一旦任务分配到某个处理器，即使其他处理器空闲，也不能进行迁移。<br>这两种approach都会以不同的方式浪费相同的处理器。我们需要更好的方案。在调度的实现上，我们将两者进行结合诞生出另一种调度方式：semi-partitioned scheduling。在任务的初始分配上，任务首先被分配到特定的处理器的任务队列上，类似于 partitioned scheduling。然而，在某些处理器过载时，semi-partitioned scheduling又允许允许少量的任务迁移到其他处理器上执行，以实现负载均衡。这种approach即实现了负载均衡，又使得调度开销相应地降低。<br><br>作业并行化是指将一个作业分解成多个可以独立执行的部分，并让多个CPU同时处理这些部分，从而加速作业的完成过程。<br><br><br><br><br><br>早期传统的UNIX调度有如System V R3和BSD 4.3，这时的系统对实时性并不支持。在后面版本SVR4才对一些实时性进行了支持。本小节中，我们所讨论的都是多级反馈调度系统，其中每个队列都使用轮转算法(Round Robin)进行时间片的切换。<br>传统的UNIX系统虽然有时间片的概念，但是时间片间隔非常长，原始版本的默认值长达1s（一般为100ms-300ms左右）。这就意味着如果进程没有在这1s内被阻塞或完成任务，那么这个进程就会被抢占。这这个时期，系统的优先级经由进程类型和之前的执行情况得出。<br>CPU的利用率可以经由下面的公式得出：其中  用来标记进程，而  是interval。<br>此外，进程的优先级可以由下面的公式得出：其中  是进程  的基础优先级， 表示进程  的一个 "nice" 值。（"nice" 值是UNIX 运行用户自愿降低进程优先级的方式，用来be "nice" to other users。）<br>那个时期的计算机很稀缺，没有人想要将宝贵的时间片让给其他人。所以 "nice" 实际上是给系统管理员使用的。nice值通常从-20到19之间调整，默认的初始值为0，但admin可以在初始时用 nice 命令在启动进程时设置 nice 值，也可以在运行时用  renice 命令让一个进程变得 nicer 一点。<br>在传统的UNIX系统里，一旦一个进程被分到某个进程优先级队列中去，系统会避免进程迁移到其他的队列中。系统会先满足自己所需要的，之后才会尽可能利用好剩下的资源。根据任务类型的不同，优先级由高到低的顺序分为：<br>
<br>Swapper (move process to and from disk)
<br>Block I/O device control
<br>File manipulation
<br>Character I/O device control
<br>User processes
<br>正如你所见，用户进程的优先级最低。然而，这种方式并不算最优，因为所有的I/O密集型进程运行速度较慢，但它们的优先级却高于用户进程。在I/O密集型进程进行I/O操作时，应将CPU让给CPU密集型进程。<br><br>在System V Release 4版本的Unix操作系统中，由于引进了实时性，系统将最高的优先级给了实时进程，然后是内核，最后是用户进程。相比之前的系统，SVR4最大的不同是增加了更多的优先级，现在我们有160种不同的优先级，我们还把他们划分为三大类别。而且引入了抢占点。<br><br>Berkeley Software Distribution是UNIX的一个变种，而FreeBSD是BSD的一个变种。它和SVR4很类似，相比SRV4，它的优先级更多，有256种。并且将进程划分为五个大类。SVR4并不支持多处理器，而在FreeBSD则实现了对多处理器的拓展支持。<br>FreeBSD通过一种交互性评分机制来判别一个线程是否是交互式线程。原理也很简单，如果一个线程经常地被阻塞(blocked)，那就说明这是一个交互式的线程。我们定义有一个最大的交互分  ，将线程的运行时间记录为  ，睡眠时间记录为  。<br>如果睡眠时间大于运行时间，那么交互分数就是：如果运行时间大于睡眠时间，那么交互分数就是：<br><br>在前面我们已经学过了亲和性和负载均衡了。FreeBSD也有Push和Pull机制。<br>Pull: bit mask to indicate it's idle.<br>
Push: twice per second tasks to equalize highest and lowest CPUs<br><br>Windows使用基于优先级的抢占调度算法来调度线程。确保拥有最高级优先级的线程运行，而优先级又随着程序的执行发生变化，确保每个线程都能够获取CPU而避免饥饿问题。这个选择线程运行的程序在Windows中被称作 dispatcher。<br>如果高优先级的线程被unblocked，他就会抢占低优先级的线程。Windows有32种不同的优先级，其中包括regular(1-15)和实时类别(16-31)。优先级为0运行的是一个内存管理任务。Dispatcher在每种优先级中都维护一个队列。当没有任务运行的时候，系统的 Idle 进程就会运行。<br><img alt="Pasted image 20250112042240.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20250112042240.jpg"><br>Windows将这些任务划分为六类优先级，分别是：<br>
<br>Realtime
<br>High
<br>Above Normal
<br>Normal (A process usually in this class)
<br>Below Normal
<br>Low
<br>当进程的时间片到达，线程执行就会被中断。如果任务是实时的，那么它的优先级就会被降低。<br>当一个进程被阻塞时，其优先级确实会暂时提升，以便在阻塞事件完成后能够更快地恢复执行。这个优先级提升的幅度取决于阻塞事件的类型。例如，等待键盘输入的进程会获得比等待磁盘操作的进程更大的优先级提升。<br>此外，为了提供更好的体验，系统还会为运行在前台(foreground)的进程提供额外的优先级。<br><br>Linux有两种调度模式：实时的和非实时的。如果你使用实时调度器，和你预想的一样，系统中仍然会存有非实时线程被调度。Linux调度器根据不同的调度类(scheduling classes)来进行调度。Linux 2.6.23版本之前，根据优先级，Linux将系统分为以下三大类：<br>
<br>SCHED_FIFO: 先进先出的实时线程。
<br>SCHED_RR: 轮转的实时线程。
<br>SCHED_OTHER: 其他（非实时）的线程。（也叫普通调度类SCHED_NORMAL）
<br>其中，每个类别中又有许多不同的优先级。与Windows中优先级越高，数字越高不同。在Linux中，数字越低，优先级越高。实时优先级的范围从[0-99]，其他优先级的范围从[100-139]。也就是说，仅当RR或FIFO队列中没有可调度线程时，SCHED_OTHER才会被调度。<br>在2.6.23版本后，根据优先级，主要的调度类有下面五种：<br>
<br>SCHED_FIFO
<br>SCHED_RR
<br>CFS: 取代了SCHED_OTHER，成为当前Linux的默认调度类。
<br>SCHED_BATCH: 用于批处理任务，尽量减少对交互任务的
<br>SCHED_IDLE: 最低优先级的任务，只有系统空闲时才会执行。
<br><br><br>在FIFO类中，线程的调度有一些需要注意的规则。当以下其中一个条件被满足，系统就会中断当前正在运行的FIFO的线程：<br>
<br>更高优先级的FIFO线程准备好了。
<br>当前FIFO线程被阻塞。
<br>当前FIFO线程让出CPU。
<br>如果相同优先级队列中两个线程同时准备好了，那么等待事件更长的线程就会被选中。<br><br>RR类中的线程调度策略和FIFO一样，只不过多了时间片轮转调度。当时间片用完且这时线程还没有执行完毕。那么调度器就会中断当前线程并选择一个更高优先级或相同优先级的线程调度执行。如果此时的线程就是优先级最高的，那么就会有选择这个线程进行调度。<br><br><br>在 Linux 2.4 和更早期的版本中，Linux内核使用传统的算法进行非实时调度，造成的结果是时间复杂度很高(O(n))。之后，在2.6.23版本之前，引入了被称为O(1)调度器的调度算法，因为执行时间是一个常数时间(O(1))。O(1)调度器更好的适配了SMP系统，加入了CPU亲和性和负载均衡。<br>但之后在2.6.23版本，CFS(Completely Fair Scheduler)代替了O(1)调度器。CFS旨在提供一种更加公平和高效的调度机制，通过红黑树数据结构来管理任务，确保每个任务都能公平地获得CPU时间片，从而提高系统的整体性能和响应速度。<br>在6.6版本之后，默认的调度器被换为EEVDF。<br><br>Because the traditional scheduling algorithm is a linear time algorithm, the more processes the current system has, the worse the performance becomes. Therefore, with the traditional scheduler, you cannot effectively handle a very large number of processes.<br>Besides, it does not match with the SMP system and would incur a penalty due to its design:<br>
<br>A single run queue.<br>
我们之前提到过，每个CPU都有自己的run queue，这是为了CPU亲和性，提高cache的命中率。系统只维护一个run queue对于负载均衡当然是好事，但是cache就很容易被架空。
<br>A single run queue lock.<br>
系统只有一个run queue lock，这就意味着只用一个mutex lock来保护对run queue的操作。当一个进程想要enqueueing或dequeueing run queue时，其他进程就只能等待。
<br>An inability to preempt running process.<br>
当低优先级进程运行时，高优先级进程必须等待。并不支持优先级抢占。
<br><br>了解如上的传统调度器的问题，我们来学习一下O(1)调度器是如何解决这些问题的。采用O(1)调度器后，内核会为每个处理器（核心）分别维护一个prio_struct数据结构，记录着array中任务的数量、优先级位图和优先级队列。MAX_PRIO指的是最大的优先数，也就是139。<br>struct prio_array {
    unsigned int nr_active;                // numbers of tasks in the array
    DECLARE_BITMAP(bitmap, MAX_PRIO+1);    // priority bitmap, 0 for empty
    struct list_head queue[MAX_PRIO];      // priority queues
};
<br>我们知道，Linux中有140种不同的优先级，每个优先级都会维护一个任务队列。优先级位图中的一位bit表示该优先级队列中有任务存在。这样，我们在调度任务的时候就不用遍历整个queue了。<br><img alt="Pasted image 20250114004941.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20250114004941.jpg"><br>在O(1)调度器中，任务会被分配到两个不同的优先级数组中，active queues和expired queues。调度器会从active数组中选择下一个要运行的任务。当一个任务用完了其时间片，就被移动到expired数组中。当active数组中的所有任务都用完了时间片，调度器会交换active和expired数组（交换指针），这样expired数组中的任务就会重新变为active，并且可以再次被调度执行。<br><br>CFS调度器是自2.6.23版本之后的内核默认调度器，由 Ingo Molnár 编写，旨在提供公平高效的调度，但可惜它的时间复杂度是O(log n)。CFS通过虚拟运行时间(vruntime)来衡量每个任务的运行时间，确保每个任务都能公平地获得CPU时间。CFS使用红黑树来建模管理就绪队列，最左边的组代表着有最小虚拟运行时间的任务，即优先级最高。获取执行最左边的组的时间复杂度为O(Iog n)。<br>当任务的时间片用完或被抢占，这个任务就会重新插入就绪队列，并更新其vruntime。这时红黑树就需要进行re-balancing，以确保自平衡的特性。<br><img alt="Pasted image 20250114013155.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20250114013155.png"><br>
CFS并不使用固定的时间片长度，而是采用了一个称为“目标延迟”（target latency）的概念。目标延迟就是一个time window，并期待所有的线程都能够在这个窗口内至少运行一次。也就是说，目标延迟越长，任务切换的频率就会越低（CPU的性能越好，目标延迟也会越短）。<br><br>vruntime，也就是virtual run time，是CFS跟踪任务执行时间的方式。从名字就能看来，vruntime并不等同于实际的运行时间，CFS会根据任务的优先级（nice）和最近的调度情况来调整虚拟运行时间。优先级较高的任务会有较小的虚拟运行时间，而优先级较低的任务会有较大的虚拟运行时间。<br>比方说，CFS有一个decay factor，最近调度过的任务其实际运行时间的权重会偏大，从而影响其虚拟运行时间。此外，nice值越大，vruntime也会偏离实际运行时间越大。一个nice值为0的线程的vruntime就等于实际的运行时间。<br><br><br>在2016年，有研究人员发表了 <a data-tooltip-position="top" aria-label="https://blog.acolyer.org/2016/04/26/the-linux-scheduler-a-decade-of-wasted-cores/?citationMarker=43dcd9a7-70db-4a1f-b0ae-981daa162054" rel="noopener nofollow" class="external-link" title="1" href="https://blog.acolyer.org/2016/04/26/the-linux-scheduler-a-decade-of-wasted-cores/?citationMarker=43dcd9a7-70db-4a1f-b0ae-981daa162054" target="_blank">The Linux Scheduler: a Decade of Wasted Cores</a>。这篇文章由Jean-Pierre Lozi、Baptiste Lepers、Justin Funston、Fabien Gaud、Vivien Quéma和Alexandra Fedorova共同撰写，发表在EuroSys 2016的会议上（<a data-tooltip-position="top" aria-label="https://people.ece.ubc.ca/sasha/papers/eurosys16-final29.pdf?citationMarker=43dcd9a7-70db-4a1f-b0ae-981daa162054" rel="noopener nofollow" class="external-link" href="https://people.ece.ubc.ca/sasha/papers/eurosys16-final29.pdf?citationMarker=43dcd9a7-70db-4a1f-b0ae-981daa162054" target="_blank">click here</a>）。<br>在138次的测试中，研究人员发现这些bug导致了系统性能下降了13%到24%。那多核调度是如何造成如此幅度的系统性能下降的？文章中提到的四种问题，造成了同一种现象：即使系统中仍然存在有等待执行的线程，系统也并不调度这些现象，而是让核心长时间处在空闲状态。核心短时间没有相关线程调度是正常的，毕竟把线程从一个核心上push/pull到另一个核心需要时间。但是，要是线程无缘无故等待很长时间（几百毫秒），那将成为一个问题。<br><br>在有的系统里，每个核心会被分配一个run queue。如果一个核心上有一个低优先级的任务，而另一个核心上有三个高优先级队列运行，不难发现，高优先级的任务实际上运行的时间反而更短。为了使得调度更加的公平，Linux会周期性地检查这些队列，保证所有核心的负载均衡。这就是我们之前介绍过的负载均衡。<br>负载均衡意味着额外的性能支出，和一些对于核心而言重新学习的时间支出，负载均衡往往意味着low cache locality和non-uniform memory access，这些都需要代价。我举一个例子，当工厂中有5个人做着不一样的工作，为了使得工人们负载均衡，老板可以每隔一段时间查看一下这些工人负载的情况如何（老板也是一个核心）。老板巡查需要一定的开销，工人A一直做着工作A，而工作A完成了，工人A被调去帮助工人B，然而任务B是工人A之前没有接触过的，所以这就需要工人A先进行学习，再开始工作。<br>因此，内核将多个硬件有相互关系的核心进行统一管理，组成一个更大的单元/组，我们称之为scheduling domain。比方说如果四个核心共享一个L2 cache，那就将其组织成一个调度域。将任务在同一个scheduling domain中进行push/pull就减少了核心的“学习”成本。<br><br><br>我们将核心分组管理，然而，某个核心可能窃取其他核心的劳动成果。相当于三人组中总有摆烂的那个人。通过组内核心的平均负载来看，数据可能很漂亮，但是有可能某几个核心满负荷而剩下的核心处于空闲状态。“平均”具有误导性。<br>如何解决呢？我们评估组内最小负载作为我们的衡量指标，即干活最轻的那个核心负载如何决定整个小组的负荷情况。这种方法解决了运行时约13%的性能损失。<br><br>Linux中我们用taskset命令让某个任务持久的在某个核心上运行，如果调度组并没有按照硬件的相近性进行组织，那么调度组的创建将没有意义。组织这种错误的调度组是因为所有调度组的构建都是从核心0的视角出发进行的。然而这种构建方法跟硬件的拓扑和相似性并无关系。<br><br>我们之前了解过处理器亲和性，但有时候过度亲和并不是一件好事。当一个现象在组1的某个核心上被阻塞，当它被其他线程唤醒时，由于处理器的亲和性，它可能还会在之前运行过的核心上运行，如果核心正忙呢？那就等待。这和我们经常出入一个理发店很类似，可能宁愿等2小时也不愿意去其他理发店里理发。<br>经过处理器亲和性可能减少cache misses，但是要是其他核心空闲，有等待的时间可能在其他核心上早已结束运行。<br><br>导致一个应用上的所有线程都在一个核心上运行。]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/8.-cpu-scheduling.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/8. CPU Scheduling.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 21 Mar 2025 16:48:12 GMT</pubDate><enclosure url="https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20240528012310.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20240528012310.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[9. Synchronization and Mutex]]></title><description><![CDATA[ 
 <br><br><br><br>在之前的学习中，我们了解到许多并发给我们带来的诸多好处，如更好的资源利用率、更低的响应时间、更好的用户体验。但在享受这些便利的同时，并发还会为系统带来许多灾难。在设计系统的并发时，我们要考虑资源共享的问题，不当的程序可能会为系统带来条件竞争(Race condition)、饥饿和死锁。这些问题一定要在开始就规避掉，不然会酿成大祸。<br><img alt="this_is_fine.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/this_is_fine.jpg"><br><br>同步指通过协调多个并发线程（或进程）的执行，是他们能够安全的共享资源或进行通信。同步的目的是防止竞争、数据不一致和死锁等问题，从而保证系统的正确性和稳定性。我们下面先举两个例子展示不同的同步模式。<br>在多核系统上，两个线程是有并行执行的能力的。但有时候，两个线程虽然可以同时执行，但是不可以同时访问某些资源，我们称这种情况为互相排斥的同步问题(mutual exclusion)。在之前的学习中，共享内存的访问就需要进行互斥的访问（虽然也需要serialization的同步）。<br>还有另一种情况，两个线程的执行必须要有一定的顺序，比如B线程需要A线程执行完毕后才能执行或是两个线程交替着执行亦或是更复杂的情况。我们一律将这种情况称作serialization的同步问题。同样的，我们之前学习管道的进程间通讯方式就需要进行serialization的同步。<br><br>我们很多写的简单测试程序都是确定性的程序，即我们在程序运行前我们就能知道输出是什么（比如简单的打印"Helloworld\n"）。但当程序涉及到并发时，我们的程序有时就不再是确定性的程序了，我们称之为不确定性程序(Non-deterministic program)。<br>下面的C++程序就是不确定性的程序：<br>#include &lt;iostream&gt;
#include &lt;thread&gt;

int counter = 0;

int main(){
	std::thread newThread([](){
        for (int i = 0; i &lt; 10000000; i++){
            counter++; 
        }   
    });
	for(int i = 0; i &lt; 10000000; i++){
		counter++;
	}
    newThread.join();
	printf("I counted: %d\n", counting);
	return 0;
}
<br>这个程序很奇怪，当你打印结果，你会发现它的输出千奇百怪，总之就是不为20000000。为什么？虽然看上去并不需要同步，但高级语言中的++、--不仅仅只是看上去那么简单。这些指令被称为read-modify-write指令，你需要先读值、修改最后写回结果。造成这种情况完全是因为read-modify-write指令并不是一气呵成的。（两线程都先读，之后两线程先后写，会造成什么情况？）<br>由这种不确定性引起的程序bug，我们将其戏称为Heisenbug（得名于 "Heisenberg Uncertainty Principle"）。这时，我们就需要对资源的操作进行 mutual exclusion 的同步操作。<br><br>我们现在明白，造成 Heisenbug 的主要原因在于资源的分配问题和执行顺序的控制问题。上边的程序中并发引起的 Heisenbug 就是由于单一资源分配不当导致的。当然，资源个数也可以有很多，这时要考虑的问题就会随着资源个数的增加而变得不同。<br>
<br>单一资源：如果资源只有一个，多个并发进程都想访问它，则需要排队一个一个地访问资源，确保在同一时刻只能有一个进程访问该资源。
<br>多个资源：如果资源有多个，需要合理地分配资源给并发进程，防止出现资源多分配或资源未分配的情况。
<br>对执行顺序的控制能够确保多个进程或线程按照预期的顺序执行，以满足特定的任务依赖关系和执行逻辑。对于这些非确定性程序，我们可以用一些同步工具来管理和控制资源或执行顺序。通过这些同步工具，我们能够有效防止竞态条件和资源冲突，确保系统的正确性和稳定性。但在此之前，我们有必要先了解一下临界区的管理。<br><br><br>在之前的示例中，我们发现程序的不确定性是由一条 read-modify-write 高级语言指令（如 i++;、i--;）引起的。为了避免数据竞争，我们只需要对这条指令进行管理即可。这也正是我们即将要学习的临界资源和临界区中所要关注的内容。<br><br><br>临界资源是指那些在同一时刻只能被一个进程访问的共享资源，如共享内存、文件、打印机及其他系统互斥资源。对临界资源的访问必须是不可中断的。前面引起Heisenbug的C++程序中，那个全局变量就是需要互斥访问的临界资源。<br><br>临界区就是并发线程（或进程）中访问了临界资源的一段代码。要使得系统运行稳定、规避并发带来的一系列问题，我们需要保证时刻只有一个进程在临界区内代码来避免出现竞争条件或是数据不一致现象。之前的例子中，counter++;就是对临界区的访问，这种情况下，我们的临界区可以划分的很小。<br>for(int i = 0; i &lt; 10000000; i++){
// Critical Section starts form here
	counter++;
// To here
}
<br><br>现实生活中，订票系统是我们身边较为常见的可能引起数据不一致的场景。我们通过 pthread 库给这个进程中生成了两个线程。我们共有两张票，两个线程都会 booking 一张票，因此我们期望进程执行后余票为0。但由于并发执行，两个线程在进入临界区时可能会导致数据的不一致性。<br>#include &lt;stdio.h&gt;
#include &lt;pthread.h&gt;
#include &lt;unistd.h&gt;

int ticket_amount = 2;

void* ticketAgent(void* arg){
	int t = ticketAmount;
	if (t &gt; 0){
		printf("One ticket sold\n");
		t--;
	}else{
		printf("Ticket sold out\n");
	}
	ticketAmount = t;
	pthread_exit(0);
}

int main(int argc, char const* agrv[]){
	pthread_t ticketAgent_tid[2];
	for(int i = 0; i &lt; 2; i++){
		pthread_create(ticketAgent_tid+i, NULL, ticketAgent, NULL);
	}
	for (int i = 0; i &lt; 2; i++){
		pthread_join(ticketAgent_tid[i], NULL);
	}
	sleep(1);
	printf("The left ticket is %d\n", ticketAmount);
	return 0;
}
<br>运行结果如下：<br><img alt="Pasted image 20240701005315.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240701005315.png"><br>代码执行后我们看到一些结果是正确的，还有一些执行中售出两张票但仍留了一张。这是因为并发线程交替执行”临界区“中的代码，在上面我们也提到了 -- 这种 read-modify-write 指令。如此，并发执行会引起 Heisenbug 。对于这种情况，我们提出临界区管理的原则。<br><br>管理临界区的本质就是要对访问临界区的并发进程进行同步，要实现的目标有互斥、前进和有限等待。通过这些目标，我们能够在不同的同步模式下管理临界区并避免竟态条件和资源冲突所带来的一系列问题。<br>
<br>互斥(Mutual Exclusion,Mutex)：同一时间只能有一个进程/线程进入临界区。
<br>前进(Progress)：进程/线程在持有锁的情况下才能执行临界区内的代码。
<br>有限等待(Bounded Waiting)：完成操作后释放锁，让其他线程有机会进入临界区。
<br><br>互斥锁是由操作系统提供的临界区同步工具，可以保证临界区的管理目标要求。互斥锁的上锁、解锁操作是原子化的，因而保证了每次只会有一个进程/线程进入临界区。互斥锁的同步模型如下：<br>acquireLock();
//+--------------------+
//|                    |
//|  critical section  |
//|                    |
//+--------------------+
releaseLock();
<br>在这段同步模型的伪代码中，我们满足了临界区管理的三大原则，即：<br>
<br>进入临界区前请求锁（互斥），如果成功则上锁并进入临界区（前进），否则等待
<br>离开临界区后释放锁，让其他进程有机会进入临界区（有限等待）
<br><br>下面是一些POSIX系统提供的一些互斥锁的系统调用。相关操作有：<br>#include &lt;pthread.h&gt;
pthread_mutex_t lock;
pthread_mutex_init(&amp;lock,NULL);
pthread_mutex_lock(&amp;lock);
pthread_mutex_unlock(&amp;lock);
pthread_mutex_destroy(&amp;lock);
<br>借助pthread库，我们就可以实现线程间的互斥。我们在 ticket booking 中加入互斥锁，如下：<br>#include &lt;stdio.h&gt;
#include &lt;pthread.h&gt;
#include &lt;unistd.h&gt;

int ticketAmout = 2; // 票的数量: 全局变量
pthread_mutex_t lock; // 定义互斥锁
void* ticketAgent(void* arg){
    pthread_mutex_lock(&amp;lock); // 上锁
	int t = ticketAmout;
	if (t &gt; 0){
		printf("One ticket sold\n");
		t--;
	}else{
		printf("Ticket sold out\n");
	}
	ticketAmout = t;
    pthread_mutex_unlock(&amp;lock); // 解锁
	pthread_exit(0);
}

int main(int argc, char const* agrv[]){
	pthread_t ticketAgent_tid[2];
    pthread_mutex_init(&amp;lock, NULL); // 锁的初始化
	for(int i = 0; i &lt; 2; i++){
		pthread_create(ticketAgent_tid+i, NULL, ticketAgent, NULL);
	}
	for (int i = 0; i &lt; 2; i++){
		pthread_join(ticketAgent_tid[i], NULL);
	}
	sleep(1);
	printf("The left ticket is %d\n", ticketAmout);
	return 0;
}
<br>观察输出，你会发现此时不会有资源共享问题导致的数据不一致性了。pthread库除了提供互斥锁，还有读写锁、自旋锁(Spin-lock) 等，这些都可以为我们临界区的管理提供同步的帮助。<br><br><br>从上节课的例子中，我们看到互斥锁的使用十分简单。借助 pthread 库，我们只需要定义并初始化一把锁，接着进行上锁、解锁和锁的摧毁操作即可。要实现互斥锁对临界区的管理，就需要满足互斥、前进、有限等待三个条件。本节课，带着对临界区的管理原则，我们来尝试实现一把锁。<br><br><br>在第一次尝试中，互斥锁并不满足互斥和有限等待的条件，因为测试和上锁并不是一气呵成的。因而，线程1和线程2可能同时通过测试并上锁，导致两个线程都认为自己获得了锁。此外，没有其他的条件分支，这个锁实际上并不能发挥其应有的作用。<br>bool mutex_lock = false;

lock(mutex_lock){
	if(mutex_lock == false){  // test
		mutex_lock = true;    // lock
	}
}
//+--------------------+
//|                    |
//|  critical section  |
//|                    |
//+--------------------+
unlock(mutex_lock){
	mutex = false;
}
<br><br>为了满足有限等待的条件，我们将判断嵌入到 while 循环中。如果线程2在进入循环时不满足  mutex_lock = false 的条件就会进入空循环，等待线程1解锁释放临界区资源。但是在第二次尝试中，测试和上锁仍然是分开的，不符合互斥的条件。<br>bool mutex_lock = false;

lock(mutex_lock){
	while(mutex_lock != true){  // test
		;
	}
	mutex_lock = true;          // lock
}
//+--------------------+
//|                    |
//|  critical section  |
//|                    |
//+--------------------+
unlock(mutex_lock){
	mutex_lock = false;
}
<br><br>为了使得测试和上锁操作连贯且不可打断，我们需要引入原子操作的概念。原子操作就是在执行过程中需要一气呵成、不会分割、不能也不会被中断的操作。原子操作也称为原语，一般由硬件实现或系统提供。无论是什么原子操作，需要实现其原子性就离不了硬件平台的支持。<br><br>硬件支持的原子操作是由处理器提供的一些指令，确保这些操作在执行时不会被其他操作中断。下面列举了几个常见的硬件原子操作指令的实现：<br>
<br>Compare-and-Swap（比较并交换）：这个指令比较内存位置的值与给定的值，如果匹配，则将其更新为新值。常用于无锁编程中的互斥操作。CAS 实现大致是这样的：
<br>// The atomic hardware instruction CAS would not be interrupted.
bool compare_and_swap(int* ptr, int old_val, int new_val){
	if(*ptr == old_val){
		*ptr = new_val;
		return true;
	} else {
		return false;
	}
}	
<br>
<br>Test-and-Set（测试并设置）：用于检查某个内存位置的值，并在检查的同时将其设置为新值。TS 指令的实现大致如下：
<br>// Same, wouldn't be interrupted
int test_and_set(int* ptr, int new_val){
	int old_val = *ptr;
	*ptr = new_val;
	return old_val;
}
<br>
<br>Fetch-and-Add（取回并增加）：这个指令从内存位置取回一个值，并将其增加一个给定的值。多用于计数器递增操作，比如实现线程安全的计数器。
<br>// Same...
int fetch_and_add(int* ptr, int value){
    int old_val = *ptr;
    *ptr += value;
    return old_val;
}
<br><br>系统提供的原子操作主要通过操作系统和编程语言的库函数实现，来确保在多线程环境下操作的安全性。以下是一些常见的方法：<br>
<br>Mutex（互斥锁）：互斥锁是一种用于保护临界区的机制，确保同一时间只有一个线程能够访问临界区代码。在POSIX线程库中，pthread_mutex_lock&nbsp;和&nbsp;pthread_mutex_unlock&nbsp;用于加锁和解锁。
<br>Spinlock（自旋锁）：自旋锁是一种简单的锁机制，线程在获取锁之前会一直循环检查锁的状态。常用于短时间持锁的情况，以减少线程上下文切换的开销。
<br>Atomic&nbsp;Variables（原子变量）：编程语言也提供原子变量和操作，保证变量的读写操作是原子的。例如，在C++中，可以使用 std::atomic 来定义原子变量，提供原子性的读写操作。
<br>需要注意的是，系统所提供的这些原子性操作通常是通过对硬件封装所得的。如果硬件层面不支持原子操作，系统很难在不借助这些底层支持的情况下实现真正的原子性。<br><br>用原子操作指令，我们能够完成一个如下的简易版 spinlock。<br>//未上锁:0
//已上锁:1
bool mutex = 0;

lock(mutex){
	while(compare_and_swap(mutex, 0, 1) == false){  //测试+上锁
	//while(test_and_set(mutex, 1) == 1){
		;
	}
}
//+--------------------+
//|                    |
//|  critical section  |
//|                    |
//+--------------------+
unlock(mutex){
	mutex = 0;
}
<br><br>忙式等待是指一个进程或线程在等待某个条件满足时，不断地循环检查该条件是否满足的技术，这个循环等待的过程仍然在消耗CPU资源。我们本节课前面的互斥锁正是应用了这种技术，这类锁也称作自旋锁(SpinLocks)。<br><br>若进程请求锁时发现锁已不可用，那就让该进程或线程睡觉(阻塞/等待状态)，这样就不会消耗CPU来执行等待。但是，临界区中的进程离开临界区时在解锁操作中要唤醒之前等待的进程(从等待状态迁移到就绪状态)。上节课我们用到的 pthread_mutex 就是这类锁，即阻塞锁。<br><br><br>上节课我们简单地实现了自己的自旋锁，在课程末尾，我们提到了阻塞锁。我们实现自旋锁时的忙等待白白浪费CPU资源，这不是我们想要的。这节课，我们就来学习互斥锁。并比较两者的差别。<br><br>POSIX 系统提供了pthread_mutex互斥锁来实现不同操作之间的互斥。我们之前也在课程中使用过pthread_mutex。当检查到互斥锁已经被其他线程所侵占时，线程就会阻塞自己，由于这种实现方式，互斥锁也被称作阻塞锁。<br>下面是POSIX thread库中所提供的互斥锁的系统调用。我们最熟悉的是lock和unlock的系统调用，简单明了。当我们使用pthread_mutex_lock()时，这个函数会先检查锁是否可用，若是不可用就阻塞自己，锁可用后会向阻塞线程发送信号。<br>int pthread_mutex_lock(pthread_mutex_t *mutex);
/* 
Parameters:
	1. mutex: Pointer to the mutex to lock.

Return value: Returns 0 on success, otherwise an error number.
*/
<br>如果你想实现一些条件分支，例如当锁不可用时怎么怎么办，pthread还提供trylock的逻辑。不同于mutex_lock，trylock并不会阻塞线程。当如果互斥锁已经被其他线程占有时trylock会返回错误码 EBUSY，表示锁当前不可用。<br>int pthread_mutex_trylock(pthread_mutex_t *mutex);
/* 
Parameters:
	1. mutex: Pointer to the mutex to try to lock.

Return value: Returns 0 on success, otherwise an error number.
*/
<br>下面是对锁的解锁操作。<br>int pthread_mutex_unlock(pthread_mutex_t *mutex);
/*
Parameters:
	1. mutex: Pointer to the mutex to unlock.

Return value: Returns 0 on success, otherwise an error number.
*/
<br>说完了加锁和解锁，要使锁可用，锁的初始化和销毁是绕不开的点。使用pthread_mutex_init()我们可用将锁初始化为几种不同的状态。如果状态参数设置为NULL，那么就会使用默认的mutex类型，即PTHREAD_MUTEX_DEFAULT，行为未被定义。此外，我们还有其他的几种行为，如下：<br>#include &lt;pthread.h&gt;

int pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *attr);
/* 
Parameters:
	1. mutex: Pointer to the mutex to initialize.
	2. attr: Pointer to a mutex attributes object, or NULL for default attributes.
	   - PTHREAD_MUTEX_NORMAL: Mutex relocking is not allowed,  will cause deadlock.
	   - PTHREAD_MUTEX_ERRORCHECK: Mutex relocking will return an error.
	   - PTHREAD_MUTEX_RECURSIVE: Allowing the same mutex relock multiple times.
	   - PTHREAD_MUTEX_DEFAULT: Default mutex, behavior undefined.

Return value: Returns 0 on success, otherwise an error number.
*/
<br>int pthread_mutex_destroy(pthread_mutex_t *mutex);
/* 
Parameters:
	1. mutex: Pointer to the mutex to destroy.

Return value: Returns 0 on success, otherwise an error number.
*/
<br>一旦调用 pthread_mutex_destroy() 销毁了一个互斥锁，该互斥锁对象就不能再被使用了。销毁互斥锁会释放与该互斥锁相关的所有资源。如果在销毁后尝试使用该互斥锁，可能会导致未定义行为，甚至程序崩溃。<br><br>int pthread_mutex_lock(pthread_mutex_t *mutex){
	//尝试使用CAS操作来获取锁
	if(atomic_compare_and_swap(&amp;mutex-&gt;lock,0,1)){  //这是一个快速路径
		//成功获取锁
		return 0;
	}
	//锁已经被其他执行流占有，进入慢速路径(阻塞自己，省略实现)
	return -1;
}
<br><br>POSIX 系统也提供了 pthread_spinlock 自旋锁来实现不同操作之间的互斥。我们前面实现过自己的一个自旋锁。自旋锁在检查到锁已经被其他线程占用时，不会阻塞线程，而是会在一个循环中不断检查锁的状态，直到锁可用。下面是 POSIX thread 库中所提供的自旋锁的系统调用：<br>#include &lt;pthread.h&gt;

int pthread_spin_init(pthread_spinlock_t *lock, int pshared);
/* 
Parameters:
	1. lock: Pointer to the spinlock to initialize.
	2. pshared: If non-zero, the spinlock is shared between processes; if zero, it is shared between threads of the same process.

Return value: Returns 0 on success, otherwise an error number.
*/
<br>int pthread_spin_destroy(pthread_spinlock_t *lock);
/* 
Parameters:
	1. lock: Pointer to the spinlock to destroy.

Return value: Returns 0 on success, otherwise an error number.
*/
<br>int pthread_spin_lock(pthread_spinlock_t *lock);
/* 
Parameters:
	1. lock: Pointer to the spinlock to lock.

Return value: Returns 0 on success, otherwise an error number.
*/
<br>int pthread_spin_trylock(pthread_spinlock_t *lock);
/* 
Parameters:
	1. lock: Pointer to the spinlock to try to lock.

Return value: Returns 0 on success, otherwise an error number.
*/
<br>int pthread_spin_unlock(pthread_spinlock_t *lock);
/* 
Parameters:
	1. lock: Pointer to the spinlock to unlock.

Return value: Returns 0 on success, otherwise an error number.
*/
<br>自旋锁的系统调用和阻塞锁的系统调用很类似，唯一的差别就在于阻塞还是忙等待。你可能注意到初始化函数也有所不同，但是你实际上可以通过下面这种方式设置互斥锁的状态：<br>pthread_mutex_t mutex;
pthread_mutexattr_t attr;

pthread_mutexattr_init(&amp;attr);
pthread_mutexattr_setpshared(&amp;attr, PTHREAD_PROCESS_SHARED);
pthread_mutex_init(&amp;mutex, &amp;attr);
<br>下面是其函数原型：<br>int pthread_mutexattr_setpshared(pthread_mutexattr_t *attr, int pshared);
/* 
Parameters:
	1. attr: Pointer to the mutex attributes object.
	2. pshared: The process-shared attribute. It can be set to:
	   - PTHREAD_PROCESS_SHARED: The mutex can be shared between processes.
	   - PTHREAD_PROCESS_PRIVATE: The mutex is shared only between threads of the same process.

Return value: Returns 0 on success, otherwise an error number.
*/
<br><br><br>#include &lt;stdio.h&gt;
#include &lt;pthread.h&gt;
#include &lt;unistd.h&gt;
#include &lt;time.h&gt;

#define NUM_ITERATIONS 100000

pthread_mutex_t mutex;
int counter = 0;

void* mutex_thread_func(void* arg){
	for (int i = 0; i &lt; NUM_ITERATIONS; ++i)
	{
		pthread_mutex_lock(&amp;mutex);			//Get mutex lock
		counter++;
		for (int j = 0; j &lt; 10000; ++j);	//Increase system load
		pthread_mutex_unlock(&amp;mutex);		//Release the lock
	}
	return NULL;
}

int main(int argc, char const *argv[])
{
	pthread_t t1,t2;
	struct timespec start, end;

	pthread_mutex_init(&amp;mutex, NULL);		//Initialize the lock

	clock_gettime(CLOCK_MONOTONIC, &amp;start);	//Start time counting

	pthread_create(&amp;t1, NULL, mutex_thread_func, NULL);
	pthread_create(&amp;t2, NULL, mutex_thread_func, NULL);

	pthread_join(t2, NULL);
	pthread_join(t1, NULL);

	clock_gettime(CLOCK_MONOTONIC, &amp;end);	//Finish time counting

	pthread_mutex_destroy(&amp;mutex);			//Destroy the lock

	double elapsed = (end.tv_sec - start.tv_sec) 
				   + (end.tv_nsec - start.tv_nsec) / 1e9;

	printf("Final counter value with pthread_mutex_t: %d\n",counter);
	printf("Elapsed time with pthread_mutex_t: %f\n",elapsed);

	return 0;
}
<br><br>#include &lt;stdio.h&gt;
#include &lt;pthread.h&gt;
#include &lt;unistd.h&gt;
#include &lt;time.h&gt;

#define NUM_ITERATIONS 100000

pthread_spinlock_t spinlock;
int counter = 0;

void* mutex_thread_func(void* arg){
	for (int i = 0; i &lt; NUM_ITERATIONS; ++i)
	{
		pthread_spin_lock(&amp;spinlock);		//Get spin lock
		counter++;
		for (int j = 0; j &lt; 10000; ++j);	//Increase system load
		pthread_spin_unlock(&amp;spinlock);		//Release the lock
	}
	return NULL;
}

int main(int argc, char const *argv[])
{
	pthread_t t1,t2;
	struct timespec start, end;

	pthread_spin_init(&amp;spinlock, PTHREAD_PROCESS_PRIVATE);		//Initialize the lock

	clock_gettime(CLOCK_MONOTONIC, &amp;start);	//Start time counting

	pthread_create(&amp;t1, NULL, mutex_thread_func, NULL);
	pthread_create(&amp;t2, NULL, mutex_thread_func, NULL);

	pthread_join(t2, NULL);
	pthread_join(t1, NULL);

	clock_gettime(CLOCK_MONOTONIC, &amp;end);	//Finish time counting

	pthread_spin_destroy(&amp;spinlock);		//Destroy the lock

	double elapsed = (end.tv_sec - start.tv_sec) 
				   + (end.tv_nsec - start.tv_nsec) / 1e9;

	printf("Final counter value with pthread_spinlock_t: %d\n",counter);
	printf("Elapsed time with pthread_spinlock_t: %f\n",elapsed);

	return 0;
}
<br><br>运行的结果因机器而异，但这两种锁的实现方式决定了它们的特点。对于互斥锁而言，线程/进程切换的开销是其主要的开销；而对于自旋锁，忙等待让CPU空转是其主要的开销。我们知道，进程/线程的切换需要保存上下文信息，这需要一定的代价，从而，两种锁的比较就变成了空转的时间更长还是上下文切换的时间更长。<br>不难想象，线程占有锁的时间越长，相比忙等待，线程切换的系统开销占比就会越小，这时mutex显然更优。但由于空循环忙等待的开销占比基本一成不变，当短时间持有锁时则 spinlock 更优。<br><br><br><br>我们学过了临界区的管理原则有：互斥、前进、有限等待。在原子操作和互斥锁工具还没有被应用的时代，Dekker算法和Peterson算法就是当是两种为了解决临界区管理问题所应用的算法。<br><br>Peterson算法是软件解决管理临界区问题经典算法。它利用线程间访问共享资源的方式实现进程/线程间互斥访问临界区的算法。<br>Peterson算法的伪代码如下：<br>//Peterson算法的变量
bool flag[2] = {false,false};  //flag[i]表示第i个线程/进程有进入临界区的意愿
int turn;                      //turn的值j表示现在第j个值有进入临界区的令牌

/*
当flag[i] &amp;&amp; turn == i,这时只有第i个进程才能进入临界区。实现了对临界区的管理
*/
<br>P0进程：<br>flag[0] = true;  //P0a
turn = 1;        //P0b
while(flag[1] &amp;&amp; turn == 1){
	//busy wait
}
//start of critical section
...
//end of critical section

flag[0] = false;               //unlock
<br>P1进程：<br>flag[1] = true;  //P1a
turn = 0;        //P1b
while(flag[0] &amp;&amp; turn == 0){
	//busy wait
}
//start of critical section
...
//end of critical section

flag[1] = false;               //unlock
<br><br>在算法执行时，由于进程的并发性，语句执行顺序及结构可能出现如下几种可能：<br><br><br>Peterson 算法是一种不依赖硬件实现的原子操作机制。如今大多数CPU以指令乱序执行来提高执行效率，此时实现 Peterson 算法就得使用相关内存屏障指令。现在一般使用硬件支持的原子操作机制（比如 test-and-set 或 compare-and-swap），这些机制往往只需要很少的硬件支持。<br><br>和 Peterson 算法一样，Dekker 算法也是用进程间共享资源的方式实现进程间的互斥操作。同年 Dijkstra 提出信号量的概念也是受 Dekker 算法的影响。<br>Dekker 算法的伪代码如下：<br>// Dekker算法的变量
bool wants_to_enter[2] = {false, false}; // 表示进程是否想要进入临界区
int turn = 0; // 表示当前的优先权
<br>进程P0：<br>// 进程P0
wants_to_enter[0] = true;    //P0a
while (wants_to_enter[1]) {
    if (turn != 0) {
        wants_to_enter[0] = false;
        while (turn != 0) {
            // 忙等待
        }
        wants_to_enter[0] = true;
    }
}
// 临界区
...
turn = 1;
wants_to_enter[0] = false;
// 剩余部分
<br>进程P1：<br>// 进程P1
wants_to_enter[1] = true;    //P1a
while (wants_to_enter[0]) {
    if (turn != 1) {
        wants_to_enter[1] = false;
        while (turn != 1) {
            // 忙等待
        }
        wants_to_enter[1] = true;
    }
}
// 临界区
...
turn = 0;
wants_to_enter[1] = false;
// 剩余部分
<br><br><br><br><br><br>信号量概念最早由荷兰计算机科学家Edsger W. Dijkstra在1965年提出，是用与多线程环境下同步和互斥的一种机制。这个机制包含一个值和两个原子操作：<br>
<br>信号量值：一个整数值
<br>P操作：荷兰语 Proberen，意为“测试”，也称为 wait 操作。
<br>V操作：荷兰语 Verhogen，意为”增加“，也称为 post/signal 操作。
<br>信号量是一种比互斥锁更强大的同步工具，它的引入极大地简化了复杂的并发控制问题，使得操作系统和并发编程中的资源管理变得更有效和可靠。<br><br><br>如果信号量只包含数值，且在数值不可用时实施忙式等待，那么就成这对PV操作为自旋PV操作。（也叫”整数信号量“）<br>semaphore sem;
wait(sem){
	while(s &lt;= 0){
		//busy waiting
	}
	s--;
}
post(sem){
	s++;
}
<br><br>要消除自旋等待，我们可以把信号量打造成一个包含值和队列指针的结构体。具体思路如下：我们在执行P操作时，先判断数值是否可用，若不可用，利用进程指针将进程给阻塞掉。等到资源可用后，V操作在阻塞队列中再一个个地唤醒阻塞进程。这就是阻塞PV操作，也叫记录型信号量。<br>typedef struct{
	int value;
	struct process* L;
}semaphore;
semaphore sem;
wait(sem){
	s.value
	if(s.value &lt; 0){
		block(s.L);
	}
}

post(sem){
	s.value++;
	if(s.value &lt;= 0){
		wakeup(P);
	}
}
<br><br>我们假设有一个信号量s，它的初始值为1，我们还有3个并发进程 P1、P2、P3 都要对s先进行P操作，再进行V操作，下面是其中一种可能的顺序：<br><br><br><br>从之前互斥锁实现中，我们已经学会如何使用“锁”来管理临界区，我们使用信号量和PV操作同样可以完成临界区管理的任务。以下我们给出一段伪代码：<br>semaphore mutex = 1;

Thread n:
	//其他代码
	wait(mutex);    //相当于lock
	//+--------------------+
	//|                    |
	//|  critical section  |
	//|                    |
	//+--------------------+
	post(mutex);    //相当于unlock
	//其他代码
<br>结合上面的伪代码，很容易想明白当有多个进程并发地要访问临界区时，只有第一个执行P操作的进程能够进入临界区，并抢占这里的唯一的信号量资源。其他进程由于没有资源可以使用，因此只能自旋或阻塞等待释放临界区资源。<br>
<br>初始状态：mutex = 1，临界区空闲，任何进程可以进入临界区。
<br>进程执行：某个进程执行了P(mutex)操作。信号量mutex减1变成0，此时临界区被占用
<br>线程离开临界区：返还临界区资源，mutex加1。其他进程可以进入临界区。
<br>这种实现互斥的信号量初值总是1，它的值总是在0和1之间变化，因此被称作二值信号量。<br><br>我们知道，在计算机世界中由于并发进程执行是异步的。如果我们想要多个进程按照某个顺序执行要怎么办呢？我们可以利用PV操作实现这多个进程之间的同步。<br>假设我们现在有两个进程P1和P2，P2需要在P1完成某些操作后才能继续执行任务，我们可以先定义一个名为sync的信号量，如下：<br>semaphore sync = 0;    //初始化为0，表示P2需要等待

P1:
	//其他代码
	//执行P2需要等待的操作
	post(sync);
	//其他代码
P2:
	//其他代码
	wait(sync);    //等待P1相关操作执行完毕
	//继续执行
	//其他代码
<br>通过上面的伪代码，我们不难看出，即使机器中的代码是异步执行的，但是P2相关操作还是可以同步等待P1相关操作的完成。不论大厨炒菜多么快速，他都需要等待菜全部切好才能开始炒菜，不然就可能导致不好的事情出现。<br>这个例子中，不论是P1先执行还是P2先执行，没有P1进行V操作，P2就无法执行P操作从而继续执行其他代码。从这个例子中也能明白，我们同步的目标是保证P2在P1完成相关操作后才能继续执行。<br><br>我们已经学习过如何用信号量实现同步和互斥，但是我们仍然有一种情况没有考虑到。如果在多进程系统中，并发的进程要同时访问共享资源呢？我们考虑以下几种情况：<br>
<br>某类管理资源在同一时刻只允许一个进程使用（二值信号量实现的临界区互斥管理）
<br>对文件或数据库资源，可以某一时刻有多个进程同时读取甚至写入。
<br>资源较多，系统可以按进程的需求进行分配。
<br>我们已经学过第一种情况的管理机制，那么底下的2、3情况呢？我们需要一种机制来防止资源竞争来确保系统的稳定性。<br><br>计数信号量的初始值是一个非负整数，用于表示多个相同资源的可用数量。从这里，我们能看出二值信号量实际上是计数信号量的特殊情况，其中计数信号量的值只能是0或1。引入计数信号量扩展了对临界区资源数量大于1的情况的处理能力，使得多个线程可以同时访问多个相同的资源。<br>例：假设系统中有3台打印机，多个进程都需要使用这些打印机，我们可以使用一个计数信号量来管理这3台打印机的申请和释放。<br>semaphore printer = 3;

Process n:
	//其他代码
	wait(printer);
	//+-----------------+
	//|                 |
	//|  using printer  |
	//|                 |
	//+-----------------+
	post(printer);
	//其他代码
<br>
<br>初始化信号量：信号量的初始值为3，表示系统中有3台可用的打印机。
<br>当进程需要使用打印机时，执行P操作。P操作会检查信号量的当前值，如果值大于0，则表示有可用的打印机，信号量值减1，进程获得使用打印机的权限。如果信号量值为0，表示没有可用的打印机，进程将等待，直到有打印机可用。
<br>当进程使用完打印机后，执行V操作。V操作会增加信号量的值，表示释放了一台打印机。如果有等待的进程，V操作将唤醒其中一个进程，使其可以继续执行。
<br>进程数量：当进程数量 ≤ 3 时，所有进程都可以同时使用打印机；当进程数量 &gt; 3 时，只有3个进程可以同时使用打印机，其他进程需要等待。
<br><br><br><br>POSIX标准提供了几个用于信号量（semaphore）的系统调用，这些调用可以用于进程或线程之间的同步。以下是几个主要的POSIX信号量系统调用：<br><br>#include &lt;semaphore.h&gt;

int sem_init(sem_t *sem, int pshared, unsigned int value);
/* 
Parameters:
	1. sem: Pointer to the semaphore to initialize.
	2. pshared: If non-zero, the semaphore is shared between processes; if zero, it is shared between threads of the same process.
	3. value: Initial value of the semaphore.

Return value: Returns 0 on success, -1 on failure and sets errno appropriately.
*/
<br><br>int sem_destroy(sem_t *sem);
/* 
Parameters:
	1. sem: Pointer to the semaphore to destroy.

Return value: Returns 0 on success, -1 on failure and sets errno appropriately.
*/
<br><br>int sem_wait(sem_t *sem);
/* 
Parameters:
	1. sem: Pointer to the semaphore to decrement (wait).

Return value: Returns 0 on success, -1 on failure and sets errno appropriately.
*/
<br><br>int sem_trywait(sem_t *sem);
/* 
Parameters:
	1. sem: Pointer to the semaphore to decrement (try to wait).

Return value: Returns 0 on success, -1 on failure and sets errno appropriately.
*/
<br><br>int sem_post(sem_t *sem);
/* 
Parameters:
	1. sem: Pointer to the semaphore to increment (signal).

Return value: Returns 0 on success, -1 on failure and sets errno appropriately.
*/
<br><br>int sem_getvalue(sem_t *sem, int *sval);
/* 
Parameters:
	1. sem: Pointer to the semaphore.
	2. sval: Pointer to an integer to store the current value of the semaphore.

Return value: Returns 0 on success, -1 on failure and sets errno appropriately.
*/
<br><br><br><br><br>之前我们学习二值信号量实现的同步中，我们实际上就已经接触了signaling的同步模式，相当于一个进程/线程对另一个进程/线程的等待。我们另外举一个例子，假如我们有信号量sem，初始化为0。通过信号量的PV操作，我们就能实现两个进程/线程之间的同步。<br>Thread A<br>Statement A1;
post(sem);
<br>Thread B<br>wait(sem);
Statement B1;
<br>上面的例子中，如果B线程开始执行，由于Statement A1并没有完成（信号量没有被post），所以线程B会被阻塞，等待信号量的释放。所以只要线程A调用post(sem)之后，线程B才会开始执行。<br><br><br>Rendezvous的同步模式是一种双向的同步模式，它相当于是对signaling的拓展。与signaling不同，rendezvous不仅仅是一个进程/线程在等待另一个进程/线程的信号，而是两个进程/线程彼此都在等待对方。因而，在这种同步模式中，我们需要两个信号量sem1和sem2并初始化为0。<br>Thread A<br>Statement A1;
post(sem1);
wait(sem2);
Statement A2;
<br>Thread B<br>Statement B1;
post(sem2);
wait(sem1);
Statement B2;
<br>上述的例子中，只有当线程A和线程B都走完Statement A1和Statement B1时，下一阶段的任务才会开始。这种双向同步确保了两个线程在特定的同步点上达成一致，然后才能继续各自的任务。<br><br>问题来了，如果线程的数量越来越多，会发生什么？如果线程数量不断增加，会导致同步和管理的复杂性显著增加。为了避免死锁，必须确保PV操作平衡，即每个post操作应有相应的wait操作。<br>在有三个线程（A、B、C）的情况下，可以如下进行rendezvous的同步：<br>Thread A<br>Statement A1;
post(sem1);
post(sem1);
wait(sem2);
wait(sem2);
Statement A2;
<br>Thread B<br>Statement B1;
post(sem2);
post(sem2);
wait(sem1);
wait(sem3);
Statement B2;
<br>Thread C<br>Statement C1;
post(sem3);
post(sem3);
wait(sem1);
wait(sem2);
Statement C2;
<br>这种方式中，每个线程在执行完自己的第一部分工作后（Statement&nbsp;A1,&nbsp;B1,&nbsp;C1），分别post一个信号量并wait两个信号量。每个线程都在等待另外两个线程的信号，从而确保所有线程都在同步点相遇后才能继续执行剩余工作。<br>虽然这种设计可以防止死锁，但随线程数量增加，同步复杂度和信号量的管理也会增加。为了简化管理和实现，我们可以使用一些更高级的同步原语或模式，我们将介绍的下一个同步模式屏障(barrier)就是为此而生的。<br><br>Thread N<br>wait(mutex)
count++
post(mutex)
if count == n
    for i from 1 to n
	post(barrier)
	end for
end if
wait(barrier)
<br><br>Turnstile&nbsp;pattern&nbsp;是一种设计模式，主要用于在并发编程中控制对共享资源的访问。它像个旋转门一样，只允许一个线程在特定时间内通过，从而确保多个线程之间能够有序地进行协调。<br>条件变量和&nbsp;turnstile&nbsp;pattern&nbsp;是相关的。在&nbsp;turnstile&nbsp;pattern&nbsp;中，条件变量可以用来管理线程的等待和唤醒。当资源不可用时，线程会被阻塞并放入条件变量中。当资源可用时，通过条件变量发出信号，唤醒等待的线程，使其继续执行。<br><br><br><br>生产者-消费者问题描述了两个进程，一个是生成数据的生产者进程，一个是负责消费数据的消费者，两者通过共享缓冲区进行通信。由于问题描述的固定大小的缓冲区，也被称有限缓冲问题。核心挑战在于如何有效地管理缓冲区，确保生产者不会在缓冲区满时继续生产，也确保消费者不会在缓冲区空时继续消费。这个问题有很多变体，例如我们可以设置 x 个生产者， y 个消费者之类的。<br><br>在生产者-消费者问题中，有许多规则需要双方遵守的。当我们设置缓冲区大小为BUFFER_SIZE。我们规定：<br>
<br>当缓冲区为空时，消费者不可以从缓冲区中读取信息。
<br>当缓冲区满了后，生产者也不可以在缓冲区写入任何东西。
<br>对于缓冲区的操作，我们需要确保其是互斥访问的，以免导致数据竞争问题。
<br><br>通过这三条规则，我们可以用以下的伪代码对生产-消费的过程进行模拟。下面是一个忙等待加互斥的例子，我们用互斥锁对临界区进行了保护（缓冲区相关操作）。如果缓冲区满，生产者会一直查看缓冲区是否有空隙；若是缓冲区空，消费者也会一直查看缓冲区是否有可读信息。<br>Producer<br>added = false;
while(added = false){
	wait(mutex);
	if(count &lt; BUFFER_SIZE){
		// Add item.
		count++;
		added = true;
	}
	post(mutex);
}
<br>Consumer<br>removed = false;
while(removed = false){
	wait(mutex);
	if(count &gt; 0){
		// Remove item.
		count--;
		removed = true;
	}
	post(mutex);
}
<br><br>我们之前比较过互斥锁和自旋锁的优劣，如果我们要长时间持有锁，忙等待显然会一直白白浪费资源。这种情况下，检查一次缓冲区，如果不满足相应的条件就直接阻塞进程/线程明显是更好的办法。使用锁好像效益来的不再可观，我们需要使用其他的工具。<br>我们可以使用两个信号量，他们的最大值都是BUFFER_SIZE。两个信号量的描述如下：<br>
<br>items信号量：从0开始，表示缓冲区内现有多少可读的数据。
<br>spaces信号量：从BUFFER_SIZE开始，表示缓冲区还有多大的可用空间。
<br>下面的伪代码中，mutex用于确保对缓冲区的访问是互斥的，从而避免了数据竞争问题。spaces和items信号量则用于控制缓冲区的容量和可读数据量。这样可以确保生产者和消费者在操作缓冲区时遵守规则，从而实现同步互斥。<br>Producer<br>wait(mutex);
wait(spaces);
// Add item.
post(items);
post(mutex);
<br>Consumer<br>wait(mutex);
wait(items);
// Remove item.
post(spaces);
post(mutex);
<br>这个示例会有什么问题？我们的确保证了对缓冲区的互斥访问。但是如果缓冲区满时，生产者率先进入临界区，生产者会阻塞在wait(spaces);。因为缓冲区满了，需要消费者进入缓冲区消耗资源但是由于生产者持有互斥锁，消费者无法进入缓冲区消耗资源。这就会导致死锁(Deadlock) 的发生。如果缓冲区为空，消费者先进入临界区也会导致类似的死锁问题。<br><br>我们对伪代码进行一些调整，生产者和消费者在等待spaces和items信号量时不再持有互斥锁，从而避免了死锁的发生。从而生产者和消费者可以在缓冲区满或空的情况下正确地等待和释放资源。<br>Producer<br>wait(spaces);
wait(mutex);
// Add item.
post(mutex);
post(items);
<br>Consumer<br>wait(items);
wait(mutex);
// Remove item.
post(mutex);
post(spaces);
<br><br>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;pthread.h&gt;
#include &lt;semaphore.h&gt;

#define BUFFER_SIZE 20
#define PRODUCER_NUMBER 10
#define CONSUMER_NUMBER 10

int* buffer;
int pindex = 0;
int cindex = 0;
sem_t spaces;
sem_t items;
pthread_mutex_t mutex;
unsigned int seed = 252;

int produce(int id){
    int r = rand_r(&amp;seed); // rand_r for thread safe.
    printf("Producer: %d\tproduced: %d.\n", id, r);
    return r;
}

void consume(int id, int value){
    printf("Consumer: %d\tconsumed %d.\n", id, value);
}

void* producer(void* arg){
    int* id = (int*) arg;
    for(int counter = 0; counter &lt; 100; ++counter){
        int num = produce(*id);
        sem_wait(&amp;spaces);
        pthread_mutex_lock(&amp;mutex);
        buffer[pindex] = num;
        pindex = (pindex + 1) % BUFFER_SIZE;
        pthread_mutex_unlock(&amp;mutex);
        sem_post(&amp;items);
    }
    free(arg);
    pthread_exit(NULL);
}

void* consumer(void* arg){
    int* id = (int*) arg;
    for(int counter = 0; counter &lt; 100; ++counter){
        sem_wait(&amp;items);
        pthread_mutex_lock(&amp;mutex);
        int num = buffer[cindex];
        buffer[cindex] = -1;
        cindex = (cindex + 1) % BUFFER_SIZE;
        pthread_mutex_unlock(&amp;mutex);
        sem_post(&amp;spaces);
        consume(*id, num);
    }
    free(id);
    pthread_exit(NULL);
}

int main(int argc, char** argv){
    buffer = malloc(BUFFER_SIZE * sizeof(int));
    for(int i = 0; i &lt; BUFFER_SIZE; i++){
        buffer[i] = -1;
    }
    sem_init(&amp;spaces, 0, BUFFER_SIZE);
    sem_init(&amp;items, 0, 0);
    pthread_mutex_init(&amp;mutex, NULL);

    pthread_t producer_thread[PRODUCER_NUMBER];
    pthread_t consumer_thread[CONSUMER_NUMBER];

    for(int i = 0; i &lt; PRODUCER_NUMBER; i++){
        int* id = malloc(sizeof(int));
        *id = i;
        pthread_create(&amp;producer_thread[i], NULL, producer, id);
    }
    for(int j = 0; j &lt; CONSUMER_NUMBER; j++){
        int* id = malloc(sizeof(int));
        *id = j;
        pthread_create(&amp;consumer_thread[j], NULL, consumer, id);
    }
    for(int k = 0; k &lt; PRODUCER_NUMBER; k++){
        pthread_join(producer_thread[k], NULL);
    }
    for(int k = 0; k &lt; CONSUMER_NUMBER; k++){
        pthread_join(consumer_thread[k], NULL);
    }

    free(buffer);
    sem_destroy(&amp;spaces);
    sem_destroy(&amp;items);
    pthread_mutex_destroy(&amp;mutex);
    pthread_exit(0);
}
<br><br><br>读者写者问题描述了多个读者和写者对共享数据的访问。读者-写者问题与生产者-消费者问题相似而又不同。相似的是两个问题中都有数据的输入（生产者/写者）和输出方（消费者/读者），而且生产者/写者修改共享数据时不能有其他线程访问共享数据。<br>不同的是，读者-写者问题中的输出方（读者）并不涉及到对数据的修改操作（do not modify），这就意味着多个读者在读取数据的同时不会引起冲突。而且很多现实问题中写入很稀有但是读操作非常常见，允许缓冲区中多个读者读数据实际上可以提升很多性能。<br><br>现在我们考虑第一种情况，即一个写者对应着多个读者。假设读和写的操作都在一个房间中进行，即进行读写操作的房间实际上是我们的临界区。因而我们需要一个二元信号量roomEmpty对临界区进行管理。在读者进入临界区时，我们不想计算读者的数量时出现数据竞争的问题，所以我们使用mutex让读者一个一个地进入临界区。<br>当写者要进入临界区中时，我们需要保证临界区中没有读者存在，在solution-1中，我们用以下的伪代码表示写者的行为：<br>Writer<br>wait(roomEmpty);
// Write something
post(roomEmpty);
<br>我们提到过，在读者-写者问题中，临界区中可以存在多个读者。因此我们在solution-1的伪代码中给出如下的读者行为：<br>Reader<br>wait(mutex);
readers++;
if(readers == 1){
	wait(roomEmpty);
}
post(mutex);
// Read data.
wait(mutex);
readers--;
if(readers == 0){
	post(roomEmpty);
}
post(mutex);
<br><br>在solution-1中写者的行为逻辑简单又清晰，等待房间里没有读者了，写者进入房间中进行写操作。而由于可能会有很多读者，读者在进出房间时会挨个登记（wait(mutex) 和 post(mutex)），如果是第一个进入房间的，就负责标识房间已被占用（wait(roomEmpty)），最后一个出房间就负责标识房间空闲（post(roomEmpty)。<br>读者的这种行为模式叫做light switch pattern（先进入房间的人开灯，最后一个离开房间的人关灯）。在solution-1中，读者的行为会为写者带来很多困扰。比如读者占用房间后，后来的读者可以随意进出，只要保证最后一个离开房间的写者离开时释放房间资源就可以了。但是，你没有办法知道后面究竟有多少读者要读。在solution-1中，写者只能干等，这会导致写者长时间得不到资源的问题，也就是饥饿(Starvation)：which means a thread may never gets a chance to run.<br>写者的饥饿可能对博客这种读写问题的影响不会很大，但是对那些对实时性有要求的系统的影响尤其大（比如数据库的读写问题）。<br><br>为了避免写者的饥饿问题，我们需要另辟蹊径，重新找一个方法。我们试想一下solution-2的描述：当写者到达，已经在房间里的读者们继续阅读，但是后来者就不可以进入临界区阅读数据了。在solution-2的假设下，写者只需要等待临界区中读者读完数据走出临界区，不需要担心无休止到来的读者。<br>Solution-2我们引入了另一个二元信号量turnstile。相当于对“门”进行控制，无论是读者还是写者，要进入房间（临界区）必须通过“门”。通过占有“门”资源，读者和写者就能顺序地进入临界区。Solution-2中的写者行为如下：<br>Writer<br>wait(turnstile);
wait(roomEmpty);
// Write data.
post(roomEmpty);
post(trunstile);
<br>Reader<br>wait(turnstile);
post(turnstile);
wait(mutex);
readers++;
if(readers == 1){
	wait(roomEmpty);
}
post(mutex);
// Read data.
wait(mutex);
readers--;
if(readers == 0){
	post(roomEmpty);
}
post(mutex);
<br><br>虽然我们成功地使写者免受了饥饿的困扰，但是写者仍然不对临界区拥有任何特权。想想看，如果前面仍然有许多的读者在写者前面排队等待进入临界区，写者就仍然需要队列前面的所有读者进入临界区-读取-出临界区后才能对临界区资源进行操作。<br>Solution-2仍然不够实时，怎么办？我们需要划分优先级，使得写者相对读者总是享有有限进入临界区的特权。可以通过将信号量roomEmpty划分为两个信号量：noReaders 和 noWriters 来实现。通过让写者持有noReaders信号量来控制读者进入临界区。<br><br>在Solution-3中，我们引入优先级机制，写者可以相对读者享有优先权。第一个写者会等待并占有noReaders信号量，阻止新的读者进入临界区。这样，写者可以在当前读者完成操作后立即进入临界区，而不需要等待新的读者完成操作。<br>Writer<br>wait(writeMutex);
writers++;
if(writers == 1){
	wait(noReaders)
}
post(writeMutex);
wait(noWriters);
// Write data.
post(noWriters);
wait(writeMutex);
writers--;
if(writers == 0){
	post(noReaders)
}
<br>Reader<br>wait(noReaders);
wait(readMutex);
readers++;
if(readers == 1){
	wait(noWriters);
}
post(readMutex);
post(noReaders);
// Read data.
wait(readMutex);
readers--;
if(readers == 0){
	post(noWriters);
}
post(readMutex);
<br><br><br>#include &lt;pthread.h&gt;
pthread_rwlock_t rwlock;
<br>#include &lt;pthread.h&gt;
int pthread_rwlock_init(pthread_rwlock_t *rwlock, const pthread_rwlockattr_t *attr);
/* 
Parameters:
	1. rwlock: Pointer to the read-write lock to initialize.
	2. attr: Pointer to a read-write lock attributes object, or NULL for default attributes.
	   - PTHREAD_PROCESS_SHARED: The lock can be shared between processes.
	   - PTHREAD_PROCESS_PRIVATE: The lock is private to the process (default).

Return value: Returns 0 on success, otherwise an error number.
*/
<br>int pthread_rwlock_destroy(pthread_rwlock_t *rwlock);
/* 
Parameters:
	1. rwlock: Pointer to the read-write lock to destroy. The lock must be uninitialized before calling this function.

Return value: Returns 0 on success, otherwise an error number.
*/
<br>// Blocks if the lock is currently held by a writer.
int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock);
/* 
Parameters:
	1. rwlock: Pointer to the read-write lock to acquire for read access.

Return value: Returns 0 on success, otherwise an error number.
*/
<br>// Does not block. Returns immediately if the lock cannot be acquired.
int pthread_rwlock_tryrdlock(pthread_rwlock_t *rwlock);
/* 
Parameters:
	1. rwlock: Pointer to the read-write lock to attempt acquiring for read access.

Return value: Returns 0 on success, otherwise an error number.
*/
<br>// Blocks if the lock is currently held by a reader or writer.
int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock);
/*
Parameters:
	1. rwlock: Pointer to the read-write lock to acquire for write access.

Return value: Returns 0 on success, otherwise an error number.
*/
<br>// Does not block. Returns immediately if the lock cannot be acquired.
int pthread_rwlock_trywrlock(pthread_rwlock_t *rwlock);
/*
Parameters:
	1. rwlock: Pointer to the read-write lock to attempt acquiring for write access.

	Return value: Returns 0 on success, otherwise an error number.
*/
<br>// Releases the lock held by either a reader or a writer.
int pthread_rwlock_unlock(pthread_rwlock_t *rwlock);
/* 
Parameters:
	1. rwlock: Pointer to the read-write lock to release.

Return value: Returns 0 on success, otherwise an error number.
*/
<br><br><br><br>条件变量和我们学过的条件语句非常类似，我们用不同的条件语句可以使得在条件满足时跳进特定的分支。条件变量也一样，you will be notified to continue when a certain condition is fulfilled 。只不过，条件变量是我们达成同步的一种方法，它确保了某些线程在条件满足之前阻塞等待。<br>那这些阻塞的线程怎么才能知道条件已经满足了呢？在之前，我们可能会使用信号量、互斥锁来实现线程同步和协调。那这些和我们本节学习的条件变量相比有何不足呢？当我们使用信号量时，我们只能给特定的某一个线程发送信号。而使用条件变量，我们就可以选择当条件得到满足后，是给某个特定的线程发送信号还是给所有等待事件发生的线程发送信号（broadcast）。<br><br><br>#include &lt;pthread.h&gt;
int pthread_cond_init(pthread_cond_t *cond, const pthread_condattr_t *attr);
/* 
Parameters:
	1. cond: Pointer to the condition variable to initialize.
	2. attr: Pointer to a condition variable attributes object, or NULL for default attributes.
	   - PTHREAD_PROCESS_SHARED: condition variable can be shared between processes.
	   - PTHREAD_PROCESS_PRIVATE: condition variable is only used within a single process (default).
	   - PTHREAD_CONDATTR_CLOCKID: clock type used by the condition variable (e.g., CLOCK_REALTIME, CLOCK_MONOTONIC).

Return value: Returns 0 on success, otherwise an error number.
*/
<br><br>int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex);
/* 
Parameters:
	1. cond: Pointer to the condition variable to wait on.
	2. mutex: Pointer to the mutex that should be locked by the calling thread.

Return value: Returns 0 on success, otherwise an error number.
*/
<br><br>int pthread_cond_signal(pthread_cond_t *cond);
/* 
Parameters:
	1. cond: Pointer to the condition variable to signal.

Return value: Returns 0 on success, otherwise an error number.
*/
<br><br>int pthread_cond_broadcast(pthread_cond_t *cond);
/* 
Parameters:
	1. cond: Pointer to the condition variable to broadcast.

Return value: Returns 0 on success, otherwise an error number.
*/
<br><br>int pthread_cond_destroy(pthread_cond_t *cond);
/* 
Parameters:
	1. cond: Pointer to the condition variable to destroy.

Return value: Returns 0 on success, otherwise an error number.
*/
<br><br>condition variables are always used in conjunction with a mutex<br><br><br><br>原先实现屏障的方法所用的系统调用太多了，我们可以用条件变量实现屏障。<br>int count;
pthread_mutex_t lock;
pthread_cond_t cv;

void barrier(){
	pthread_mutex_lock(&amp;lock);
	count++;
	if(count &lt; NUM_THREADS){
		pthread_cond_wait(&amp;cv, &amp;lock);
	} else{
		pthread_cond_broadcast(&amp;cv);
	}
	pthread_mutex_unlock(&amp;lock);
}
<br><br><br>条件变量可以用于管程的创建（更高层级的抽象），所以管程是一个更高级的同步工具，有点类似于OOP中的类。在C++中，我们用类来打包数据和相关的操作，管程的目标就是将那些共享的数据和对这些共享数据的操作进行打包封装起来。有了管程，我们就不需要手动地操作那些共享数据了，减少了出错的可能性。<br><br>在传统的方法中，我们需要人为地对锁进行管理。下面这里例子中，我们有一个加锁和一个解锁，乍一看是正确的，但是程序中的if条件判断使得程序实际上存在着两个分支。我们需要给这两个分支的互斥锁都做好善后工作，因此实际上我们需要两个解锁函数。<br>void foo(){
	pthread_mutex_lock(&amp;lock);
	/* Read some data. */
	if(condition_is_true){
		printf("Cannot continue due to reasons.\n");
		// Missing something here~
		return;
	}
	/* Do something more. */
	pthread_mutex_unlock(&amp;lock);
}
<br>这种人为管理资源的模式太麻烦了，我们需要一种更加智能的管理方式。在C语言中，我们可以使用pthread库中的条件变量和互斥锁来实现管程。而C++的RAII机制使得管程的实现尤为容易。<br>#include &lt;pthread.h&gt;
#include &lt;stdio.h&gt;

typedef struct {
    pthread_mutex_t mutex;
    pthread_cond_t cond;
    int count;
} Monitor;

void init(Monitor *m) {
    pthread_mutex_init(&amp;m-&gt;mutex, NULL);
    pthread_cond_init(&amp;m-&gt;cond, NULL);
    m-&gt;count = 0;
}

void increment(Monitor *m) {
    pthread_mutex_lock(&amp;m-&gt;mutex);
    m-&gt;count++;
    pthread_cond_signal(&amp;m-&gt;cond);
    pthread_mutex_unlock(&amp;m-&gt;mutex);
}

void wait_for_count(Monitor *m, int target) {
    pthread_mutex_lock(&amp;m-&gt;mutex);
    while (m-&gt;count &lt; target) {
        pthread_cond_wait(&amp;m-&gt;cond, &amp;m-&gt;mutex);
    }
    pthread_mutex_unlock(&amp;m-&gt;mutex);
}

void destroy(Monitor *m) {
    pthread_mutex_destroy(&amp;m-&gt;mutex);
    pthread_cond_destroy(&amp;m-&gt;cond);
}

int main() {
    Monitor m;
    init(&amp;m);

    pthread_t t1, t2;
    pthread_create(&amp;t1, NULL, (void *(*)(void *))increment, &amp;m);
    pthread_create(&amp;t2, NULL, (void *(*)(void *))wait_for_count, &amp;m);

    pthread_join(t1, NULL);
    pthread_join(t2, NULL);

    printf("Final count: %d\n", m.count);

    destroy(&amp;m);
    return 0;
}
<br>#include &lt;iostream&gt;
#include &lt;mutex&gt;
#include &lt;condition_variable&gt;
#include &lt;thread&gt;

class Monitor {
private:
    std::mutex mtx;
    std::condition_variable cond;
    int count = 0;
public:
    void increment() {
        std::unique_lock&lt;std::mutex&gt; lock(mtx);
        count++;
        cond.notify_one();
    }
    void wait_for_count(int target) {
        std::unique_lock&lt;std::mutex&gt; lock(mtx);
        cond.wait(lock, [this, target] { return count &gt;= target; });
    }
    int get_count() const {
        return count;
    }
};

int main() {
    Monitor monitor;

    std::thread t1(&amp;Monitor::increment, &amp;monitor);
    std::thread t2(&amp;Monitor::wait_for_count, &amp;monitor, 1);

    t1.join();
    t2.join();

    std::cout &lt;&lt; "Final count: " &lt;&lt; monitor.get_count() &lt;&lt; std::endl;

    return 0;
}
<br><br><br>在学习原子类型变量之前，要规避并发访问共享数据带来的竞争条件问题，我们可能想当然地使用锁来解决。将共享数据的访问放到一个临界区中，然后对临界区进行加锁和解锁来实现这一过程。但是会带来额外的性能开销（两次系统调用）。<br>#include &lt;pthread.h&gt;

pthread_mutex_lock();   // system call * 1
shared_var++;
pthread_mutex_unlock(); // system call * 2
<br>上面利用互斥锁实现的对共享资源访问的方法中，我们看到，系统调用的开销要远远大于对共享资源操作所带来的开销。这时只会使用锁的单一解决方法就成为了一种枷锁。那有没有办法降低这种资源损耗？当然，我们没必要绕一个远路（因为锁和原子类型都是封装机器提供的指令得来的）。<br><br>我们前面已经学习过像&nbsp;test-and-set、compare-and-swap&nbsp;等硬件提供的原子操作指令。没有硬件提供的原子指令，软件再怎么模拟也不可能实现相似的原子性操作。利用机器提供的这些原子操作指令的接口，我们可以在上层封装这些原子操作为己所用。实际上，锁和原子类型都是对这些机器指令的封装和抽象，但不同的是，原子类型直接利用指令提供的原子性操作，避开了系统调用的开销，而锁更加高级，常用于处理复杂的竞争条件问题。对于单一共享资源的处理，我们简单地利用原子类型就可以了。<br>早期C标准库没有引入原子操作时，GNU标准下的C库（glibc）就通过对下层机器指令的封装提供了原子类型。这些原子类型操作保证了操作的原子性，规避简单的条件竞争。在 C++11 之后，我们可以包含&lt;atomic&gt;头文件来使用C++中的原子操作。当我们在高级语言中使用这些原子类型时，编译器会将这些数据类型转换成硬件能够提供的原子操作指令。<br>下面我们展示了C++11中的原子类型。对 std::atomic 类型的操作是原子性的，不可被打断的。<br>#include &lt;atomic&gt;

std::atomic&lt;int&gt; shared_var(0);

shared_var++; // Operations to shared_var is unbreakable.
<br><br><br>下面是GCC（GNU&nbsp;Compiler&nbsp;Collection）提供的一组内建函数，主要用于进行原子操作和实现无锁编程。它们利用硬件提供的原子指令，确保操作的原子性，避免了竞态条件。<br>type __sync_lock_test_and_set(type *ptr, type value)
bool __sync_bool_compare_and_swap(type *ptr, type oldval, type newval)
type __sync_val_compare_and_swap(type *ptr, type oldval, type newval)
<br>type&nbsp;__sync_lock_test_and_set(type&nbsp;*ptr,&nbsp;type&nbsp;value):&nbsp;该函数将value写入*ptr，并返回*ptr的旧值。这是一个原子的“测试并设置”操作，常用于实现简单的锁。<br>bool&nbsp;__sync_bool_compare_and_swap(type&nbsp;*ptr,&nbsp;type&nbsp;oldval,&nbsp;type&nbsp;newval):&nbsp;该函数如果*ptr等于oldval，则将newval写入*ptr，返回true；否则，不修改*ptr，返回false。<br>type&nbsp;__sync_val_compare_and_swap(type&nbsp;*ptr,&nbsp;type&nbsp;oldval,&nbsp;type&nbsp;newval):&nbsp;该函数如果*ptr等于oldval，则将newval写入*ptr，并返回*ptr的旧值。<br>除此之外，gcc还提供其他的一些内建函数。如下：<br>// Return the old value:
type __sync_fetch_and_add(type *ptr, type value);
type __sync_fetch_and_sub(type *ptr, type value);
type __sync_fetch_and_or(type *ptr, type value);
type __sync_fetch_and_and(type *ptr, type value);
type __sync_fetch_and_xor(type *ptr, type value);
type __sync_fetch_and_nand(type *ptr, type value);

// Return the new value:
type __sync_add_and_fetch(type *ptr, type value);
type __sync_sub_and_fetch(type *ptr, type value);
type __sync_or_and_fetch(type *ptr, type value);
type __sync_and_and_fetch(type *ptr, type value);
type __sync_xor_and_fetch(type *ptr, type value);
type __sync_nand_and_fetch(type *ptr, type value);
<br><br>自始至终，我们学到的原子操作都是关于 modifying 的原子操作，但从来没有提到读指令的原子操作。那该如何保证每次读到的数据都是最新的呢？<br>x86机器并没有 build-in 读原子操作指令。由于机器上的读指令在大多数情况下是原子性的，单独的读操作通常是不可分割的。在x86机器上，读取一个32位整数或一个64位整数（在64位架构上）通常默认就是原子操作。但如果这样，我们仍然可能得到过时的数据，因为如果读的时候刚好写入了新的数据，那么读到的数据可能就不再是最新的了。<br>我们其实可以用 modifying 的原子操作来做一个读的事情。比如对原先的变量原子加或减0，就能够保证我们每次读到的数值都是最新的。如果不在乎性能开销，使用锁也是可以的。]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/9.-synchronization-and-mutex.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/9. Synchronization and Mutex.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 21 Mar 2025 17:22:12 GMT</pubDate><enclosure url="https://congzhi.wiki/congzhi&apos;s-os-series/pics/this_is_fine.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/congzhi&apos;s-os-series/pics/this_is_fine.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[10. Deadlock]]></title><description><![CDATA[ 
 <br><br><br>哲学家就餐问题(Dining Philosophers' Problem) 是除生产者消费者问题、读者写者问题外第三个经典的并发算法问题，由Edsger W. Dijkstra在1965年提出。哲学家就餐问题描述了这样一种情况：有五位哲学家围坐在一张圆桌旁，每位哲学家面前有一盘食物和一根筷子，哲学家们除了在思考，就是在吃饭。桌上的筷子只数是有限的，正好与哲学家数量相同。<br><img alt="Pasted image 20241104161252.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241104161252.png"><br>我们先规定：哲学家需要两根筷子才能就餐，而且哲学家吃饭的时候不能打断。由于哲学家吃饭时会争夺筷子，就有可能导致一系列的问题。可能导致某个哲学家一直吃不到饭，也就是我们所说的饥饿问题，假如每个哲学家都同时拿起左手边的筷子，这时所有的哲学家永远都不能进食（所有的进程都被永久地卡住），这就是我们所说的死锁问题。<br>在这个人人都要挨饿的例子中，我们用哲学家类比进程，筷子则是这些进程可以重复使用的资源。要实现争端最开始的互斥，我们需要规定每次只能有一个哲学家从桌子上取筷子（即用同步机制保护资源的获取）。这样，我们就能防止出现两个哲学家同时握着一只筷子的情况了，也就是争端开始的情况。如何避免所有的哲学家挨饿是我们追求的。但之前，我们需要先了解一下死锁是什么。<br><br><br><br>
Deadlock is a set of blocked processes each holding a resource and waiting to acquire a resource held by another process in the set.
<br><br>A Real Example:<br>
- System has 2 disk drives.<br>
- P1 and P2 each hold one disk drive and each one needs another one.<br>A Bridge Crossing Example:<br>
- Traffic only in one direction.<br>
- Each section of a bridge can be viewed as a resource.<br>
- If a deadlock occurs, it can be resolved if one car backs up (preempt resources and rollback).<br>
- Several cars may have to be backed up if a deadlock occurs.<br>
- Starvation is possible.<br>
<br>
<img alt="Pasted image 20240716220750.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240716220750.png"><br><br>
<br>A system consists of a finite number of resources 
<br>The resources are partitioned into several types, each consisting of some number of identical instance. 

<br>physical resources: CPU cycles, memory space, I/O devices 
<br>logical resources: files, semaphores, and monitors<br>
In those resources, some are reusable, some are consumable.


<br>System model 

<br>Resource types R1, R2, ..., Rm 

<br>Each resource type Ri has Wi instances. 
<br>Each process utilizes a resource as follows: 

<br>request : may wait until it can acquire the resource 
<br>use : use the resource for its purpose
<br>release : release the resource after using it






<br><br>
<br>Mutual exclusion(互斥): only one process at a time can use a resource. 
<br>Hold and wait(持有并等待): a process holding at least one resource is waiting to acquire additional resources held by other processes. 
<br>No preemption(不可剥夺): a resource can be released only voluntarily by the process holding it, after that process has completed its task. 
<br>Circular wait(循环等待): there exists a set {P0, P1, ..., P0} of waiting processes such that P0 is waiting for a resource that is held by P1, P1 is waiting for a resource that is held by P2, ..., Pn−1 is waiting for a resource that is held by Pn, and Pn is waiting for a resource that is held by P0.
<br><br>
<br>System Halt: The system may come to a complete standstill because the processes involved in the deadlock are unable to proceed.
<br>Resource Wastage: Resources held by the deadlocked processes remain allocated and unused, leading to inefficient resource utilization.
<br>Reduced Throughput: The overall system throughput decreases as processes are unable to complete their tasks.
<br>Increased Response Time: The response time for other processes in the system may increase due to the unavailability of resources.
<br>Potential Data Inconsistency: If the deadlock involves processes that are updating shared data, it can lead to data inconsistency or corruption.
<br><br><br><br>死锁问题可能有操作系统资源调度策略不当造成，也可能是程序员的程序不规范所造成。为了解决死锁问题，操作系统会采取不同的处理策略，可能很严格，也可能非常松弛。<br><br>死锁的预防是在系统设计时就采取措施，确保系统永远不会进入死锁状态的方法。上节课中我们了解到死锁的四个必要条件。死锁预防的思路就是通过破坏死锁的四个必要条件之一就能预防死锁的发生。死锁的预防是静态的，旨在设计阶段就完全避免死锁的发生。<br><br>死锁的避免则允许系统存在某些不安全状态，但通过动态检测避免进入死锁状态。在资源分配时进行动态检查，确保每次资源分配不会把系统带入死锁状态。像银行家算法(Banker's&nbsp;Algorithm)，它通过模拟资源分配，来判断当前请求是否安全，只有在不导致死锁的情况下才会分配资源。（带来资源损耗问题，每次资源的分配都会带来检测开销）<br><br>检测和恢复死锁允许系统进入死锁状态，但通过定期检测是否存在死锁并在发现死锁后采取措施恢复系统状态。一旦检测到死锁，系统会采取措施恢复，例如终止某个进程或回收资源。这种方法适用于死锁频率较高且需要自动处理的系统。我们会使用资源分配图(Resource-allocation graph)来判断是否有死锁发生。<br><br>还有一种策略就是对死锁的无视，计算机科学中用鸵鸟算法来描述这样一种策略。鸵鸟算法的名词来源于“鸵鸟效应(ostrich effect)”，意为“将头埋在沙子里，假装没有问题”。使用鸵鸟算法的系统会假设这些问题几乎不会发生，因此不花费额外的资源去预防或检测死锁问题。至于发生死锁的原因，系统设计人员会将锅抛给程序员不当的程序。像Windows和Unix操作系统都采用这种放养式的策略处理死锁。<br><br>前面我们了解了死锁发生的必要条件，即当前系统中互斥、持有并等待、不可剥夺、循环等待四个条件均满足时，死锁发生。因而，我们只要让其中一个条件不满足，死锁就不可能再发生。这就是死锁预防的思路。<br><br>互斥条件使得系统支持某些资源一时间是不能共享使用的。破坏互斥条件就是要尽量避免资源的独占使用，允许资源共享。如果两个哲学家共享一根筷子，当然也就不会存在这种餐桌上的死锁了。<br>但正如我们之前在 <a data-tooltip-position="top" aria-label="9. Synchronization and Mutex > 1.1 Concurrency is a Disaster" data-href="9. Synchronization and Mutex#1.1 Concurrency is a Disaster" href="https://congzhi.wiki/congzhi's-os-series/9.-synchronization-and-mutex.html#1.1_Concurrency_is_a_Disaster" class="internal-link" target="_self" rel="noopener nofollow">同步阶段</a> 学到的，系统的并发性使得两个进程/线程对某些资源同时访问可能造成结果的不确定性，被称为Heisenbug。而且一些资源（打印机、CPU等）本质上就是不可共享的。所以破坏系统的互斥条件显然是不现实的。<br><br>正如哲学家们需要获得一双筷子才能吃饭一样，进程也要在获得所有需要的资源之后才能开始执行。为了预防死锁，我们破坏持有并等待条件，即要求进程在开始运行之前一次性请求所有需要的资源，或者强制进程在请求资源之前释放已经占有的资源。<br>而进程不能预见整个运行过程中所有需要的资源，而且每次申请资源时释放已占有的资源又会导致大量的资源释放和重分配，这会使得资源的利用率、系统开销和性能降低。<br><br>为了避免获取锁时的持有并等待，我们可以用两阶段锁定协议的相关尝试锁定函数(Try lock)。Two-phase locking 使得哲学家拿到一只筷子后去拿另一只筷子，如果有就申请另一只筷子的资源，如果没有另一只筷子就放下原先拿到的筷子，而不是阻塞等待另一只筷子。<br><br>pthread_mutex_trylock():&nbsp;尝试获取一个互斥锁(mutex)。如果锁不可用，立即返回一个错误代码（通常为EBUSY），而不是阻塞等待。<br>#include &lt;pthread.h&gt;

int pthread_mutex_trylock(pthread_mutex_t *mutex);
/* 
Parameters:
	1. mutex: A pointer to the mutex to be locked.

Return value: Returns 0 on success. If the mutex could not be acquired, returns an error code (typically EBUSY).
*/
<br>pthread_rwlock_tryrdlock():&nbsp;尝试获取一个读写锁(rwlock)的读锁。读锁允许多个线程同时持有。如果锁不可用，立即返回一个错误代码。<br>int pthread_rwlock_tryrdlock(pthread_rwlock_t *rwlock);
/* 
Parameters:
	1. rwlock: A pointer to the read-write lock to be acquired for reading.

Return value: Returns 0 on success. If the read lock could not be acquired, returns an error code (typically EBUSY).
*/
<br> pthread_rwlock_trywrlock():&nbsp;尝试获取一个读写锁的写锁。写锁是独占的，如果锁不可用，立即返回一个错误代码。<br>int pthread_rwlock_trywrlock(pthread_rwlock_t *rwlock);
/*Parameters:
	1. rwlock: A pointer to the read-write lock to be acquired for writing.

Return value: Returns 0 on success. If the write lock could not be acquired, returns an error code (typically EBUSY).
*/
<br>sem_trywait():&nbsp;尝试对一个信号量(semaphore)执行P操作（等待操作）。如果信号量值为0，则立即返回一个错误代码，而不是阻塞等待。<br>int sem_trywait(sem_t *sem);
/* 
Parameters:
	1. sem: A pointer to the semaphore to be decremented.

Return value: Returns 0 on success. If the semaphore's value is 0, returns an error code (typically EAGAIN).
*/
<br><br>在哲学家吃饭时，他们手中的筷子是不可剥夺的，这就是不可剥夺的条件。如果某个哲学家边玩手机边吃饭，就可能导致其他哲学家的饥饿。我们可以设置一个管理者，当哲学家太长时间没吃饭就强制剥夺其手上的筷子。这就是不可剥夺条件的破坏。<br>而允许资源被强制剥夺可能引起破坏进程的正常运行。例如，强行抢占文件写入资源，可能导致数据损坏或丢失。此外，频繁的资源剥夺还会导致进程频繁地被中断和恢复，增加系统开销。<br><br>如果哲学家能按照一定的顺序吃饭，那么就不会发生死锁。下面是一个包含3个进程 {P1, P2, P3} 的进程集，其中P1等待P2占用的资源，P2等待P3占用的资源，P1等待P2占用的资源。<br><img alt="Pasted image 20240716230346.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240716230346.png"><br>要破坏这种循环等待，我们可以采用一种全局的资源请求顺序，要求所有进程按顺序请求资源。例如，资源按某种顺序编号，进程必须按升序请求资源。<br>为所有的资源设定全局的顺序在复杂的系统中非常难实现，更别说操作系统中的资源需求时刻在变化的。强制进程按照顺序请求资源可能不符合实际应用的需求，降低系统的灵活性和效率。<br><br>在上小节中，我们讨论了死锁的预防。其中，我们从死锁的必要条件入手讨论了四种死锁的预防方案。而现实性分析使得死锁的预防方案的实现不太现实，不仅仅是额外引入的系统开销，还会导致一系列如数据的一致性、数据损坏、系统崩溃的问题。因而我们需要考虑一种新的死锁解决方案。<br><br>我们知道系统当前状态只有四个条件均满足才可能发生死锁。我们允许四种条件的存在，餐桌上也不一定刚开始就发生死锁，只是说可能进入死锁的状态。我们将系统分成两个状态：安全状态(Safe state) 和 不安全状态(Unsafe state)。安全状态不可能发生死锁，不安全状态可能导致死锁发生。<br><img alt="Pasted image 20240717125542.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240717125542.jpg"><br>
系统在运转过程中，难免进入不安全状态。在死锁的预防中，我们预防系统进入不安全状态。但在死锁的避免中，我们准许系统进入不安全状态，但是通过动态检测资源分配状态来确保系统不会进入循环等待状态。<br><br><br>资源申请的顺序对于死锁的影响是巨大的，在同步的阶段中，我们也感受过类似的事情。假如我们有两种资源R1和R2，它们的数量都为1，如下两个进程并发执行时并不处在安全状态。因为进程A可能持有R1而进程B持有R2，两个进程都进入阻塞态等待另一资源。环状依赖出现，系统发生死锁。<br>Process A<br>1. wait(R1)
2. wait(R2)
3. Statement
4. signal(R1)
5. signal(R2)
<br>Process B<br>1. wait(R2)
2. wait(R1)
3. Statement
4. signal(R1)
5. signal(R2)
<br>如果我们调整资源的申请顺序，进程B的资源申请顺序与进程A一致，这时系统将不存在持有并等待的条件，死锁避免。当进程数量很多时，这种调整进程资源的申请顺序的方案将变得臃肿复杂。<br>Process B (The second try)<br>1. wait(R1)
2. wait(R2)
3. Statement
4. signal(R1)
5. signal(R2)
<br>为了避免持有并等待并减少进程间的资源竞争，我们集中式分配所有资源给一个进程，减少死锁的可能性。<br><br>在上面的例子中，如果我们不调整资源的申请顺序，系统就会处于不安全状态。为了避免死锁发生，我们可以集中式地为某一个进程分配资源，并引入系统的安全性检查机制，确保资源的分配不会导致系统进入不安全状态。这就是死锁避免的基本思路。<br>为了实现这一点，系统在每次资源请求时需要进行安全性检查。假设某个进程请求资源，系统会模拟这个分配过程并检查是否会导致死锁。只有在确认不会进入不安全状态的情况下，系统才会实际分配资源给该进程。<br>例如，我们可以让线程A先获取R1，再获取R2，而线程B则在确保线程A释放资源后再请求资源。通过这种方式，系统可以确保所有进程都在一个安全的状态下运行，避免死锁。<br><br>当一个进程申请可用资源时，系统需要确认资源的分配会不会使系统处于安全状态(Safe state)。如果系统能够找到一个进程执行顺序，使得每个进程在其所需资源都可以满足的情况下运行并最终释放资源，从而使得其他进程也能继续运行并完成，那么这个顺序就是安全序列(safe sequence)。<br>
<br>如果系统处于安全状态，则存在至少一个安全序列。
<br>如果系统处于不安全状态，则不能保证一定存在一个安全序列。
<br><br>银行家算法是由 Edsger W. Dijkstra 提出的一种用于死锁避免的算法。它通过模拟资源分配过程确保系统始终处于安全状态，从而避免死锁的发生。银行家算法的基本思路为：1）资源请求；2）安全性检查；3）系统分配资源。<br>当某个进程请求资源时，系统并不会立即分配资源，而是会先子类当前的资源分配状态，然后模拟给各个进程资源分配的过程。经过模拟，系统会检查是否存在一个安全序列。只有在找到安全序列的情况下，系统才会对资源进行有顺序的分配。如果安全性检查不通过，即不存在安全序列，系统则会拒绝资源请求。<br><br>假如我们有以下系统，请问是否存在安全序列呢？<br><br>我们一步一步来分析：<br>
<br>当前可用资源为 {3, 3, 2}，资源可以分配给P1和P3；（我们用P1做例子）
<br>P1完成后释放资源，我们接着更新Available为 {5, 3, 2};
<br>之后资源能够分配给P2和P3，我们这里选择P2进行分配；
<br>P2完成后释放资源，我们更新Available为 {8, 3, 2}；
<br>然后P3的资源请求能够得到满足，我们将资源分配给P3；
<br>P3完成后释放资源，现在Available为 {10, 4, 4}；
<br>最后，系统资源能够满足P0的资源需求了，我们将资源分配给P0。P0执行结束后释放资源。
<br>经过这7步的分析，我们得到了 P1-&gt;P2-&gt;P3-&gt;P0 的安全序列。实际上还有安全序列。但是我们只需要一条就好了。<br><br>#include &lt;stdio.h&gt;

int main() {
    int numProcesses = 5; // Number of processes
    int numResources = 3; // Number of resources

    int allocationMatrix[5][3] = {{0, 1, 0}, {2, 0, 0}, {3, 0, 2}, {2, 1, 1}, {0, 0, 2}}; // Allocation Matrix
    int maxMatrix[5][3] = {{7, 5, 3}, {3, 2, 2}, {9, 0, 2}, {2, 2, 2}, {4, 3, 3}};   // MAX Matrix
    int availableResources[3] = {3, 3, 2}; // Available Resources

    int isFinished[numProcesses], safeSequence[numProcesses], index = 0;
    for (int k = 0; k &lt; numProcesses; k++) {
        isFinished[k] = 0;
    }

    int needMatrix[numProcesses][numResources];
    for (int i = 0; i &lt; numProcesses; i++) {
        for (int j = 0; j &lt; numResources; j++)
            needMatrix[i][j] = maxMatrix[i][j] - allocationMatrix[i][j];
    }

    for (int k = 0; k &lt; numProcesses; k++) {
        for (int i = 0; i &lt; numProcesses; i++) {
            if (isFinished[i] == 0) {
                int flag = 0;
                for (int j = 0; j &lt; numResources; j++) {
                    if (needMatrix[i][j] &gt; availableResources[j]) {
                        flag = 1;
                        break;
                    }
                }
                if (flag == 0) {
                    safeSequence[index++] = i;
                    for (int y = 0; y &lt; numResources; y++)
                        availableResources[y] += allocationMatrix[i][y];
                    isFinished[i] = 1;
                }
            }
        }
    }

    int flag = 1;
    for (int i = 0; i &lt; numProcesses; i++) {
        if (isFinished[i] == 0) {
            flag = 0;
            printf("The system is not safe.\n");
            break;
        }
    }

    if (flag == 1) {
        printf("SAFE Sequence: ");
        for (int i = 0; i &lt; numProcesses - 1; i++)
            printf("P%d -&gt; ", safeSequence[i]);
        printf("P%d\n", safeSequence[numProcesses - 1]);
    }

    return 0;
}
<br><br>与死锁的预防相比，死锁的避免实现起来好像更切合实际了，但是这一切都是有代价的。首先就是死锁避免的算法实现起来过于复杂。我们举了一个非常简单的例子，但实际上系统不可能仅仅只有这几个进程在争夺资源。甚至在安全性检查时如果有高优先级进程插队也是我们要考虑的问题。<br>如果进程频繁的进行资源请求，系统就需要进行频繁的安全性检查，引入了额外的开销。再者，系统需要提前知道每个进程现在和未来的最大资源需求，对于资源需求固定且可预测的系统，死锁避免的算法尚且可行。但不太适用于动态变化的系统。<br>为了尽可能地避免死锁的发生，算法在一些情况下可能会趋于保守，拒绝一些可安全分配的资源请求，从而降低系统的并发性和效率。由于种种制约，银行家算法在死锁的避免上发挥的作用极其有限，然而，银行家算法在死锁的检测上可以大放异彩。<br><br><br>我们回到餐桌上，我们先用一个形象的例子来类比一下死锁的避免。我们把操作系统类比为一个管家，负责筷子的分发。对于死锁的避免，管家在每次分配筷子时都需要思考按什么样的顺序来分配筷子，这时需要时间的，多一份思考就意味着哲学家吃饭的时间少一分。这是我们不愿看到的。<br>对于死锁的检测和恢复，管家分发筷子时不需要考虑会不会引起死锁问题。只需要在发生死锁时介入（死锁检测），打破死锁的局面即可（死锁恢复）。使得管家可以用更多的时间在其他更重要的事情上。<br>为了提高系统的效率，我们需要另外一种解决死锁的方法。而且实际上，系统发生死锁的概率并不大，我们是否可以允许系统进入死锁状态，并通过死锁的检测与恢复让系统解除死锁状态呢？<br><br>资源分配图是一种用于表示资源分配的图形化工具。我们可以通过资源分配图来判断当前系统是否处在死锁状态。资源分配图由节点(vertices) 和 边(edges) 构成，不同的节点和边拥有不同的含义。<br>RAG有两种节点：资源节点(resource vertex) 和进程节点(process vertex) ，其中我们用圆圈表示进程节点，用方框表示资源节点。资源节点中点的数量表示资源的数量。<br>
<img alt="Pasted image 20240717142805.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240717142805.jpg"><br>
RAG中的边也有两种：申请边(assign edge) 和 分配边(request edge)。申请边表示进程P申请箭头指向的资源，分配边表示当前的资源被进程P所持有。<br>
<img alt="Pasted image 20240723100243.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240723100243.jpg"><br><br>Example 1 (Single instances RAG)<br>下面两图展示了当资源数为1时RAG的两种情况。第一张图是单资源有死锁的RAG。P1进程和P2进程都渴望获得对方持有的资源，但同时又持有对方想获得的资源，我们称这种情况为环状依赖(circular dependency)。在资源数为1的情况下，如果RAG存在环状依赖就会形成死锁。<br>
<img alt="Pasted image 20240723165143.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240723165143.jpg"><br>
下面这张图是另一种资源数为1的RAG。由于不存在环状依赖因此不存在死锁。<br>
<img alt="Pasted image 20240723165716.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240723165716.jpg"><br>
Example 2 (Multi-instances RAG)<br>当某个资源节点的资源数不止一个时，分析系统的资源分配就会开始变得复杂。下面我们展示了多资源无死锁的RAG，虽然我们可以在RAG中看到环状依赖，但系统不会因此发生死锁。P3并不请求资源，所以P3可以安全地释放资源R2。而P1需要R2，一旦P3释放R2，P1就可以得到R2并释放R1。最后，P2获得P1所释放的R1并释放R2。不会发生死锁。<br>
<img alt="Pasted image 20240723170556.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240723170556.jpg"><br>
如果我们在上图中加入一个请求边，情况则大有不同，这时RAG会变成多资源有死锁的RAG。我们在下面的请求矩阵和分配矩阵中可以一睹真容。<br>
<img alt="Pasted image 20240723172000.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240723172000.jpg"><br><br>化简方法<br>
<br>约去分配边：如果一个进程可以顺利结束，则会释放占有的资源，那么我们就可以约去这个进程节点的分配边。
<br>约去申请边：如果一个进程可以申请到某类资源，则我们可以约去这个进程节点的申请边。
<br>重要命题<br>
<br>如果一个系统的RAG是可完全化简的（所有分配边和申请边都可约），则该状态不是死锁状态。
<br>如果一个系统不是死锁状态，则它的RAG可完全化简。
<br><br><br>我们在RAG中检测图中是否存在环状依赖来推测系统中是否存在死锁，这些工作由cycle detection algorithm来完成。假如图中的进程节点和资源节点有  个，这样的检测算法的时间复杂度将会是 ，检测环状依赖的时间会由节点数量的增加指数级增加。有没有办法减少图中节点的数量？<br><img alt="Pasted image 20241102225956.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241102225956.png"><br>当资源节点的只有单例时，我们可以将RAG化简成wait-for graph。<br><img alt="Pasted image 20241102231911.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241102231911.png"><br>虽然对于人类而言，有些环状依赖一眼就能看出来，好像对RAG的化简没有多大作用。对于机器而言，我们前面看到了，节点的减少对环状依赖的检测速度提升是巨大的。由于WFG的节点更少了，所以WFG中算法检测环状依赖的速度更快，因此WFG被专门用于检测系统中的死锁情况。<br><br>为支持系统每种资源类型的多种实例，我们可以用通用死锁检测算法来判断系统内是否存在死锁。<br><br>假设我们有从  到  这样  个进程和  种类的资源。我们用两个向量来表示资源—— existing资源向量  和可用资源向量  。此外，我们需要两个矩阵来表示当前系统的situation。当前分配矩阵  ，其中，行  表示  拥有每种（）资源的数量。申请矩阵  用来表示进程  需要的每种资源的数量。 <br>Resources in Existence Vector:Resources Available Vector:Current Allocation Matrix:Request Matrix:Resource Existence Total:为方便起见， 我们意为  从1到n， 。<br><br>通用死锁检测算法判断死锁的方法和银行家算法一样，都是判断、资源分配、资源回收。因而也被称作扩展的银行家算法，因为其支持多种资源类型和实例，适用于更复杂的系统环境。我们来看看这种算法检测死锁的基本思想：<br>
<br>初始化：

<br>设置工作向量  等于  资源向量。
<br>设置  向量，如果进程没有完成则为  ，否则为  。


<br>寻找符合条件的进程：

<br>找到一个  且  的进程  。


<br>资源分配：

<br>如果找到了这样一个进程，则将其资源加到  中，释放资源并设置 。


<br>循环检查：

<br>返回步骤2，继续检查，直到无法找到这样的进程。


<br>检测结果：

<br>如果所有进程的  都是  ，系统处于安全状态。
<br>如果有未完成的进程，系统可能处于死锁状态。


<br>这种支持多重实例的死锁检测算法的时间复杂度将会是  。（ 表示系统中进程的数量）<br><br>什么时候该检测死锁呢？每次资源的申请的时候？那就和死锁的避免无异了，代价太沉重了，得换一个。当进程申请资源不到时，其会显然阻塞态，那要不在进程/线程被阻塞时检测？阻塞好像也挺频繁的，感觉也不行。那干脆就周期性的检测一次吧？听上去好像不错。<br>现在我们的问题就变成了 "how often a detection is reasonable?"。如果死锁经常发生，经常性地检测死锁听上去好像不错。但有的关键系统(critical system)发生死锁后，我们需要立即将其从死锁中恢复出来，定时检测可能满足不了这一需求。<br>那我们换个思路，从CPU的负载出发。当死锁发生时，许多的进程都阻塞起来了，CPU上运行的进程数将会减少，负载也会下降。当CPU低负荷运行或CPU利用率一时间忽然降低，可能就是死锁发生的信号。在这种情况下设置一个检测点来进行死锁检测是一个好方法。<br><br>当检测到死锁后，我们需要采取一些措施对死锁进行恢复。虽然我们可以有不同的策略对死锁进行恢复，理想情况下我们想要像一切没有发生过一样结束死锁。但是只要发生死锁，恢复都是需要代价来进行交换的。这些代价可能是数据的丢失、任务完成延时或其他问题。<br><br>资源抢占是指根据优先级或其他标准，操作系统选择部分进程，强制回收其占有的资源，并将这些资源重新分配给其他更需要的进程。在这个过程中，操作系统需要记录被抢占进程所拥有的资源（相当于打“白条”），抢走这些资源并将进程阻塞，等到合适的时候将资源归还给被抢占的进程。<br>对于资源抢占来说，例如CPU时间片、网络带宽等这类资源可以被抢占，因为操作系统可以轻易地记录并归还这类资源。而打印机、内存这类资源通常不适合被抢占，因为抢占这类资源可能会导致无法恢复的错误或数据损坏。<br><br>对于结束死锁而言，进行一场对所有引发死锁进程的“屠杀”是一种最简单和高效的方法。而且这种方法十分常见。这种方法虽然易于实现，但可能不能从根本上解决问题。如果导致死锁的环境依然存在，死锁可能会再次发生，此时再一次终止所有相关进程似乎不太合适。<br>“大屠杀”并非优选，我们想让“处理”变得更优雅一些，该怎么做？我们可以根据优先级、进程的重要性或进程的执行时间等标准，选择并“处理”一个进程以释放资源。当这一切完成后，操作系统将获得这些进程持有的资源。我们可能需要再运行一次检测算法来确保死锁不会再次发生。如果死锁仍然存在，那就再“处理”一个进程。<br><img alt="Pasted image 20241103015057.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241103015057.jpg"><br>在“处理”这些进程时，我们需要注意不能误伤旁观者！下面我们例举一些相关的影响因素：优先级、运行时长、剩余执行时间、拥有的资源种类和数量、未来申请的资源信息、进程的种类 (user-interactive 还是 backgrounded) 和进程被选为受害者终止的次数。<br><br>回滚是将进程状态回退到进程早些时候保存过的一个状态。要进行回滚，进程必须事先保存过至少一个状态，不然就没有能够回滚的状态。这些保存的状态被称为检查点(checkpoint)，相当于进程的存档点。进程可以在需要申请很多资源之前创建一个检查点。<br>检查点包含了存储映像，其中包括调用栈（call&nbsp;stack）和进程的资源状态。设置检查点时，通常会将其写到磁盘上以便长期保存，防止因系统掉电等意外造成进程终止导致的信息丢失。回滚本质上类似于版本控制，我们使用的版本控制软件如Git和Subversion也是基于相同的原理。<br>但是很遗憾，回滚也不能完全解决死锁问题。和终止进程一样，回滚可能使进程回到发生死锁的前几步，紧接着又踏上了通往死锁的道路。在系统寻找其他策略之前，可能会尝试多次回滚。<br><br>我们还有杀伤力更大的方法。就是重启机器。<br><br>我们在本节课中介绍了从严格到宽松的四种死锁解决方案。现代的操作系统多数情况下不主动处理死锁，采用鸵鸟算法来处理死锁，这样做有以下几个原因：<br>
<br>复杂度和开销
<br>死锁发生概率不大
<br>应用程序级别处理
<br>Windows 和 Linux 等主流操作系统通常不再内核层面主动处理死锁，而是提供死锁检测器供开发者检测和调试。MySQL 数据库系统通常会内置死锁检测机制，可以自动检测并终止死锁进程，恢复系统正常运行。<br>如果真的发生死锁怎么办？<br><img alt="Pasted image 20240723182429.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240723182429.png"><br>或者re-boot<br><br><br>活锁（Livelock）&nbsp;是指一组进程在试图解决资源争用或其他问题时不断地改变状态但无法取得进展。尽管进程没有完全阻塞（即没有进入死锁状态），但它们也无法完成工作。通常这是由于进程在响应对方的动作时不停地相互让步，却总是错过能够完成任务的时机。<br>比如两个进程A和B，每次检测到对方正在占用某资源时都会释放自己的资源，让对方先用。结果，两个进程不断重复“试探-释放”的循环，导致没有任何进程能够实际获取到资源进行工作。<br>这个比喻相当于两个人不断互相礼让，“你先”，“不，你先”，最终谁都没有通过门。尽管他们没有阻塞，但也没有取得实质性的进展。<br>为了防止活锁，可以通过引入随机延迟、优先级机制或限制重试次数等方法，确保进程能够在适当的时机取得所需资源并完成工作。]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/10.-deadlock.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/10. Deadlock.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sat, 15 Mar 2025 08:35:20 GMT</pubDate><enclosure url="https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20241104161252.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20241104161252.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[10.5 Advanced Concurrency Problems]]></title><description><![CDATA[ 
 <br><br><br><br><br><br><br><br>]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/10.5-advanced-concurrency-problems.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/10.5 Advanced Concurrency Problems.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 22:04:03 GMT</pubDate></item><item><title><![CDATA[10.x A Thread Pool Library in C++]]></title><description><![CDATA[ 
 <br><br><br>在之前我们引入线程的时候，我们比较了线程相比进程的优势。线程更小更轻，调度起来CPU的开销更小。此外，我们还介绍了协程，协程并不是一个调度单位。相比线程，协程的切换开销更小，而且协程的切换不需要进行用户态到内核态的切换。但协程并不能像线程那样可被 CPU 所调度。比较下来，线程的优势还是很明显的，我们想要一种方法让使用线程的开销更小些。<br><br><br>线程使用的开销主要在线程的创建、销毁和切换上。我们常使用从1加到1000来举例使用多线程的好处，如本来一个进程从1加到1000需要多长时间，我们可以将任务划分给10个线程，第一个线程从1加到100、第二个线程从101加到200....依此类推。<br>即使上面列举的例子十分简单的说明了多线程的好处，但不妨碍它是一个理想化的模型。因为线程的创建和销毁需要时间，而创建一个线程所用的时间可能已经超过单个线程从1加到1000所用的时间了。这就为我们留下了一些思考的问题：如何避免线程频繁创建和销毁所带来的开销？<br><br>为了避免频繁实时的创建和销毁线程所带来的开销，我们可以在使用线程之前就预先创建一些线程，例如在服务器启动时创建一定数量的线程。这实际上就是池化技术的思想，即通过提前创建好资源并在运行过程中复用这些资源来提高系统的响应速度和鲁棒性。<br><br>线程池中的线程并非越高越好，因为线程的切换（上下文切换）同样需要开销。当任务的粒度被划分得过分细时，线程切换所带来的系统开销占比就会非常大。甚至会大过多线程在多核系统上并行执行所带来的收益。所以我们需要平衡计算资源利用率和系统开销。<br>我们提到了线程的上下文切换开销。除此之外，线程还会带来一定的内存占用。在Linux中，一个线程默认8MB的栈空间（可以通过ulimit -s进行调整）。所以创建过多的线程可能会导致虚拟内存占用过多。<br>对于CPU密集型任务，常见的线程数配置策略基础公式如下：其中  表示处理器的物理核心数， 表示CPU的利用率（通常为0.7-0.9）， 表示等待时间(wait)和计算时间(compute)的比率。<br>对于CPU密集型，一般线程池中的线程数大约在 ，而IO密集型线程池中的线程数量为 。<br><br>线程池有以下几种不同的模式，每种模式都适用于不同的应用场景。最常见的要数fixed pool和cached pool，这两种池模式也适用于其他的object pools。<br><br> 固定线程池指线程池中的线程数量固定。这种线程池适用于任务数量相对稳定的场景。如果线程池中的所有线程都在忙时，新任务就需要在任务队列中等待。<br><br>缓存线程池允许线程池中的线程数量动态调整。适用于任务数量波动较大的场景。这种线程池会设置一个初始线程数量和线程阈值，池中的线程数就会在这个范围内波动。如果线程空闲超过一定时间，线程就会被终止并销毁。<br><br><br><br>]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/10.x-a-thread-pool-library-in-c++.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/10.x A Thread Pool Library in C++.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 14 Mar 2025 15:04:57 GMT</pubDate></item><item><title><![CDATA[11. Memory Management]]></title><description><![CDATA[ 
 <br><br><br>操作系统的诞生源于人们为了更有效的操作裸机（硬件）和对操作高层次抽象的追求。为了更好的理解本阶段的内容，内存管理阶段开始前，我们需要先了解一点组成原理和体系结构的内容。<br><br>我们知道，冯诺依曼计算机是以存储器为中心的。不管是我们的操作系统还是应用都要跑在主存上。那内存和外存的关系是怎么样的？在我们执行某些程序时，程序和数据会从外存批量传送到内存上，在由 CPU 从内存中取指执行。CPU 执行完毕后结果写回到内存中，必要时再由内存成批传送到外存长久保存。<br><img alt="Pasted image 20240728054403.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240728054403.png"><br>下图展示了主存的结构，我们假设系统按字节连续编址，那么每个存储单元就是一个字节。不难理解，地址线的条数和主存的最大字节数关系就等于：虽然地址线条数能够产生主存的访存空间有这么大，但由于各种限制，内存可能做不到这么大（首个32位机 Intel 80386 早在1985年就出现了，但是4GB的内存条知道2000年代初期才开始普及）。为了能够利用到这么大的访存空间，计算机系统引入了内存层次结构，这是理解虚拟存储器的关键技术之一。<br><br>早期人工操作计算机的过程繁琐而复杂。为了简化操作并提高效率，操作系统诞生了，操作系统为人们提供一个”虚拟的机器“，人们再也不用和底层电路打交道。但对于程序员，使用这样的计算机仍不知足，因为内存的发展和 CPU 的相比太慢了。程序员想要的是一种和 CPU 速度相匹配，容量   ”无限大“的存储器。存储器层次结构的思想就是处于这种情况下诞生的。<br><img alt="Pasted image 20240729010510.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240729010510.png"><br>在存储器的层次结构中，只有寄存器和cache能够与 CPU 的速度相匹配，但败在容量小。主存相比 CPU 要慢上10多倍，容量相比cache可以大很多。辅助存储器更是能够提供几近无限的存储大小，但对于 CPU 而言太慢（个时钟周期）。而通过组合这些不同层次的存储器并采取合理的映射方式和读写策略，存储结构就可以为程序员提供非常好的使用体验。这种多层次存储器结合起的、存储容量又大访问速度又快的“存储器”就是我们说的虚拟存储器。<br>这样层次化的存储器结构中，相邻两个层次之间是一定要进行数据传送的。传送的最小单位是一个定长块 (block)，互为副本。在主存和磁盘之间，这种定长块被称为页 (page)。在cache和主存之间，就叫定长块（32/64/128字节），cache中最小传送单位叫槽 (slot)，定长块大小和槽大小相同。<br><br><br>早期的操作系统并不提供内存管理机制。主存空间是需要程序员自己管理的，如果主存空间很小，每次只能在内存中运行一个程序，要运行另一个程序时就需要将上一个进程从内存中取出来，换到外存中先放着，再将外存中需要运行的进程加载到内存中。<br>在1961年，曼彻斯特的研究人员提出一种自动执行(overlay)的方式，其思想是将地址空间和主存容量的概念区分开。程序员在虚拟地址空间中编写程序，而程序在真正的内存中运行。由一个专门的机制实现地址空间和实际主存之间的映射。<br>在当时的一种典型计算机中，指令中主存地址是16位，但是主存容量只有4KB。地址空间有  这么大，我们要如何自动执行程序？可以将地址空间划分成4K大小的一个个区间，让内存空间的地址以4096（4K）取模，将区间内每位地址都能对应上4K的主存范围间。程序员可以在 16KB（0-65535）的范围内写程序，不用关心主存空间的大小。<br><img alt="Pasted image 20240729033616.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240729033616.png"><br>这种可寻址的地址就是一种虚拟内存，区间后来也叫做页(page)，把主存中存放页的区域叫做页框(frame)。最早的主存只有一个页框。<br><br>现代的分页方式和早期分页方式十分类似。其基本思想都是把内存分成固定长度的存储块（也叫页框、实页、物理页），每个进程也划分成固定长的程序块（又称为页，虚页、逻辑页）。<br>在执行程序时，我们就可以把程序块装到可用的存储块中，不需要用连续页框存放一个进程。为此，操作系统会为每个进程分配一个页表(page table)。通过页表就可以实现逻辑地址向物理地址的转换(Address Mapping)。我们下面举例说明一下地址转换：<br>
<img alt="Pasted image 20240729035023.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240729035023.png"><br>
假如某个进程有四个页的大小。因为虚拟内存中的页和主存中的页框是一样大的，因此我们只需要在页表中描述虚拟页和物理页框之间的映射关系就行了。而且由于程序的局部性，只将活跃的页面留在主存并不会太多影响运行速度。这种”按需调页(Demand Paging)“方式分配主存就是虚拟存储管理的概念。<br><br>人们引入虚拟存储技术是为了解决一对矛盾：<br>
<br>由于技术成本等原因限制的主存容量；
<br>程序要求的主存容量越来越大。
<br>有了虚拟内存，上面的矛盾迎刃而解。程序员可以在比主存大得多的空间内编写程序。当程序执行起来时，只把当前需要的程序段和相应数据块调入主存，不用的地方先放在磁盘上。只当发生缺页(page fault) 时，操作系统才需要介入并进行主存和磁盘之间的信息交换。<br>虚拟存储器的机制由硬件和操作系统共同协作实现，涉及到操作系统中许多概念，如进程、上下文切换、存储器分配、虚拟地址空间和缺页处理等等。<br><img alt="Pasted image 20240729180635.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240729180635.png"><br>在之前的学习中，我们学习了虚拟地址空间的概念。在32位机器中，每个进程都可以分配高达4GB的虚拟地址空间，不同的操作系统对用户空间和内核空间的大小有不同的规定。我们也可能会有疑问：如果每个进程都在磁盘中占4GB的虚拟空间，磁盘岂不是只能存放很少数量的用户程序？实际上当然不是这样！虽然每个进程都会分配4GB的虚拟内存空间，实际上在磁盘上每个进程可能只会用到很小的磁盘存储（空洞页面不占用磁盘）。<br><img alt="Pasted image 20240729183709.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240729183709.png"><br><br>我们想要实现虚拟存储器的管理，我们还要考虑：<br>
<br>页大小应该为多大？
<br>主存与辅存的空间如何分区管理？
<br>程序块/存储块之间如和映像？
<br>逻辑地址和物理地址如何转换，转换速度怎么提高？
<br>主存和辅存之间如何进行替换？
<br>页表如何实现，页表项要记录那些信息？
<br>如何加快访问页表的速度？
<br>要找的内容不在主存怎么办？
<br>如何保护进程各自的存储区不被其他进程访问？
<br>虚拟存储器的管理分为了三种方式：分页式、分段式、段页式。<br>假定一个页有4KB，在32位机器上，页表的项数就会有：页表有这么多项，假如一个页表项占4KB，那么页表会有4MB的大小，比页还大。因此页表也要分页管理。页表存放在虚拟地址空间中的内核区。每个进程有一个页表，其中有装入位、修改（Dirt）位、替换控制位、访问权限位、禁止缓存位、实页号。各个进程理论上有相同的虚拟空间，但是实际大小看具体的实现方式，如”空洞“页面如何处理等。<br>我们将页分成了三类：<br>
<br>未分配页：进程的虚拟地址空间中“空洞”对应的页（如VP0、VP4） 
<br>已分配的缓存页：有内容对应的已装入主存的页（如VP1、VP2、VP5等） 
<br>已分配的未缓存页：有内容对应但未装入主存的页（如VP3、VP6）
<br><img alt="Pasted image 20240729201529.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240729201529.png"><br>
可执行文件的存储器映像如下图所示。<br><img alt="Pasted image 20240729201908.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240729201908.png"><br><br>我们已经了解了分页式虚拟存储器是怎么工作的。将虚拟存储空间划分成大小相等的一个个页，然后将主存空间划分成和页大小相同的一个个页框。然后用页表中的页表项对应每个页到页框的关系。但分页的方式会有一些问题，比如一个数据跨在两个不同的页中。<br>将虚拟地址空间分段很好的解决了这种问题。通过程序数据的需求分配不同的段，按照程序逻辑结构将虚拟地址空间划分成多个相对独立的部分（代码段、只读数据段、课读写数据段等等）。而且相比分页，分段方式能更好地进行存储保护（数据和代码在同一个页中，地址越界、保护违例）。<br><img alt="Pasted image 20240730015834.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240730015834.png"><br>
编译器优化和操作系统调度管理。分段系统将主存空间按实际程序中的段来划分，每个段在主存中的位置记录在段表中，并附以“段长”项。段表由段表项组成，段表本身也是主存中的一个可再定位段。<br><br>分段式的虚拟内存管理确确实实解决了分页式虚拟内存管理的痛点，但是它也走向了另一个极端。占空间多，段内存换进换出很难管理。因此我们折中，段页式存储器完美的迎合了我们的需求。<br>程序的虚拟地址空间按模块先分段、段内再分页，但进入主存仍以页为基本单位。这一，逻辑地址就由段地址+段内页地址+页内偏移量三个字段构成。用段表和页表（每段一个）进行两级定位管理。根据段地址到段表中查阅与该段相应的页表首地址，转向页表，然后根据页地址从页表中查到该页在主存中的页框地址，由此再访问到页内某数据。<br><br><br>在第零课的学习后，我们应该对虚拟内存有了大概的理解。在操作系统中，内存管理涉及的是“内存-外存”这个层次的管理。外存（如磁盘）作为一个大仓库，为用户进程提供逻辑上无限大的编程空间。由于磁盘是一种外部设备，我们将这种磁盘提供的后备资源称为虚拟内存。因为这种逻辑上的关系，也被称为逻辑内存。在本阶段，我们需要额外关注以下的话题：<br>
<br>内存的物理地址和进程的逻辑地址
<br>地址映射和内存保护
<br>内存分配和回收
<br>分页和分段
<br>虚拟内存
<br><br>当我们使用内存时，感受到的是一段连续的内存，这多亏了操作系统的抽象。而我们实际上使用的内存在物理上的地址可能并不连续。我们下面先来了解什么是物理内存地址，它是怎么得到的？<br><br>我们直接访问的数据无一例外都存放在主存中。由于主存采用随机存取方式，因此也称为随机存取存储器（Random Access Memory, RAM）。它是计算机系统中的关键硬件组件，用于临时存储和快速访问数据和指令。<br>下面是RAM的一个组织图，每个bit数据存放在内存中一个个cell中。计算机通过字线和位线将这些cell编址成一个位平面(Bit plane)。由于大多机器按字节编址，所以一般的DRAM bank需要8个这样的位平面摞在一起。下图的例子并不确切，但对于理解地址译码来说是一个很好的例子。<br><img alt="Pasted image 20240730033638.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240730033638.png"><br>物理地址和地址译码的关系很紧密。假设上图我们有8个位平面，我们可以通过物理地址来得到我们想要的byte。其中，我们就需要一个译码器将物理地址翻译成某个确切的byte信息。<br>地址译码器有n个地址输入线和  个输出线。对于每一种输入组合，只有一条输出线会被选中（低电平），其他线保持高电平。因为32位机器上地址位数有32位（现代计算机通常有行缓存，行选中和列选中是分批次进行的），所以能够产生4GB的物理地址。<br><br>物理地址是计算机内存中的实际地址。每个内存单元都有唯一的物理地址，通过这个地址，CPU可以直接访问内存中的数据。物理地址是由硬件直接管理的，因为它在硬件层面上是唯一且固定的，因此也被称为绝对地址(absolute address)。<br>物理地址一般从0开始，而且一般以字节作为最小单位。至于物理地址的长度多大要取决于CPU的架构。32位架构就能访问4GB大小的物理内存。64位架构能访问的大小则是一个天文数字，有生之年也不知道能不能见到这么大的存储器。<br><br>在第零课的先导课中，我们提到了段页式虚拟内存管理。逻辑地址就等于段基址+偏移量（相对地址）实现的。这里的相对地址就是相对段基址而言的。将地址从一种形式（如逻辑地址）转换成另一种形式（如物理地址）的过程。在现代计算机中，一般使用MMU来完成地址转换的工作。<br>在用户眼中连续的地址就是逻辑地址。逻辑地址是程序运行时CPU生成的，操作系统分配给进程使用的地址。每个进程都有各自的逻辑地址，通常从0开始。<br><br>物理地址 = 绝对地址，但逻辑地址 != 相对地址。相对地址是相对于某个基准地址来说的。由编译器在编译时生成，通常用于指令中的跳转、调用等。也就是偏移量(offset)。<br><br><br><br>在我们用c程序编写了一个hello.c文件后，计算机是不能直接执行这个文件的。原因是计算机只能识别二进制的机器级代码，hello.c是源程序的文本文件。要让计算机识别并执行我们所编写的源程序，还需要做以下步骤：<br>
<br>预处理(cpp)<br>
预处理阶段，程序会处理以 '#' 开头的预编译指令并删除所有的代码注释。经过预编译的处理，我们得到预处理文件（hello.i），这时的文件仍然是一个可读的文本文件，不包含任何宏定义。
<br>编译(cc1)<br>
编译过程就是将预处理后得到的预处理文件（如hello.i）进行 词法分析、语法分析、语义分析、优化后，生成汇编代码文件。经过编译后，得到的汇编代码文件（如hello.s）还是可读的文本文件，CPU无法理解和执行它。
<br>汇编(as)<br>
程序经过编译后生成汇编语言源程序，在汇编阶段，汇编程序（汇编器）会用来将汇编语言源程序转换成机器指令序列（机器语言程序）。汇编指令和机器指令一一对应，前者是后者的符号表示，它们都属于机器级指令，所构成的程序称为机器级代码。汇编结果是一个可重定位目标文件（如，hello.o）。
<br>链接(ld)<br>
链接过程将多个可重定位目标文件合并以生成可执行目标文件。<br>
<img alt="Pasted image 20240730092536.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240730092536.png">
<br>装入内存<br>
<img alt="Pasted image 20240729201908.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240729201908.png">
<br><br>因为汇编代码和二进制机器代码都是机器级代码，因此我们能很明白地在汇编代码中，窥见一些程序加载前的要做的事。代码中CALL和PRINT两个标号代表了那一行指令的逻辑地址，这些标号会在链接过程中经过符号解析和重定位转换成相应的逻辑地址。而这些逻辑地址会在不同时机 中将逻辑地址转换成不同的物理地址。<br>Logical address          Assembly code
0000               START: MOV AX, 1234H
0003                      ADD AX, 5678H
0006                      JMP NEXT
0009                HERE: SUB AX, 1234H
000C                NEXT: MOV BX, AX
000F                      CALL PRINT
0012                      HLT
0013               PRINT: PUSH AX
0014                      POP AX
0015                      RET
<br><br><br>源代码被编译成目标文件，生成的目标文件包含逻辑地址，逻辑地址从0x000开始。在链接阶段，决定程序将被加载到物理内存中的确切位置。之后链接器会将目标文件中的所有逻辑地址转换位相对于加载地址的物理地址。例如，假设决定程序将加载到物理位置0x300，随后，0x300就变成一个基地址，虚拟地址0x003就会被转换为物理地址0x303。<br>这种链接时地址转换的好处就是简单，而且系统开销低。但是缺点也是显而易见的，那就是灵活性差，不适合多任务的环境。只用场景只有哪些简单的单任务系统。<br><br>链接时转换的方案是在可执行文件加载进内存前就已经指定好在物理内存的哪个位置运行了。装载时转换指在可执行文件被加载到内存时，将程序中的逻辑地址转换成物理地址的过程。这种方法在程序加载时进程一次性转换，并将地址固定下来，也称为静态重定位。适用于内核模块和动态链接库(DLL)等场景。<br>相比链接时转换，加载时转换的方式更为灵活，因为程序的逻辑地址在编译和链接时不需要是固定的，可以在加载时根据内存的实际情况进行调整。但是这种方式不可避免的导致加载时间增加，而且加载后不可在内存中移动。<br><br>加载进内存程序中的指令地址仍然保存逻辑地址，在执行过程中，将逻辑地址动态转换成物理地址。这个过程就是运行时地址转换，也叫动态重定位。动态重定位通常通过硬件和操作系统的支持，比如使用 MMU 实现逻辑地址到物理地址的映射。运行时转换是现代系统中广泛采用的方法。<br>
<br>优点：高灵活性、内存保护、高效内存利用。
<br>缺点：性能开销大、复杂性高、对硬件要求。
<br><br>
<br>编译阶段：源代码转成目标代码，每个目标文件中的地址称为逻辑地址。
<br>链接阶段：将多个目标文件链接合成可执行文件，该阶段会分配每个段的虚拟地址，在根据目标文件的逻辑地址和加载段生成全局虚拟地址。此时虚拟地址空间就构建完毕，构建信息就是ELF的头部信息。
<br>加载阶段：OS 会先读取ELF头部信息，根据虚拟地址空间的信息加载必要的段到物理内存中，其他部分留在虚拟内存。
<br>运行阶段：当某个要访问的页不再内存中，则请求操作系统从虚拟内存将其调入物理内存。如果物理内存不足就进行页面置换。
<br><br><br><br>内存管理单元(MMU)，也叫页内存管理单元(PMMU)，是一种支持虚拟内存和分页的硬件设备或电路，负责将虚拟地址转换成物理地址。<br>
<br>在现代操作系统中，进程的逻辑地址空间大小理论可达计算机架构的最大值，而物理内存通常比理论最大值小。
<br>一个进程通常不会用完全部的逻辑地址空间，也很少会在在某一时刻使用大量内存。因此，可以同时在物理内存中容纳多个进程。
<br>MMU的任务就是把每个进程的逻辑地址映射到物理内存的不同区域，同时也要保证进程之间的隔离性（保护地址不会越界或溢出）。
<br><img alt="Pasted image 20240730215541.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240730215541.jpg"><br><br>基址和限长是虚拟内存的一种简单形式，通过一组或少量处理器寄存器（基址寄存器和限长寄存器）来控制对计算机内存的访问。工作原理如下：<br>
<br>分配内存区域<br>
每个用户进程被分配一个连续的主存区域。操作系统将该区域的物理首地址加载到基址寄存器（重定位寄存器）中，将其大小加载到限长寄存器中。
<br><img alt="Pasted image 20240730220832.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240730220832.jpg"><br>
<br>
物理地址转换<br>
我们已经了解了基址寄存器和编址寄存器的作用，我们通过下图直观学习以下物理地址是这么转换的。当进程重定位到 14000 地址的基址时，这个基址会存放在基址寄存器中，和CPU送来的所及地址相加就可以得出物理地址了。不过要注意，在这里还要判断地址是否越界的问题，我们马上介绍。<br>
<img alt="Pasted image 20240730223332.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240730223332.jpg">

<br>
内存保护<br>
通过进程P中基址和限长寄存器中的值，我们就可以轻松地判断是否存在非法的址错误。在下图中，硬件（MMU）会检查每个CPU送来的地址，检查是否越界等等。一旦发现送来的地址值小于基地址，或者大于限长寄存器（base+limit）中的值，MMU就会通过一条trap指令叫出操作系统处理这种 addressing error。

<br><img alt="Pasted image 20240730220817.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240730220817.jpg"><br>结合物理地址转换和内存保护，我们就可以简单的描述出MMU地址转换和内存保护方法的步骤了。因为CPU送来的是逻辑地址，因此我们在这里省略和基地址的比较过程。<br><img alt="Pasted image 20240730221149.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240730221149.jpg"><br><br><br>在计算机的内存管理中，连续分配管理方式是一种基础的分配方法。它的主要特点是将进程装入内存时，要求进程占据一块连续的内存空间。这种方法可以有效的管理和分配内存资源，但是也会有一些限制。<br>连续分配管理方式可以进一步细分为固定分区和可变分区两种模式。这两种模式各有优缺点，适用于不同的应用场景。后面的分段、分页就是对这两种模式的延伸。<br><br>固定分区管理方式是一种将内存划分为若干固定大小分区的方法（分区大小不一定相同）。由于内存分区大小固定，所以每个分区在系统启动时就已经确定，不能动态调整。此外，在固定分区中，每个分区只能容纳一个进程，如果一个进程之战1MB，而分区大小为5MB，这就会造成4MB的浪费，即内部碎片(Internal fragmentation)。当我们分配分区时，尽量使得内部碎片尽可能的小。<br>当系统有多个进程需要运行时，会将每个进程分配到一个合适大小的分区中。如果所有分区都被占用，新到的进程将无法进入内存，必须等待。<br><img alt="Pasted image 20240801010828.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240801010828.png"><br><br>在固定分区中，为了实现内存的分配和回收，系统需要维护一张表用于跟踪分区当前的状态。这张表记录着各个分区的编号、起始地址、大小和占用情况。<br><br>在固定分区下，当进程需要申请内存空间时，分配器会根据进程的大小，在表中寻找一个合适的分区进行分配。之后，将该分区的起始地址填入 Base register 中，将分区大小或进程大小填入 Limit register 中，并标注占用该分区的进程 ID 号。<br><br>当进程结束后，清除该分区的占用情况使分区重新可用。<br><br>在固定分区中的地址转换和保护中有两种不同的声音：<br>
<br>限长寄存器中应当存放的是分区大小，也就是物理地址在内部碎片中也是允许的；
<br>限长寄存器存放的是进程大小，限制进程在分区内部碎片的访问权限。
<br><br>权衡利弊，固定分区的好处就是简单易实现。但是其不灵活的缺点难免导致产生大量的内存内部碎片，不可避免的造成资源的浪费。<br><br>与固定分区的管理方式不同，可变分区的管理方式并不与先划分固定大小的分区，而根据进程的实际需要动态地分配内存。<br><br>由于可变分区的内存管理方式不再固定地划分分区。为了确保内存分配高效性，系统需要维护两张表：空闲分区表和已用分区表。空闲的分区也叫做孔(holes)，初始情况下，整个内存区域就是一个空闲分区。<br><img alt="Pasted image 20240730220934.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240730220934.jpg"><br><br>根据进程大小在空闲分区表中寻找一个合适的分区进行分配，更新空闲分区表和已用分区表，并初始化进程的 Base register 和 Limit register。<br><br>在释放内存时，更新已用分区表和空闲分区表（如果可以，合并多个连着的空闲分区，这被称为 coalescence）。<br><br>没什么好说的，参见上节课内存保护的部分。<br><br>相比固定分区，可变分区为我们带来了一定的灵活性。由于分区大小就是进程的大小，所以可变分区避免了内部碎片的产生。然而，这种分区为我们带来了外部碎片，也就是我们说的holes。如果孔的分配不合理，就可能出现许多无法利用的孔。<br>为了减少外部碎片的占比，在可变分区中，我们有许多分配算法。<br><br>由于可变分区的分区方式是动态可调整的，因此如何分配“孔”就决定了内存的利用率。常见的分区策略有——First fit、Next fit、Best fit、Worst fit、Quick fit。<br><br>首次适应从头开始搜索空闲分区表，检查每个块。一旦找到大小合适的空闲分区块，将其分配给进程。除了这种分配方式可能产生过多的内存碎片外，首次适应有许多优点：<br>
<br>速度快 O(n)，找到第一个合适的就能分配了。
<br>易于实现。
<br><br>下次适应是从上次分配结束的位置开始，继续向前查找，找到第一个足够大的空闲块进行分配。如果到达内存末尾，则从头开始继续查找。下次适应具有与首次适应（First Fit）相同的优点：速度快O(n)和易于实现。<br>在某些情况下，下次适应可能更均匀地利用内存，因为它不会总是从内存的起始位置开始查找。然而，它也可能会导致更多的内存碎片，因为它不会总是选择最靠前的空闲块。此外，下次适应可能在某些情况下更快，因为它避免了每次分配都从头开始查找。<br><br>相比于前两种傻瓜式的比较适应算法，最佳适应会搜索整个空闲分区表，找到最接近进程所需大小的空闲分区块，然后将其分配给进程。相比较于前两者，最佳适应的外部碎片产生最小。但是有些实现方式可能使得搜索时间过长。<br>然而，如果使用 AVL 树或红黑树，最佳适应算法的速度可能会优于首次适应算法：Θ(In(n))。<br><br>最差适应算法反其道而行之，它通过搜索整个空闲分区表，找到最大的空闲分区表，将其分配给进程。为什么是最大的内存块？因为大块内存分配后，留下的空闲区域依然很大，便于后续的分配。这就是最差适应的中心思想，但是也可能造成更大的内存浪费。<br>可以使用 max heap、 binomial heap 或 Fibonacci heap 来实现最差适应算法。<br><br>快速适应是一种优化内存分配速度的算法。它通过维护多个空闲块列表，每个列表对应不同大小的内存块。当需要分配内存时，Quick Fit 会直接从对应大小的空闲块列表中查找和分配内存。这种方法可以显著减少内存分配和释放的时间开销，但可能会导致内存碎片问题。<br><br>
<br>可变分区方式的内存利用率较高，可以更灵活地适应不同大小进程的需求。
<br>存在外部碎片（孔）和分配开销。
<br>合并技术 (coalescence)：内存管理器会将相邻的空闲块合并成一个更大的空闲块。
<br>紧凑技术 (compaction)：将进程在内存中进行移动，消除不可用的孔。但是这种移动内存块的方式会增加系统开销。
<br><br><br><br>在上节课的连分配管理方式中，我们看到无论是固定分区还是可变分区，都要求进程在内存中是完整的。但无论是哪种连续分配方式，都不可避免的会有碎片产生。因此，在本节课及往后，我们开始讨论非连续性存储管理方式，为找到一种更好的方式管理我们的内存。<br>实际上，我们在阶段6第三课中已经对“段”这个概念有所耳闻了。我们知道虚拟内存中不同的段承担的职责是不一样的，我们有代码段、全局变量段、stack、heap、C标准库等各种段。尽管段内地址连续，但不同的段在内存中可以离散排布，我们依据不同的段对内存进行管理。<br><br>段式存储管理方式中，逻辑空间被分为了若干个段，每个段定义了一组完整逻辑意义的信息（代码段、数据段、堆栈段）。段式存储管理的优点是不同的段在加载进内存时不要求是连续的，但是某一个段内的内存需要是连续的。<br>
<br>分段：每个逻辑段都有一个段号。
<br>段内连续：段内的逻辑地址总是从 0 开始。
<br>段的大小：不同段的大小不完全相同。
<br>段表：段表用来记录每个逻辑段的编号。物理起始大小、段大小及访问权限等。<br>
下面举例用段表只展示出内存保护所需的段基址和段长部分。<br>
<img alt="Pasted image 20240801075550.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240801075550.png">
<br>分配方式：读取ELF头部，识别出需要加载的各个段，为每个段分配内存（查找、更新空闲分区表），最后更新段表。
<br>回收过程：更新段表-&gt;释放内存（更新空闲表）。
<br><br><br>逻辑地址由两部分构成：（1）段号，（2）段内偏移。段号决定虚拟内存中可划分多少个段，段内位移决定最小的段大小是多大。<br><br>
<br>防止越界
<br>访问权限（CPL 和 DPL，还有段属性是只读、只写还是怎样）<br>
<img alt="Pasted image 20240801075704.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240801075704.png">
<br><br><br><br>我们在 ICS 先导课中已经学过页式存储的基本原理，我们将进程逻辑地址空间划分成大小相同的块，我们称为页(page)；再把物理内存划分成若干相同大小的块，称为页框(page frame)。一个页框放一个页。当我们分配内存时，我们可以将进程的页面离散地存放到也框里面，通过页表保存页和页框的映射关系（虚拟地址到物理地址之间的映射）。<br><br>在32位机器上，逻辑地址占32bits，其中有页内位移12bits和页面号20bits。我们知道，页和页框中的页内位移是一一对应的。其中，逻辑地址通过页表映射出相对应的物理地址。因此要实现页式存储管理，页表中的页表项不需要记录页内位移的任何信息。而且虚拟地址空间是连续的，我们只需要在页表项中记录页框号和一些标志位即可。<br><br>32位机器上的页表项占四个字节，这里提供下面的图简单了解相关位的含义。<br><img alt="Pasted image 20240805013618.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240805013618.png"><br><br><br>32位机器上，一个进程的虚拟地址空间理论上是 4GB 空间，每个页 4KB 情况下可以划分出来 1M 个页出来。我们知道每个页表项需要 4B 空间，那么维护这一个进程的页表就需要占用 4MB 的内存空间（单级页表静态分配需要1000个连续页框的大小）。为了解决单个进程的页表占用大量内存的问题，通常采用多级页表(Multi-Level Page Table) 方案，我们会在之后的课程中学习。<br><br>当 CPU 想要访问一个逻辑地址时，会触发地址转换，这时需要访问物理内存两次。<br>
<br>访问页表：不难理解，你想从虚拟地址得到物理地址，你就需要从PTBR(Page Table Base Register)读取页表起始地址，然后从这个页表中查询页面号对应的页框号。随后得到物理地址。
<br>访问转换后的物理地址
<br>当 CPU 频繁访问内存时，页表查找的开销会显著增加。这时，我们采用一种更高效的解决方案——快表。我们将在下节课介绍。<br><br>
<br>分配过程

<br>读取ELF头部，识别出需要加载的各个段
<br>为每个段的虚拟地址划分页面
<br>为每个页面分配一个页框（查找并更新页框表）
<br>更新页表


<br>回收过程

<br>更新页表
<br>释放内存（更新空闲页框表）


<br><br><br>在虚拟地址空间中，我们把虚拟的地址空间划分成一个一个页，因而产生的逻辑地址很容易得出来：虚拟地址 = 页面号 + 页内位移。<br>
<img alt="Pasted image 20240801081814.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240801081814.jpg"><br><br>页表项处理页框外，还有很多标志位来提供更为精细的访问控制。<br>
<br>P(Present)位：表示页是否在物理内存中（1表示页在内存中）
<br>R/W(Read/Write)位：控制页的读写权限（0表示可读/1表示可读写）
<br>U/S(User/Supervisor)位：控制页的访问权限（0表示只有内核能访问/1表示用户也可以访问）
<br>A(Accessed)位：指示该页是否被访问过（页的置换算法）
<br>D(Dirty)位：指示该页是否被写过（write-back）
<br>NX(No Execute)位：表示该页是否可执行（64位机器）
<br><br><br>我们已经学习了段式内存管理和页式内存管理。在 ICS 先导课中，我们结合32位机器（IA-32）进行了学习。在32位机器上，段页式内存管理应用非常普遍。在64位机器上，页式存储管理方案更为常见。常见的分页表结构有三种，分别是：<br>
<br>分层分页(Hierarchical Paging)
<br>哈希分页表(Hashed Page Tables)
<br>倒排分页表(Inverted Page Tables)
<br>在后续的课程中，我们将探讨分层分页的页式存储管理方式，包括快表和多级页表等。<br><br><br><br>学习页式存储管理方案中，每当CPU 访存时，访问页表会为机器带来额外的开销（两次访存）。为了减少这种开销，设计人员使用 Cache 来减少时间上的开销。现代计算机使用地址转换旁路缓冲存储器，由于合理使用TLB能够将查询页表的时间开销降低到原先的5%甚至以下，由此得名快表。<br><br>TLB&nbsp;是用 SRAM 做成的一种全相联存储器（命中率高）。TLB 中存储最近使用的页表项，加快了地址的转换速度（减少访存次数）。因为是全相联存储器，所以它会将 CPU 送来的页号和 TLB 中缓存的所有页号同时比较（硬件实现复杂，成本高）。如果找到匹配条目即为命中（TLB hit）。<br>若命中(hit)，就会直接返回匹配条目的物理地址，这种情况当然最好。根据匹配条目的位置，我们有两种不同的结局：<br>
<br>物理地址中的数据在缓存中，不需要访问内存。
<br>如果物理地址中的数据块不在缓存中，则需要额外访问一次内存。
<br>若不命中(miss)，就会再查看页表，转换物理地址的同时将页表项写进 TLB。物理地址中的数据在缓存中，需要访问一次内存。<br>
<br>物理地址中的数据不在缓存中，页表命中。产生两次访存。
<br>页表不命中。最差的情况，需要访问磁盘。<br>
<img alt="Pasted image 20240805022104.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240805022104.png">
<br><br>TLB 的命中率对系统性能至关重要，越高的命中率就以为这更多的地址转换可以在 TLB 中完成，减少了访存的次数（访问内存页表）。<br>通常情况下，TLB的命中率非常高。一般在 90% 到 99% 之间。影响的因素有多个：<br>
<br>程序的访问模式（程序的局部性原理）
<br>TLB 的大小和结构
<br>要保持TLB命中率，我们还需要注意：当发生进程切换时，会使所有的 TLB 条目失效。<br><br>
<br>TLB 的造价高：SRAM的全相联存储器
<br>TLB 的功耗高：能占到微处理器总功耗的 10% 以上
<br><br><br> 在上节课快表的学习中，我们用快表（一种cache）解决了页表所带来频繁的访存开销。在本节课中，我们学习多级页表，了解一下多级页表是如何优化页表所带来的存储开销的。<br><br>现如今，16GB、32GB甚至64GB的主机内存屡见不鲜。对于本节课，我们看到页表的分级可能不太理解，我们继续用 32 位 4GB 的虚存举例子。没有页表的分级结构前，我们需要 4MB 的连续内存来存储每个进程的页表。<br>现在的内存价格大约是 15rmb/GB，换算成 rmb/MB 更加便宜。而在1985年 Intel 386 推出时，内存的价格是骇人的 500$/MB。当时Windows 1.0 (Nov 1985) 只需要 192KB RAM 就可以运行。我们可能感觉不到那是一个多么黑暗的年代，但是我们能够感同身受的是多级页表的存在真的非常必要。当时的 i386 使用的就是二级页表。<br><br>在 x86-32 架构下，一个进程的虚拟地址空间的理论大小为: 假设一个页面大小为 4KB，可划分出来的页面数量就有 1M 这么多，每个页表项 4B ，就会产生 1M*4B = 4MB 的连续空间大小。如果系统中有100个进程，那么即使什么都不做，都会用掉400M的连续内存。而进程一般不会用掉4GB的内存，因而有很多空洞页面。也就是说，每个进程是用不掉这1M个这么多的页表项的。<br>但是在单级页表下，即使进程不访问主存，也要为进程分配足够的页表项来覆盖整个虚拟地址空间。（连续存储）<br>而我们可以将页表的内存空间再进行分页，就可以把这些页表页离散的存到内存里了。这样不仅仅有助于提高内存的利用率（将大象分块放入冰箱），同时操作系统也可以实现按需分配页表空间了。刚刚单级页表中，操作系统需要为那些空洞页面也分配页表项，这太浪费空间了！当操作系统可以按需分配页表后，就可以完全不为空洞页面分配页表项，节省内存。<br>为了实现页表的分页，我们当然还需要额外地准备一张页目录表(Page Directory Table)，用来记录页表页存放的页框号。（二级页表）<br><br><br>先将页表分页，本来 4MB 大小的页表可以分成 1K 页，每个页目录表(page directory/first level page table) 就只占 4KB 的空间，刚好是一个页的大小。其中每个页目录表项有 4B，记录页表页的存放的页框号，页目录表项就是 PDE(Page Directory Entry)。<br>
<img alt="Pasted image 20240924011424.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240924011424.jpg"><br>
每个页目录表项都对应着一个页表(page table)。我们知道，一个页表可以映射4MB的内存，那么使用二级页表就可以通过第1级页表映射第2级页表，第二级页表进一步映射有：那这4GB虚拟内存需要全部分配吗？当然不！在下图中，红色的部分就是页目录表项所记录的空洞页框号，在主存中并不用分配所对应的页框号，在页表中不需要给这部分空间分配页表项。所以操作系统就不用给这部分空间分配页表页(second level page table)，直到进程申请到了这部分的内存（按需分配）。<br><img alt="Pasted image 20240814201027.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240814201027.png"><br>
从上面的图中，我们看到页目录表的出现好像为内存增加了额外的负担，但别忘了这是操作系统不需要为空洞页面分配相应页表页的前提下的。如果进程只是用了 1GB 的虚存空间，那么用这 4KB 去换取 3MB 的页表页不载入内存好像是一个不错的交换。<br><img alt="Pasted image 20240814203923.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240814203923.png"><br><br>进入 64 位架构的时代后，进程的虚拟地址空间剧增（用户区和内核区各占256TB）。如果我们仍然使用二级页表的连续页框来存储，那么将产生：的二级页表空间，我们的内存显然是不够用的，因而出现了多级页表。我们在这里介绍四级页表。解决方法简单粗暴——对页目录表继续分页。在四级页表中，页面大小仍然是 4KB，从顶至底的页表分别是：<br>
<br>PGD（9bits）：Page Global Directory
<br>PUD（9bits）：Page Upper Directory
<br>PMD（9bits）：Page Middle Directory
<br>PTE（9bits）：Page Table Entry
<br>Page（12bits）
<br><br>优点：<br>
<br>分散的页表管理
<br>支持非常大的地址空间<br>
缺点：
<br>地址转换时间增加（通过增加TLB优化）
<br>开销增加
<br>复杂性增加
<br><br><br>Caching是一种用于提高数据访问速度和系统性能的技术。在中学时，我们常常把正在用的书放在面前，把常用到的书摞在一起放到课桌上，不常用的书放到书包里。这就是一种cache。在我们学习快表的时候，我们知道当 TLB 命中率越高，机器的性能就越好。（因为cache常用更快的存储介质）<br><br>局部性原理，也叫引用局部性。分为时间局部性和空间局部性。局部性原理在计算机科学中的应用是非常广泛的，不仅仅应用在替换算法中。局部性原理还体现在存储器层次结构和编译器优化上。<br><br>时间局部性指的是，如果某个数据在被访问过一次，那么在不久的将来很可能还会被访问。当我们将这些数据放在 cache 中不进行替换，就会大大增加系统的运行性能。我们用一个例子来说明：<br>#include &lt;stdio.h&gt;

int main() {
    int i, j, sum = 0;
    int matrix[1000][1000];
	// matirx的初始化
	for(){
	...
	}
	
    for (i = 0; i &lt; 1000; i++) {
        for (j = 0; j &lt; 1000; j++) {
            sum += matirx[i][j];
        }
    }

    printf("Value of sum is: %d\n", sum);
    return 0;
}

<br>在这个例子中，变量&nbsp;sum&nbsp;和&nbsp;j&nbsp;是经常被访问的数据。将这些数据保存在缓存中可以显著提升性能，因为它们在短时间内被多次访问。。<br><br>空间局部性是指，当某个数据被访问到后，它周围空间之后一段时间也很有可能被访问到。继续上面的例子，如果将循环中变量 i 和 j 进行如下改动，那么空间局部性就会变得非常差。因为每次访问的地址都不是连续的，而且每一行都有1000个元素（4000字节），所以完全利用不到 cache 这个层次，总是访问主存甚至磁盘。<br>    for (j = 0; j &lt; 1000; j++) {
        for (i = 0; i &lt; 1000; i++) {
            sum += matrix[i][j];
        }
    }
<br>我们看到，尽管先按列访问的方法的作用和按行访问相同，但是由于空间的局部性，它们对 cache 利用率会大不一样，因此列访问效率会不如行访问的效率。<br><br>引用局部性是计算机系统中的一种可预测行为，强局部性的系统非常适合通过 cache、预取等技术进行性能优化。局部性的典型应用有层次化存储。<br>层次化存储是一种利用时间和空间局部性的硬件优化，可用于多个层次的内存结构中。层次化存储系统通过将存储器分为多个层次，每个层次都有不同的速度和容量，来提高内存访问效率。层次化的存储有：<br>
<br>CPU寄存器：存储速度最快，速度有限（8-256个）
<br>L1 Cache：每个核心各有一个，容量32KB-512KB，速度很快
<br>L2 Cache：多个核心共享，容量128KB-24MB，速度比L1 Cache慢
<br>L3 Cache：所有核心共享，容量2MB-64MB，速度比L2 Cache慢
<br>主存储器：容量大，但存取速度慢
<br>磁盘存储：容量巨大，存取速度最慢
<br>云存储：容量无限制，存取速度根据网络状况而定
<br>根据局部性原理，现代计算机会将那些更频繁使用的数据放在高层级的存储器中。如果高层级存储器空间不够用，就会用内存置换算法将存储空间中一部分内容对换到下层次的存储器中。在替换的过程中难免会有cache数据一致性的问题，我们用替换策略和写策略来做相应应对。<br><img alt="Pasted image 20241123015750.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241123015750.jpg"><br><br>缺页是指当程序访问的页面不在物理内存中时，操作系统需要从磁盘中将该页面调入内存的情况。这种情况会导致程序暂时停止执行，直到所需页面被加载到内存中。缺页特指主存到磁盘存储这一层次的页面缺失。缺页会引起中断，使操作系统介入将页面加载到内存里，由于涉及到磁盘这一层次，所以缺页非常慢，高频次的缺页可能引起性能的大幅下降。<br>缺页这类现象并不局限于主存-磁盘的存储结构，从Cache的结构到主存也会涉及到“缺页”相关的现象。只不过主存以下的缺页所带来的系统开销足够小，并不需要引发操作系统的重视。<br><br>缓存写满时，就要再写入新数据就必须选择 cache line 进行替换，此时就要考虑替换策略：<br>
<br>FIFO：最早进入缓存的数据最先被替换。这种策略简单易实现，但可能不总是最优的，因为最早进入的数据不一定是最不常用的。
<br>LRU：最近最少使用的数据被替换。这种策略更符合局部性原理，但实现起来相对复杂，需要维护每个缓存行的使用时间戳或链表。
<br><br>当一个数据再缓存中被修改了，那么对应内存数据如何处理也成了一个问题。一般情况下，我们有这两种写策略：<br>
<br>Write-Through：每次写操作都同时更新缓存和主存。虽然数据一致性高，但由于每次写操作都涉及主存，速度较慢。
<br>Write Back：每次写操作只更新缓存，只有缓存行被替换时才写回主存。这种策略速度快，但需要额外的机制来确保数据一致性，例如脏位（Dirty Bit）来标记哪些缓存行需要写回主存。
<br><br>在之前的学习中，我们了解了虚拟内存和进程的分页机制。这些机制共同作用，使系统可以加载比有限内存大得多的程序。当缺页发生（page fault），操作系统将缺失的页面加载进内存。然而这个过程是有代价的，我们这小节比较不同的算法，看看哪种算法下的hit ratio最高。<br>本小节我们将着重关注当主存空间满时，页面是如何置换到磁盘中，为后来加载的页面腾出空间。当CPU要访问某一页面时，如果页面在内存中就Hit，如果不在页面中就Miss。对于页面置换算法而言，命中率越高，表明性能越好，反之，性能越坏。<br><br>先进先出算法是简单的队列算法(Queue)，队列的数据结构插入和删除发生在不同的端头，在尾部插入，在头部删除(Enqueue in rear, dequeue in front)。这种结构确保了最早进入队列的元素能够得到最早的处理，在进程调度、打印任务管理的场景得到了很好的应用。这种结构是否适用于内存的置换呢？我们最关心的是这种结构的命中率如何。我们接着看。<br>
<img alt="Pasted image 20240923222601.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240923222601.png"><br>
凡是缺页的就标记为Miss，命中的标记为Hit。如果队列满且下一次页面访存Miss，那么FIFO页面置换算法的操作系统就会选择最早进入内存的页面进行置换。我们直觉上就会感到这种算法很不靠谱，事实上也确实不靠谱。FIFO页面置换算法的命中率相比其他算法是相当低的。<br>而且FIFO还会引发反直觉的Bélády's Anomaly现象。主要原因是FIFO只考虑了页面的时间序列，而没有考虑页面的引用局部性。<br><br>贝莱蒂现象得名于匈牙利科学家贝莱蒂发现的一种现象，即随着分配页面的增多缺页率反而增加。这是十分反直觉的，这种现象主要发生在FIFO算法中，原因我们上文也已给出。在OPT算法、LRU算法等考虑时间局部性的算法中几乎不会发生这种现象。<br>下面我们用一个例子直观感受一下这种现象。假设当前的队列为空，我们下面即将访问页面的顺序是：1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5。当队列中页框数为3时，我们有：<br>
<img alt="Pasted image 20240923230804.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240923230804.png"><br>
我们看到，在第一个例子中，我们总共发生了9次page faults。但是下图中，我们将队列中页框数增加到4时，我们看到，缺页次数不但没有下降，反而增加了。<br>
<img alt="Pasted image 20240923230816.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240923230816.png"><br>
“基于栈”的页面置换算法就不会受到贝莱蒂现象的影响。因为这些算法在实现时使用了类似栈的数据结构来管理页面。具体来说，这些算法维护一个页面栈，栈顶的页面是最近使用的，而栈底的页面是最久未使用的。下面我们将会学习到OPT算法和LRU算法，这两个算法都是stack-based algo。<br><br>FIFO算法最大的优点就是实现简单，但是没有考虑到页面的引用局部性是FIFO最大的缺点。我们选用页面置换算法的目的是提高主存的命中率，从而减少访问磁盘的次数，使得机器的存取速度更接近主存的存取速度，进来提高机器的速度。<br><br>时钟算法是FIFO的改进版，除了考虑页面的时间顺序，同时也照顾到了页面的引用情况。在之前的学习中，我们知道页表项(PTE)有一个属性位(Accessed bit)，1表示访问过，0表示未访问过。CLOCK算法就是在FIFO算法的基础上为每个页面增添一个引用位(reference bit)，和页表项中的accessed bit类似。<br>由于是FIFO算法的改进，CLOCK会按照FIFO的顺序检查每一个页面的reference位，如果reference位为1，则将此位设置为0，然后检查下一页。如果页引用位是0，就选中该页作为淘汰页。这种方式给了页第二次驻留内存的机会，因此也称为二次机会算法。<br>当检查完队列最后一个页面就会循环检查第一页。（Like a CLOCK spining again and again）<br><br>CLOCK+算法是对CLOCK算法的一种改进，旨在延迟页面的置换操作。假如某个页面在加载进内存后被修改，那么它的dirty位就会置为1。我们知道，如果页面置换策略采用回写策略(write-back)，则表示只有页面置换到磁盘上时才会将数据进行同步。<br>如果我们结合页的accessed bit和dirty bit两个属性，我们一共可以得到四种情况：<br>1. A = 0, D = 0    // 最先淘汰
2. A = 0, D = 1
3. A = 1, D = 0
4. A = 1, D = 1    // 最后淘汰
<br>
<br>第一轮检查：

<br>按照FIFO顺序检查1类页面，如果检出就淘汰
<br>如果没有检出就进行第二轮检查


<br>第二轮检查：

<br>按照FIFO顺序检查2类页面，如果检出就淘汰
<br>如果没有2类页面，则将后续页面的A位置为0
<br>如果第二轮结束依然没有找到二类页面，则重复第一轮


<br><br>最佳页面置换算法会选择在将来最长时间内不会访问的页面进行替换。虽然这种算法理论上的命中率是最高的，但是这种算法过于理想，预知未来将要访问的页面在实际的应用中几乎是不可能的。而且即使在模拟环境中实现OPT算法，所需要的计算资源也将是巨大的。<br><br>由于OPT算法理论上的命中率是最高的，从而我们可以用OPT算法与其他的算法进行比较。为其他算法提供一个理想的参考标准，用来评估其他页面置换算法的性能。<br><br>最近最久未使用算法是接近OPT算法的成功尝试，LRU会替换最近最少使用的页面。这个根据是程序的局部性原理，即最近使用过的数据在未来一段时间后仍可能被使用。<br>在算法的实现中，尽管我们不能预测未来，但是我们仍然可以观察过去。我们可以通过过去访问的页来指定未来哪些页需要被先置换出去，哪些页应当保留。要实现LRU，我们需要额外地维护一个链表，用于保存刚刚访问的页面及最久未被访问的页面。且每次访问页都可能对链表排序进行调整，又是额外的时间开销。<br><br><br><br><br><br>我们终于将虚拟内存作为单独的专题进行讨论了。我们先回顾一下为什么我们需要虚拟存储器。在早些时候，内存容量很小，所以我们需要二级存储器来作为后备力量。现在虽然我们有 16/32GB 甚至更大的主存容量，能够容纳大多数的软件，但随着软件数量的增多和体积的增大，这么大的主存容量可能还是不够用。<br>那么如果我们只将程序的一小部分放在主存中呢？根据程序局部性原理，我们当然可以这样做，而且带来的好处远远大于整个程序的 swapping 所带来的系统开销。先导课程中，我们介绍过早期的虚拟内存实现。当程序不再需要完全放在内存中时，这不仅节省了内存空间，还减少了每个程序使用的主存空间，同时也减少了使用 IO 进行 swapping 的次数（每次只需加载程序的一部分）。<br><br>虚拟内存(VM) 是操作系统管理内存的一种技术。通过将小部分的程序调入内存中运行，它可以向应用程序提供一个独享、连续且巨大的内存空间。尽管内存无法容纳所有进程，但虚拟内存提供了一种非常有效的方法来应对这种情况。即按需调入，并将长时间未访问的页调出到磁盘中。利用磁盘的大容量来运行程序。<br>
<img alt="Pasted image 20241112175054.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241112175054.png"><br>
我们前面提到了页表、虚拟内存的思想blablabla，我们来总结一下虚拟内存怎么用：<br>
<br>段检查（Segmentation Check）：每次CPU要访问某个内存地址的指令或数据时，内存管理单元（MMU）都会检查这个内存引用是否有效。MMU会先进行段检查，如果段不可用，就会终止程序并抛出segmentation fault。
<br>缺页处理（Page Fault Handling）：如果段地址有效，但引用的页不在内存中，就会发生缺页。这时操作系统会找到一个空闲页框，请求磁盘读操作（可能还会写），然后将新页面载入内存。
<br>更新页表和恢复执行：当页面加载完成后，操作系统会更新页表并记录相关信息。最后，重新对该虚拟地址进行访问，继续执行程序。
<br><br>由于虚拟内存涉及到内存-磁盘这一层次的存储层次，当部分加载进内存的程序发生缺页时会发生什么呢？当进程访问的虚拟页不在物理内存中就会产生页错误。当缺页发生时，会：<br>
<img alt="Pasted image 20240808004636.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240808004636.png"><br>
<br>发生缺页，向操作系统报告。随后操作系统接管并保存运行上下文，操作系统figure out这是一个缺页中断。随后MMU检查这个地址是否合法。
<br>然后就是决定加载页面到内存的某个页框中（使用页面替换算法）。在选择装入前先检查一下要替换的页面是否被修改过（脏位是否为1）。

<br>如果没有修改过，跳到第 5 步。


<br>如果修改过，先将该页面写回到磁盘中。磁盘写请求放在一个队列中。然后等待磁盘写执行，CPU这时会做其他的事情。当磁盘写完成之后会向操作系统发出中断信号。
<br>保存寄存器和其他进程状态（为什么？）
<br>发起磁盘读操作，将磁盘中的数据读到内存的空闲页框里。和前面的写操作一样，对磁盘读的请求会放在一个队列里，在磁盘读操作进行的过程中，CPU做其他的事情。
<br>当磁盘完成I/O操作后，向系统发生中断信号。
<br>如有必要，保存寄存器和其他进程状态。（为什么？）
<br>最后更新页表，恢复执行。
<br><br>：只有在需要的时候才从外存中加载到内存。（处理 page fault 就是一种 lazy approach）<br><br>尽管缺页需要这么多步才能恢复执行，但实际上对磁盘（HHDs）的操作是最耗费时间的。重启进程和内存的管理需要耗费 1μs - 100μs。然而，磁盘的延迟有 3ms（3000μs），寻道时间 5ms（5000μs），而传输时间只用 0.05ms（50μs）。所以，当缺页中断率很高时，性能会非常非常差。（一般而言，缺页中断率会控制在这个水平）这也就是为什么说page fault is painful。<br>现在，我们大多使用SSDs这种介质作为二级存储器，相比于HHDs，SSDs是一种更快、更可靠的存储解决方案。SSD的延迟通常在几十微秒（μs）范围内，远低于HHDs的毫秒（ms）级别延迟。SSD没有机械部件，因此没有寻道时间，数据传输速度也更快。这使得SSD在处理缺页中断时的性能显著优于HHDs。<br><br>当缺页(page fault)或换入换出(swapping)发生时，操作系统会进入内核态来处理这些事件。处理这些事件会有一定的时间开销。如果缺页的发生频率过高，CPU就不得不花费更多的时间来处理这些换出操作。这种由于换出过于频繁而导致系统性能大幅下降的现象称为抖动。<br>
<img alt="Pasted image 20240924163417.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240924163417.png"><br><br>引发抖动的原因可能有多个，比如并发进程数量、内存分配策略、页面调入策略、页面置换算法等。上节课我们已经了解过页面置换策略是如何影响页命中率的，下面我们着重来看内存分配策略和调页策略对抖动的影响和如何避免抖动。<br><br>OS为进程分配内存有两种策略，固定页框(fixed allocation) 和可变页框(variable allocation)。固定页框是指操作系统为每个进程分配一组固定数量的物理页框（物理内存块），且在进程运行期间一直保持这样数量的物理页框。固定页框策略要求每个进程只能使用自己分配的页框，不能使用其他进程的页框。等分页框(Equal Allocation) 就是一种固定页框，系统中的所有物理页框平均分配给每个进程。<br>可变页框是操作系统根据进程的需求动态地分配物理页框，进程运行期间，页框的数量可以增加或减少。比例分配(Proportional Allocation) 是可变页框的一种，进程分配的页框数量可以根据进程的大小和进程数量来动态调整。<br>固定页框实现简单，管理方便，因为每个进程的内存需求是预先确定的。但是这种分配策略的灵活性很差，可能导致内存利用率不高。如果分配的页框数量过多，会浪费内存；如果分配的页框数量过少，可能导致频繁的缺页中断。<br>可变页框的优缺点完全和固定页框的实现反着来，可变页框灵活性高，可以根据实际需求调整内存分配，提高内存利用率。但是实现复杂，需要更复杂的管理机制来跟踪和调整页框的分配。<br><br>当缺页中断发生，操作系统需要swapping需要置换的页。我们也有两种相关的实现方式：局部置换和全局置换。<br>局部置换是指当发生缺页中断时，操作系统只在当前进程的物理页框中选择一个页面进行置换。这样，每个进程只能使用自己分配的物理页框，不会影响其他进程的内存使用。如果某个进程的内存需求突然增加，可能会频繁发生缺页中断，影响该进程的性能。<br>全局置换是指当发生缺页中断时，操作系统可以在所有进程的物理页框中选择一个页面进行置换。这样，操作系统可以动态调整各个进程的物理页框数量，根据实际需求进行分配。内存利用率更高，可以更好地适应不同进程的内存需求变化。可能导致进程之间的相互干扰，一个进程的内存需求增加可能会影响其他进程的性能。<br>为什么固定页框和全局置换是矛盾的。<br><br>请页式(Demand Paging) 是当进程需要访问某个页面而页面不在内存中时，产生缺页中断，操作系统将该页面从磁盘调入内存的页面调入策略。只在需要时加载页面，减少了不必要的内存占用，但是也可能导致频繁的缺页中断，影响系统性能。<br>调页式(Pre-paging) 是在执行访问页面之前将之后要访问的多个页面提前加载到内存中。如果预测准确，就会减少缺页中断的频率，如果预测不准确就会加载不必要的页面，浪费内存资源。<br><br>除了上面的因素，页面置换算法也是影响系统发生抖动的重要因素。页面置换算法不同，缺页次数就不相同。我们熟悉的LRU就是一种好的页面置换算法。<br><br><br>工作集模型基于局部性原理，根据局部性大致地给出程序之后最有可能访问的页有哪些。根据工作集，我们能够减少缺页的同时尽可能地节省内存页框的资源。<br>为确定工作集窗口，我们检测最近使用过的页，看看哪些页的使用是最频繁的，之后将工作集设置为局部时间Δ内引用最多的页面的集合（如下Δ = 10）。不难理解，如果某页面被频繁地访问，那么就会出现在工作集中。<br><img alt="Pasted image 20240925010529.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240925010529.png"><br>当工作集一旦被确定，系统就可以在进程启动或重启之前，根据这些历史访问数据将工作集中的页面预先调入主存（预调页的实现）。进程开始执行时就能减少缺页中断的发生，提高了系统性能。<br><br>通过之前的学习，我们了解了抖动问题的根源在于频繁的页面置换，即缺页中断频率（PFF）。如果一个进程的PFF过高，这表示系统给该进程分配的页框过少；如果系统给当前进程分配的页框非常多，就不会引起频繁的换入换出。<br><img alt="Pasted image 20240925004924.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240925004924.png"><br>
随着进程分配页框数的增加，PFF一定会减少。我们发现PFF会根据页框数呈类似于1/N的减少趋势。基于此，我们可以划定合适的上限PFF(upper bound)和下限PFF(lower bound)。根据这两个边界划分进程分配页框数。当分配的页框数过少时，PFF会显著增加（超过upper bound），从而影响性能；而当分配的页框数过多时（小于lower bound），会浪费内存页框，性价比不高。<br><br>在程序中申请内存时，我们操作的是虚拟内存。操作系统负责将这些虚拟地址映射到物理内存或磁盘空间（mmap()）。虚拟内存区域的分配只需确保不与现有映射冲突，无需采用物理内存管理中的best fit等算法。由于虚拟内存无需考虑碎片问题，所以通常使用更高效的方式（如 first fit ）管理地址空间。<br>我们有两种不同的虚拟内存分配方式：静态的和动态的。<br><br>静态内存分配是在编译时分配内存的方式。程序在编译时确定变量的虚拟地址布局（如 .data 段、 .text 段等），其生命周期覆盖整个程序运行周期。物理内存的实际分配由操作系统在程序加载时完成，且内存大小不可在运行时调整。<br><br>如果你需要在运行时申请内存（堆内存），你就会用到动态内存分配函数在程序运行时根据需要分配和释放内存。常见的动态内存分配函数包括 malloc 、calloc 、realloc 和 free。动态内存分配的灵活性高，可以根据程序的需要动态调整内存大小。但需要手动管理，容易发生内存泄漏。<br>在 Linux 系统中，malloc 库函数会在底层调用 brk（小于 128KB 的内存申请） 和 mmap 系统调用（大于 128KB 的内存申请）。（一般情况下）<br><br>它们的函数原型如下：<br>#include &lt;unistd.h&gt;
int brk(void *end_data_segment);
/*
Parameters:
	1. end_data_segment: Pointer to the new end of the data segment. This value is interpreted as the new program break.
   
Return value: Returns 0 on success, otherwise -1 and errno is set to indicate the error.
*/

void* sbrk(intptr_t increment);
/* 
Parameters:
	1. increment: The amount by which to increase or decrease the program break. If the value is positive, the break is increased by increment bytes. If the value is negative, the break is decreased by increment bytes.
   
Return value: Returns the previous program break on success. On error, (void *) -1 is returned, and errno is set to indicate the error.
*/
<br><br>mmap 我们在 IPC 章节已经介绍过，这里不在赘述。<br><br><br><br>在本阶段，我们一直讨论有关虚拟内存怎么实现、段、页等等，但是我们的讨论仿佛一直局限在用户程序。你有没有好奇过内核在哪里存放？内核代码也需要向用户代码那样按需分配么？本节课，我们就来回顾前面阶段的知识并探讨下一些重要又有趣的细节。<br>i386采用二级页表<br>CR3 Register用于存储页目录表的基地址。<br><br>0-1M<br><br>物理地址1M往上就是内核代码和数据，再往上就是内核分配的一些数据结构，用来存放页目录或管理物理内存的结构。在往上就是空闲的物理内存。在IA32上，虚拟内存大小为4GB，其中前面的0GB-3GB我们会将其划分给用户程序，将高地址的3GB-4GB划分给内核程序。Linux将内核的1GB内存分为两部分：<br>
<br>低端地址是内核虚拟空间的低896MB，与物理内存一一映射；
<br>空闲的128MB是高端内存(High memory)，用来处理当物理内存大于896MB的情况。
<br>/* This file contains the definitions for memory management in our OS. */

/* *
 *     Virtual memory map:
 *     4G ------------------&gt; +---------------------------------+ 0xFFFFFFFF
 *                            |         High Memory (*)         | 128M
 *     KERNTOP -------------&gt; +---------------------------------+ 0xF8000000
 *                            |    Remapped Physical Memory     | KMEMSIZE(896M)
 *                            |                                 |
 *     KERNBASE ------------&gt; +---------------------------------+ 0xC0000000(3G)
 *                            |        Invalid Memory (*)       | --/--
 *     USERTOP -------------&gt; +---------------------------------+ 0xB0000000
 *                            |           User stack            |
 *                            +---------------------------------+
 *                            |                                 |
 *                            :                                 :
 *                            |         ~~~~~~~~~~~~~~~~        |
 *                            :                                 :
 *                            |                                 |
 *                            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 *                            |       User Program &amp; Heap       |
 *     UTEXT ---------------&gt; +---------------------------------+ 0x00800000
 *                            |        Invalid Memory (*)       | --/--
 *                            |  - - - - - - - - - - - - - - -  |
 *                            |    User STAB Data (optional)    |
 *     USERBASE, USTAB------&gt; +---------------------------------+ 0x00200000
 *                            |        Invalid Memory (*)       | --/--
 *     0 -------------------&gt; +---------------------------------+ 0x00000000
 * (*) Note: The kernel ensures that "Invalid Memory" is *never* mapped.
 *     "Empty Memory" is normally unmapped, but user programs may map pages
 *     there if desired.
 *
 *
 *    physical memory:
 *     4G -------------  ---&gt; +---------------------------------+ 0xFFFFFFFF
 *                            |           外设映射空间            |
 *                            |                                 |
 *     384M ----------------&gt; +---------------------------------+ 0x20000000
 *                            |           空闲内存~382M          |
 *                            |                                 |
 *     pages end -----------&gt; +---------------------------------+ pages end
 *                            |    npages*sizeof(struct Page)   | -- (768KB)
 *     kpgdir end ----------&gt; +---------------------------------+ kpgdir end
 *                            |           kern_pgdir            | -- PGSIZE
 *     bss end -------------&gt; +---------------------------------+ bss end
 *                            |           kernel code           |
 *     1M ------------------&gt; +---------------------------------+ 0x00100000
 *                            |           BIOS ROM              |
 *     960KB ---------------&gt; +---------------------------------+ 0x000F0000
 *                            |           16位外设,扩展ROMS       |
 *     768KB ---------------&gt; +---------------------------------+ 0x000C0000
 *                            |           VGA显示缓存            |
 *     640KB ---------------&gt; +---------------------------------+ 0x000A0000
 *                            |           bootloader            |
 *     0  ------------------&gt; +---------------------------------+ 0x00000000
 *
 * */
<br>由于是一一映射的方式，内核的虚拟地址减去KERNBASE就可以得到内核的物理地址了，方便内核对实际的内核物理内存进行管理。<br><img alt="Pasted image 20240924020957.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240924020957.png"><br>而对用户程序的地址空间会根据用户程序的情况把内存与物理内存空间进行映射。<br>--- 如何知道某个物理页可以释放？页结构体中有一项 uint_16t pp_ref; 表示当前页有多少个虚拟内存映射到该页代表的物理内存页。当 pp_ref 为0时就代表该页可以释放掉了。<br><img alt="Pasted image 20240924021026.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240924021026.png"><br><img alt="Pasted image 20240924023629.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240924023629.png"><br><br>在进程控制块 task_struct 中，我们有 mm_struct，它是一个描述进程内存管理信息的数据结构，用来管理用户进程的虚拟地址空间。mm_struct 包含了进程的地址空间信息，包括代码段、数据段、堆、栈等。它还包含了与内存管理相关的其他信息，如页表、内存映射等。<br>而在用户区的所有段，操作系统都会为其建立一个 vm_area_struct，存放在 mm_struct 中的 mmap 链表中，这是一个描述进程虚拟内存区域的数据结构。vm_area_struct 包含了虚拟内存区域的起始地址、结束地址、权限等信息。<br>对于有些数据，vm_area_struct 会和实际的物理内存建立映射。而如一次性申请 1GB 的堆内存时，操作系统只会分配一个 vm_area_struct 结构体，并不会立马与实际的物理内存建立映射关系。只有当使用时才会与物理内存建立映射关系（缺页异常并建立映射）。<br>此外，mm_struct 中还有一个 mmap_cache 字段，用于缓存最近访问的虚拟内存区域，以提高内存访问的效率。]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/11.-memory-management.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/11. Memory Management.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 21 Mar 2025 17:17:30 GMT</pubDate><enclosure url="https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20240728054403.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20240728054403.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[12. IO Systems]]></title><description><![CDATA[ 
 <br><br><br>在第一个阶段时，我们提到了计算机的五大部件，包括输入设备、输出设备、存储器、运算器和控制器。站在上层封装好的视角，计算机主要做了三件事：输入-运算-输出。运算是CPU为我们完成的，对于我们用户而言，一台计算机I/O就基本上决定了机器的可使用性（想想，一台只有机箱的电脑。尽管安装了操作系统，你仍无法操作这台机器）。<br>相比CPU那几个固定的架构，IO的处理可就麻烦多了（鼠标、硬盘、打印机、键盘、音响、摄像头......）。即使不同I/O设备可能遵循行业内的相关协议，而且我们现在有各式各样的USB I/O设备为I/O的管理提供了便利。但由于这些设备使用的数据、工作方式的不尽相同，处理这么多不同种类的I/O是一件令操作系统头大的事。<br><br>I/O设备能够工作离不开总线(bus) 和控制器(controller) 的支持。前者负责I/O设备与主机(host)的连接，后者负责信号转换、数据缓冲和设备控制。I/O设备往往由唯一的I/O端口（控制器）所标识，I/O端口通常包含四个寄存器：输入数据寄存器(input data register)、输出数据寄存器(output data register)、状态寄存器(status register) 和控制寄存器(control register)，有些设备还包括地址寄存器(address register)。<br><br>总线是一组线路和通过这些线路传输信息的协议。在计算机系统中，总线用于连接计算机的各个部件，是他们能够互相通信。总线承担着数据、地址和控制信号传输的功能，是计算机系统中不可或缺的一部分。总线可以根据传输方式分为并行总线和串行总线。<br><br>并行总线会使用多条线路同时传输多位数据。每条线路传输一位bit，多条线路可以同时传输多个bits的数据。但是并行总线之间存在电磁干扰，会导致信号的完整性和同步性问题。虽然直觉上并行总线肯定是要比串行总线快的，但当传输频率变高时，严重的信号干扰和同步问题又会使得并行总线的传输效率下降。常见的并行总线有IDE(Integrated Drive Electrons)、PCI(Peripheral Component Interconnect) 等。<br><br>串行总线虽然只使用单条线路传输一位数据，但由于其信号的干扰更少，所有串行总线可以在较高的时钟频率下运行，从而实现了高效的数据传输。且串行总线的成本更低，支持更长距离的传输。现代高速传输技术，如USB(Universal Serial Bus)、SATA(Serial ATA) 和PCIe(PCI Express)，都是基于串行传输的。<br><br>端口是一个很有趣的话题。我们可以把端口的类型分成物理端口和逻辑端口。物理端口是人类可以直观看到、摸到的，包括总线和控制器。而逻辑端口则是操作系统视角下的I/O端口。我们接下来介绍物理端口和逻辑端口。<br><br>物理端口可以理解为计算机与I/O设备连接的接口。通过端口，计算机系统可以与各种外设进行数据交换。端口的种类繁多，每种端口都对应着不同总线协议的功能实现和特定的连接标准。常见的端口有USB、HDMI等。<br><br>逻辑端口提供了一种抽象，使得应用程序不需要了解底层硬件的具体细节。通过逻辑端口，应用可以通过统一的接口与各种I/O设备进行交互。现代操作系统支持即插即用技术，使得用户可以方便地添加和移除I/O设备。操作系统会自动检测新设备，并加载相应的驱动程序，使设备能够立即使用。操作系统的I/O子系统提供了这样一套标准化的逻辑端口。<br>在早期的操作系统中，操作系统仅支持几个特定的I/O设备。你要使用某个设备，你就需要更新或者换成另外支持这个设备的操作系统。由于I/O设备的数量太过于庞杂，这种方式的管理太过于麻烦。IBM PC的一大成功就在于每个用户都可以通过一个标准的接口将自己的I/O设备加入到系统中。<br><br>我们说逻辑接口是内核I/O子系统提供的逻辑接口。为了使这样的逻辑接口便于上层所有的应用提供服务，我们需要在操作系统和I/O设备之间增加一层抽象，即设备驱动程序，以便实现设备的操作和管理。为了逻辑接口的标准统一，I/O子系统向下提供了一个标准的驱动程序接口。因此，不同设备使用统一的驱动程序接口。<br>设备驱动程序是操作系统与硬件设备之间的桥梁。它们负责将操作系统的高级指令转换为设备控制器能够理解的低级指令，并将设备的反馈传递回操作系统。驱动程序的质量直接影响系统的稳定性和性能，因此高质量的驱动程序对于系统的正常运行至关重要。<br><br>硬件设备各不相同，为了实现对设备更方便的管理，系统会从下面几方面来对设备进行抽象分类：<br>
<br>Data transfer mode
<br>Access method
<br>Transfer schedule
<br>Dedication
<br>Device speed
<br>Transfer direction
<br><img alt="Pasted image 20241121010744.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241121010744.jpg"><br><br>在Windows系统设计中，设备驱动程序会在内核模式下运行，其他的一些操作系统可能会将驱动程序运行在用户模式或者用户-内核之间的模式下。<br>Windows中，设备驱动程序在内核下运行可以唤起引发蓝屏(blue screen of death)的系统调用。这是Windows常被人诟病的方面之一，尽管Windows很无辜（引发蓝屏并不是系统的问题），可能是某些I/O设备引发的问题。而通常情况下，用户并不能注意引发蓝屏问题的原因是什么。<br>为了解决BSOD的问题，Windows在系统中加入了许多设备的驱动程序作为其默认的驱动。如果系统中没有某个设备的驱动程序，厂商可以先在Windows上进行驱动器的测试，确保在Windows的环境下安装驱动后不会引发BSOD。通过测试的设备会获得Windows的认证标志，表示该设备在Windows系统中可以稳定运行。<br><br>如果说设备驱动器作为最底层的软件层实现了I/O设备的逻辑端口的话，设备控制器则更像是提供I/O设备的物理端口。I/O控制器是一种用于管理I/O设备和主机之间传输数据的硬件，用于管理和操作I/O设备。每种I/O设备都有特定的控制器，通常而言，I/O控制器会集成在主板上，也可以通过扩展卡的形式存在。<br>设备控制器直接接受来自主机传输来的指令信号，并负责将来自主机的指令转换为设备可以理解的电信号控制设备的运作。设备完成后，控制器还要负责将设备的响应反馈给主机。<br><br>了解完了设备的驱动程序和控制器，我们现在知道，驱动程序是内核和控制器（硬件）之间的桥梁，而控制器是实际上控制设备工作的电子元件。即层次化的关系是&nbsp;kernel&nbsp;-&gt;&nbsp;drivers&nbsp;-&gt;&nbsp;controller。那么用户想要使用某个设备，总共需要穿越多少个抽象层？<br>当我们想要使用一个设备时，我们需要将想法编写成应用程序。由于操作系统的封装性和保护性，我们需要使用系统调用来间接地使用I/O设备。内核的I/O子系统会根据高级指令寻找对应的设备驱动程序，由驱动程序将上层的指令转换成设备控制器能够理解的低级指令，并发送给设备控制器。最后，设备控制器解析这些低级指令来控制设备做出相应的动作。<br><img alt="Pasted image 20241124023333.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241124023333.jpg"><br><br>根据数据的传输模式，我们可以将I/O设备分为块设备和字符设备。在使用相关的系统调用时，我们应当注意块设备每次应至少 read 或 write 一个块，而不是一个字节。字符设备也应每次 get 或 put 相应的一个字节。<br><br>块设备是面向块设备（譬如磁盘）的设备。任何的设备都支持 read 和 write 指令，如果这个设备是一个随机访问的设备，那它还会有一个 seek 指令跳转到相应的块。应用程序通常上经由文件系统访问磁盘。<br>块设备的特点是它们可以以固定大小的块进行数据传输，这样可以提高数据传输的效率。块设备通常用于存储设备，如硬盘和光盘。<br><br>字符设备是面向比特流（例如键盘）的设备。字符设备的相关系统调用有 get 和 put。字符设备通常用于需要逐字节处理数据的设备，如串口设备和终端设备。<br>字符设备的特点是它们以字符流的形式进行数据传输，这样可以更灵活地处理数据输入和输出。字符设备通常用于输入输出设备，如键盘和鼠标。<br><br>之前我们说过，I/O设备往往由唯一的I/O端口（控制器）所标识。要使CPU和正确的I/O设备进行通讯，控制器为每个寄存器分配了唯一的编号，即端口号(port number)，也称为I/O地址。每个外设都需要通过I/O地址于CPU进行通信，通过不同的I/O地址，CPU能够知道数据发送的地方。<br><br>端口映射I/O（Port-Mapped&nbsp;I/O）&nbsp;是我们要介绍的第一种I/O地址类型，这种类型下的I/O地址是独立的，与内存地址无关。在开发板上，我们通常会看到这种I/O地址类型。设备拥有自己独立的I/O地址，CPU会通过专用的指令和信号与设备进行通信。例如，通过IN指令、OUT指令，以及控制信号IOR（I/O&nbsp;Read）、IOW（I/O&nbsp;Write）等来进行操作。<br>在这种方式下，I/O的地址总线和控制总线和内存的地址总线分离。然而，IO的数据总线仍然使用系统的数据总线。<br><br>内存映射IO(Memory-Mapped IO) 方式下的IO地址被映射到了系统内存地址空间中。CPU通过访问内存地址来访问设备。这样一来，访问I/O就可以通过标准的内存访问指令来访问了，例如，MEMR和MEMW指令。它的总线和内存也都是共用的。<br><img alt="Pasted image 20241121021731.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241121021731.jpg"><br><br>在计算机组成中，我们学习过轮询、中断和DMA(direct memory access)的I/O控制方式。我们本小节简单了解一下这三种方式的工作原理。<br><br>轮询是最简单的I/O控制方式，尽管它的实现很直接，但在性能方面可能并不总是最佳选择。然而，有时候，轮询可能是你唯一能选的I/O控制方式。在轮询方式中，CPU会周期性地询问I/O设备：“你有没有需要处理的事情？/你忙不忙？我有些事情想让你做”。这种周期性检查设备状态的方法，尽管简单，却非常耗费CPU资源。<br>我们上述的轮询一般指tight polling(紧轮询)，与之相对的，loose polling会在每次检查条件之间加入一定的延迟，以减少 CPU 的占用。这种方法更节省资源，但响应速度较慢。<br><br>轮询会使用一个比特位来标识设备是否忙（busy bit），还有一个比特位标识设备的就绪状态（ready bit）。当设备忙时，busy bit就会被设置为1，标识设备正在执行某项任务。当设备就绪时，ready bit就会被设置为1，表示设备准备好接收新的数据了。<br><img alt="Pasted image 20241123043749.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241123043749.png"><br><br>CPU在对外设进行询问时，首先会检查设备是否忙碌，若是设备忙碌就不再打扰。当设备空闲时，CPU会给I/O端口特定的命令来读/写相应的数据。CPU会把ready bit设置为1，通知设备控制器可以执行新的命令了（如果是向外设输入数据，还需要向data-in register输入相关的数据）。<br>当设备控制器检测到相应就绪位的设置后，就会将busy bit设置为1，表示外设开始工作了。然后设备控制器从命令寄存器中读取命令并进行相应的操作。最后，设备控制器完成数据的处理后，会将ready bit和busy bit清除掉（置0），设备重新变为可用状态。<br><br>在Polling的情况下，由于要求CPU时时刻刻地参与，CPU的周期性轮询或忙等待某一个设备都会消耗CPU的资源，使得CPU利用率下降。Polling作为最简单的方法，可能并不是最优选。<br>而且如果CPU不及时响应，就可能造成数据的丢失。回到传感器的例子，由于传感器的缓冲区很小或是传感器对实时性的要求，如果不及时响应读取缓冲区内的数据，就可能导致新的数据覆盖掉旧的数据，导致数据的丢失。<br><br>在之前，我们用一个阶段来解释中断，但届时我们并没怎么涉及到什么关于I/O设备上面的中断。我们谈论到了外部中断，但只是一笔带过。那设备是如何向CPU发送相关的中断信号的呢？实际上，在物理线路的连接上，外设和CPU之间会架设一条中断请求线(Interrupt request line)，外设通过向这条线路发送信号，CPU就能够识别到外设是否在请求中断。<br>CPU检测到中断之后，后面的流程和我们学过的就很类似了，保存上下文、调用中断处理程序和恢复执行。但是作为系列的末尾，我们有必要复杂化的看待问题，或者说它本来的样子。比如，我们需要考虑中断优先级、中断禁用(disabling interrupt) 等。<br><br>在中断的方式中，CPU不需要时时刻刻地围绕在I/O身边，而是专注于做自己的事情。I/O设备一般都非常慢，当CPU少去大量忙等待的时间（第2、3步），效率自然就会提高。<br>在中断方式下，CPU需要做的是发送相关的I/O请求，之后不需要等待I/O设备的完成转而做其他事情。之后，I/O设备准备好之后向主机发送中断信号，CPU响应中断并执行响应的中断服务例程。之后恢复执行。<br><img alt="Pasted image 20241123190040.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241123190040.jpg"><br><br>相比于轮询的I/O控制方式，中断总算是把CPU从繁重的periodic polling中解救出来了。在中断的I//O控制方式下，当设备需要CPU来处理时，设备可以发送中断信号给CPU，CPU只需要抽空过来处理就好了。但有时候，中断并不需要立即被相应执行。延迟处理(Delay handling)可能带来的效益更高，例如网络数据包的接收（NIC）。<br>相比轮询，中断的应用到处都是。而为了避免高频次的中断，延迟处理相关的I/O，我们下面开始介绍一种更好的I/O控制方式——DMA。<br><br>没有DMA的世界中，当devices想向memory传输数据时，数据的流向必须经过CPU这个中介，即传输路径为Devices-&gt;CPU-&gt;Memory。而DMA的方式运行I/O设备直接对内存进行访问，绕过CPU进行数据传输。当传输完成之后，通知一下CPU就好（可能是一次中断）。<br>我们可以告诉DMA控制器(DMA controller)源是哪个I/O设备，目的在哪，读操作还是写操作。初始化DMA控制器完成之后，DMA控制器就可以代替CPU进行数据的传输任务，进一步解放了CPU。这种实现方式中，CPU仍然会被中断，但次数要少得多。实际上，DMA控制器并不完全独立于CPU，甚至可能会由于总线争用(bus contention)而拖慢CPU的运行速度。<br><img alt="Pasted image 20241123042009.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241123042009.jpg"><br><br>ioctl 是一个用于操作系统和设备驱动程序之间通信的UNIX系统调用。它允许应用程序通过设备文件向设备发送相关的控制命令。它的函数原型如下：<br>#include &lt;sys/ioctl.h&gt;

int ioctl(int fd, unsigned long request, ...);
/* Parameters:

1. fd: File descriptor of the device.
2. request: Device-specific request code.
3. ...: Additional arguments, depending on the request code.

Return value: Returns 0 on success, otherwise -1 and sets errno to indicate the error.
*/
<br>这个系统调用的功能极为强大，这个部分有待更新。<br><br><br>在第一节课中，我们见到过这张图，I/O系统结构是层次化的。而内核I/O子系统层位于设备驱动层之上，为上层的应用提供了虚拟的I/O端口，使应用程序可以通过统一的接口访问不同的硬件设备，而不必担心具体实现。为了提供更好的速度和安全性，这一层次还实现了buffering、I/O protection等。我们下面逐步了解这些内容。<br><img alt="Pasted image 20241121010724.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241121010724.jpg"><br><br>为上层应用提供统一的访问I/O设备的接口抽象是I/O子系统层的职责之一。无论是磁盘、打印机还是网络接口，应用程序都可以使用相同的系统调用与之进行交互。在类Unix的系统中，无论是字符设备还是块设备都被抽象成文件。一切对设备的访问都被看做是对文件的访问。<br>通过这种统一的文件模型抽象，我们可以使用相同的系统调用（比如，open()、read()等）对设备进行访问。这些设备文件被放在/dev目录下，这种将设备视为文件的抽象是文件系统在设备独立性上发挥的作用。<br><br>不论是对于character-oriented devices还是block-oriented devices，由于设备之间传输速度不匹配的问题，我们在传输过程中需要增加一块缓冲区，这就是缓冲(buffering)的概念。比如，键盘是一个低速的外设，尽管你打字再快，在主机的视角来看仍然非常慢。如果你想用键盘在磁盘中的文件中写一些内容，每次都输入一个字符并同步一个块显然是不划算的。<br>Buffer相当于一个储水罐(reservoir)，用于数据的暂存。当我们观看网络视频时，网络状况好的情况下，视频的播放一般会满慢网络中视频数据传输的速度。然而，如果网络状况时好时坏，我们就可以在网络好的时候将视频先暂存到buffer中，不至于在网络差的时候影响观看体验。<br>当高速设备给低速设备发送数据，若是没有buffering，低速设备没有办法准确的收到来自高速设备的数据。而低速设备给高速设备发送数据时，若是没有buffering，高速设备就会等待低速设备，这样会造成性能的浪费。<br><img alt="Pasted image 20241121010947.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241121010947.jpg"><br>从操作系统的视角看，buffering的实现简单而直接：将一个东西加入到buffer和将一个东西从buffer中取出来。实际上就是生产者-消费者模型，我们之前也将其称为有限缓冲问题，还记得么？<br><br>当我们引入了buffering，另一个问题就随之而来了。缓冲的大小应当设置多大，我们应当设置小缓冲区还是大缓冲区呢？当缓冲区很大时，一方面会挤占内存资源；另一方面，如果缓冲区过大，还会造成延迟的增加。当缓冲区过小，就会导致无法容纳足够的数据，这会导致频繁的I/O操作，还可能导致数据的丢失。<br>所以我们应当在一个范围内设置缓冲区的大小，从而在减少延迟和提升传输效率间找到平衡。假如 T 是向输入一个块所要的时间，C 是输入请求之间所需要的计算时间。那么，在没有buffer的情况下，完成将一个块的传输时间就需要：而buffer的加入使得数据的传输和处理可以同时进行，从而执行时间缩短为：M表示将数据从系统buffer移动到进程内存的时间。<br><br>假设我们在码字。在只有一个缓冲的情况下，buffer满了，就会把buffer中的内容整个地写入到磁盘中。然而，写入磁盘并不是瞬间完成的，我们想要继续码字。在之前学习生产者-消费者问题时，我们就了解到，生产者和消费者，一时间只能有一个进入临界区。如果我们想要不间断地写，我们可能就需要两个buffer来存放我们生产的物品，这就是double buffering，即双缓冲。<br>在double buffering中，系统使用两个缓冲区（Buffer A 和 Buffer B）来存储数据。当一个缓冲区正在被填充数据时，另一个缓冲区可以同时被处理。这样，数据的读写操作可以并行进行，减少了等待时间。当一个缓冲区的数据处理完成后，系统会切换到另一个缓冲区继续操作。这个过程不断交替进行，从而实现高效的数据传输。<br><br>Circular buffering是双缓冲的进阶版，并不难想清楚。<br><br>SPOOLing(Simultaneous Peripheral Operations On-Line)是一种将数据暂时存储在中间存储设备（如磁盘或内存）中的技术，以便设备可以在后台处理这些数据，而不影响前台的操作。最典型的例子就是打印机。当向打印机发送多个打印任务时，这些任务会被暂时存储在一个缓冲区(spool)中。<br>当用户进程提交打印任务时，这个任务并不会直接送给打印机，而是送到一个提供SPOOLing service的服务器上，这个服务器会将提交的这些任务排序，最后逐个打印。这种方式可以提高系统的效率，因为计算机可以继续处理其他任务，而不需要等待打印机完成打印。<br><br>回想一下早些时候我们引入了内核模式和用户模式的概念，我们简单地谈论了引入内核模式的好处和对系统的保护。在对待I/O设备上，我们也希望用户对I/O设备的访问和操作在系统内核的监督下进行，避免用户因不当指令导致系统或设备的故障（例如，启动一个I/O的后背隐藏能源）。同时，我们还希望操作系统可以帮我们检查该指令是否有效。<br><br>模式转换往往意味着开销。在这里，我们实际上用了性能为代价增加了系统的安全性。但有时候，我们想发挥系统的全部性能。比如说，显卡(graphic card)。在玩游戏时，为了获得全部的性能，我们想要游戏直接访问显卡的内存(direct access)。如果让每次访问(access)都经过内核，那带来的游戏体验将会很差。<br>因此，为了让用户获得显卡和处理器的全部性能，内核将会给予特定的游戏进程有关游戏显示相关的那一部分显卡内存的相关权限。这种情况下，应用进程访问这部分显卡内存将不需要经过内核的协助。少了内核中间商赚差价，性能收益自然就高了。<br><br>对于操作系统内核而言，知道哪个设备和主机建立了连接、设备正在为哪个进程所使用和当前设备的状态信息是必须的。在后续学习的文件系统中，我们会了解到“万物皆文件”的理念。在实际的进程内存和内核内存中，都记录着一些文件描述符(file descriptor)。内核就是根据这些文件描述符来操作I/O设备的。<br><img alt="Pasted image 20241121010449.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241121010449.jpg"><br>后续文件系统的学习中，我们会补充打开文件表是如何为设备的访问提供抄近道的机会。此外，经过了文件系统的封装，某些设备访问出错时就会直接返回错误码，将I/O硬件隔离开，提供了硬件的安全性。<br><br>大多数的I/O操作都是异步的，这意味着I/O设备的请求可能在任何时间点到来。这些请求源自用户程序，操作系统需要及时将请求加入到设备的队列中，并对这些I/O请求进行调度。操作系统根据队列中的信息了解设备状态，并对这些I/O请求进行定位和调度。<br>在FCFS的I/O调度方式中。当线程想要使用设备时，它会先检查设备的状态。如果设备空闲，就将设备的状态设置为忙并立即提交请求；如果设备忙，则将阻塞线程并将线程加入到等待队列中。当设备使用完毕后，我们可以将队列中的线程唤醒(unblock)，然后让其使用I/O。当没有线程使用设备时，就将设备的状态置为空闲。<br><img alt="Pasted image 20241121010924.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241121010924.jpg"><br><br>我们刚才谈论了FCFS的I/O调度方式。尽管这种方式非常公平，但未必是最高效的。CPU调度为我们提供了很多调度I/O的思路。例如，在CPU调度阶段中，我们学到了优先级，并将进程分为不同的等级。同样，在I/O调度上，我们也可以根据进程的优先级对I/O进行调度，让高优先级的进程优先使用I/O。<br>然而，I/O设备并不像进程那样可以通过CPU和RAM进行统一操作。对于I/O设备而言，非一致性访问时间(non-uniform access time)更为关键，因为I/O很慢嘛。对于闪存驱动器(flash drive)，读和写的时间不因数据的物理位置不同而变化，但对于其他类型的设备，访问时间可能会有所不同。然而，对于类似于硬盘这样的I/O设备而言，物理结构和操作方式导致了访问时间的变化。<br><br><img alt="Pasted image 20241125035405.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241125035405.jpg"><br><br><img alt="Pasted image 20241121021143.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241121021143.jpg"><br><br>在使用telnet或SSH时，打一个字母到远程主机会发生以下的中断：<br>
<br>本地的键盘中断
<br>本地的网络请求中断
<br>远程的网络达到中断
<br>编辑器进程打印字母并更新屏幕
<br>远程的网络请求中断
<br>本地的网络到达中断
<br>为了显示一个字符，我们可真是做了不少。<br><img alt="Pasted image 20241124024405.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241124024405.jpg"><br>如何减少中断呢？我们有很多鬼点子，比如将进程直接放到核心态去运行，这就不会产生任何中断了，但是太危险，不可取。第二种方案就是找一种功能特化的硬件来专门处理，像TLB那样，但是增加费用的同时还提升了学习成本，也不可取。那我们可以像之前学习buffer那样等输入一个块的数据后在将数据发送到远程服务器上去么？这种情形下肯定不可以了。<br>而这种情况下使用DMA就能算得上是一个不错的选择了，DMA控制器负责将数据从网络适配器传输到系统内存，而不需要CPU的干预。这样，系统可以减少CPU处理I/O请求的次数，减少了两次中断的发生。还不错。<br><br>一些I/O设备可能会为操作系统带来一些安全隐患。这是因为设备的驱动抽象是运行在操作系统内核中的，操作系统非常信任这些drivers，这就为安全问题埋下了隐患。攻击者可能通过利用系统中的漏洞、配置错误或弱访问控制，获得比其原本权限更高的访问权限。（Privilege escalation）<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/12.-io-systems.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/12. IO Systems.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sat, 15 Mar 2025 08:04:29 GMT</pubDate><enclosure url="https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20241121010744.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20241121010744.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[13. File Systems]]></title><description><![CDATA[ 
 <br><br><br>我们使用计算机，我们对文件并不陌生。文件有许多不同的格式。在完成程序设计实验中，我们就接触了 .c/.cpp 源代码文件，编译生成 exe 或 elf 格式的可执行文件格式，还有一般实验报告递交的 doc 文件格式。我们的生活离不开这些由文件系统管理的不同类别的文件。此外，文件系统还涉及文件的检索和保护，影响系统的性能和可靠性。对于操作系统，文件系统至关重要。<br><br>内存是计算机的核心部件之一，然而内存并不能提供持久性的存储，内存中的数据信息会由于系统的关闭或掉电而丢失掉。为了避免这种情况，我们需要一种能够在掉电后保证数据的完整性的存储介质。实际上，不易失的存储介质有很多，HDD、SSD、CD等。在文件系统的应用上，现多采用HDD和SSD作为文件系统的存储介质。<br><br><img alt="hhd.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/hhd.jpg"><br><br><img alt="ssd.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/ssd.jpg"><br><br>既然我们说到了文件系统，那我们的话题必然离不开文件。我们时时刻刻在使用着各种各样的文件，那文件是什么？文件是存储在永久性存储介质上相关数据的集合。文件可以是常见的文本、照片、视频，还可以是系统配置、代码等信息。文件的功能有：数据存储、数据交换和数据保护等。<br><img alt="Pasted image 20241126212945.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241126212945.jpg"><br><br>文件元数据(File Metadata)，也被称为文件属性(File Attributes)，包含对文件特征的描述信息，文件元数据并不作为文件数据，而是存储在文件系统的目录结构中。常见的文件属性有：<br>
<br>文件名：人类可读文件的标识符，区别于其他文件。
<br>文件标识符：唯一的文件id，与其他文件进行区分。
<br>文件类型：操作系统需要文件类型信息才能提供相应的支持。
<br>文件路径：文件在文件系统中的位置。
<br>文件大小：文件占用存储空间的大小。
<br>时间戳：记录创建、修改的时间等。
<br>链接计数
<br>文件权限
<br>文件所有者和用户组
<br>访问次数等。
<br><br>通过对文件的类型进行分类，文件可以被分为普通文件、目录文件、符号链接文件、特殊文件、套接字文件和管道文件。<br>文件类型是无穷多的，而操作系统并不能直接识别和解析所有类型的文件。虽然操作系统可以识别文件的基本类型（例如，通过文件扩展名或文件头信息），但要打开和正确显示特定类型的文件就需要安装相应的软件。典型的有Java的可执行字节流，这是一种二进制程序文件，但要是系统上没有安装 JVM，操作系统就无法直接运行这些Java字节码文件。<br><br>常规文件是文件系统中标准的文件类型，也是最常见到的文件类型。常规文件类型包括文本文件、二进制文件、图像文件、音频文件、视频文件等。为了操作系统能够加载并执行程序，所以操作系统必须至少完全支持一种可执行文件类型。<br><br>目录文件(directory files) 是一类特殊的文件，它记录着文件目录(file directories) 的信息。文件目录不仅仅包含数据，也包括对其他文件和子目录的引用。在 Linux 中，目录文件会被标注d属性，说明这个文件的内容实则是一个目录项清单，可用ls "directory file name"命令查看这个清单。<br>一般而言，目录文件中的内容我们一般是无法查看的，但我们可用通过ls命令来列出目录文件中引用的文件，也可用cd命令来进入目录文件记录的文件目录中。<br>du@du-virtual-machine:~/Desktop/OS$ ls -alh
total 136K
drwxrwxr-x 3 du du 4.0K  8月 23 00:50 .
drwxr-xr-x 7 du du 4.0K  8月  8 05:09 ..
drwxrwxr-x 2 du du 4.0K  7月  1 00:51 a_file_dir
<br>d属性就表示这是一个目录文件。文件目录以目录文件的显示存储在磁盘上。我们可以通过tree命令以树状结构显示目标目录及其子目录中的所有文件和目录。<br><br>符号链接实际上就是软连接(soft link)，之后再介绍文件目录的时候会提到。<br><br><br>套接字和FIFO文件在IPC的阶段<a data-href="6.5 Inter-Process Communications" href="https://congzhi.wiki/congzhi's-os-series/6.5-inter-process-communications.html" class="internal-link" target="_self" rel="noopener nofollow">6.5 Inter-Process Communications</a>里我们已经了解过了，虽然它们的地位较为显赫。但此处不做赘述。<br><br><br>在用户眼中，文件系统为我们提供了许多的便利，通过系统为我们提供的窗口（如：open()等的系统调用），用户并不需要了解这一切是怎么实现的。然而，负责文件系统结构设计的系统设计人员要做的可就多了。接下来，让我们从宏观的角度一层一层地了解下文件系统结构的设计。<br><img alt="Pasted image 20240824180225.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240824180225.png"><br><br>文件都是存放在磁盘上的，文件系统的职责是把各种各样的信息数据存放到非易失的存储介质上面。作为I/O设备，我们知道用户任何的请求都会转换成控制磁盘I/O的低级硬件指令交给I/O控制器处理。I/O控制层会收到basic file system layer的高级指令（如：read disk block 1），然后将其转换成磁盘能够理解的指令。又由于外设的低速性，我们对磁盘的操作一般是DMA的I/O控制方式。<br>具体来说，应用程序先是发出读文件的请求，这些请求经过层次转换到磁盘驱动程序将转换后的磁盘控制器命令交给CPU，然后CPU下达DMA控制操作，DMA控制器直接在内存和磁盘之间传输数据，而不需要CPU的持续干预。这种方式大大提高了数据传输效率，减少了CPU的负担。<br><br>基本文件系统负责与硬件交互，是文件系统中开始与硬盘硬件对接的层次。它会向磁盘驱动程序发布指定扇区的读写命令，之后由磁盘控制器驱动程序将命令传给磁盘控制器，控制器执行并返回结果，最终将结果交给操作系统。在这一层次中，对文件的操作是在物理磁盘上的，类似于磁盘1、12号柱面、7号磁道、1号扇区这样精确的磁盘访问请求就发生在这个层次。<br>由于磁盘访问的低速，在系统中实际上存在了许多buffers和caches来应对访问磁盘带来的开销。所以在这一层次，我们还需要考虑这些系统中存在的buffers和caches。只有当前要访问的数据不在这些buffers/caches中时，我们才需要考虑访问磁盘。也因此，我们需要承担突然断电时带来的数据丢失问题。<br><br>用户总希望自己的文件在系统中是连续存放的，正如我们之前学习虚拟存储技术时了解过的一样，即便我们看到的文件是连续的，但文件在磁盘上的存储块不一定是连续的。因此我们需要一个模块将逻辑块转换成底层硬件能够识别的物理块。<br>这种逻辑到物理上的转换就是由文件组织模块(File organization module)，也叫块管理器提供的。它是一个映射器(mapper)，将逻辑块地址映射成物理块地址。文件组织模块维护一个映射表，将文件的逻辑块转换为磁盘上的物理块地址，同时它也管理空闲空间列表，用于跟踪为分配的物理块。<br>除此，这一模块还负责空闲空间的管理，我们之后介绍。<br><br>对于用户而言，一个屏蔽底层硬件、简单、易操作的交互接口和能够对文件的属性进行方便管理的接口是ta们最想要的。而这个为用户提供方便接口的文件系统层次就由逻辑文件系统(Logical file system) 所提供。<br>逻辑文件系统负责管理文件的元数据。管理文件路径解析、文件描述符、权限检查等，并提供文件的操作接口（打开、创建、读和写）为用户使用，用户可以用系统调用（open/read/write等）与该层次交互。该层次也支持对文件的逻辑访问（逻辑上的文件）。<br>文件的元数据存放在一个叫文件控制块的东西里面，即FCB，在Unix中，文件控制块也叫inode。<br><br>文件系统非常多，我们有UFS、AFS、ZFS、NTFS、ext2/3/4、FAT32/64等等。这些文件系统各有不同，但是总有一些共同点，比如跟踪磁盘块的个数，多少个空闲块，多少个已被占用的块；还要管理文件目录的结构和各种文件。<br><br>在<a data-href="4. System Boots Up" href="https://congzhi.wiki/congzhi's-os-series/4.-system-boots-up.html" class="internal-link" target="_self" rel="noopener nofollow">4. System Boots Up</a>阶段中，我们谈到了计算机上电启动的一些内容。要使计算机正常启动，我们至少需要一块磁盘分区(volume)来存放操作系统的相关数据。我们谈到了磁盘分区上的第一个扇区，也叫启动扇区(boot sector)。当我们将视线放宽到整个volume，我们会看到：<br>
<br>引导区(Boot block)：包含启动代码和磁盘信息，有MBR和GPT的实现方式。
<br>目录区(Directory area, FCB)：一级、二级、树形等目录实现方式。
<br>空闲空间表(Free space table)：管理数据区，有位图、空闲链表、成组链接等实现方式。
<br>数据区(Data area)：连续、链接、索引等实现方式。
<br>在FAT的课程中，我们会结合FAT文件系统来进行介绍。<br><br>除了将一块磁盘一整块地使用，我们还可以逻辑上将磁盘分成若干个不同的区块来使用，这种方法也被称为磁盘分区。我们学习过 MBR 和 GPT 两种磁盘分区的方式。简单来说，磁盘分区就是在存储设备上创建一个或多个独立区域的过程，每个区域都可以作为独立的逻辑磁盘被管理使用。<br>为了管理这些不同的分区，我们需要一个分区表(partition table)，有时也被称为超级块(super block) 或 master file table。分区的相关信息就记录在分区表中，这些信息有开始和结束位置、分区类型和大小等。<br>在Windows中，磁盘分区常常与盘符相关联，每一个分区对应一个盘符（如 C: 、D:、E:等）。虽然一个物理磁盘可以分出多个盘符，但通常而言，一个物理磁盘我们当成一个分区使用。而在Linux系统中，磁盘通常会被分成多个分区，每个分区有不同的用途。例如，根分区（/）、引导分区（/boot）、交换分区（swap）等。<br><br>磁盘分区表的位置和大小会随着分区方式的不同而不同。我们学习过 MBR 和 GPT 两种分区模式。我们下面介绍这两种方式分区表存放位置。<br>主引导记录存放在磁盘的第一号扇区中，它包含了引导代码和分区表。MBR的大小通常为512字节，其中的bootloader占据446字节，分区表占据64字节。但如果系统采用 GPT 的分区方式，第一号扇区的大小就可能是 4KB 大小。<br>GPT(GUID Partition Table)：<br>
<br>LBA0：为了保证向下兼容，第一个扇区 LBA0 存放保护性 MBR。
<br>LBA1：存放 GPT header。
<br>LBA2-LBA34：存放GPT分区条目数组（即GPT分区表）。
<br>磁盘末尾：分区表的备份。
<br><br>和我们在一台电脑上可以安装多个操作系统一样，我们同样可以在操作系统上安装多个文件系统。但是每个分区只能有一个文件系统。多个分区我们可以有很多文件系统的话，问题就来了。在用户程序中我们使用的是统一的系统调用。当我们用统一接口的系统调用接口访问不同分区（文件系统）中的文件时，如何保证文件的正确访问？<br>我们的解决方案是：增加一层抽象：虚拟文件系统。我们将不同的文件系统统一交给VFS进行管理。VFS是文件系统之上的一层内核软件层，用于处理 POSIX 文件系统相关的系统调用，给各种不同的文件系统提供统一的操作接口，使得应用程序可以不必关心底层使用哪个文件系统。用户程序可以通过统一的接口来访问不同分区（文件系统）中的文件，而不会遇到兼容性问题。<br><img alt="Pasted image 20240824184231.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240824184231.png"><br>VFS的作用有两个。一个是上面我们所提到的，无所谓下面文件系统是怎么实现的，我们都可以通过VFS提供的统一接口来对文件进行操作。另一个是将系统中全部的文件进行唯一化标识。VFS通过使用 vnode 数据结构来唯一标识系统中的所有文件。<br>在传统文件系统中，FCB用于在分区内唯一标识文件，但在不同的分区中，FCB的唯一性无法得到保证。VFS通过 vnode 数据结构解决了这个问题，每个文件对应一个唯一的 vnode，使得即使在不同文件系统甚至在remote file system中，文件也能够被唯一标识。<br><br><br><br>对于文件，我们有很多操作，如创建文件、读文件、写文件、移动文件指针的位置(repositioning)、删除文件和文件的截断(truncation)。文件系统为我们提供了这些基本的文件操作的系统调用，下面我们来一起看一看。<br><br>当你对文件进行操作，你需要使用文件描述符(file descriptor)来对文件进行操作。在POSIX系统调用open()中，open()会返回给我们一个fd。而在C标准库中，我们会使用fopen()，其会返回一个指向FILE结构的指针。你可以用int fd = fileno(f);将FILE转换成fd。<br>#include &lt;stdio.h&gt;

// Use C standard library opening a file.
FILE* f = fopen(argv[1], "r");
if(f == NULL) {
	printf("Unable to open the file %s.\n", argv[1]);
	return -1;
}
/* Read the file.*/
fclose(f)

/*
Mode options in fopen() function:
r  : Open the file for reading only.(File must exist, or return NULL.)
w  : Create the file for writing. If file exist, it's overwritten.
a  : Open the file, writing data at the end of the file.(a for append)
r+ : Open for read and update.(File must exist, or return NULL.)
w+ : Create the file for reading/writing. If file exist, it's overwritten.
a+ : Same as above, but in rw mode.
*/
<br>#include &lt;stdio.h&gt;
#include &lt;fcntl.h&gt; // For open(), O_RDONLY, O_WRONLY, O_RDWR, and file access modes
#include &lt;unistd.h&gt;// For close(), read(), write(), fsync(), lseek(), and others.

// Use POSIX system call opening a file.
int fd = open(argv[1], O_RDONLY);
if (fd == -1) {
    perror("Unable to open the file");
    return -1;
}
/* Read the file.*/
close(fd);
<br>以上是两种打开文件的形式，第一种使用C标准库，提供了一种更高级易用的接口，而底下我们使用POSIX系统调用，相比之下更为直接，但是不够user friendly。因为，用户并不知情FILE实际上是一个整数。我们之后会了解到，文件描述符是一个表示打开文件的整数。<br>以下是打开和关闭文件的POSIX系统调用原型函数：<br>#include &lt;fcntl.h&gt; // For open(), O_RDONLY, O_WRONLY, O_RDWR, and file access modes
#include &lt;unistd.h&gt;// For close(), read(), write(), fsync(), lseek(), and others.
#include &lt;sys/types.h&gt; // For data types used in some system calls
#include &lt;sys/stat.h&gt;  // For file status and mode information

int open(const char *pathname, int flags, ...);
/* Parameters:

1. pathname: Pointer to the name of the file to be opened.
2. flags: File access modes and other flags.
   Common flags:
   - O_RDONLY: Open for reading only.
   - O_WRONLY: Open for writing only.
   - O_RDWR: Open for reading and writing.
   - O_CREAT: Create the file if it does not exist.
   - O_EXCL: Ensure that this call creates the file (fails if the file exists).
   - O_NOCTTY: If the pathname refers to a terminal, do not make it the controlling terminal.
   - O_TRUNC: Truncate the file to zero length if it already exists and is opened for writing.
   - O_APPEND: Open the file in append mode.
   - O_NONBLOCK: Open the file in non-blocking mode.
   - O_DSYNC: Write operations will complete according to the requirements of synchronized I/O data integrity completion.
   - O_SYNC: Write operations will complete according to the requirements of synchronized I/O file integrity completion.
   - O_RSYNC: Synchronize read operations.
   - O_DIRECT: Minimize or eliminate cache effects of the I/O to and from this file.

Return value: Returns a file descriptor on success, otherwise -1.
*/
<br>int close(int fd);
/* Parameters:

1. fd: File descriptor of the file to be closed.

Return value: Returns 0 on success, otherwise -1.
*/
<br><br>以下是读写文件和移动文件指针的 POSIX 系统调用。<br>off_t lseek(int fd, off_t offset, int whence);
/* Parameters:

1. fd: File descriptor of the file.
2. offset: Offset to set the file position to.
3. whence: Starting point for the offset (SEEK_SET, SEEK_CUR, SEEK_END).

Return value: Returns the resulting offset location on success, otherwise -1.
*/

ssize_t read(int fd, void *buf, size_t count);
/* Parameters:

1. fd: File descriptor of the file to read from.
2. buf: Buffer where the read data will be stored.
3. count: Number of bytes to read.

Return value: Returns the number of bytes read on success, otherwise -1.
*/

ssize_t write(int fd, const void *buf, size_t count);
/* Parameters:

1. fd: File descriptor of the file to write to.
2. buf: Buffer containing the data to be written.
3. count: Number of bytes to write.

Return value: Returns the number of bytes written on success, otherwise -1.
*/

int fsync(int fd);
/* Parameters:

1. fd: File descriptor of the file to be synchronized.

Return value: Returns 0 on success, otherwise -1.
*/
<br><br>remove 函数和 unlink 函数在删除文件时的行为是相同的。当我们使用 remove 或 unlink 删除文件时，实际上是删除了文件系统中的一个硬链接。如果文件有多个硬链接，只有指定的那个链接会被删除，文件的内容仍然存在，直到所有的硬链接都被删除为止。<br>#include &lt;stdio.h&gt;
int remove(const char *filename);
/* Parameters:

1. filename: Pointer to a null-terminated string that specifies the name of the file to be deleted.

Return value: Returns 0 on success, otherwise -1.
*/
<br>#include &lt;unistd.h&gt;
int unlink(const char *pathname);
/* Parameters:

1. pathname: Pointer to a null-terminated string that specifies the name of the file to be deleted.

Return value: Returns 0 on success, otherwise -1.
*/
<br><br>我们用文件描述符来对文件进行操作。而fd只是一个整型数，实际上并不能唯一的标识一个文件。就相当于厕所隔间里面的人，在某一刻，你能够确定厕所里就是这个人，你用xx号厕所来标识这个人，但是当这个人离开厕所，这个文件描述符将会失效。即在不同时刻，不同的文件可能使用相同的fd。<br><br>在第一节课，我们提到了文件的元数据，相当于文件的各种信息，这些信息被存储在文件控制块中。操作这些文件的创建修改删除是logical file system layer的工作。当我们要创建一个新的文件，对应着的，一个文件控制块也会随之被创建。系统内，每个文件的文件控制块都是唯一的。<br><img alt="Pasted image 20241127205724.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241127205724.jpg"><br>当用户想要读取系统中的某个文件时，操作系统就会把文件的文件控制块加载进内存。由于文件控制块中有文件的元数据，所以系统可以根据文件控制块中文件在磁盘上的位置来加载文件信息。<br><br>Inode实际上就是类Unix系统中的文件控制块。我们将在后续ext文件系统的学习中进行介绍。<br><br>由于文件系统要频繁地与磁盘进行交互，为了提升存储的性能，我们当然的会想到局部性原理，即caching来提升性能。实际上，文件系统的确有很多caching策略指导的结构。我们有：<br>
<br>Mount Table
<br>Cache
<br>Global Open File Table
<br>Process Open File Table
<br>Buffers
<br>为了避免频繁的访问I/O，这些文件系统的结构会被加载进内存中。我们将用演示文件的操作过程演示打开文件表是如何提高系统的效率的。<br><br>我们之前说，进程想要操作文件，就需要FCB中的信息。FCB载入内存需要我们使用open()系统调用，但之前，我们看到open系统调用返回的是fd，和FCB有什么关系？我们接着看。当进程打开文件时，OS就会在进程打开文件表里添加一个新表项。之后，操作系统会检查系统级打开文件表，如果没有找到关于该文件的表项，OS就会创建新的系统打开文件表项来跟踪文件的FCB。<br><img alt="Pasted image 20241128230955.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241128230955.jpg"><br>
进程打开文件表中存放着系统打开文件表表项的一个索引（fd），便于进程可以通过这个索引找到全局的系统打开文件表里面的表项，进一步对文件进行操作。进程打开文件表每个进程都有一张，每一个条目都对应着进程打开的文件和指向系统级打开文件表的指针，一般而言，进程打开文件表项数为1024，当然你可以将其设置的更高。include/linux/fdtable.h<br>当FCB加载到内存中后，系统用系统打开文件表对FCBs进行管理，系统打开文件表整个系统只有一张。系统打开文件表项的数据有文件名、文件打开方式、文件偏移量、文件的引用计数和FCB指针等信息。include/linux/fs.h<br>open文件调用会返回一个指向进程打开文件表中一个特定表项的索引，我们称其为文件描述符/文件句柄（unix中叫做file descriptor，而在windows中叫file handle）。<br><br>当进程要访问文件时，系统会根据文件的目录在磁盘上找到该文件的文件控制块。之后，将所需要的FCB都缓存在内核内存的FCB表/Inode表。然后系统在系统打开文件表中由相关的系统调用信息和FCB信息创建新的表项，其中有文件的一些元数据和一些其他信息。<br><img alt="Pasted image 20241018011136.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241018011136.png"><br><br>当我们使用open("example.txt", O_RDONLY);时会发生以下情况：<br>
<br>进程调用 open("example.txt", O_RDONLY)。<br>
2. 操作系统检查系统级打开文件表，发现 "example.txt" 已经被打开。<br>
3. 在进程级打开文件表中增加一个条目，指向系统级打开文件表中的 "example.txt" 条目，然后在全局的系统打开文件表中对文件的引用计数加一。<br>
4. 返回文件描述符 fd，指向进程级打开文件表中新增加的条目。
<br>操作系统检查系统级打开文件表，发现没有打开 "example.txt" 条目
<br>在磁盘目录中搜索 "example.txt"，如果找到了，那就在系统级打开文件表增加一个条目，将FCB加载到FCB表中，初始打开文件表项。最后将系统的打开文件表中对文件的引用计数设置为1。
<br>增加该进程级代开文件表的条目，用指针指向系统级打开文件表的对应条目。
<br>返回文件描述符 fd，指向进程级打开文件表中新增加的条目。
<br>在打开文件表中，除了文件的一些元数据外，还要存储文件引用计数信息，即这个文件被系统内的进程打开了多少次。每当使用open()或close()系统调用时，这个数值就会发生改变。只要不为0，该文件的元数据就会一直保留在内存的内核区中。<br><br>实际上，多个FD(file descriptor) 是可用指向相同的OFD(open file table descriptor)。像如下fd1和fd20都指向偏移为23的OFD（用dup2()复制文件描述符），还有两个进程的fd2都指向偏移为73的OFD（用fork()创建新的子进程）。<br><img alt="Pasted image 20241018011136.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241018011136.png"><br><br>偏移为0的OFD和偏移为86的OFD指向的却是同一个Inode。为什么？这可能是因为两个进程都独立的打开同一个文件。当不同文件描述符的行为不同时，即使多个文件描述符指向同一个文件，每个文件描述符的行为可能因为其具体的使用方式和上下文而有所不同。<br>比如两个文件描述符维护不同的文件偏移量或是不同的文件状态标志，就会出现多个OFD却指向同一个inode的情况。（说的简单一点就是数据结构不再相同了）<br><br><br><br><br>提到目录，大家都不会陌生。在小学一年级，老师就教过我们用字典目录去查汉字，拿到新的语文，我们可能会翻阅目录寻找自己感兴趣的文章去阅读。和”目录“这么久的交情，我们不难描述目录是一个怎么样的人：目录是一张对内容编排和组织的表，便于我们更好的找到特定的内容。<br><br>文件目录就是一张编排组织文件的表（数据结构），便于用户查找相关的文件信息。文件目录容纳其他文件和目录（文件夹），将这些文件和文件夹用某种结构组织起来。有了这种组织，文件和目录管理起来就更加便捷。<br><br>对于文件目录，文件系统需要支持关于目录的很多操作。最基础的就是用文件名来遍历查找文件，这是目录最基本的作用。此外，我们还想知道目录下有哪些文件，所以我们需要支持列出目录文件的功能。要查找文件，我们就得先创建文件，所以还需要支持文件的创建、删除和文件名的修改。<br>在命令行下，我们能见到很多目录相关的命令，例如：<br>
<br>查找文件find、locate
<br>创建文件touch
<br>删除文件rm
<br>显示当前目录pwd
<br>列出目录文件ls
<br>文件重命名mv、rename
<br>创建目录mkdir
<br>删除目录rmdir、rm -r
<br>切换目录cd
<br><br>文件的元数据存放在FCB中，文件系统通过FCB来实际控制管理一个文件；而目录是编排组织文件的表，通过目录中对相关文件的指针索引，实际上让我们得以访问对应文件的FCB，从而获取文件的详细信息并进行操作。文件目录以目录文件的形式存储在磁盘上，目录文件存储着系统目录的数据结构信息。<br><br>为了更好的组织、管理和访问文件，我们选用很多数据结构对文件目录进行记录。以下我们介绍几种构建文件目录时常见的目录形式。<br><br>单级目录是最简单的目录结构，所有的文件都放在同一个根目录下。由于这种结构将所有文件放在一起，所以单级目录要求所有文件名必须是唯一的。这种结构是实现起来最简单的，但是文件的命名唯一而且对文件缺少归纳。导致这种目录管理文件就是一摊鸡毛。<br><img alt="Pasted image 20241202010255.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241202010255.jpg"><br>在单级目录结构下，没有文件路径的概念。<br><br>在二级目录结构中，我们有一个主文件目录和子文件目录(sub-directories)。主文件目录可以向下级的用户文件目录提供索引。从而，每个用户可以拥有自己独立的目录来存储和管理文件。解决了一些单级目录中命名冲突问题，并为不同用户提供了文件隔离性。<br>从二级目录结构开始，文件路径有了意义，每个文件的文件路径(file pathname)在系统中都是唯一的。在引用文件时，如果确定当前的工作目录（用户目录），我们检索不包括用户名的文件时，操作系统会假设文件位于当前的工作目录下。这种不包含文件路径的路径名就是文件相对路径。<br>而绝对路径是指从根目录开始的完整路径，它包含了从根目录到目标文件或目录的所有目录名。例如，/user1/cat 就是一个绝对路径。无论当前工作目录是什么，通过绝对路径都可以唯一地定位到目标文件或目录。<br>在用户的目录下，用户无法创建新的目录来对文件进行进一步的归类。<br><img alt="Pasted image 20241202010304.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241202010304.jpg"><br><br>树形目录是二级目录结构的升级版，树形结构目录允许子目录创建条目的子目录树，从而消除了文件不能归类的问题。整个目录树有一个根目录，所有的文件或目录都会有包含root的唯一路径名。树形结构为系统带来了更好的灵活性和可变性，在树型结构中，进程可以从一个目录下“跳跃”到另一个目录，也因而，相对目录通常上性能更好（减少了“跳跃”的动作）。在Linux下，我们用"."来指代当前目录（如./hello）。<br><img alt="Pasted image 20241202010310.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241202010310.jpg"><br><br>上述的三种目录都不能够使得同一个文件/子目录在多个不同的目录下共享，用户访问其他用户的某些文件的愿望将无法得到满足。无环图目录允许一个文件/子目录同时存在于多个目录下，允许文件/子目录在用户多个间共享（不同目录访问同一个文件得到了实现）。<br><img alt="Pasted image 20241202010318.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241202010318.jpg"><br>这种共享性有时候会用符号链接，也就是软连接实现，有时候也会通过硬链接实现。这两种不同的链接形式我们马上就会了解到。<br><br>在无环图目录结构中，目录不可以成”环“。然而这种环状目录在通用图目录结构中是允许的。环状目录或者成环其实就是目录中包含循环到起点的路径，即在下级目录中包含上级目录。<br><img alt="Pasted image 20241202231218.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241202231218.jpg"><br>由于这种环状的存在，所以设计检索和遍历算法时就更加困难。这种环状可能导致遍历算法的无限循环，为了避免这种情况，设计者干脆禁止在目录中允许上级目录的存在。<br><br><br><br><br>在文件系统中，硬链接是一个指向数据块的直接引用，出现在inode中。硬链接使得多个文件名指向相同的inode，因此它们共享相同的数据内容。<br>软链接是一种特殊的文件类型，出现在目录项中，它包含指向另一个文件路径的指针，而不是直接指向数据块。因此，软链接相当于文件的快捷方式。<br><img alt="Pasted image 20240831003914.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240831003914.jpg"><br><br>在Linux中，我们用命令ln来创建一个硬链接，例如：<br>du@du-virtual-machine:~/Desktop/OS$ ./Hello
Hello world
du@du-virtual-machine:~/Desktop/OS$ ln Hello Hard_Link
du@du-virtual-machine:~/Desktop/OS$ ./Hard_Link 
Hello world
<br>创建硬链接之后，两个文件会共享相同的inode（如上面例子中的Hello和Hard_Link）。也就是说它们会指向相同的数据内容。我们用stat命令查看Hello文件的元数据，可得：<br>du@du-virtual-machine:~/Desktop/OS$ stat Hello
  File: Hello
  Size: 15960     	Blocks: 32         IO Block: 4096   regular file
Device: 803h/2051d	Inode: 1049216     Links: 2
Access: (0775/-rwxrwxr-x)  Uid: ( 1000/      du)   Gid: ( 1000/      du)
Access: 2024-08-31 00:06:02.431095349 +0800
Modify: 2024-08-31 00:04:56.176093580 +0800
Change: 2024-08-31 00:05:46.451336108 +0800
 Birth: 2024-08-31 00:04:56.128094303 +0800

du@du-virtual-machine:~/Desktop/OS$ stat Hard_Link 
  File: Hard_Link
  Size: 15960     	Blocks: 32         IO Block: 4096   regular file
Device: 803h/2051d	Inode: 1049216     Links: 2
Access: (0775/-rwxrwxr-x)  Uid: ( 1000/      du)   Gid: ( 1000/      du)
Access: 2024-08-31 00:06:02.431095349 +0800
Modify: 2024-08-31 00:04:56.176093580 +0800
Change: 2024-08-31 00:05:46.451336108 +0800
 Birth: 2024-08-31 00:04:56.128094303 +0800
<br>我们看到，这两个文件名所指向的数据都是一样的。我们看到Links字段为2，这表示当前有两个目录项指向这个文件，也是文件的硬链接数。当硬链接数为0时，文件系统就会释放并回收文件资源。<br><br>我们用ln -s命令来创建一个软链接：<br>du@du-virtual-machine:~/Desktop/OS$ ln -s Hello Soft_Link 
du@du-virtual-machine:~/Desktop/OS$ ./Soft_Link 
Hello world
<br>当软链接创建好后，软链接文件和源文件的inode并不相同。软链接本身是一个独立的文件，存储对源文件的路径引用。文件大小就是字符串的长度。我们用ls查看Soft_Link的大小，大小为5字节，正好是Hello文件名的长度。这里引用的是相对路径，但也可以引用绝对路径。<br>du@du-virtual-machine:~/Desktop/OS$ stat Soft_Link 
  File: Soft_Link -&gt; Hello
  Size: 5         	Blocks: 0          IO Block: 4096   symbolic link
Device: 803h/2051d	Inode: 1049994     Links: 1
Access: (0777/lrwxrwxrwx)  Uid: ( 1000/      du)   Gid: ( 1000/      du)
Access: 2024-08-31 00:43:40.242348874 +0800
Modify: 2024-08-31 00:43:40.238349935 +0800
Change: 2024-08-31 00:43:40.238349935 +0800
 Birth: 2024-08-31 00:43:40.238349935 +0800
du@du-virtual-machine:~/Desktop/OS$ ls -l Soft_Link 
lrwxrwxrwx 1 du du 5  8月 31 00:43 Soft_Link -&gt; Hello
du@du-virtual-machine:~/Desktop/OS$ ls -l Hard_Link 
-rwxrwxr-x 2 du du 15960  8月 31 00:04 Hard_Link
<br>当源文件被删除，软链接就会指向一个不存在的路径。这时，软链接会变为无效链接，这就是“断链”现象。<br><br><br>和内存的分配策略一样，文件系统在磁盘空间的利用上也有不同的分配方法。这节课我们将学习三种不同的分配方法，分别是contiguous、linked和indexed。但在此之前，我们先了解一下用户视角上的文件。<br><br>我们生活中的文件类型有很多种。您现在所看的算是一种线性的顺序结构，而当你看到这个系列，你可以直接点击阶段的大标题从而进入你想了解的阶段笔记进行学习，这是一种类似索引的结构。而在这个笔记中，我们有很多大标题小标题，这又可以看作是一种层次式的结构。在我们学习ELF文件时，文件中的数据又可以分段处理，这是一种分段式结构的文件。<br>文件的逻辑结构关注的是文件内容在用户视角下是如何组织的。即如何从软件层面组织和访问文件内容。上面提到过的四种逻辑结构有：<br>
<br>线性顺序结构/流式文件(Sequential Structure)：文件内容按顺序存储和访问，一般用纯 ASCII、Unicode 编写的字符文档的内容是按线性顺序存储的(能够cat的文件)。
<br>索引结构(Indexed Structure)：文件内容按索引表进行组织（如字典），索引表再指向实际数据的位置。索引结构允许快速定位到文件中某个特定数据上，常用于数据库文件或大型文件中，页表就是最常见的索引结构。
<br>层次式结构(Hierarchical Structure)：文件内部被组织成多级结构，每一级可以包含不同的数据段或子文件。层次化的逻辑结构有文件树形目录等。
<br>分段结构(Segmented Structure)：ELF 可执行文件就是这样分段的结构，文件中的内容被划分到各个独立的段中，每个段设置单独的属性分别管理。
<br><br>我们看到的文件（即逻辑上的文件）主要有两种访问方式：顺序访问和随机访问（直接访问）。还有其他的访问方式都是在这两种访问方式的基础上建立的。<br><br>顺序访问要求数据按照存储顺序从文件开头到结尾逐步读取或写入，你想看笔记的最有一小节时，你需要将笔记前面的内容全部加载到内存中。即便你只想要知道最后的内容，你也需要将文件整个加载。<br><img alt="Pasted image 20241202002753.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241202002753.jpg"><br><br>随机访问则允许直接跳转到文件中的任意位置进行读取或写入。由于文件内容可以非顺序处理，不需要将不需要的文件部分加载进内存，所以访问速度相较顺序访问要快。由于程序的局部性原理，在我们加载一些大型程序到内存中时，可能并不会将文件整个的加载进内存，这就是一种随机访问的文件访问方式。<br><img alt="Pasted image 20241202002801.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241202002801.jpg"><br><br>我们前面提到了四种文件结构，对于这四种不太文件结构的文件而言，它们会遵循不同的访问方式。对于线性顺序结构的文件来说，由于要读取访问下一个字符数据必须先访问上一个字符数据。所以文件的访问必须是连续的，这不难理解。<br>对于索引结构的文件来说，索引表可以让我们访问文件的不同位置。然而，通过索引表跳转之后，文件的访问转而变成线性顺序的访问（宏观上跳转，微观上连续）。类似的，由于层次化的结构相当于多级索引，我们可以跳转到我们想要数据的最小目录下访问，这个访问是线性连续的。<br>对于分段结构的文件，我们可以将其理解成类索引的顺序结构文件。在 ELF 中，我们将文件中不同的内容划分到各个节中，这些段相当于独立的线性顺序结构的文件，但我们通过节头表定义并索引了文件中各个节的位置及属性。在 ELF 文件中，文件访问同样是节外跳转、节内连续。<br><br>文件存放在持久性的存储设备上，文件的物理结构关注文件在硬盘、SSD等持久存储设备上的实际布局方式。文件的物理结构对于存储介质的特性、文件系统的实现密切相关（SSD可以随机存取；硬盘是随机存取+顺序存取；磁带只能顺序存取），主要包括以下几种形式：<br>
<br>连续分配(Contiguous Allocation)
<br>链式分配(Linked Allocation)
<br>索引分配(Indexed Allocation)
<br>多级索引(Multilevel Index)
<br>混合分配(Hybrid Allocation)
<br><br>连续分配就是指文件占用一组连续的磁盘块。逻辑上相连的块在物理上也相邻。所以这种分配方式带来的好处就是当磁头读到的文件位于磁盘块b时，读取下一个文件块b+1时，磁头并不需要怎么移动，也就不存在寻道时间了（最小的寻道时间）。在这种分配方式下，磁盘的目录项包括：<br>
<br>文件名
<br>第一个块的起始地址，块地址 = 扇区id（块大小 = 扇区大小）
<br>文件长度（块长度）
<br>即你只需要两个参数（起始块地址和文件长度）就能够keep track of this file。如果你需要读取 b+n 磁盘块中的内容，你只需要将磁头移动到相应的位置上，而不需要顺序一格一格地移动磁头，算是一种随机存取。这种方式可以轻易地实现对文件的顺序和直接访问。<br>而且这种方式在检查文件访问是否有效时非常简单，假设文件长度是 n，文件的起始块地址是 b。如果访问的磁盘块地址&gt; b + n，那么就可以断定这个访问是不合法的。<br><img alt="Pasted image 20240825132025.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240825132025.png"><br>享受完顺序分配给我们带来的简单性，我们就需要来承担相应的缺点。在顺序分配方式中，我们如果有一个大小为 N 个磁盘块的文件，在存储这个文件时，我们需要考虑：<br>
<br>磁盘分区中有没有这么大的空间能够被分配？
<br>如果有，我们应该选哪个空间？
<br>在磁盘空间动态分配时也可以选用不同的分配策略（首次适应、最佳适应、最差适应）。显而易见的是，这种分配方式会造成不可避免的外部碎片(external fragmentation)，内部碎片(internal fragmentation)由于被控制在一个块的大小内，所以我们不需要注意。在这种分配方式下，如果文件很大，所有孔的容纳不下，那么文件将无法载入磁盘。<br><br>除了要应对文件太大没有孔能够容纳这么大的文件之外，连续分配还给我们带来动态存储分配(dynamic storage allocation) 的问题。这是不可利用的外部碎片给连续分配方式带来的，这意味着大文件的扩展可能是很困难的。<br>对于外部碎片的处理，我们在内存分配的时候介绍过紧凑技术(compaction)，那对于磁盘而言，通过移动磁盘块，将非空闲的磁盘块紧凑在一块，那将会为我们带来很大的一块空闲空间。然而，磁盘可比内存慢多了，这么做的代价将会非常大。（Disk defragmentation for more）<br><br>好，既然我们不确定文件有多大，也不想任何外部碎片的产生，我们为何不将文件块链式地存放在磁盘上呢？将文件进行分割成块，分配在多个离散的磁盘块中，通过指针连接。不会产生任何的外部碎片，而且文件扩展较为容易。如何？<br>顺序分配和链式分配的关系相当于数组和链表之间的关系。链式分配带来了诸多好处，其中最主要的就是避免了任何的外部碎片。但是由于需要指向下一个磁盘块的指针和不能随机访问的特性，使得链式分配方式会不可避免地占用一点空间用于存储指针，并且速度慢（存在寻道时间）。<br><img alt="Pasted image 20240825132044.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240825132044.png"><br>链式分配方式的一大缺点就是当你要找一个文件块，你就必须得顺着指针链条往上找。所以一般的实现上，通常会结合连续分配和链式分配的优点。即以簇(clusters) 为单位进行连续分配，我们可以设置为4个块1个簇，然后将这些单位链接起来。这种方法可以提高访问速度，同时减少碎片问题。<br><br>如果你是原始链式分配的原教旨主义者，你就会将自己困在无法随机访问带来的访问速度的困境中。然而，我们可以给每个文件建立索引表，把所有的指针都顺序地放在一个磁盘块中，记录文件各逻辑块对应的物理块。这样就可以实现随机访问文件了，吸收了顺序分配的优点；而且不会产生任何的外部碎片，同样结合了链式分配的优点。<br><img alt="Pasted image 20240825132254.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240825132254.png"><br>这种分配方式真不错，既保留了顺序连续分配的优点，也保留了链式分配的优点。但是有一点不足，即当文件变得很大，我们就没有办法对文件进行分配了，因为一个块能够索引的大小很有限。对于这种窘境，人们想出来很多办法。如：将index block最后一个index entry作为下一个index block的entry（linked scheme）；加入上级的index对index block进行索引（multilevel index）；将上述的方法结合起来，这也是inode所使用的方式（combined scheme）。<br><br>下图展示了unix inode的multilevel indexing，在本阶段后续的课程中我们会详细介绍。<br><img alt="Pasted image 20241128030948.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241128030948.jpg"><br><br><br><br><br>我们学习了文件系统的设计。其中负责空闲空间管理的是文件组织模块/文件组织层。这个层次不单单负责逻辑块到物理块的转换，也负责逻辑上对磁盘存储块的管理，之后对逻辑块的管理进一步映射到物理块上。为了确保对磁盘的空闲空间能得到有效的利用，我们有许多对空闲空间管理的方法。我们接下来一个一个地介绍。<br><br>位图是一连串比特位的集合。在位图法中，我们用一位bit代表一块磁盘块。Bit可以取0和1，因而我们用0表示空磁盘块，用1表示已使用磁盘块。如下的磁盘空间就可以用16bits的位图：1111 0001 1111 1001 来表示。<br><img alt="Pasted image 20240826135306.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240826135306.png"><br>这种方式无论是理解还是实现都非常的简单。一个bit表示一个磁盘块，空间上也很划得来，利用率肯定不低。然而，如果我们暂时只能用磁盘很小一部分区域，位图法就会占有不该占有的内存空间。而且位图的大小是固定的，如果磁盘扩展，就需要重新初始化位图。<br><br>为了扩充磁盘的便利，我们可以使用链表。空闲链表法的实现方式就是将所有空闲块用链表链接起来。空闲块中包含指向下一个空闲块的指针，在下图的实现中，空闲空间链接头指向 Block5，然后 Block5 的指针域指向 Block6 以此类推。<br><img alt="Pasted image 20240826135310.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240826135310.png"><br>相比于位图法，空闲链表法的空间利用效率不会浪费其不该占用的内存空间。而且动态分配很容易，因而也可以动态的增加磁盘空间。但是指针动态分配的便利性也会造成该方法的指针维护很复杂，而且并不适合遍历。<br><br>这是空闲链表法的变种。不同于空闲链表，在分块成组法中，每一个空闲块的地址存放在 n 个磁盘块中，通过将这 n 个磁盘块链接起来，我们就能够轻松的找到那些未分配的磁盘块了（相当于索引+链接）。这种方式看起来很不错，因为我们可以很轻松的分配一大片空闲磁盘块。但是缺点也很明显，每一次的分配都会使得整个列表重新修正整个list。<br><img alt="Pasted image 20240826173012.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240826173012.png"><br><br>在counting的方法中，系统会用特定的格式（start base address, # numbers of free blocks）记录这些连续的空闲块。如果大多数连续空间块的长度超过了1块，那么这个列表将会非常紧凑。为了保证搜索、插入和删除的高效性，系统通常会用一个平衡树中存储这些记录。保证操作的效率。<br><br><br><br><br><br>文件分配表(File Allocation Table, FAT) 是链式分配的变种。最早由微软在1970年代为MS-DOS操作系统开发。由于简单的设计，FAT适用于各种各样的存储设备如软盘、硬盘、移动存储设备等。FAT采用簇链式存储分配，但簇中不再存放下一个簇的指针信息了，FAT会额外使用一块空间专门记录这些簇指针的信息，也就是FAT表，这也是FAT文件系统的特点和命名由来。<br>FAT早期版本包括 FAT12 和 FAT16，应用于存储容量较小的设备上，随着存储设备容量的不断增加，FAT32 被引入，用于支持更大的分区和文件大小。今天，NTFS代替了FAT作为Windows系统上应用的文件系统，但FAT32仍广泛应用在U盘上（兼容性佳）。<br><br>FAT文件系统下，磁盘结构被划分成引导扇区、文件分配表FAT、根目录区和数据区域。我们接下来逐步介绍。<br><br>作为磁盘分区的开始，为了保证计算机的正常启动，传统的，我们将第一个扇区作为引导扇区使用（第二个扇区可能会作为冗余对引导扇区进行备份）。引导扇区包括我们介绍过的启动代码和磁盘参数块(disk parameter block)，在磁盘参数块中包含磁盘的信息和文件系统的基本信息。<br>磁盘信息有：每个扇区多少字节、每个track几个扇区、磁头信息等。文件系统的信息有：FAT表数量、每个FAT表的扇区数、根目录项的数量、簇的信息等。<br><br>在引导扇区之后，作为FAT的重中之重，我们通常会看到两个相同的FAT表用于冗余和数据的恢复。每个FAT表都记录了磁盘上所有簇的状态和链表信息。FAT表是一个数组，其中的每个元素对应磁盘中的一个簇，元素的数值代表了该簇的状态：<br>
<br>值为0：簇空闲（空闲空间管理）
<br>值为正整数：簇已被占用，其中的数字指示下一个簇的编号
<br>值为EOF(-1)：文件结尾
<br><img alt="Pasted image 20240825132134.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240825132134.png"><br>通过把这些指针信息整合到一块，实际上FAT会比传统的簇链式方式要快很多。因为操作系统可以将整个FAT都加入到内存中（FAT不会很大），避免了对I/O的重复访问。<br><br>根目录区域(Root Directory)：存储文件和目录的目录项信息，包含文件名、扩展名、属性、创建时间、起始簇号等。<br><br>之后的一大片空闲的磁盘块就都用来作为数据区域(File and Directory Area)。这个区域存放文件和目录的数据内容。文件的数据被分配到多个簇中，簇之间通过FAT表链接。<br><br>我们常常会看到FAT16/FAT32，FAT后面的数字代表什么呢？这代表着FAT表中表项的位数，即FAT能够寻址的簇数。通过这个信息和簇大小信息，我们就可以得到最大分区大小是多大了。文件大小根据目录表项（FCB）中文件大小字段的位数决定。<br><br>FAT16的FAT表项是16bits，代表着每个表项可以表示  个不同的值，即65536个簇。FAT16通常使用32KB大小的簇。所以最大分区大小是：而目录项有32Bytes，其中文件大小属性占4Bytes（也就是32位）。所以单个文件大小为：虽然单个文件大小能达到4GB，但受限于最大分区大小，FAT16的单个文件最大为2GB。<br><br>同样，在FAT32中，FAT表项是32bits，但是实际上用于表示簇的有效位只有28位，其余的位数用来标记EOF和保留位。其余部分和FAT16相同的情况下，最大分区大小为：这可比4GB大多了，所以在FAT32中单个文件最大是4GB，和文件系统支持的最大文件大小相同。<br><br>我们现在能够明白FAT文件系统分区大小和单文件大小限制的因素有哪些，并且是如何影响FAT最大分区大小和最大文件大小的。然而FAT变种有很多，因此FAT16/32的最大文件大小或最大分区大小并不是固定的。根据不同的实现方式，所得出来的结果也是不一样的。<br><br>扩展文件系统是Linux系统中常见的文件系统，ext系统算是一种类UNIX文件系统的文件系统，ext的出现就是为了克服MINIX文件系统的一些缺点。在ext文件系统中的块(blocks)、索引节点(inodes) 和目录和一些文件所有权/访问权限(ownership/access)、链接(symbolic/hard links) 等都是继承传统UNIX文件系统的概念。<br>ext2是原始版本ext的重写，这些类UNIX文件系统的ext特点就是作为核心地位的“inode”。Ext2文件系统在1990年代初到2000年代初的近十年间，作为Linux的文件系统被广泛使用。后来，它被支持日志功能的文件系统ext3和ReiserFS所取代。<br><br>在ext2文件系统中，磁盘空间被划分为连续的逻辑块(blocks)。块大小并不需要与磁盘的物理扇区大小相同，因此块的大小还能更大，以便优化文件系统的性能和数据管理效率。在ext文件系统中，超级块负责卷空间信息的记录和管理。块大小由超级块中特定的字段所设置。<br>块大小一般会设置为是1024字节、2048字节或4096字节（ext2中块最大可以设置为65536个字节）。一旦文件系统初始化完成，块大小就将固定。块大小越小，存储文件产生的存储碎片就越少，但是相应地就会带来额外的管理开销（而且文件大小和文件系统大小就越小）。当前，主流的默认块大小是4KB。<br><br>块组是许多个块聚合在一起所构成的。磁盘空间被划分成了若干个块组，这样组织有效的避免了文件分散在磁盘的各个位置，从而减小了磁头的寻道时间；同时，也对碎片化有重要的影响。除此之外，块组中包含有一些重要数据的备份（如超级块等），使得文件系统能够在必要的时刻重建。<br><img alt="Pasted image 20241205203358.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241205203358.png"><br>磁盘被划分为若干个块组。每个块组由一定数量的块(Blocks)构成，包含：超级区块(Super Block)、组描述符表(Group Descriptor Table)、区块位图(Block Bitmap)、索引节点位图(Inode Bitmap)、索引节点表(Inode Table)、数据块区(Data Blocks)。<br>当一个文件的数据量超过一个块组的容量时，文件的数据块会分布在多个块组中。inode中的块指针可以指向不同块组中的数据块，从而实现跨块组的存储。一般而言，块组描述符表还会有一个备份，一个标准的块组0磁盘布局如下（N&gt;&gt;n）：<br><br><br>块组描述符表存储每个块组的基本信息，如inode表的起始块号、空闲块位图的起始块号等。<br><br>如果块大小是4KB，那么数据块位图和inode位图就能够表示  个的数据块和inode。在ext2/3中，inode占128B，那么inode表就需要占用  的磁盘空间。剩余数据块理论大小可达  。<br>上面这些是理论值的计算，实际上，我们可以设置inode和块数存在一定的对应关系。比方说一个块组中最多存放32个文件，那么inode表就只需要4KB的磁盘空间。<br><br>ext2文件系统所有核心配置信息都存储在超级块中，它包含了如文件系统中的inode总数、块总数、块大小、空闲块和空闲inode数量等信息，对于文件系统的正常运行和管理至关重要。超级块位于卷偏移1024字节后（boot loader之后），由于超级块的重要性，在最初的ext2版本中，每个块组中都会留有超级块的备份。之后的版本将组号为0、1还有奇数的平方作为超级块的备份块组使用。<br>ext2文件系统的超级块以小端方式存放在磁盘上，所以文件系统在不同机器上是可移植的。<br><br>struct ext2_super_block {
	__le32	s_inodes_count;		/* Inodes count */
	__le32	s_blocks_count;		/* Blocks count */
	__le32	s_r_blocks_count;	/* Reserved blocks count */
	__le32	s_free_blocks_count;	/* Free blocks count */
	__le32	s_free_inodes_count;	/* Free inodes count */
	__le32	s_first_data_block;	/* First Data Block */
	__le32	s_log_block_size;	/* Block size */
	__le32	s_log_frag_size;	/* Fragment size */
	__le32	s_blocks_per_group;	/* # Blocks per group */
	__le32	s_frags_per_group;	/* # Fragments per group */
	__le32	s_inodes_per_group;	/* # Inodes per group */
	__le32	s_mtime;		/* Mount time */
	__le32	s_wtime;		/* Write time */
	__le16	s_mnt_count;		/* Mount count */
	__le16	s_max_mnt_count;	/* Maximal mount count */
	__le16	s_magic;		/* Magic signature */
	__le16	s_state;		/* File system state */
	__le16	s_errors;		/* Behaviour when detecting errors */
	__le16	s_minor_rev_level; 	/* minor revision level */
	__le32	s_lastcheck;		/* time of last check */
	__le32	s_checkinterval;	/* max. time between checks */
	__le32	s_creator_os;		/* OS */
	__le32	s_rev_level;		/* Revision level */
	__le16	s_def_resuid;		/* Default uid for reserved blocks */
	__le16	s_def_resgid;		/* Default gid for reserved blocks */
	/*
	 * These fields are for EXT2_DYNAMIC_REV superblocks only.
	 *
	 * Note: the difference between the compatible feature set and
	 * the incompatible feature set is that if there is a bit set
	 * in the incompatible feature set that the kernel doesn't
	 * know about, it should refuse to mount the filesystem.
	 * 
	 * e2fsck's requirements are more strict; if it doesn't know
	 * about a feature in either the compatible or incompatible
	 * feature set, it must abort and not try to meddle with
	 * things it doesn't understand...
	 */
	__le32	s_first_ino; 		/* First non-reserved inode */
	__le16   s_inode_size; 		/* size of inode structure */
	__le16	s_block_group_nr; 	/* block group # of this superblock */
	__le32	s_feature_compat; 	/* compatible feature set */
	__le32	s_feature_incompat; 	/* incompatible feature set */
	__le32	s_feature_ro_compat; 	/* readonly-compatible feature set */
	__u8	s_uuid[16];		/* 128-bit uuid for volume */
	char	s_volume_name[16]; 	/* volume name */
	char	s_last_mounted[64]; 	/* directory where last mounted */
	__le32	s_algorithm_usage_bitmap; /* For compression */
	/*
	 * Performance hints.  Directory preallocation should only
	 * happen if the EXT2_COMPAT_PREALLOC flag is on.
	 */
	__u8	s_prealloc_blocks;	/* Nr of blocks to try to preallocate*/
	__u8	s_prealloc_dir_blocks;	/* Nr to preallocate for dirs */
	__u16	s_padding1;
	/*
	 * Journaling support valid if EXT3_FEATURE_COMPAT_HAS_JOURNAL set.
	 */
	__u8	s_journal_uuid[16];	/* uuid of journal superblock */
	__u32	s_journal_inum;		/* inode number of journal file */
	__u32	s_journal_dev;		/* device number of journal file */
	__u32	s_last_orphan;		/* start of list of inodes to delete */
	__u32	s_hash_seed[4];		/* HTREE hash seed */
	__u8	s_def_hash_version;	/* Default hash version to use */
	__u8	s_reserved_char_pad;
	__u16	s_reserved_word_pad;
	__le32	s_default_mount_opts;
 	__le32	s_first_meta_bg; 	/* First metablock block group */
	__u32	s_reserved[190];	/* Padding to the end of the block */
};
<br><br>Inode是ext2文件系统中的一个重要概念。Inode本质上是文件控制块，任何在ext2文件系统上的对象都需要用inode来表示，如文件、目录、符号链接等。inode中包含着除了文件名以外的所有文件元数据，如文件的权限(permissions)、所有者、组、flags、大小、使用的块数、访问创建修改删除时间、链接数、ACLs等。<br>每个块组都有一个线性数组来存储inode节点数据，这个数组被称为 inode table。在ext2/3中，每个inode需要128KB的存储。每个inode都属于一个特定的块组，并存储在相应的 inode table 中。<br><br>ext2/3的inode数据结构占用128个字节，ext4扩展为256个字节。以下是ext2/3的inode数据结构：<br><br>在ext2/3的inode数据结构中，最高的16bits数据用来表示类型和权限(Type and Permission)。其中 higher 4 bits 用来表示文件的类型，如：<br><br>Lower 12 bits are used to present file permission as following below：<br><br>我们用ls -alh命令就会看到相关的i_mode信息，如：<br>du@du-virtual-machine:~/Desktop/OS$ ls -alh
total 136K
drwxrwxr-x 3 du du 4.0K  8月 30 02:05 .
drwxr-xr-x 7 du du 4.0K  8月  8 05:09 ..
drwxrwxr-x 2 du du 4.0K  7月  1 00:51 critical_section
-rwxrwxr-x 1 du du  17K  7月  2 13:50 mutex
-rw-rw-r-- 1 du du 1.2K  7月  2 13:50 Mutex_locks.c
......
<br><br>inode本身并不存储数据信息，其会通过存放指向数据块的索引表来引用文件的实际内容。通常情况下，一个inode对应一个文件或目录，但通过硬链接，可以有多个文件名指向同一个inode。<br>索引文件数据块是inode最重要的功能，inode也因此得名（index-node）。inode通过一张索引表来索引文件文件块，这个索引表有15个字段，每个字段4字节，共60字节。记录了指向一个数据块的指针。其中有直接块(direct block)、单级间接块(single indirect)、双级间接块(double indirect)、三级间接块(triple indirect)。<br><img alt="Pasted image 20240825181709.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240825181709.png"><br>
<br>直接块指针：每个inode包含12个直接块指针，直接块指针直接指向一个数据块。
<br>单级间接块指针：一个单级间接块指针指向一个间接块表，间接块表中包含指向数据块的指针。若一个块4KB，每个指针大小为4字节，那么一个间接块表可以包含1024个直接块指针。
<br>双级间接块指针：一个双级间接块指针指向一个间接块表，间接块表中的每个指针又指向另一个间接块表。这样可以寻址更多的数据块。
<br>三级间接块指针：一个三级间接块指针指向一个间接块表，间接块表中的每个指针指向另一个间接块表，依次类推，直到最终指向数据块。
<br><br>通过多级间接寻址方式，ext2文件系统理论上能够在32位系统上支持高达4TB的文件大小。具体计算如下，假如一个块的大小为4KB：<br>
<br>直接块：12个块
<br>单级间接块：1024个块
<br>双级间接块：1024 * 1024个块
<br>三级间接块：1024  1024  1024个块
<br>总共可以寻址的块数为：总共可以寻址的文件大小为:<br>
<br>然而，实际上文件大小限制还要收到文件系统实现和内核的限制。根据<a data-tooltip-position="top" aria-label="https://docs.kernel.org/filesystems/ext2.html" rel="noopener nofollow" class="external-link" href="https://docs.kernel.org/filesystems/ext2.html" target="_blank">相关的Linux文档</a>，当块大小为1KB时，单个文件大小限制在16GB，2KB的块为256GB的文件大小限制，块大小更大时，单个文件最大大小为2TB。<br><br>在ext2文件系统中，目录也是以文件的形式存储在磁盘上的，目录文件的文件控制块（FCB）也是一个inode。在目录文件中包括许多目录项(Entry)，文件名和其inode编号就存放在目录项中，通过这一对文件信息可以检索到某一个文件。这些目录项使得操作系统可以通过文件名查找到对于文件的inode，进而访问文件的元数据和实际内容。目录项包含以下内容：<br><br>其中文件类型有以下几种：<br><br>ext2文件系统用单链表来存储目录中的文件名；在改进后的版本中，使用文件名的哈希值来进行查找，免去了对整个文件目录的扫描。<br><br>
<br>通过文件名获取inode编号：使用目录项（directory entry）查找文件名对应的inode编号。
<br>读取超级块：获取文件系统的基本信息，包括每个块的大小、每个块组中的块数量、每个块组中的inode数量以及块组描述符表的起始块位置。
<br>确定inode所属的块组：根据inode编号和每个块组中的inode数量，计算出inode所属的块组。
<br>读取块组描述符：读取对应块组的块组描述符，获取该块组的详细信息。
<br>提取inode表的位置：从块组描述符中提取该块组的inode表的起始位置。
<br>确定inode在inode表中的索引位置：根据inode编号和inode表的起始位置，计算出inode在inode表中的具体位置。
<br>读取指定的inode：通过索引inode表，读取出指定的inode，获取文件的元数据和指向数据块的指针。
<br><br><br><br>通过第六课的学习，我们已经对inode有了一定的认识，inode是类Unix系统中用于表示文件的数据结构。Inode意为索引节点，通过inode，我们可以对文件数据进行索引，这是inode的两个最主要的作用。如果有多个进程想要并发地使用同一个文件，我们该怎么做？我们先从文件锁开始介绍。<br><br>对一个文件的读写实际上就是我们在之前在同步问题中学到的读者写者问题。当文件打开时，程序会获得该文件的引用。如果你不想其他的应用程序使用文件，防止数据竞争和不一致问题，我们就可以将文件给锁起来。我们用fcntl系统调用来实现文件锁。<br><br>POSIX有个系统调用flock()，我们可以用它来对文件进行加锁。下面实现了一个对文件的互斥锁（一个写锁）。flock()有两个字段，第二个属性字段除了LOCK_EX之外，还有LOCK_SH用于设置一个共享的锁、LOCK_UN对锁进行解锁。<br>#include &lt;stdio.h&gt;
#include &lt;sys/file.h&gt;
FILE* f = fopen("example.txt", "r");
int fd = fileno(f);
int result = flock(fd, LOCK_EX);
<br>flock()的函数原型如下：<br>#include &lt;sys/file.h&gt;

int flock(int fd, int operation);
/* Parameters:

1. fd: File descriptor of the file to be locked.
2. operation: Operation to be performed (e.g., LOCK_SH for shared lock, LOCK_EX for exclusive lock, LOCK_UN for unlocking).

Return value: Returns 0 on success, otherwise -1.
*/
<br>这种写锁（LOCK_EX）只允许一个进程访问文件，对整个文件都进行了加锁。如此，其他进程不能读写该文件，如果我们想要对文件进行粒度更细的管理怎么办？我们可以使用POSIX提供的fctnl系统调用。 <br><br>fcntl() 提供了更复杂和灵活的文件锁定机制，支持对文件的部分区域进行锁定。通常情况下，部分锁定(partial locking)也会被称为记录锁定(record locking)。我们常常在data record中看到这种记录锁定。我们现在其实并不怎么使用这种部分锁定，因为有数据库在背后帮我们处理这些事情。<br>通过将文件划分成多个部分，例如6个部分，我们最多可以同时有6个程序对文件进行读写操作。fcntl()是一个强大的系统调用，命令字段实际上有很多参数信息。我们在这里只讨论关于文件锁的部分信息。以下是 fcntl() 的原型：<br>#include &lt;fcntl.h&gt;

int fcntl(int fd, int cmd, ... /* struct flock *lock */);
/* Parameters:

1. fd: File descriptor of the file to be locked.
2. cmd: Command to be performed. Common file locking commands include:
   - F_GETLK: Get record locking information.
   - F_SETLK: Set record locking information (non-blocking).
   - F_SETLKW: Set record locking information (blocking).
3. lock: Pointer to a struct flock that specifies the lock parameters (used with F_GETLK, F_SETLK, and F_SETLKW).

Return value: Returns 0 on success, otherwise -1.
*/
<br><br>这个系统调用的第一个参数是文件描述符，第二个参数是一些关于文件锁的一些命令，第三个参数是一个指向flock结构体的指针，这个结构体如下，这些字段并不难理解：<br>struct flock {
	short l_type;    // F_RDLCK, F_WRLCK, F_UNLCK
	short l_whence;  // SEEK_SET, SEEK_CUR, SEEK_END
	off_t l_start;   // offsets in bytes, relative to l_whence
	off_t l_len;     // length in bytes; 0 means lock to EOF
	pid_t l_pid;     // returned lock owner's PID with F_GETLK, otherwise return 0
}
<br>通过设置l_len字段，我们事实上可以将整个文件区域进行锁定，我们需要设置l_len = 0;<br><br>下面，我们来看fcntl的第二个参数。和文件锁相关的有三个命令，第一个命令F_GETLK就是检查指定的区域是否被其他进程所锁定。如果被锁定，那将把l_type设置为不同的锁类型并在l_pid字段返回持有锁进程的ID，如果没有被锁定，那就会将l_type设置为F_UNLCK。但是这个命令作用并不大，因为F_GETLK的检查并不是原子化的（我们检查时可能发生状态变化）。<br>下面的两个命令F_SETLK和F_SETLKW（set lock wait），两个命令的作用实际上非常相似，只是阻塞和非阻塞的区别。F_SETLK会尝试设置指定的锁定区域。如果锁定区域被其他进程锁定，调用将失败并返回 -1，并不会等待区域变为可用（和try_lock很像）；而F_SETLKW会在检查到区域锁定后阻塞并等待，直到锁定区域变为可用或接收到一个信号中断。<br>在应用中，我们并不会先检查指定区域是否可用后将区域锁定，而是通过F_SETLK的方式设置锁，如果当前程序可以等，那就将其阻塞，使用F_SETLKW确保程序后续能够将区域锁定。<br><br>int write_lock_file(int fd) {

	struct flock fl;
	fl.l_type = F_WRLOCK;
	fl.l_start = 0;
	fl.l_whence = SEEK_SET;
	fl.l_len = 0;    // Lock the entire file due to l_len = 0

	return fcntl(fd, F_SETLK, &amp;fl);
}
int unlock_file(int fd) {

	struct flock fl;
	fl.l_type = F_UNLOCK;
	fl.l_start = 0;
	fl.l_whence = SEEK_SET;
	fl.l_len = 0;    // Unlock the entire file

	return fcntl(fd, F_SETLK, &amp;fl);

}
<br>Lock the part of the file:<br>int fd = open("example.txt", O_RDONLY);

struct flock fl;
fl.l_type = F_RDLOCK;
fl.l_start = 1024;
fl.l_whence = SEEK_SET;
fl.l_len = 256;

fcntl(fd, F_GETLK, &amp;fl);

if(fl.l_type == F_UNLCK){
	// Lock is unlocked, we may proceed.
}
else if(fl.l_type == F_WRLOCK){
	printf("File is locked by process ID %d.\n", fl.l_pid);
	return -1;
}
<br><br>使用fcntl有两个缺点，那就是你要用重用结构体的话那就需要将结构体reset，你还需要确保字段的正确设置；此外，代码的逻辑需要额外地注意，当F_SETLK返回-1时，后续的逻辑流就不能够再出现相关F_UNLOCK的操作。<br><br>如果你不想让文件锁定操作那样复杂，那你可以使用lockf系统调用。在一些系统上，lockf是由fcntl系统调用封装而来的，但有的系统可能使用其他的机制。所以当你lock a file时，确保使用同样的系统调用来lock and unlock，避免可能出现的一些未定义行为。<br>#include &lt;unistd.h&gt;

int lockf(int fd, int command, off_t length);
/*
Parameters:

1. fd: File descriptor of the file to be locked.
2. command: Command to be performed. Common commands include:
   - F_LOCK: Lock a section of the file.(blocking)
   - F_TLOCK: Try to lock a section of the file (non-blocking).
   - F_ULOCK: Unlock a section of the file.
   - F_TEST: Test a section of the file for locks held by other processes.
3. length: Length of the section to be locked, in bytes. A value of 0 means to lock from the current position to the end of the file.

Return value: Returns 0 on success, otherwise -1.
*/
<br><br>mandatory locks do exist,but are hard to use and not recommended<br><br>除了上述我们学习过的这些文件锁，我们可以用文件来控制文件的并发访问。将一个文件的存在当作一把锁，如果文件存在，则说明区域已被锁定。Git会通过在特定的目录处放置一个index.lock的文件来指示进行中的操作。通过这个文件，git就能避免多个git客户端同时操作一个repo。<br>为了实现这种机制，我们可以使用以下的系统调用：<br>int open(const char *pathname, int flags);
int rename(const char* old_filename, const char* new_filename);
int remove(const char* filename);
<br>open系统调用有许多选项，在这种情形下，我们并不想使用”如果文件存在，则打开文件“的open系统调用。我们想要系统告诉我们：”如果文件存在，则创建失败并返回错误码“。所以我们要用O_CREAT和O_EXCL这两个flags。前者是创建文件，后者是exclusive的缩写，当两个一起使用时，就会在文件存时返回失败并设置errno为EEXIST。<br>用于open系统调用是原子化的，所以实际上避免了多个进程的并发问题。在操作完成后，我们用remove系统调用来删除文件，让下一个用户进程对文件或repo进行操作。<br>那rename系统调用是做什么的？rename系统调用和open一样，也是原子化的。这样，我们其实可以单单用rename来进行lock和unlock操作。改名就是锁定，解锁呢，就是将文件名改回来。<br><br>前面我们介绍了如何用文件作为锁来控制并发。在版本控制系统中，我们常常会看到两种不同的并发控制策略，分别是Lock-Modify-Unlock 和 Copy-Modify-Merge（也称为 Lock-Modify-Merge），它们在不同的场景下被使用。<br><br>Lock-Modify-Unlock常会用在集中式的版本控制系统中。在开发者修改文件之前，首先锁定文件，防止其他人同时修改（lock）；之后，开发者对文件进行修改（modify）；完成后解锁文件，运行其他人对文件进行修改（unlock）。以下是我们用文件作为锁对这种方式的简单实现：<br>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;pthread.h&gt;

#define NUM_THREADS 10

int lock_fd;
int shared = 0;

void* run(void* arg){
    int* id = (int*) arg;
    while(rename("file.lock", "file.unlock") == -1){ // Lock the lock
        // thread is waiting.
    }
    // thread in critical section
    printf("Thread %d is in the critical section.\n", *id);
    printf("Shared incremented from %d", shared);
    shared++;
    printf(" to %d.\n", shared);
    rename("file.unlock", "file.lock"); // Unlock the lock.
    
    free(arg);
    pthread_exit(NULL);
}

void* writer(void* arg){
    /* Write data implementation not shown*/
    pthread_exit(NULL);
}

int main(int argc, char** argv){
    lock_fd = open("file.lock", O_CREAT | O_EXCL, 0644);
    if(lock_fd == -1){
        printf("File creation failed.\n");
        return -1;
    }
    pthread_t threads[NUM_THREADS];
    for(int i = 0; i &lt; NUM_THREADS; i++){
        int* id = malloc(sizeof(int));
        *id = i;
        pthread_create(&amp;threads[i], NULL, run, id);
    }
    for(int i = 0; i &lt; NUM_THREADS; i++){
        pthread_join(threads[i], NULL);
    }
    close(lock_fd);
    remove("file.lock");
    return 0;
}
<br>这种方法确保了在修改期间没有其他人可以修改同一个文件，从而避免了冲突。然而，它也可能导致开发效率降低，因为其他开发者在等待锁释放时无法进行修改。<br><img alt="Pasted image 20241207162851.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241207162851.png"><br><br>而在分布式版本控制系统，如git中，有了分支的概念。多个开发者可以把代码从远程仓库复制到本地，每个开发者可以在自己的分支上独立开发，并行工作（copy-modify）；修改完成后，开发者可以将自己的分支合并到主分支，git会自动处理大部分的合并（merge）。<br>对文件的这些修改会被记录到项目的提交记录中。如果两个分支修改了同一文件的同一部分，那么这些修改将不会被自动合并，我们称之为冲突（conflict）。如果出现冲突，合并操作将暂停，直到冲突被手动解决。<br>为了避免不连续性，合并操作要么成功，要么失败，这是由事务机制实现的。事务(transaction) 相当于要一气呵成完成的一组操作，一个事务有两个开始事务和结束事务两个状态。在merge的过程中，对合并文件的一些检查会用一个log记录下来来进行检查，对事务的检查是不可中断的，如果发生冲突那么合并就会失败并回退到之前的状态（roll-back）并等待开发者的手动解决。<br><br>实际上，inotify应当被单拎出来。inotify是内核为我们提供的监视文件系统是否有事件发生的工具，它可以监控文件或目录的各种事件，如创建、删除、修改等。它本身并不是一个并发控制的工具，但一些情况下，inotify可以在并发控制中起到一些辅助的作用。<br>利用inotify API，你可以让你的程序对一些事件做出反应，比方说当某个文件被打开，程序做出一些响应。要让inotify给你发消息，你需要遵循以下步骤：<br>
<br>
初始化并创建一个管理结构：使用inotify_init函数初始化inotify实例，并获取一个文件描述符，用于管理这些事件。

<br>
添加监控事件：使用inotify_add_watch函数告诉内核你想监控哪些事件，并将这些事件加入到inotify实例中。

<br>
读取事件：内核会通过文件描述符通知进程事件发生的信息。你可以使用read函数读取这些事件，并根据需要进行处理。

<br>
关闭文件描述符：完成后，使用close函数关闭文件描述符，释放资源。

<br>值得注意的是，这个过程不是递归的。<br><br>我们有以下系统调用，初始化inotify的系统调用很好理解，即初始化创建一个inotify实例，一旦实例被创建，内核就会设置必要的数据结构和资源来管理inotify子系统。<br>#include &lt;sys/inotify.h&gt;

int inotify_init(void);
/*
Parameters: None

Return value: Returns a file descriptor for the inotify instance on success, otherwise -1.
*/
<br><img alt="Pasted image 20241207225739.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20241207225739.png"><br>实例创建完之后，我们就要用inotify_add_watch()来指定你想要以监视的文件或目录。系统调用inotify_add_watch()会返回一个监视描述符，用于唯一标识的监视项（文件）。另一个系统调用inotify_rm_watch()是将特定的wd从inotify instance中删去。<br>int inotify_add_watch(int fd, const char *pathname, uint32_t mask);
/*
Parameters:

1. fd: File descriptor returned by inotify_init.
2. pathname: Path to the file or directory to be monitored.
3. mask: Bitmask of events to be monitored. Common events include:
   - IN_ACCESS: File was accessed.(Read/Execute)
   - IN_MODIFY: File was modified.(Write for example)
   - IN_ATTRIB: Metadata changed.
   - IN_CLOSE_WRITE: File opened for writing was closed.
   - IN_CLOSE_NOWRITE: File not opened for writing was closed.
   - IN_OPEN: File was opened.
   - IN_MOVED_FROM: File was moved out of the watched directory.
   - IN_MOVED_TO: File was moved into the watched directory.
   - IN_CREATE: File or directory was created.
   - IN_DELETE: File or directory was deleted.
   - IN_DELETE_SELF: Watched file or directory was deleted.

Return value: Returns a watch descriptor on success, otherwise -1.
*/

int inotify_rm_watch(int fd, int wd);
/*
Parameters:
1. fd: File descriptor returned by inotify_init.
2. wd: Watch descriptor returned by inotify_add_watch.

Return value: Returns 0 on success, otherwise -1.
*/
<br><br>之后你可以read(fd, buf, size)，阻塞直到相应的事件发生。当你要监视的事件发生，inotify会将事件信息填充到 inotify_event 结构体中，并通过初始化得到的文件描述符返回给你。<br>struct inotify_event {
    int         wd;      // Watch descriptor
    uint32_t    mask;    // Bitmask of events that occurred
    uint32_t    cookie;  // Unique cookie associating related events
    uint32_t    len;     // Length of the name field
    char        name[];  // Optional null-terminated name of the file
};
<br>由于最有一个字段是可选的，因而inotify_event结构体大小为：<br>event_size = sizeof(struct inotify_event) + inotify_event.len;
<br>由于长度是不确定的，由此我们想要设置缓冲区时可能会设置的过大或过小。在设置缓冲区之前，我们可以用ioctl(inotify_fd, FIONREAD, &amp;numbytes)先获取文件当前可读取的长度。但一般情况下，我们会用空间换时间。<br><br>#include &lt;sys/inotify.h&gt;
#include &lt;unistd.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;stdbool.h&gt;

const char filename[] = "file.lock";

int main() {
    int lockFD;
    bool our_turn = false;

    while (!our_turn) {
        lockFD = open(filename, O_CREAT | O_EXCL | O_RDWR, 0666);
        if (lockFD == -1) {
            printf("The lock file is existing, and process %ld will wait...\n", (long)getpid());
            int notifyFD = inotify_init();
            uint32_t watch = inotify_add_watch(notifyFD, filename, IN_DELETE_SELF);
            int buf_size = sizeof(struct inotify_event) + strlen(filename) + 1;
            char* event_buffer = malloc(buf_size);
            printf("Setup complete, waiting for event.\n");
	        // Read the file descriptor while the event happens.(blocking)
            read(notifyFD, event_buffer, buf_size);
            struct inotify_event* event = (struct inotify_event*)event_buffer;
            printf("Event occurred!\n");

            free(event_buffer);
            inotify_rm_watch(notifyFD, watch);
            close(notifyFD);
        } 
        else {
            int namelen = sizeof(filename);
            write(lockFD, filename, namelen); 
            close(lockFD); 
            our_turn = true; 
        }
    }
    printf("Process %ld is in the critical area.\n", (long)getpid());
    // remove(filename);
    return 0;
}
<br><br><br><br>我们用文件系统管理磁盘来存储我们所需要的数据。然而，由于某些情况，文件系统中也可能会发生数据的丢失或数据的不连续（如系统掉电而文件还没有来得及写回磁盘）。为了发现文件系统中数据的不连续，我们可以周期性地检查系统中不连续的数据。<br>但由于一个volume可能很大，而且磁盘又很慢，所以检查一个volume上是否有不连续性的数据会很耗费时间。因此，系统在运行时并不会主动扫描磁盘。一般而言，系统启动的时候或者用户下达命令时才会扫描volume。UNIX中，用户可以使用 fsck 系统调用来扫描磁盘；Windows中，则可以使用 chkdsk/scandisk。<br><br>那么，什么是不连续状态？文件不连续后操作系统会如何反应？我们提到了系统掉电而文件没有来得及写回磁盘的情况。当系统重新上电后，我们会发现一部分文件块由于掉电时在内存中而遗失掉了，这就是文件的不连续状态。不连续的文件可能会导致一些严重的问题。<br>例如，我们本来要创建一个大小10个块的文件，在FCB中文件大小字段中就将其标识为10个磁盘块。然而，之后的文件链表中只包含有5个块。当使用这些系统调用工具检查出不连续状态时，我们希望系统能够把遗失的块找回来并链在一起，但文件系统可能并不能这么做，文件系统会修改相关的信息（如FCB的文件大小字段修改为5），从而保证文件的连续性。<br>系统视角下的recovery和我们想象中的recovery好像并不太一样，但不论怎样，现在文件是连续的了，系统内没有错误了。任务完成！<br><br>我们当然希望避免不连续问题的发生，以防因此出现严重的系统故障。避免因一些错误导致的数据不连续，你可能会想到原子操作。实际上，我们要使用避免数据不连续的方法事务其实我们可以看作原子操作的一种变种。事务使得操作要么完美地完成，要么就什么都不做。当今几乎所有的文件系统都会使用事务来避免data inconsistency的发生。<br>在版本控制系统和数据库中，为了使每个版本的数据都是连续的，这些软件会在修改文件相关结构之前，先列出一个待办事项清单。当这个待办事项清单中的所有待做项都完成之后，我们才会认为这个事务结束了，系统随之修改相关的数据结构。<br><br>ZFS使用single-atomic-update的事务机制来避免磁盘上的不连续性，这种机制类似于copy-modify-merge模型。数据先是从磁盘拷贝到内存，之后修改拷贝的磁盘块，最后将拷贝写回磁盘。这些修改后的新数据写回磁盘是并不会覆盖原旧数据块，而是将拷贝写到新磁盘块。这样其实为操作提供了冗余，如果写磁盘不连续，我们可以抛弃写回的数据块（即什么也不做）。如果操作一切顺利，那么我们就可以将旧磁盘块的引用用新的磁盘块所替代。<br>如果磁盘空间满了怎么办呢？那就买一块更大的后备硬盘吧！<br><br>APFS引入了文件系统快照(snapshots)，记录了某一时刻的文件系统状态。快照可以用于备份和恢复，确保在发生数据损坏或丢失时能够快速恢复到之前的状态。<br><br><br><br>在NTFS中，所有对文件元数据的修改都会顺序地放到一个日志文件(log文件)中，一旦修改写入日志文件后，系统才会实际修改文件的元数据。这种机制被称为日志记录(journaling)。当系统修改完文件的元数据后，系统会将日志文件中标记为“已完成”的日志记录（事务）进行相应的清理。<br>之后，当系统崩溃，日志文件中就可能包括0个或多个事务待处理。0个当然最好，你不需要担心任何事；如果届时日志文件中有多个事务还没有处理，就意味着仍有事务没有完成。我们将有两种解决方案：前进和回退。<br><br>当系统上电后，如果这个清单可以接着之前的做，那当然最好，我们实际上并没有损失什么。比如下载软件到一半之后，系统掉电，但是上电后我们可以接着之前的继续下载。<br><br>如果事务不能接着之前的做，系统就会回退到之前的版本，也就是在版本控制系统中常见的方式。<br><br>在NTFS中，日志记录的实现如下：<br>
<br>
当需要对文件元数据进行修改时，首先将这些修改记录在缓存中的日志文件里。这一步确保了所有修改操作都有一个记录，以防在实际写入磁盘之前发生故障。

<br>
在日志文件中记录修改后，系统会在缓存中进行实际的卷修改。这意味着这些修改还没有真正写入物理磁盘，但已经在内存中准备好了。

<br>
缓存管理器（cache manager）负责将缓存中的日志文件写入到物理磁盘上。这一步非常关键，因为它确保了日志记录的持久性，即使系统在此后崩溃，日志文件中的修改记录也不会丢失。

<br>
日志文件写入磁盘后，缓存管理器会开始将缓存中的卷修改写入到物理磁盘上。这一步确保了文件系统的一致性，因为即使在卷的实际修改过程中发生了系统故障，日志文件中的记录仍然可以用于恢复未完成的修改。

<br><br><br><br>]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/13.-file-systems.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/13. File Systems.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 21 Mar 2025 17:09:44 GMT</pubDate><enclosure url="https://congzhi.wiki/congzhi&apos;s-os-series/pics/hhd.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/congzhi&apos;s-os-series/pics/hhd.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[14. Asynchronous IO]]></title><description><![CDATA[ 
 <br><br><br><br>异步——Asynchronous这个单词由否定前缀 "A-" 、表示一起、同的前缀 "SYN-" 和表示时间的希腊词根 "CHRON" 构成。字面意思就是不同时/不同步的意思，也就是我们所说的异步。当然，你也可以理解为随机。<br>由于I/O完成的时间是随机的，我们总会担心I/O操作完成后的中断被错过，我们可能就会想到阻塞/自旋等待I/O操作的完成。这段阻塞/自旋的时间就会被白白浪费，这不是我们想要的。而通过异步I/O，CPU就可以在I/O操作完成前继续执行其他任务，不需要阻塞等待整个I/O操作完成。<br>其实就相当于等公交，你并不会在等公交时傻傻地盯着远处一直看，而是在等待的过程中做自己的事情，当公交车到了你听见哔哔~声才会停下手上的活去挤公交。<br><br>学过线程，我们可以用多个线程来处理多个I/O操作。如果线程被I/O阻塞了我们就重新创建一个线程。这确实是可行的，但是额外的线程就意为着多一份资源消耗和复杂性，滥用多线程可能并不是一个好的选择。况且有的语言并不支持多线程，如JavaScript，只有一个线程，我们别无选择。<br><br><br>不是所有的I/O操作都能够异步完成，在文件系统的章节中，我们会学到read()系统调用。read()就是一个阻塞的 I/O 操作，意味着当程序调用 read() 时，它会等待数据被读取到内存buffer后才继续执行后续的代码，当遇到阻塞的I/O操作，你只能同步等待I/O操作完成。<br>// Non-blocking file read. It still blocks, not what we expected.

int fd = open("example.txt", O_RDONLY | O_NONBLOCK);
int bytes_read = read(fd, buffer, numbytes);
// Do something here.
close(fd);
<br>尽管操作系统为我们提供了O_NONBLOCK的文件flag选项，但当设置文件的操作是O_NONBLOCK后，read()可能仍然会阻塞当前的线程。我们所想的是使用read()时，无论数据是否被放到缓冲区里，read()系统调用都应当立即返回一个返回值。但其实只有当使用 O_NONBLOCK 标志打开文件且没有数据可读，read() 调用才会立即返回。然而，对于磁盘文件，数据通常是立即可用的，因为文件系统会尽量将数据缓存到内存中。<br><br>不同于读文件的确定性，从网络socket中读信息时，我们不能确定socket什么时候能有数据，数据的大小是多少。所以，我们确实是可以把一个socket变成一个non-blocking的socket。<br>int sockfd = socket(AF_INET, SOCK_STREAM, 0);
fcntl(sockfd, F_SETFL, O_NONBLOCK);
<br>当设置非阻塞套接字后，accept(), recv() 和 recvfrom()都将是非阻塞的。这些系统调用将返回 -1 并设置 errno 为 EAGAIN 或 EWOULDBLOCK。<br><br>那设置non-blocking的sockets有什么用处？我们的服务器总是要服务许多的客户端，假设每个客户端对应一个socket连接，那么服务器就需要响应监听这么多的sockets连接。这些网络相关的系统调用往往是阻塞的，但我们并不想使用多线程来监听这些连接。通过设置非阻塞sockets，我们就不用被socket相关的系统调用所阻塞。进而，我们可以在主线程中轮询监听这些sockets，即tight polling。只在检测到客户端的连接时创建线程来响应服务客户端。<br><br>Tight polling(轮询)我们在<a data-tooltip-position="top" aria-label="12. IO Systems > 1.3.1 Tight Polling" data-href="12. IO Systems#1.3.1 Tight Polling" href="https://congzhi.wiki/congzhi's-os-series/12.-io-systems.html#1.3.1_Tight_Polling" class="internal-link" target="_self" rel="noopener nofollow">IO 阶段</a>中了解过。我们了解了tight polling会不停的循环问询浪费CPU资源，尽管简单，但是无法避免地CPU做无用功。所以我们并不想这么做。<br>内核为我们提供了一种更好的办法：select。select使得我们可以设置一个监视器来监视一组的套接字，并告诉我们组中每个套接字的状态。socket状态可以是待读、待写和发生异常情况三种状态。select()会根据socket的状态将sockets放到可读、可写和一些异常的三种集合中进行管理。<br>下面是select()系统调用的函数原型：<br>#include &lt;sys/select.h&gt; // For select() and related macros
#include &lt;sys/time.h&gt;   // For struct timeval
#include &lt;sys/types.h&gt;  // For data types used in some system calls
#include &lt;unistd.h&gt;     // For close(), read(), and other unix system calls

int select( int nfds, 
		    fd_set *_Nullable restrict readfds,
            fd_set *_Nullable restrict writefds,
            fd_set *_Nullable restrict exceptfds,
            struct timeval *_Nullable restrict timeout);
/* Parameters:

1. nfds: The highest-numbered file descriptor in any of the three sets, plus 1.
2. readfds: Pointer to an fd_set that will be checked for readability.
3. writefds: Pointer to an fd_set that will be checked for writability.
4. exceptfds: Pointer to an fd_set that will be checked for exceptional conditions.
5. timeout: Pointer to a struct timeval that specifies the maximum interval to wait for any file descriptor to become ready. If NULL, select() will block indefinitely.

Return value: 
- On success, returns the number of file descriptors contained in the three returned descriptor sets (that is, the total number of bits that are set in readfds, writefds, and exceptfds).
- On error, returns -1 and sets errno to indicate the error.
*/
<br><br>我们来看第一个参数，nfds 是要监视文件描述符集合中最大文件描述符的值加 1。它用于告诉 select() 要检查的文件描述符的范围。具体来说，select() 会监控文件描述符从 0 到 nfds - 1 的文件描述符，等待一个或多个文件描述符变为"ready"状态。为什么要这样？<br>许多系统将文件描述符的最大数量设置为 1024（FD_SETSIZE (1024)），也就是每个进程最多可以打开的文件数。因此，select() 的监视集合 fd_set 能够最多监视 1024 个文件描述符。fd_set 是用固定大小的 bit field (bit array) 来实现的，每个文件描述符对应一个 bit。<br>通过设置 nfds，在 select() 遍历时，内核遍历到最大的监视项后就会立即停止遍历。现在很多系统中，一个进程可能需要打开的文件数量可能要比 1024 个大得多。而 select() 最多也只能监视 1024 个文件描述符，这也是 select() 的缺点。在<a data-tooltip-position="top" aria-label="https://www.man7.org/linux/man-pages/man2/select.2.html" rel="noopener nofollow" class="external-link" href="https://www.man7.org/linux/man-pages/man2/select.2.html" target="_blank">select Linux manual</a>中，也推荐使用<a data-tooltip-position="top" aria-label="14. Asynchronous IO > 1.4 Alternative Poll" data-href="14. Asynchronous IO#1.4 Alternative Poll" href="https://congzhi.wiki/congzhi's-os-series/14.-asynchronous-io.html#1.4_Alternative_Poll" class="internal-link" target="_self" rel="noopener nofollow">poll</a>或<a data-tooltip-position="top" aria-label="14. Asynchronous IO > 1.5 epoll I/O Event Notification Facility" data-href="14. Asynchronous IO#1.5 epoll I/O Event Notification Facility" href="https://congzhi.wiki/congzhi's-os-series/14.-asynchronous-io.html#1.5_epoll_I/O_Event_Notification_Facility" class="internal-link" target="_self" rel="noopener nofollow">epoll</a>来获取更大的文件句柄监视范围。<br>我们用fd_set结构来定义该类型的结构：<br>#include &lt;sys/select.h&gt;

fd_set readfds;
<br><br>fd_set用于表示一个文件描述符的集合。在POSIX下，fd_set最多能够容纳的文件描述符的数量在FD_SETSIZE宏中定义，我们前面提到了，这个数字在很多系统中都是1024，而且可能不会改变。<br>select()提供了一些设置fd_set的函数，如下：<br>#include &lt;sys/select.h&gt; // For select() and related macros

void FD_ZERO(fd_set *set);
/* Parameters:

1. set: Pointer to an fd_set structure that will be initialized to have zero bits set, meaning no file descriptors are part of the set.
*/
<br>FD_ZERO(fd_set *set)用于初始化或清除一个fd_set结构，将其所有位清零，表示集合中没有任何文件描述符。由于 select 要循环地检查这些文件描述符，当要复用文件描述符时，你要重新进行初始化这些集合。<br>void FD_SET(int fd, fd_set *set);
/* Parameters:

1. fd: The file descriptor to be added to the set.
2. set: Pointer to an fd_set structure where the file descriptor will be added.
*/
<br>FD_SET(int fd, fd_set *set)用于将一个文件描述符添加到 fd_set 结构中。它会设置相应的位，表示该文件描述符现在是集合的一部分。<br>void FD_CLR(int fd, fd_set *set);
/* Parameters:

1. fd: The file descriptor to be removed from the set.
2. set: Pointer to an fd_set structure from which the file descriptor will be removed.
*/
<br>FD_CLR(int fd, fd_set *set)用于从 fd_set 结构中移除一个文件描述符。它会清除相应的 bit 位，表示该文件描述符不再是集合的一部分。<br>int FD_ISSET(int fd, fd_set *set);
/* Parameters:

1. fd: The file descriptor to be checked.
2. set: Pointer to an fd_set structure that will be checked to see if the file descriptor is part of the set.

Return value:
- Returns a non-zero value if the file descriptor is part of the set, otherwise returns 0.
*/
<br>FD_ISSET(int fd, fd_set *set)用于检查一个文件描述符是否在 fd_set 结构中。如果该文件描述符在集合中，则返回非零值，否则返回 0。<br><br>select()会将文件描述符归为三类，分别是可读(readfds)、可写(writefds)和异常(excaptfds)。这三类参数是可选的，当你不需要某一类时，你可以将那个参数设置为NULL。这三个参数也是select最重要的参数。<br><br>最后一个参数是timeval，这是一个结构体，用于指定 select() 等待文件描述符变为就绪的最大时间间隔。在这个等待时间内，select会阻塞直到（1）一个文件描述符准备好了；（2）被信号所中断；（3）时间到了。<br>timeval结构体的定义如下：<br>#include &lt;sys/time.h&gt;

struct timeval {
    long tv_sec;    /* seconds */
    long tv_usec;   /* microseconds */
};
<br>当你将两个字段都设置为0，select()就会立刻返回。要是sockets中有数据可读，select()就会告诉你，不然就会告诉你监视的fds都没有准备好呢。如果timeval为 NULL或者，select() 将无限期地阻塞，直到至少有一个文件描述符变为就绪。<br><br>无论因为何种原因导致select()的返回，除了 nfds 之外的一些参数可能会被更新。<br><br>当我们调用 select() 时，传入的文件描述符集合（readfds、writefds 和 exceptfds）会被内核修改，以反映哪些文件描述符在调用期间变为就绪状态。这是因为 select() 需要告诉你哪些文件描述符可以进行I/O操作，而不会阻塞。<br>例如，你传入一个包含多个文件描述符的 readfds 集合，select() 会在返回时修改这个集合，只保留那些在调用期间变为可读的文件描述符。这样，你可以通过检查返回的集合来确定哪些文件描述符可以进行读取操作。<br><br>如果在调用 select() 时传入了 timeval 结构体，内核可能（不）会修改这个结构体，以反映在调用期间实际经过的时间。如果你设置了一个 5 秒的超时时间，但 select() 在 2 秒后返回，有的操作系统内核实现可能会将 timeval 结构体中的剩余时间更新为 3 秒；而有些系统则会保留原先 5 秒的超时。因此，重新使用 timeval 结构体是不安全的，应该在每次调用 select() 前重新设置。<br><br>当select()返回时，它会将哪些可以直接进行的I/O操作保留在fd_sets里。要知道有哪些 I/O 操作，我们就需要迭代遍历检查我们之前添加过的所有文件描述符。这时，FD_ISSET 宏的作用就显现出来了。<br>因为 select() 调用会修改传入的参数，以反映哪些文件描述符已经准备好进行 I/O 操作，以及实际经过的时间。所以在处理完成一轮的 select() 调用之后，我们需要重新设置 fd_sets、timeval 甚至 nfds。<br><br>void listen_for_connections(int client_sock1, int client_sock2, int client_sock3);
{
	int nfds = 1 +  (client_sock1 &gt; client_sock2 
	                ?
	                (client_sock1 &gt; client_sock3 ? client_sock1 : client_sock3)
	                : 
	                (client_sock2 &gt; client_sock3 ? client_sock2 : client_sock3));

	fd_set s;
	struct timeval tv;
	ptintf("Startup complete!\n");
	while(!quit){
		FD_ZERO(&amp;s);
		FD_SET(service1_sock, &amp;s);
		FD_SET(service2_sock, &amp;s);
		FD_SET(service3_sock, &amp;s);
		tv.tv_sec = 30;
		tv.tv_usec = 0;

		int res = select(nfds, &amp;s, NULL, NULL, &amp;tv);
		// An Error occurred.
		if(res == -1){
			printf("An error occurred in selest(): %s.\n", strerror(errno));
			quit = 1;
		}
		else if(res == 0){
			printf("Still waiting events...\n");
		}
		else{
			if(FD_ISSET(service1_sock, &amp;s)){
				service1_activate();
			}
			if(FD_ISSET(service2_sock, &amp;s)){
				service2_activate();
			}
			if(FD_ISSET(service3_sock, &amp;s)){
				service3_activate();
			}
		}
	}
}
<br><br>除了select()，我们还有一个pselect()函数。pselect()的最后两个参数与select()有所不同。用于定义时间间隔的结构体timespec是一个const类型的参数，pselect()保证不对这个结构体的任何改变。另一个大的改变就是sigmask参数，用于定义哪些信号在等待期间被屏蔽。<br>pselect()的函数原型如下：<br>#include &lt;sys/select.h&gt; // For select() and related macros
#include &lt;sys/time.h&gt;   // For struct timeval
#include &lt;sys/types.h&gt;  // For data types used in some system calls
#include &lt;unistd.h&gt;     // For close(), read(), write(), and other system calls
#include &lt;signal.h&gt;     // For sigset_t and related functions

int pselect(int nfds, 
			fd_set *_Nullable restrict readfds,
            fd_set *_Nullable restrict writefds,
            fd_set *_Nullable restrict exceptfds,
            const struct timespec *_Nullable restrict timeout,
            const sigset_t *_Nullable restrict sigmask);
/* Parameters:

1. nfds: The highest-numbered file descriptor in any of the three sets, plus 1.
2. readfds: Pointer to an fd_set that will be checked for readability.
3. writefds: Pointer to an fd_set that will be checked for writability.
4. exceptfds: Pointer to an fd_set that will be checked for exceptional conditions.
5. timeout: Pointer to a struct timespec that specifies the maximum interval to wait for any file descriptor to become ready. If NULL, pselect() will block indefinitely.
6. sigmask: Pointer to a sigset_t that specifies the signal mask to be used during the wait. If NULL, the signal mask is not changed.

Return value: 
- On success, returns the number of file descriptors contained in the three returned descriptor sets (that is, the total number of bits that are set in readfds, writefds, and exceptfds).
- On error, returns -1 and sets errno to indicate the error.
*/
<br><br>pselect()中的timespec结构体容许我们设置更精细的时间间隔，它的结构体原型如下：<br>#include &lt;sys/time.h&gt;

struct timespec{
	long tv_sec; /* seconds */
	long tv_nsec; /* nanoseconds */
};
<br><br>允许你在调用pselect()的同时原子化地修改signal mask。在这个并发的世界中，我们对原子化的爱是毋庸置疑的。下面的一条pselect()语句：<br>ready = pselect(nfds, &amp;readfds, &amp;writefds, &amp;exceptfds, timeout, &amp;sigmask);
<br>和原子化的<br>sigset_t origmask;
pthread_sigmask(SIG_SETMASK, &amp;sigmask, &amp;origmask); // Mask the signals in sigmask.
ready = select(nfds, &amp;readfds, &amp;writefds, &amp;exceptfds, timeout);
pthread_sigmask(SIG_SETMASK, &amp;origmask, NULL); // Back to origmask stage.
<br>是等价的。<br><br>另一个与select相近的函数叫poll()，相比于select()，poll()要求的参数更少。现在，你不再需要计算最大的nfds是多少了，也不用再提供三种集合了，对于我们而言省了很多力气。但由于它们实现上的相近，poll()作为select()的表亲，并没有带来什么性能上的boost，它们都很慢。<br>poll()的函数原型如下：<br>#include &lt;poll.h&gt; // glibc library for poll() and related macros

int poll(struct pollfd *fds, nfds_t nfds, int timeout);
/* Parameters:

1. fds: Pointer to an array of struct pollfd, which specifies the file descriptors to be monitored.
2. nfds: The number of items in the fds array.
3. timeout: The maximum number of milliseconds that poll() will block. A negative value means an infinite timeout, while zero means poll() will return immediately.

Return value: 
- On success, returns the number of file descriptors with events, which may be zero if the timeout expired.
- On error, returns -1 and sets errno to indicate the error.
*/
<br><br>poll()将所有的监视项都放在了一个pollfd结构体类型的数组中。在使用时，你还需要提供数组的项数（你想让它监视多少项），这比select()方便了不少。你想指定的事件需要在pollfd结构体中说明，这个结构体的原型如下：<br>#include &lt;poll.h&gt;

struct pollfd{
    int fd;         /* file descriptor */
    short events;   /* requested events */
    short revents;  /* returned events */
};
/*
events/revents:
- POLLIN: Look for if there is data to read.
- POLLOUT: Writing is now possible without blocking.
- POLLRDHUP: Stream socket peer closed connection, or shut down writing half of connection.
- POLLPRI: There is urgent data to read.

revents specific(be ignored in events):
- POLLERR: Error condition.
- POLLHUP: Hang up, otherside closed socket.
- POLLNVAL: Invalid request: fd not open.

compiling with _XOPEN_SOURCE(additional bits):
- POLLRDNORM: equivalent to POLLIN
- POLLRDBAND
- POLLWRNORM
- POLLWRBAND
*/
<br>fd表示要监视的文件描述符。events是一个bit mask用于指定要监视何种事件，这是一个输入变量。revents是内核所设置的return events，用于标识当poll() 返回时，实际发生的事件。如果fd是一个负值，那么字段events就会被忽略，而且revents会返回0值。<br><br><br>void listen_for_connections(int client_sock1, int client_sock2, int client_sock3)
{
	struct pollfd pollfds[3];
	pollfds[0].fd = client_sock1;
	pollfds[0].events = POLLIN;
	pollfds[1].fd = client_sock2;
	pollfds[1].events = POLLIN;
	pollfds[2].fd = client_sock3;
	pollfds[2].events = POLLIN;
	int timeout = 30 * 1000;
	printf( "Going to start listening for socket events.\n" );

	while(!quit){
		int res = poll(&amp;pollfds, 3, timeout);
		// Error checking.
		if(res == -1){
			printf
			quit = 1;
		}
		// 0 sockets had events occur
		else if(res == 0){
			printf("Still waiting for events...\n");
		}
		// things happened
		else{
			if(pollfds[0].revents &amp; POLLIN){
				service0_activate();
			}
			if(pollfds[1].revents &amp; POLLIN){
				service1_activate();
			}
			if(pollfds[2].revents &amp; POLLIN){
				service2_activate();
			}						
		}
	}
}
<br><br>poll和ppoll的关系就如同select和pselect一样。同pselect一样，ppoll允许应用safely wait直到其中一个文件描述符准备好了或者有信号被捕获。<br>#define _GNU_SOURCE         /* See feature_test_macros(7) */
#include &lt;poll.h&gt;

int ppoll(struct pollfd *fds, nfds_t nfds,
		  const struct timespec *_Nullable tmo_p,
          const sigset_t *_Nullable sigmask);
<br><br>epoll()是一个 Linux-specific API，功能和poll()差不多，都通过监视一组文件描述符来看 I/O 是否可用。epoll API 所提供的特性要相比poll要多一些，epoll API 提供了边沿触发和电平触发两种使用接口。在高并发情境下，epoll API 的性能要好得多。<br><br>对于 epoll API 而言，最重要的就是 epoll instance 。epoll instance 是一个内核数据结构。在用户程序眼中，他就是一个包含两个列表的容器。这两个列表是 interest list(兴趣列表) 和 ready list(就绪列表)。从名字中你就能大致知道这两个列表的作用。<br>
<br>
Interest list 也叫 epoll set，是一个包含一些文件描述符的集合。在 interest list 中的文件描述符是用户进程所感兴趣的一些监视项。通过将这些感兴趣的文件描述符添加到 interest list 中，我们就能用 epoll API 让操作系统帮我们监视这些文件描述符的状态。

<br>
Ready list 是第二个列表。这个列表包含了那些准备好了进行 I/O 操作的文件描述符，ready list 是 interest list 的一个子集。一旦 interest list 中的文件描述符有 I/O 活动，内核就会动态地把相应的文件描述符添加到 ready list 中。

<br><br>我们前面学习的 select 和 poll 模型需要不断地遍历所有监听的文件描述符（时间复杂度  ），而 epoll 会通过回调机制仅仅跟踪活跃的文件描述符。内核会维护一个就绪列表，调用 epoll_wait 时直接返回就绪的文件描述符（时间复杂度 ），性能不随监听的fds数量增长而下降。<br>相比 select 和 poll ，epoll 使用共享内存映射 <a data-tooltip-position="top" aria-label="6.5 Inter-Process Communications > 第四课 Memory Mapped Files" data-href="6.5 Inter-Process Communications#第四课 Memory Mapped Files" href="https://congzhi.wiki/congzhi's-os-series/6.5-inter-process-communications.html#第四课_Memory_Mapped_Files" class="internal-link" target="_self" rel="noopener nofollow">mmap</a> ，避免了将文件描述符从内核态到用户态的复制（避免数据拷贝）。<br>此外，epoll 使用红黑树来存储 epoll instance。插入、删除、查找的时间复杂度均为  ，适合管理大量的文件描述符。<br><br>现在，我们先了解了解用来创建和管理 epoll instances 的系统调用：<br><br>要创建一个 epoll instance，我们有两种方式：epoll_create 和 epoll_create1。epoll_create 会创建一个 epoll instance。在 Linux 2.6.8 之后，内核会动态地检查 epoll instance，所以这个系统调用参数 size 会被忽略，但为了兼容新版本，size 必须比 0 大。<br>它的系统调用原型如下：<br>#include &lt;sys/epoll.h&gt;

int epoll_create(int size);
/* Parameters:

1. size: initial size (ignored in modern implementations, but must be &gt; 0)

Returns a file descriptor for the new epoll instance, or -1 on error.
*/
<br>在 Linux 2.6.27 后，内核提供了另一种创建 epoll instance 的系统调用。我们不再需要担心 size 是否大于 0 的问题了，而且还引入了 flags 参数。flags 可以是 0 或 EPOLL_CLOEXEC，用于在执行 exec 系列函数时自动关闭 epoll 文件描述符。<br>#include &lt;sys/epoll.h&gt;

int epoll_create1(int flags); // create a new epoll instance with flags
/* Parameters:

1. flags: epoll instance flags (0 or EPOLL_CLOEXEC)

Returns a file descriptor for the new epoll instance, or -1 on error.
*/
<br>当不再需要这些文件描述符后，记得用 close() 系统调用关闭掉相关的文件描述符。当 epoll instance 中的所有文件描述符都关闭后，内核就会销毁 instance 并释放相关联的资源。<br><br>在 epoll instance 创建好之后，我们就可以通过创建返回的 epfd 往 interest list 中添加、修改或删除 list entries（也就是文件描述符和 event 字段中特化的事件）。<br>以下是 epoll_ctl 系统调用的原型：<br>#include &lt;sys/epoll.h&gt;

int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); 
/* Parameters:

1. epfd: file descriptor returned by epoll_create or epoll_create1
2. op: operation to be performed 
	- EPOLL_CTL_ADD: Add an entry to the interest list of the epfd.
	- EPOLL_CTL_MOD: Change the settings associated with fd in the interest list
		             to the new settings specified in event.
	- EPOLL_CTL_DEL: Remove the target file descriptor fd from the interest list.
3. fd: file descriptor to be added, modified, or removed
4. event: pointer to epoll_event structure (can be NULL for EPOLL_CTL_DEL)

Returns 0 on success, or -1 on error.
*/
<br>除了我们刚才提到的 epfd 参数外，我们还有三个参数，分别是 op, fd, 和一个指针指向结构体 epoll_event。最开始的时候，epoll instance  为空，我们就需要在 op 上填入 EPOLL_CTL_ADD 来向 interest list 中添加相关的文件描述符，同时，在 epoll_event 结构体中选择让内核按何种方式来监视这些文件描述符。<br>op 字段提供将某个文件描述符加入到 interest list 中进行监视、fd 字段指示监视项、event 主要是一些监视选项。结构体 struct epoll_event 原型如下：<br>#include &lt;sys/epoll.h&gt;

struct epoll_event {
    uint32_t      events;  /* Epoll events */
    epoll_data_t  data;    /* User data variable */
};
/*
events/revents:
- POLLIN: Look for if there is data to read.
- POLLOUT: Writing is now possible without blocking.
- POLLRDHUP: Stream socket peer closed connection, or shut down writing half of connection.
- POLLPRI: There is urgent data to read.

revent specific:
- POLLERR: Error condition happened.
- POLLHUP: Hang up, otherside closed socket.
- POLLNVAL: Invalid request: fd not open.

additional epoll-specific flags:
- EPOLLET: Requests edge-triggered notification.
- EPOLLONESHOT: Requests one-shot notification.
- EPOLLWAKEUP: Prevent system suspend while event is pending.
- EPOLLEXCLUSIVE: Sets exclusive wakeup mode.
*/
union epoll_data {
    void     *ptr;
    int       fd;
    uint32_t  u32;
    uint64_t  u64;
};
<br><br><br>#include &lt;sys/epoll.h&gt;

int epoll_pwait(int epfd, struct epoll_event events[.maxevents],
                int maxevents, int timeout,
                const sigset_t *_Nullable sigmask);
int epoll_pwait2(int epfd, struct epoll_event events[.maxevents],
                 int maxevents, const struct timespec *_Nullable timeout,
                 const sigset_t *_Nullable sigmask);
<br><br><br><br>第一节课的时候，我们学习了三个用于服务器上的异步I/O处理方式。本节课，我们来了解一些如何通过Client URL来处理网络客户端上的异步I/O。cURL是一个用户程序，也作为libcurl中的库函数默认包含在Linux、MacOS这样的类Unix系统中。通过包含头文件curl/curl.h，你就能在你的程序中使用libcurl库来请求HTTP服务、下载文件和一些其他的网络服务。<br>大多数的资源在服务器的手中，客户端想要某些资源就需要向服务器发送响应的请求。当你使用cURL进行请求时，默认的cURL API（curl_easy_perform()）会阻塞我们的程序。而通过上节课，我们知道，这种阻塞并不是我们想要的。我们想不浪费资源的同时提高程序的效率。<br>幸运的是，libcurl库中有能够让我们同时handle多个异步IO的API。curl_multi允许客户端同时进行多个网络操作请求，而且不会阻塞用户程序。但再此之前，我们先来看看EZ的那个。<br><br>在使用这些libcurl的库函数之前，我们需要调用curl_global_init()进行全局初始化，并在程序结束时调用curl_global_cleanup()进行全局清理。<br>下面是它们的函数原型：<br>#include &lt;curl/curl.h&gt;

CURLcode curl_global_init(long flags);
/* Initializes the cURL library globally.
   Parameters:
   1. flags: Bitmask of options to initialize. Commonly used values include:
      - CURL_GLOBAL_DEFAULT: Initialize all supported features (equivalent to CURL_GLOBAL_SSL | CURL_GLOBAL_WIN32).
      - CURL_GLOBAL_SSL: Initialize SSL.
      - CURL_GLOBAL_WIN32: Initialize Windows-specific features.
      - CURL_GLOBAL_ALL: Equivalent to CURL_GLOBAL_DEFAULT.
      - CURL_GLOBAL_NOTHING: Initialize no features.
   Return value:
   - On success, returns CURLE_OK.
   - On failure, returns a CURLcode error value. Those error values include:
	   - CURLE_UNSUPPORTED_PROTOCOL
	   - CURLE_FAILED_INIT
	   - CURLE_URL_MALFORMAT
	   - CURLE_COULDNT_RESOLVE_HOST
	   - CURLE_COULDNT_CONNECT
	   - CURLE_OPERATION_TIMEDOUT
	   - CURLE_SSL_CONNECT_ERROR
	   - CURLE_PEER_FAILED_VERIFICATION
*/
<br>CURLcode curl_global_init(long flags);为我们提供了一些可选项。一般我们会使用在flags字段中填入CURL_GLOBAL_DEFAULT，表示初始化所有cURL支持的功能，它和CURL_GLOBAL_ALL是等价的。在初始化完成之后，用户会得到CURLcode类型的返回值，用于反馈操作结果。<br>void curl_global_cleanup(void);
/* Cleans up the cURL library globally.
   Parameters: None.
   Return value: None.
*/
<br>在程序结束或我们不再需要cURL库的服务时，我们就可以使用curl_global_cleanup(void)全局清理cURL库。这个函数不需要任何参数，也不会有返回值。<br><br><br>libcurl库为我们提供了一些库函数用于与cURL进行交互，这些函数使得我们可以方便地进行网络请求和数据传输。通过使用这些库函数，我们可以实现HTTP、HTTPS、FTP等多种协议的支持。在cURL Easy API Interface中，我们会使用cURL easy handle来获取cURL的服务。<br>libcurl库为我们提供了一些库函数用于与cURL进行交互，这些函数使得我们可以方便地进行网络请求和数据传输。通过使用这些库函数，我们可以实现HTTP、HTTPS、FTP等多种协议的支持。在cURL Easy API Interface中，我们会使用cURL easy handle来获取cURL的服务。<br><br>在全局初始化完成之后，我们就可以获取cURL handle并设置相应的选项来获取cURL的服务。其中我们用curl_easy_init()初始化并获取一个cURL easy handle，用curl_easy_setopt()设置handle的属性。<br>下面是这两个函数的原型：<br>CURL *curl_easy_init(void);
/* Initializes a CURL easy handle.
   Return value:
   - On success, returns a pointer to a CURL easy handle.
   - On failure, returns NULL.
*/
<br>curl_easy_init()并不需要什么参数，如果初始化成功完成，它会返回一个指向初始化handle的指针，如果失败，它会返回NULL。<br>CURLcode curl_easy_setopt(CURL *handle, CURLoption option, ...);
/* Sets options for a CURL easy handle.
   Parameters:
   1. handle: The CURL easy handle.
   2. option: The option to set. Common options include:
      - CURLOPT_URL: The URL to fetch.
      - CURLOPT_POSTFIELDS: The data to send in a POST request.
      - CURLOPT_HTTPHEADER: A linked list of HTTP headers to include in the request.
      - CURLOPT_WRITEFUNCTION: A callback function to handle data received from the server.
      - CURLOPT_WRITEDATA: A pointer to pass to the write callback function.
      - CURLOPT_READFUNCTION: A callback function to handle data sent to the server.
      - CURLOPT_READDATA: A pointer to pass to the read callback function.
      - CURLOPT_TIMEOUT: The maximum time in seconds that the request is allowed to take.
   3. ...: The value to set for the option, depends on the option being set.
   Return value:
   - On success, returns CURLE_OK.
   - On failure, returns a CURLcode error value.
*/
<br>curl_easy_setopt()要复杂的多。这个库函数会根据不同的设置项来配置&nbsp;cURL&nbsp;easy&nbsp;handle&nbsp;的行为。而且每个选项后面的参数类型会根据不同的选项而有所不同。<br><br>全部的全部完成之后，我们就可以使用curl_easy_perform()来执行请求了。<br>CURLcode curl_easy_perform(CURL *handle);
/* Performs the file transfer.
   Parameters:
   1. handle: The CURL easy handle.
   Return value:
   - On success, returns CURLE_OK.
   - On failure, returns a CURLcode error value.
*/
<br><br>完成请求后，我们使用curl_easy_cleanup()来清理handle。<br>void curl_easy_cleanup(CURL *handle);
/* Cleans up a CURL easy handle.
   Parameters:
   1. handle: The CURL easy handle to clean up.
   Return value: None.
*/
<br><br>在上面，我们看到好几个函数都会返回的CURLcode用于指示函数是否正常运行。我们可以通过库函数curl_easy_strerror()&nbsp;来查看具体的错误信息。这个函数会返回一个描述错误的字符串，帮助我们理解问题之所在。<br>以下是&nbsp;curl_easy_strerror()&nbsp;的函数原型：<br>const char *curl_easy_strerror(CURLcode errornum);
/* Returns a string describing the CURLcode error.
   Parameters:
   1. errornum: The CURLcode error value.
   Return value:
   - Returns a pointer to a null-terminated string describing the error.
*/
<br><br>#include &lt;stdio.h&gt;
#include &lt;curl/curl.h&gt;

int main(int argc, char** argv){
    CURL *curl;
    CURLcode res;

    curl_global_init(CURL_GLOBAL_DEFAULT);

    curl = curl_easy_init();
    if(curl){
        curl_easy_setopt(curl, CURLOPT_URL, "https://example.com/");
        res = curl_easy_perform(curl);
    }
    if(res != CURLE_OK){
        fprintf(stderr, "curl_easy_perform() failed: %s\n",
				curl_easy_strerror(res));
        curl_easy_cleanup(curl);
    }
    curl_global_cleanup();
    return 0;
}
<br>这个例子什么都好，但在res = curl_easy_perform(curl);这一步会阻塞，这就是easy perform最大的缺点。<br><br>为了确保一个线程能够操作多个异步I/O，libcurl库中还提供了cURL&nbsp;multi&nbsp;API。cURL&nbsp;multi用于管理一组easy&nbsp;handles，通过将多个easy&nbsp;handles放到一个队列中，并检查它们的状态来实现异步I/O。我们将包含多个easy handles队列的这样一个结构叫做multi handle。<br>因为 cURL multi 是在 cURL easy 的基础上建立起来的，所以在使用cURL multi时，我们仍然需要进行cURL全局上的初始化、清理等。此外，由于我们引入了新的结构，我们需要一个新的类型来表示multi handle。在libcurl中，这个结构叫CURLM。<br><br><br>curl_multi&nbsp;内部维护了两个队列，分别是正在进行的传输队列和已经完成的传输队列。当curl multi handle初始化完成后，两个队列也随之初始化。<br>此外，multi init还会初始化内部状态和数据结构、分配必要的资源和内存等。<br>函数原型如下：<br>#include &lt;curl/multi.h&gt; // Included &lt;curl/curl.h&gt;

CURLM *curl_multi_init(void);
/* Initializes a CURL multi handle.
   Return value:
   - On success, returns a pointer to a CURL multi handle.
   - On failure, returns NULL.
*/
<br><br>我们有了新的结构后，我们可以往里面添加任意数量的easy handle。我们所添加的easy handles就会被放到正在进行的传输队列中。<br>CURLMcode curl_multi_add_handle(CURLM *multi_handle, CURL *easy_handle);
/* Adds a CURL easy handle to a CURL multi handle.
   Parameters:
   1. multi_handle: The CURL multi handle.
   2. easy_handle: The CURL easy handle to add.
   Return value:
   - On success, returns CURLM_OK.
   - On failure, returns a CURLMcode error value.
*/
<br><br>在添加完需要添加的easy handles之后，我们就可以使用curl_multi_perform()来启动多个并发的网络请求（第一次使用），这个函数会立即返回正在进行传输队列中的easy handles的数量，所以这些请求不会阻塞当前程序。<br>其函数原型如下：<br>CURLMcode curl_multi_perform(CURLM *multi_handle, int *still_running_handles);
/* Performs the transfers for all added handles.
   Parameters:
   1. multi_handle: The CURL multi handle.
   2. still_running_handles: Pointer to an integer that will be set to the number of running handles.
   Return value:
   - On success, returns CURLM_OK.
   - On failure, returns a CURLMcode error value.
*/
<br>启用后，当我们使用curl_multi_perform()时，它会更新参数still_running_handles用于指示multi handle中仍在进行传输的easy handles的数量。当这个参数指向的数字变成0，你就知道IO全部完成了。而这就意味着我们需要多次调用curl_multi_perform()，这是否意味着我们在轮询呢？<br><br>尽管我们实现了在一个线程中处理多个IO，我们仍不希望无意义的轮询占用太多CPU时间。为了解决这个问题，libcurl 提供了 curl_multi_wait() 函数，它可以在有数据可读或可写之前阻塞一段时间，让紧轮询变成松轮询。<br>下面是它的函数原型：<br>CURLMcode curl_multi_wait(CURLM *multi_handle, struct curl_waitfd extra_fds[], unsigned int extra_nfds, int timeout_ms, int *numfds);
/* Waits for activity on any of the curl easy handles within a multi handle.
   Parameters:
   1. multi_handle: The CURL multi handle.
   2. extra_fds: An array of extra fds to wait on.(NULL)
   3. extra_nfds: The number of extra file descriptors.(0)
   4. timeout_ms: The maximum time to wait in milliseconds.
   5. numfds: Pointer to an integer number of "interesting" events occurred.
   Return value:
   - On success, returns CURLM_OK.
   - On failure, returns a CURLMcode error value.
*/
<br>同样的，我们可以用curl_mulri_strerror()来查看发生了什么错误。<br>const char *curl_multi_strerror(CURLMcode errornum);
/* Returns a string describing the CURLMcode error.
   Parameters:
   1. errornum: The CURLMcode error value.
   Return value:
   - Returns a pointer to a null-terminated string describing the error.
*/
<br><br>当加入cURL multi的cURL easy handle完成传输任务后，curl multi就会将其添加到一个已完成传输的队列中。之后我们就可以通过curl_multi_info_read()读取easy handle的状态了。<br>curl_multi_info_read()的函数原型如下：<br>CURLMsg *curl_multi_info_read(CURLM *multi_handle, int *msgs_left);
/* Reads information about completed transfers.
   Parameters:
   1. multi_handle: The CURL multi handle.
   2. msgs_left: Pointer to an integer that will be set to the number of messages left in the queue.
   Return value:
   - On success, returns a pointer to a CURLMsg structure.
   - On failure, returns NULL.
*/
<br>当读取成功时，curl_multi_info_read()会返回一个结构体并将所读取的curl easy从完成传输队列中移除。CURLMsg是一个结构体，用于提供有关传输完成的详细信息。它的原型如下：<br>typedef struct {
    CURLMSG msg;       /* What this message means */
    CURL *easy_handle; /* The handle it concerns */
    union {
        void *whatever; /* Message-specific data */
        CURLcode result; /* Return code for transfer */
    } data;
} CURLMsg;
<br>这个结构体的第一个字段CURLMSG表示消息的类型。这是一个枚举类型，可能的值有CURLMSG_DONE表示传输完成和CURLMSG_ERR表示有发生错误。<br>第二个字段表示与当前消息相关联的easy handle。<br>第三个字段是一个联合体data，用于存储不同的类型，其中CURLcode result;表示curl easy传输的结果，我们前面见过。<br><br>当一个easy handle完成后，我们就可以将它从multi handle中移除出去了。我们可以通过msg-&gt;easy_handle在结构体CURLMsg中获取到确切的easy_handle。然后通过相关的库函数将其移除并进行清理。（curl_easy_cleanup(CURL* eh)）<br>curl_multi_remove_handle()的函数原型如下：<br>CURLMcode curl_multi_remove_handle(CURLM *multi_handle, CURL *easy_handle);
/* Removes an easy handle from a multi handle.
   Parameters:
   1. multi_handle: The CURL multi handle.
   2. easy_handle: The CURL easy handle to remove.
   Return value:
   - On success, returns CURLM_OK.
   - On failure, returns a CURLMcode error value, such as:
     - CURLM_BAD_HANDLE: The provided multi handle is invalid.
     - CURLM_BAD_EASY_HANDLE: The provided easy handle is invalid.
     - CURLM_OUT_OF_MEMORY: Memory allocation failed.
*/
<br><br>当我们不再需要curl multi时，就可以通过curl_multi_cleanup()将其清理掉，其函数原型如下：<br>CURLMcode curl_multi_cleanup(CURLM *multi_handle);
/* Cleans up a CURL multi handle.
   Parameters:
   1. multi_handle: The CURL multi handle to clean up.
   Return value:
   - On success, returns CURLM_OK.
   - On failure, returns a CURLMcode error value.
*/
<br><br><br><br><br><br><br><br>]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/14.-asynchronous-io.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/14. Asynchronous IO.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sat, 15 Mar 2025 08:07:03 GMT</pubDate></item><item><title><![CDATA[15. Virtualization and Container]]></title><description><![CDATA[ 
 <br><br><br>如果你有一台Mac，运行苹果公司的MacOS操作系统，那么当你想使用一些仅支持Windows操作系统的软件时该怎么办呢？人们想到通过虚拟化物理硬件，在同一台主机上运行不同的操作系统（称为虚拟机）来解决这个问题。这种技术就是虚拟化（和操作系统四大特征中的虚拟化略有不同）。<br>在这些不同的操作系统的视角上，它们并不知道它们运行在虚拟化的物理硬件之上，那么，这些虚拟机如何才能知道这是梦境还是现实世界？<br><br>要运行多台不同的虚拟机，我们需要一个底层硬件作为支撑上层虚拟化的根基，也就是主机(Host)。然后，我们有虚拟机管理程序(Virtual Machine Manager, VMM)，也叫hypervisor。VMM负责管理并向不同的虚拟机分配主机硬件的资源。具体来说，它会将底层的硬件进行抽象并向不同的虚拟机提供看上去像是主机的一个接口。这些虚拟机(guest)就会与VMM分配的虚拟的主机进行交互。<br><img alt="Pasted image 20250121002345.jpg" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20250121002345.jpg"><br>虚拟化技术实际上和Java虚拟机所做的事情差不多。Java承诺“编写一次，到处运行”（Write Once, Run Anywhere）。通过在编程语言和机器之间加一层虚拟机层来实现WORA。即使机器的架构有所不同，Java也可以通过在不同的机器上运行Java虚拟机，将相同的Java字节码运行在不同的平台上<br><br>尽管虚拟化和仿真很像，都创建一种环境使得软件能够运行在不同的硬件或系统上。但它们本质是不同的。我们所提到的虚拟机涉及在同一个物理硬件上创建多个不同的虚拟环境。每个虚拟环境（虚拟机）彼此隔离，每个虚拟环境中都运行着其自己的操作系统和应用。<br>而仿真是通过在一个系统上模拟另一个系统上的行为来运行另一个系统上的应用。和虚拟化相比，仿真的性能要慢得多，因为虚拟机直接在硬件上运行，而仿真需要复制原系统的行为，因而性能会很慢。<br><br>此外，虚拟机为我们带来另一个好事情就是当你使用虚拟机时，你可以挂起整个虚拟机。整个过程和挂起进程很相像，保存当前的状态，在之后再读取状态进行恢复（VM image）。<br><br>Hypervisor 有两种主要类型：Type 1（裸金属）和 Type 2（托管）:<br><br>裸机虚拟机(Type-1, Hypervisor) : 直接安装在物理硬件上而不需要宿主操作系统。这种类型的虚拟机管理程序直接控制硬件资源并管理各个虚拟机。由于没有运行全功能宿主操作系统的额外开销，裸机虚拟机通常能提供更好的性能和更高的资源使用效率。<br><img alt="Pasted image 20240925014938.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240925014938.png"><br><br>The hypervisor runs directly on and has full control over the hardware, but device driver implementations are provided by a special domain-0 (Dom0) OS. Other guest OSes are called domain-U (DomU). Guest kernel device requests are redirected to the Dom0 kernel.<br><img alt="Pasted image 20240925014933.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240925014933.png"><br>
Typically, the DomU kernels may need a few modifications to be able to fit in this model. This characteristic is called&nbsp;para-virtualization, meaning that it is OK to apply small modifications to the guest kernels and they do not need to work out-of-the-box as if without virtualization.<br>
Sometimes, there are even special, minimal OS kernels written just to be used as these DomU kernels in type-1b VMs. They are called “unikernels”.
<br>Examples of type-1b hypervisors include Xen&nbsp;<a data-tooltip-position="top" aria-label="https://www.josehu.com/technical/2021/05/24/os-kernel-models.html#fn:17" rel="noopener nofollow" class="external-link" href="https://www.josehu.com/technical/2021/05/24/os-kernel-models.html#fn:17" target="_blank">17</a>.<br><br>宿主操作系统虚拟机(Type-2, Hosted) 是安装在已有宿主操作系统之上的软件。这类虚拟机依赖于宿主操作系统来管理硬件资源。虽然性能上可能略逊于裸机虚拟机，但安装和使用更为简便，且能在不同操作系统间提供更好的兼容性和灵活性。<br><img alt="Pasted image 20240925021538.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20240925021538.png"><br>
Examples include VMware Workstation, Virtual Box, and QEMU (on Linux, possibly with KVM support).<br>
Pure software emulators deliver poor performance as they add in an expensive layer of abstraction. Modern hypervisors, whichever type it belongs to, often take advantage of dedicated hardware support to provide more efficient virtualization if the guest ISA is the same as the host machine (e.g., running x86-64 VMs on an x86-64 platform).
For type-2 use cases, some host OSes like Linux also provides kernel-based virtual machine (KVM) support which allows emulators like QEMU to run more efficiently and “natively”.
<br><br><br><br>虚拟机能够运行的关键就在于virtual CPU，VCPU并不执行二进制的程序，VCPU是guest所看到的CPU状态。我们现在知道虚拟机可以挂起并恢复，在虚拟机挂起的时候，虚拟机会以为程序还在运行，它所看到的CPU状态是运行的。然而，我们知道其实虚拟机看到的只是梦境。VCPU存储着虚拟机的状态，它是一个数据结构。VMM负责管理VCPU的状态。<br>当guest从挂起态恢复时，状态信息就会从VCPU中加载。<br><br><br>slow down the VM<br><br><br><br><br><br><br><br><br><br>Manual Install<br>
Package Manager<br>
Virtual Machines<br>
Containerization<br><br><img alt="Pasted image 20250121030340.png" src="https://congzhi.wiki/congzhi's-os-series/pics/pasted-image-20250121030340.png">]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/15.-virtualization-and-container.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/15. Virtualization and Container.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Feb 2025 06:33:02 GMT</pubDate><enclosure url="https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20250121002345.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/congzhi&apos;s-os-series/pics/pasted-image-20250121002345.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Congzhi's OS Series]]></title><description><![CDATA[ 
 <br><br><br>This series is intended solely for educational purposes. Some images used in this series are sourced from the internet. If any of these images conflict with your creation principles, please contact me at <a data-tooltip-position="top" aria-label="mailto:duzhi02@qq.com." rel="noopener nofollow" class="external-link" href="https://congzhi.wiki/mailto:duzhi02@qq.com." target="_blank">duzhi02@qq.com.</a> I would address the issue ASAP.<br>所有内容均由我独自完成，所有学习资料来源如下：<br>
<br><a data-tooltip-position="top" aria-label="https://space.bilibili.com/286191426/channel/collectiondetail?sid=2293786" rel="noopener nofollow" class="external-link" href="https://space.bilibili.com/286191426/channel/collectiondetail?sid=2293786" target="_blank">Y4NGY操作系统课程</a>
<br>(<a data-tooltip-position="top" aria-label="https://www.youtube.com/playlist?list=PLFCH6yhq9yAHFaI00FrrgG0dPg8a5SjTJ" rel="noopener nofollow" class="external-link" href="https://www.youtube.com/playlist?list=PLFCH6yhq9yAHFaI00FrrgG0dPg8a5SjTJ" target="_blank">ECE 252: Systems Programming and Concurrency</a>)
<br>(<a data-tooltip-position="top" aria-label="https://www.youtube.com/playlist?list=PLFCH6yhq9yAHFUGyk4U5KaoA24gnnDJA-" rel="noopener nofollow" class="external-link" href="https://www.youtube.com/playlist?list=PLFCH6yhq9yAHFUGyk4U5KaoA24gnnDJA-" target="_blank">ECE 350: Real-Time Operating System</a>)
<br><a data-tooltip-position="top" aria-label="https://zh.z-lib.gs/book/25277046/1b1f19/operating-system-concepts.html?ts=1905" rel="noopener nofollow" class="external-link" href="https://zh.z-lib.gs/book/25277046/1b1f19/operating-system-concepts.html?ts=1905" target="_blank">Operating System Concepts from Z-Lib</a>
<br><a data-tooltip-position="top" aria-label="https://www.cs.csustan.edu/~john/Classes/CS3750/" rel="noopener nofollow" class="external-link" href="https://www.cs.csustan.edu/~john/Classes/CS3750/" target="_blank">Prof. John Sarraillé's CS3750 course notes</a>
<br><a data-tooltip-position="top" aria-label="https://wiki.osdev.org" rel="noopener nofollow" class="external-link" href="https://wiki.osdev.org" target="_blank">OSDev Wiki</a>
<br><a data-tooltip-position="top" aria-label="https://www.josehu.com/notes.html" rel="noopener nofollow" class="external-link" href="https://www.josehu.com/notes.html" target="_blank">Notes | Guanzhou Hu</a>
<br>...
<br><br><br>Your Attention Please!
系列仍在施工中......在2025年内，将计划第一遍重写整个系列，旨在补全系列中缺失的内容。阶段章节中许多空标题多来源于原作者内容的编排，第一遍重写会逐步补全这些内容。
	 |ˉˉˉˉˉˉˉ|
	 |Salute!|
	 |__  ___|
	    |/
	(◍•ᴗ•◍)ゝ

后续，系列的结构还会不断调整更新。
<br><br><br>目前，所有的阶段都罗列如下，其中 x(extend) 表示拓展阶段或小节。部分暂未补全但不影响阅读：<br>Congzhi's OS Series
<a data-href="1. Introduction to the OS" href="https://congzhi.wiki/congzhi's-os-series/1.-introduction-to-the-os.html" class="internal-link" target="_self" rel="noopener nofollow">1. Introduction to the OS</a><br>
<a data-href="2. OS Development Stages" href="https://congzhi.wiki/congzhi's-os-series/2.-os-development-stages.html" class="internal-link" target="_self" rel="noopener nofollow">2. OS Development Stages</a><br>
<a data-href="3. Operating System Structures" href="https://congzhi.wiki/congzhi's-os-series/3.-operating-system-structures.html" class="internal-link" target="_self" rel="noopener nofollow">3. Operating System Structures</a><br>
<a data-href="4. System Boots Up" href="https://congzhi.wiki/congzhi's-os-series/4.-system-boots-up.html" class="internal-link" target="_self" rel="noopener nofollow">4. System Boots Up</a><br>
<a data-href="5. Interruption" href="https://congzhi.wiki/congzhi's-os-series/5.-interruption.html" class="internal-link" target="_self" rel="noopener nofollow">5. Interruption</a><br>
<a data-href="6. Processing The Processes" href="https://congzhi.wiki/congzhi's-os-series/6.-processing-the-processes.html" class="internal-link" target="_self" rel="noopener nofollow">6. Processing The Processes</a><br>
<a data-href="6.5 Inter-Process Communications" href="https://congzhi.wiki/congzhi's-os-series/6.5-inter-process-communications.html" class="internal-link" target="_self" rel="noopener nofollow">6.5 Inter-Process Communications</a><br>
<a data-href="7. Thread and Concurrency" href="https://congzhi.wiki/congzhi's-os-series/7.-thread-and-concurrency.html" class="internal-link" target="_self" rel="noopener nofollow">7. Thread and Concurrency</a><br>
<a data-href="8. CPU Scheduling" href="https://congzhi.wiki/congzhi's-os-series/8.-cpu-scheduling.html" class="internal-link" target="_self" rel="noopener nofollow">8. CPU Scheduling</a><br>
<a data-href="9. Synchronization and Mutex" href="https://congzhi.wiki/congzhi's-os-series/9.-synchronization-and-mutex.html" class="internal-link" target="_self" rel="noopener nofollow">9. Synchronization and Mutex</a><br>
<a data-href="10. Deadlock" href="https://congzhi.wiki/congzhi's-os-series/10.-deadlock.html" class="internal-link" target="_self" rel="noopener nofollow">10. Deadlock</a><br>
<a data-href="10.5 Advanced Concurrency Problems" href="https://congzhi.wiki/congzhi's-os-series/10.5-advanced-concurrency-problems.html" class="internal-link" target="_self" rel="noopener nofollow">10.5 Advanced Concurrency Problems</a><br>
<a data-href="10.x A Thread Pool Library in C++" href="https://congzhi.wiki/congzhi's-os-series/10.x-a-thread-pool-library-in-c++.html" class="internal-link" target="_self" rel="noopener nofollow">10.x A Thread Pool Library in C++</a><br>
<a data-href="11. Memory Management" href="https://congzhi.wiki/congzhi's-os-series/11.-memory-management.html" class="internal-link" target="_self" rel="noopener nofollow">11. Memory Management</a><br>
<a data-href="12. IO Systems" href="https://congzhi.wiki/congzhi's-os-series/12.-io-systems.html" class="internal-link" target="_self" rel="noopener nofollow">12. IO Systems</a><br>
<a data-href="13. File Systems" href="https://congzhi.wiki/congzhi's-os-series/13.-file-systems.html" class="internal-link" target="_self" rel="noopener nofollow">13. File Systems</a><br>
<a data-href="14. Asynchronous IO" href="https://congzhi.wiki/congzhi's-os-series/14.-asynchronous-io.html" class="internal-link" target="_self" rel="noopener nofollow">14. Asynchronous IO</a><br>
<a data-href="15. Virtualization and Container" href="https://congzhi.wiki/congzhi's-os-series/15.-virtualization-and-container.html" class="internal-link" target="_self" rel="noopener nofollow">15. Virtualization and Container</a><br>
<a data-href="T1. Valgrind and Helgrind" href="https://congzhi.wiki/congzhi's-os-series/t1.-valgrind-and-helgrind.html" class="internal-link" target="_self" rel="noopener nofollow">T1. Valgrind and Helgrind</a>
<br><br><br>如果您发现任何知识上的疑问、错误和错别字问题，也欢迎通过邮箱 <a data-tooltip-position="top" aria-label="mailto:duzhi_02@qq.com" rel="noopener nofollow" class="external-link" href="https://congzhi.wiki/mailto:duzhi_02@qq.com" target="_blank">duzhi_02@qq.com</a> 联系我。]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/congzhi&apos;s-os-series.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/Congzhi&apos;s OS Series.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 16:05:47 GMT</pubDate></item><item><title><![CDATA[T1. Valgrind and Helgrind]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/congzhi&apos;s-os-series/t1.-valgrind-and-helgrind.html</link><guid isPermaLink="false">Congzhi&apos;s OS Series/T1. Valgrind and Helgrind.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sun, 16 Mar 2025 08:07:42 GMT</pubDate></item><item><title><![CDATA[CS50 SQL]]></title><description><![CDATA[ 
 <br><br><br><a data-tooltip-position="top" aria-label="https://www.youtube.com/cs50" rel="noopener nofollow" class="external-link" href="https://www.youtube.com/cs50" target="_blank">CS50</a>本身是 Harvard 开设的面向大众的计算机科学入门课程(Introduction to Computer Science)，由 David J. Malan 教授进行授课，其中就包含 SQL 和其他的内容。现在，你可以在 CS50 上学到很多 Harvard 和 Yale 所开设的一些小而精的计算机科学课程，很多都作为 CS50 Lectures 内容的延申，其中就包括这个 folder 下的 CS50's Introduction to Databases with SQL。<br><br><br>这个系列是对 CS50 数据库课程的一些笔记。内容结构会基本按照 CS50 课程的编排走，内容也会相对基础。参考来源有：<br>
<br><a data-tooltip-position="top" aria-label="https://cs50.harvard.edu/sql/2024/" rel="noopener nofollow" class="external-link" href="https://cs50.harvard.edu/sql/2024/" target="_blank">CS50's Introduction to Databases with SQL</a>
<br>...
<br><br><br><a data-href="CS50 SQL" href="https://congzhi.wiki/cs50-sql/cs50-sql.html" class="internal-link" target="_self" rel="noopener nofollow">CS50 SQL</a> 的目录结构如下，你可以在 <a data-tooltip-position="top" aria-label="https://cs50.harvard.edu/sql/2024/" rel="noopener nofollow" class="external-link" href="https://cs50.harvard.edu/sql/2024/" target="_blank">CS50</a> 学到 Lecture 0 - Lecture 6 的所有知识。你还能在官网上做 CS50 的课后作业并提交。Lecture x 是另一些课程中的内容。<br>CS50 SQL (NC Stand for Not Covered)

<br><a data-href="Lecture 0 - Querying" href="https://congzhi.wiki/cs50-sql/lecture-0-querying.html" class="internal-link" target="_self" rel="noopener nofollow">Lecture 0 - Querying</a>
<br><a data-href="Lecture 1 - Relating (NC)" href="https://congzhi.wiki/cs50-sql/lecture-1-relating-(nc).html" class="internal-link" target="_self" rel="noopener nofollow">Lecture 1 - Relating (NC)</a>
<br><a data-href="Lecture 2 - Designing (NC)" href="https://congzhi.wiki/cs50-sql/lecture-2-designing-(nc).html" class="internal-link" target="_self" rel="noopener nofollow">Lecture 2 - Designing (NC)</a>
<br><a data-href="Lecture 3 - Writing (NC)" href="https://congzhi.wiki/cs50-sql/lecture-3-writing-(nc).html" class="internal-link" target="_self" rel="noopener nofollow">Lecture 3 - Writing (NC)</a>
<br><a data-href="Lecture 4 - Viewing (NC)" href="https://congzhi.wiki/cs50-sql/lecture-4-viewing-(nc).html" class="internal-link" target="_self" rel="noopener nofollow">Lecture 4 - Viewing (NC)</a>
<br><a data-href="Lecture 5 - Optimizing (NC)" href="https://congzhi.wiki/cs50-sql/lecture-5-optimizing-(nc).html" class="internal-link" target="_self" rel="noopener nofollow">Lecture 5 - Optimizing (NC)</a>
<br><a data-href="Lecture 6 - Scaling (NC)" href="https://congzhi.wiki/cs50-sql/lecture-6-scaling-(nc).html" class="internal-link" target="_self" rel="noopener nofollow">Lecture 6 - Scaling (NC)</a>

<br>Consistency Checking in Database

<br><a data-href="Transaction in Database (NC)" href="https://congzhi.wiki/cs50-sql/transaction-in-database-(nc).html" class="internal-link" target="_self" rel="noopener nofollow">Transaction in Database (NC)</a>

<br><br><br>如有疑问或内容问题，欢迎通过 <a data-tooltip-position="top" aria-label="mailto:duzhi_02@qq.com" rel="noopener nofollow" class="external-link" href="https://congzhi.wiki/mailto:duzhi_02@qq.com" target="_blank">duzhi_02@qq.com</a> 联系我。]]></description><link>https://congzhi.wiki/cs50-sql/cs50-sql.html</link><guid isPermaLink="false">CS50 SQL/CS50 SQL.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 16:05:27 GMT</pubDate></item><item><title><![CDATA[Lecture 0 - Querying]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://cs50.harvard.edu/sql/2024/weeks/0/" rel="noopener nofollow" class="external-link" href="https://cs50.harvard.edu/sql/2024/weeks/0/" target="_blank">Week 0 Querying - CS50's Introduction to Databases with SQL</a><br>本节课，你先会接触到 Database 和 DataBase Management System 的相关知识。之后，我们会简单地学习如何用SQL与数据库进行交互、查询你想知道的信息。下面是本节课的目录：<br>
<br><a data-tooltip-position="top" aria-label="Information Age" data-href="#Information Age" href="https://congzhi.wiki/about:blank#Information_Age" class="internal-link" target="_self" rel="noopener nofollow">Information Age</a>
<br><a data-tooltip-position="top" aria-label="Databases, SQL and SQLite" data-href="#Databases, SQL and SQLite" href="https://congzhi.wiki/about:blank#Databases,_SQL_and_SQLite" class="internal-link" target="_self" rel="noopener nofollow">Databases, SQL and SQLite</a><br>
- <a data-tooltip-position="top" aria-label="Databases" data-href="#Databases" href="https://congzhi.wiki/about:blank#Databases" class="internal-link" target="_self" rel="noopener nofollow">Databases</a><br>
- <a data-tooltip-position="top" aria-label="SQL" data-href="#SQL" href="https://congzhi.wiki/about:blank#SQL" class="internal-link" target="_self" rel="noopener nofollow">SQL</a><br>
- <a data-tooltip-position="top" aria-label="SQLite" data-href="#SQLite" href="https://congzhi.wiki/about:blank#SQLite" class="internal-link" target="_self" rel="noopener nofollow">SQLite</a>
<br><a data-tooltip-position="top" aria-label="`SELECT`" data-href="#`SELECT`" href="https://congzhi.wiki/about:blank#`SELECT`" class="internal-link" target="_self" rel="noopener nofollow">`SELECT`</a><br>
- <a data-tooltip-position="top" aria-label="Uppercase and Double Quotes for Good Practice" data-href="#Uppercase and Double Quotes for Good Practice" href="https://congzhi.wiki/about:blank#Uppercase_and_Double_Quotes_for_Good_Practice" class="internal-link" target="_self" rel="noopener nofollow">Uppercase and Double Quotes for Good Practice</a>
<br><a data-tooltip-position="top" aria-label="`LIMIT`" data-href="#`LIMIT`" href="https://congzhi.wiki/about:blank#`LIMIT`" class="internal-link" target="_self" rel="noopener nofollow">`LIMIT`</a>
<br><a data-tooltip-position="top" aria-label="`WHERE`" data-href="#`WHERE`" href="https://congzhi.wiki/about:blank#`WHERE`" class="internal-link" target="_self" rel="noopener nofollow">`WHERE`</a><br>
- <a data-tooltip-position="top" aria-label="`!=` and `<>`" data-href="#`!=` and `<>`" href="https://congzhi.wiki/about:blank#`!=`_and_`<>`" class="internal-link" target="_self" rel="noopener nofollow">`!=` and `&lt;&gt;`</a><br>
- <a data-tooltip-position="top" aria-label="`AND` and `OR`" data-href="#`AND` and `OR`" href="https://congzhi.wiki/about:blank#`AND`_and_`OR`" class="internal-link" target="_self" rel="noopener nofollow">`AND` and `OR`</a>
<br><a data-tooltip-position="top" aria-label="`NULL`" data-href="#`NULL`" href="https://congzhi.wiki/about:blank#`NULL`" class="internal-link" target="_self" rel="noopener nofollow">`NULL`</a>
<br><a data-tooltip-position="top" aria-label="`LIKE`" data-href="#`LIKE`" href="https://congzhi.wiki/about:blank#`LIKE`" class="internal-link" target="_self" rel="noopener nofollow">`LIKE`</a>
<br><a data-tooltip-position="top" aria-label="Range Conditions" data-href="#Range Conditions" href="https://congzhi.wiki/about:blank#Range_Conditions" class="internal-link" target="_self" rel="noopener nofollow">Range Conditions</a>
<br><a data-tooltip-position="top" aria-label="ORDER BY" data-href="#ORDER BY" href="https://congzhi.wiki/about:blank#ORDER_BY" class="internal-link" target="_self" rel="noopener nofollow">ORDER BY</a>
<br><a data-tooltip-position="top" aria-label="Aggregate Functions" data-href="#Aggregate Functions" href="https://congzhi.wiki/about:blank#Aggregate_Functions" class="internal-link" target="_self" rel="noopener nofollow">Aggregate Functions</a>
<br><br><br>人类一直在和信息、数据打交道。在象形文字发明初期的早些时候，人们将文字篆刻在石壁上、龟壳上来记录一些部落的高光时刻。之后，人们学会了如何造纸，将信息写到纸上，便于驮运和阅读学习。由此，人类文明得以发扬壮大。<br>在计算机出现之前，人们用纸质的表(Table)来记录数据。纸质记录虽然可以长久保存，但是有许多缺点：如数据冗余、不一致性、效率低下、而且安全性低。在PC机出现后，人们记录和处理信息的方式发生了变化。可以选用文本文件并按一定格式存储数据，但缺点依旧。<br><img alt="Table with Temple Workers' Stipends" src="https://cs50.harvard.edu/sql/2024/notes/0/images/templeworkerstipends.jpg" referrerpolicy="no-referrer"><br>随着信息技术的发展，我们进入了信息时代。传统的信息存放方式已经不再能够满足我们对信息获取时效性、准确性和安全性的需求。人们开始把信息存放在计算机中，随之而来的是许多专门用于按存放数据的spreadsheet softwares，如 Apple Numbers, Microsoft Excel, Google Sheets 等。<br>但这个课程是关于数据库和SQL的，我们并不关心这些 spreadsheet softwares。我们关心使用数据库的好处优点？或者说有什么是这些spreadsheet softwares无法带给我们的？我们有三个理由去使用数据库，分别是扩展性（十亿级别的扩展性）、CRUD的频率和速度。<br><br><br><br>数据库是一种组织数据的方式，你可以通过数据库管理系统(DBMS)同数据库进行交互。在数据库中，你可以进行CURD的操作，即Create, Update, Read, Delete我们常说的增删改查操作。<br>使用DBMS来管理和处理数据，除了能提高数据存储和检索的效率，还可以保证数据的完整性和安全性保障。如今，SQL成为了管理和操作数据库的标准语言，使得数据处理更加便捷和高效。市面上也有诸多的 DBMS，使用 DBMS，你就可以同数据库进行 CRUD 的交互。常见的 DBMS 有 MySQL, Oracle, MongoDB, SQLite 等。<br><br>DBMS 通常使用 SQL(Structured Query Language)来向上层应用提供服务的接口。SQL 最早是由 IBM 公司在 System R 上首次实现的，最早的时候叫 SEQUEL(Structured English Query Language)。在下面学习 SQL 语句的时候你就能感受到，使用 SQL 进行 CRUD 操作时实际上和英语非常类似，相比于晦涩的 C, Java 等高级语言，SQL 的使用要简单得多。<br>SQL 有相应的标准，由 ISO 和 ANSI 制订，标准的存在让不同的 DBMS 都需要给用户提供通用的接口。此外，用户可以在不同的 DBMS 之间迁移数据和应用程序，而不需要进行大量的修改。但需要注意的是，不同的 DBMS 可能会在标准的基础上增加一些扩展和功能。我们这里将使用SQLite作为我们的DBMS。<br><br><br><br>为了回答我们的数据库里面有哪些数据，我们需要用到 SELECT 关键字。这是我们接触到的第一个关键字，SELECT 允许我们在数据库中的表中选择特定的行打印出来。在下面，我们将 longlist 数据库中的所有行都打印了出来，在 SQL 中，* 就是全部的意思。<br>SELECT *
FROM "longlist";
<br>上面的 SQL 语句的意思就是：Select and print all the rows from the "longlist" database table. 也就是将数据库 longlist 中所有行所有列都打印出来。<br>如果我们想要查看一些特定列中所有行的数据，我们就要用 SELECT 选择特定的列进行打印。我们用下面的 SQL 语句来打印所有关于 title 的数据：<br>SELECT "title"
FROM "longlist";
<br>这句 SQL 语句就表示：Select and print all the rows in the "title" column  from the "longlist" database table. <br>如果想查看更多的一些信息，比如说作者的信息，只需要在 title 列后面隔个逗号加上要查询的列信息，如下：<br>SELECT "title", "author"
FROM "longlist"
<br><br><br><br>在上面的查询中，我们看到一次查询显示出来的数据太长了。假如我们的数据库有几百万行，那一次查询出来的数据根本不是看一眼就能够大致知道发生什么了的。在这种情况下，我们引入一个新的关键字 LIMIT 。LIMIT 让我们可以简单地瞥见表中都有什么东西。<br>我们有下面的语句，表示 Select and print the rows in the "title" column from the "longlist" database table with a limit of 10 queries.<br>SELECT "title"
FROM "longlist"
LIMIT 10;
<br><br><br>有时候，我们并不想要查看所有行的数据，我们只想要查看自己感兴趣的一些数据。这时候，我们就会用到另一个关键字 WHERE 用于条件选择查找。当特定的条件满足时输出特定行。<br>比如下面的语句，表示 Select and print the rows in the "title" and "author" columns from the "longlist" database table where the listed "year" is equal to 2023.<br>SELECT "title", "author" 
FROM "longlist" 
WHERE "year" = 2023;
<br><br>我们用 = 表示 "equal to"，在 SQL 中，我们用 != 和 &lt;&gt; 来表达 "not equal to"，这两个是等价的。比如下面的语句就可以表示：Select and print the rows in the "title" and "format" columns from the "longlist" table where the "format" cover is not equal to 'hardcover'.<br>SELECT "title", "format" 
FROM "longlist" 
WHERE "format" != 'hardcover'; -- equals to WHERE "format" &lt;&gt; 'hardcover'
<br>除了用 != 和 &lt;&gt; 来表达不等于，在 SQL 中，我们还额外地有一个关键字 NOT 来表示一层否定的关系。上面的 SQL 语句用 NOT 就相当于：<br>SELECT "title", "format"
FROM "longlist"
WHERE NOT "format" = 'hardcover';
<br><br>知道如何用 WHERE 条件性选择查找后，我们现在要考虑的事情就是如果同时选择多个条件同时查找？在 SQL 中，我们有 AND 和 OR 关键字来整合我们想要查询的多个条件。比如说，我们想查一下在 2022 和 2023 年 longlisted 的作者和书名，我们可以这样：<br>SELECT "title", "author" 
FROM "longlist" 
WHERE "year" = 2022 OR "year" = 2023;
<br>上面语句的意思就是： Select and print the rows in the "title" and "author" columns from the "longlist" database table where the longlisted year is equal to 2022 or 2023.<br>我们还可以加入一个条件，比如说在这些在 2022 或 2023 年 longlisted 的书中，我们再选择那些不是 hardcover 的。我们可以这样：<br>SELECT "title", "format" 
FROM "longlist" 
WHERE ("year" = 2022 OR "year" = 2023) AND "format" != 'hardcover';
<br>通常而言，AND 的优先级默认高于 OR。这里的 () 表示一种优先级，意思就是说这里强制让 OR 的条件先计算，再与 AND 结合。使用括号可以让逻辑变得更加清晰。<br><br><br>在数据库中，有的字域可能没有填入数据，我们称为数据缺失 (data missing) 。在 SQL 中，我们用 NULL 类型来指示某个数据可能没有值或在数据库中不存在。在 longlist.db 中，我们记录了许多书籍的信息，如果书籍没有翻译者，那么格子的数据就会被标记为 NULL。<br>为了查看哪些书籍没有翻译，我们可以：<br>SELECT "title", "translator" 
FROM "longlist"
WHERE "translator" IS NULL;
<br>这句 SQL 语句的意思就是： Select and print the rows in the "title" and "author" columns from the "longlist" database table where the "translator" field is an empty NULL.<br>注意这里我们使用 IS 而不使用 = 或者 != 是因为 NULL 是一个无值的状态，用 = 比较 NULL 会返回一个 UNKNOWN 而不是 TRUE 或 FALSE。而 IS 操作符专门用于检查某个字段是否是 NULL 。<br>查看哪些书籍有翻译，我们在 IS 后面加一个 NOT 就可以了，和英语一样。如下：<br>SELECT "title", "translator" 
FROM "longlist"
WHERE "translator" IS NOT NULL;
<br><br><br>如果我们不能确定确切的字符串叫什么，我们可以用关键字 LIKE 粗略的查询一些字符串。比如，等下我们会用 LIKE 来查询一些书名含有某个单词的书籍。顺便提一下， LIKE 所查询的字符串并不区分大小写。<br>在我们用 LIKE 查询时，我们通常会配合通配符使用。在 SQL 中，我们有两个通配符 % 和 _ 。%  用于匹配大于等于0个的任意字符；_  用于匹配一个任意字符；如果要查询不以某某开头的任意字符，我们可以用 '[^AB]%' 来表示不以AB开头的任意字符串。<br>例如，当我们想查询书名带 'love' 的书籍，我们可以用下面的 SQL 语句：<br>SELECT "title"
FROM "longlist"
WHERE "title" LIKE '%love%';
<br>这句 SQL 语句的意思就是：Select and print the rows in the "title" column from the "longlist" database table where the "title" contains the substring like "love".<br>当我们想查询书名是 "The" 开头的书籍，我们可以用：<br>SELECT "title" 
FROM "longlist" 
WHERE "title" LIKE 'The%';
<br>意为：Select and print the rows in the "title" column from the "longlist" database table where the "title" starts the substring like "The".<br>上面的查询中，我们想要的是单词 "The" 开头的书籍，但实际上我们查询的书名开头可能是任何以 The 开头的单词。如果要查询以单词 "The" 开头的书籍，我们可以在 % 前加一个空格。<br>如果你有一本书叫 "Pyre" ，但是你忘记这本书是 "Pyre" 还是 "Pire"。你可以用 _ 通配符来匹配字符串中的任何单个字符。如下：<br>SELECT "title" 
FROM "longlist" 
WHERE "title" LIKE 'P_re';
<br>Select and print the rows in the "title" column from the "longlist" database table where the "title"  is like something matches the pattern 'P_re'.<br><br><br>此外，SQL 中还引入了 &gt; , &lt; ,  &gt;= , &lt;= 用于匹配特定值范围内的数据。比如我们可以用下面的 SQL 语句筛选一下在 2019 年到 2022 年 longlisted 的书籍名和作者：<br>SELECT "title", "author"
FROM "longlist"
WHERE "year" &gt;= 2019 AND "year" &lt;= 2022;
<br>同样的，我们还可以用 关键字 BETWEEN 和 AND 来获得相同的结果：<br>SELECT "title", "author"
FROM "longlist"
WHERE "year" BETWEEN 2019 AND 2022;
<br>这两句 SQL 语句的意思都是：Select and print the rows in the "title" and "author" columns from the "longlist" database table where the "year"  is between 2019 and 2022.<br>此外，我们还可以通过范围条件来筛选评分大于 4.0 的书籍：<br>SELECT "title", "author"
FROM "longlist"
WHERE "rating" &gt; 4.0;
<br>意为：Select and print the rows in the "title" and "author" columns from the "longlist" database table where the book "rating"  is more than 4.0.<br>最后，通过 AND 或 OR 的组合条件逻辑，我们还可以筛选一下评分大于 4.0 而且投票数大于 10,000 的书籍：<br>SELECT "title", "author"
FROM "longlist"
WHERE "rating" &gt; 4.0 AND "votes" &gt; 10000;
<br>意为：Select and print the rows in the "title" and "author" columns from the "longlist" database table where the book "rating"  is more than 4.0 and votes is more than 10000.<br><br><br>我们已经学过了用 WHERE 进行条件查询、在条件中加入条件范围、组合条件逻辑和用 LIMIT 来筛选出最初出现的 n 行数据。现在，我们来学习如何用关键字 ORDER BY将选出的数据进行排序。<br>例如之前的语句”筛选评分大于 4.0 而且投票数大于 10,000 的书籍“，我们可以用 ORDER BY 语句对这些书籍按评分进行排序。我们再引入俩个关键字 DESC 和 ASC，意思是降序(Descending)和升序(Ascending)。<br>SELECT "title", "author"
FROM "longlist"
WHERE "rating" &gt; 4.0 AND "votes" &gt; 10000;
ORDER BY "rating" DESC
LIMIT 10;
<br>上面这一长串语句的意思就是再前面的基础上选出 10 本评分最高的书籍。意为：Select and print the rows in the "title" and "author" columns from the "longlist" database table where the book "rating"  is more than 4.0 and votes is more than 10000, order by "rating" in descending and limit the output to the top 10 entries.<br><br><br>本节的最后一节课，我们来介绍一下 SQL 中的聚合函数。这些函数用于再多个数据行上执行计算并返回单个值，通常用于汇总、统计和分析数据。常见的聚合函数有：<br>COUNT() - 计算并返回指定列中非空值的数量。<br>-- 查询数据库中有多少行数据，也就是书籍的数量。
SELECT COUNT(*) AS "Book Count"
FROM "longlist";
<br>SUM() - 计算并返回指定列中所有值的总和。<br>-- 查询所有书籍的投票数量总和。
SELECT SUM("votes") AS "Sum of Votes"
FROM "longlist";
<br>AVG() - 计算并返回指定列中所有值的平均值。<br>-- 查询所有书籍的平均评分。
SELECT AVG("rating") AS "Average Rating"
FROM "longlist";
<br>ROUND(number, decimals) - 对数值进行四舍五入，第一个参数通常填入 AVG()，第二个参数是要保留的小数位数。<br>SELECT ROUND(AVG("rating"), 2) AS "Average Rating" 
FROM "longlist";
<br>MAX() - 查询并返回指定列中的最大值。<br>-- 查询最受好评的书籍。
SELECT MAX("rating") AS "The Most Favorite Book"
FROM "longlist";
<br>MIN() - 查询并返回指定列中的最小值。<br>-- 查询最不受好评的书籍。
SELECT MAX("rating") AS "The Last Favorite Book"
FROM "longlist";
<br><br><a data-tooltip-position="top" aria-label="Lecture 1 - Relating (NC)" data-href="Lecture 1 - Relating (NC)" href="https://congzhi.wiki/cs50-sql/lecture-1-relating-(nc).html" class="internal-link" target="_self" rel="noopener nofollow">下一节--&gt;</a>]]></description><link>https://congzhi.wiki/cs50-sql/lecture-0-querying.html</link><guid isPermaLink="false">CS50 SQL/Lecture 0 - Querying.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Wed, 12 Mar 2025 14:50:11 GMT</pubDate><enclosure url="https://cs50.harvard.edu/sql/2024/notes/0/images/templeworkerstipends.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cs50.harvard.edu/sql/2024/notes/0/images/templeworkerstipends.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Lecture 1 - Relating (NC)]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="Lecture 0 - Querying" data-href="Lecture 0 - Querying" href="https://congzhi.wiki/cs50-sql/lecture-0-querying.html" class="internal-link" target="_self" rel="noopener nofollow">&lt;--上一节</a><br><a data-tooltip-position="top" aria-label="https://cs50.harvard.edu/sql/2024/weeks/1/" rel="noopener nofollow" class="external-link" href="https://cs50.harvard.edu/sql/2024/weeks/1/" target="_blank">Week 1 Relating - CS50's Introduction to Databases with SQL</a><br>本节课，我们会接着上节课的内容，你将进一步了解到什么叫关系型数据库。后面，我们还会做一些 Querying 的延申，本节我们会学习 nested querying 。本节课的内容有：<br><br><br>上节课，我们专注于<br>
<br>Databases can have multiple tables. Last class, we saw a database of books longlisted, or nominated, for the International Booker Prize. We will now see that database has many different tables inside it — for books, authors, publishers and so on.
<br>First, open up the database using SQLite in the terminal of your&nbsp;<a data-tooltip-position="top" aria-label="https://cs50.dev/" rel="noopener nofollow" class="external-link" href="https://cs50.dev/" target="_blank">Codespace</a>.
<br>We can use the following SQLite command to see all the tables in our database:
.tables

  This command returns the names of the tables in&nbsp;longlist.db&nbsp;— 7 in all.<br>

<br>These tables have some relationships between them, and hence we call the database a&nbsp;relational database. Look at the list of tables in&nbsp;longlist.db&nbsp;and try to imagine relationships between them. Some examples are:

<br>Authors write books.
<br>Publishers publish books.
<br>Books are translated by translators.


<br>Consider our first example. Here is a snapshot of the&nbsp;authors&nbsp;and&nbsp;books&nbsp;tables with the author name and book title columns!
<br><img alt="&quot;Author Name and Book Title columns from different tables&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p6.jpg" referrerpolicy="no-referrer"><br>
<br>Just looking at these two columns, how can we tell who wrote which book? Even if we assume that every book is lined up next to its author, just looking at the&nbsp;authors&nbsp;table would give us no information about the books written by that author.
<br>Some possible ways to organize books and authors are…

<br>the honor system: the first row in the&nbsp;authors&nbsp;table will always correspond to the first row in the&nbsp;books&nbsp;table. The problem with this system is that one may make a mistake (add a book but forget to add its corresponding author, or vice versa). Also, an author may have written more than one book or a book may be co-written by multiple authors.
<br>going back to a one-table approach: This approach could result in redundancy (duplication of data) if one author writes multiple books or if a book is co-written by multiple authors. Below is a snapshot of the one-table approach with some redundant data.
  <img alt="&quot;One-table approach: author with multiple books&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p8.jpg" referrerpolicy="no-referrer"><br>



<br>After considering these ideas, it seems like having two different tables is the most efficient approach. Let us look at some different ways in which tables can be related to each other in relational databases.
<br>Consider this case, where each author writes only one book and each book is written by one author. This is called a one-to-one relationship.
  <img alt="&quot;One-to-one relationship&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p10.jpg" referrerpolicy="no-referrer"><br>

<br>On the other hand, if an author can write multiple books, the relationship is a one-to-many relationship.
  <img alt="&quot;One-to-many relationship&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p11.jpg" referrerpolicy="no-referrer"><br>

<br>Here, we see another situation where not only can one author write multiple books, but books can also be co-written by multiple authors. This is a many-to-many relationship.
  <img alt="&quot;Many-to-many relationship&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p12.jpg" referrerpolicy="no-referrer"><br>

<br><br>
<br>We just described one-to-one, one-to-many and many-to-many relationships between tables in a database. It is possible to visualize such relationships using an entity relationship (ER) diagram.
<br>Here is an ER diagram for the tables in&nbsp;longlist.db.
  AuthorBookPublisherTranslatorRatingwrotepublishedtranslatedhas<br>

<br>Each table is an entity in our database. The relationships between the tables, or entities, are represented by the&nbsp;verbs&nbsp;that mark the lines connecting entities.
<br>Each line is this diagram is in crow’s foot notation.

<br>The first line with a circle looks like a 0 marked on the line. This line indicates that there are no relations.
<br>The second line with a perpendicular line looks like a 1 marked on the line. An entity with this arrow has to have at least one row that relates to it in the other table.
<br>The third line, which looks like a crow’s foot, has many branches. This line means that the entity is related to many rows from another table.
  <img alt="&quot;Lines in ER Diagrams&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p17.jpg" referrerpolicy="no-referrer"><br>



<br>For example:

<br>We read the notation left to right. An author writes one book (or, every author can have one book associated with them).
  <img alt="&quot;1-Relation Notation: an author writes one book&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p18.jpg" referrerpolicy="no-referrer"><br>

<br>Now, not only does an author write one book but a book is also written by one author.
  <img alt="&quot;1-Relation Notation: an author writes one book and one book is written by one author&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p19.jpg" referrerpolicy="no-referrer"><br>

<br>With this addition, an author writes at least one book and a book is written by at least one author. To rephrase, an author could be associated with one or multiple books and a book can be written by one or multiple authors.
  <img alt="&quot;Adding multiple lines: an author writes at least one book and a book is written by at least one author&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p20.jpg" referrerpolicy="no-referrer"><br>



<br>Let us revisit the ER diagram for our database.
  AuthorBookPublisherTranslatorRatingwrotepublishedtranslatedhas<br>

<br>On observing the lines connecting the Book and Translator entities, we can say that books don’t&nbsp;need&nbsp;to have a translator. They could have zero to many translators. However, a translator in the database translates at least one book, and possibly many.
<br><br>
If we have some database, how do we know the relationships among the entities stored inside of it?
<br>
<br>The exact relationships between entities are really up to the designer of the database. For example, whether each author can write only one book or multiple books is a decision to be made while designing the database. An ER diagram can be thought of as a tool to communicate these decisions to someone who wants to understand the database and the relationships between its entities.
<br>
Once we know that a relationship exists between certain entities, how do we implement that in our database?
<br>
<br>We will shortly see how we can use&nbsp;keys&nbsp;in SQL to relate tables to one another.
<br><br><br>
<br>In the case of books, every book has a unique identifier called an ISBN. In other words, if you search for a book by its ISBN, only one book will be found. In database terms, the ISBN is a primary key — an identifier that is unique for every item in a table.
  <img alt="&quot;Table with ISBNs and book titles&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p29.jpg" referrerpolicy="no-referrer"><br>

<br>Inspired by this idea of an ISBN, we can imagine assigning unique IDs to our publishers, authors and translators! Each of these IDs would be the primary key of the table it belongs to.<br>

<br><br>
<br>Keys also help relate tables in SQL.
<br>A foreign key is a primary key taken from a different table. By referencing the primary key of a different table, it helps relate the tables by forming a link between them.
  <img alt="&quot;Relating the books and ratings tables using foreign key&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p31.jpg" referrerpolicy="no-referrer">
  Notice how the primary key of the&nbsp;books&nbsp;table is now a column in the&nbsp;ratings&nbsp;table. This helps form a one-to-many relationship between the two tables — a book with a title (found in the&nbsp;books&nbsp;table) can have multiple ratings (found in the&nbsp;ratings&nbsp;table).<br>

<br>The ISBN, as we can see, is a long identifier. If each character occupied a byte of memory, storing a single ISBN (including the dashes) would take 17 bytes of memory, which is a lot!
<br>Thankfully, we don’t necessarily have to use the ISBN as a primary key. We can just construct our own using numbers like 1, 2, 3… and so on as long as each book has a unique number to identify it.
<br>Previously, we saw how to implement the one-to-many relationship between the&nbsp;books&nbsp;and&nbsp;ratings&nbsp;entities. Here’s an example of a many-to-many relationship.
<br><img alt="&quot;Relating the authors and books tables using a foreign key and another table&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p40.jpg" referrerpolicy="no-referrer"><br>There is now a table called&nbsp;authored&nbsp;that maps the primary key of&nbsp;books&nbsp;(book_id) to the primary key of&nbsp;authors&nbsp;(author_id).<br><br>
Can the IDs of the author and the book be the same? For example, if&nbsp;author_id&nbsp;is 1 and&nbsp;book_id&nbsp;is also 1 in the&nbsp;authored&nbsp;table, will there be a mix-up?
<br>
<br>Tables like&nbsp;authored&nbsp;are called “joint” or “junction” tables. In such tables, we usually know which primary key is referenced by which column. In this case, since we know that the first column contains the primary key of&nbsp;authors&nbsp;only and the second column similarly contains the primary key of&nbsp;books&nbsp;only, it would be okay even if the values matched!
<br>
If we have a lot of joint tables like this, wouldn’t that take up too much space?
<br>
<br>Yes, there is a trade-off here. Tables like these occupy more space but they also enable us to have many-to-many relationships without redundancies, like we saw earlier.
<br>
On changing the ID of a book or author, does the ID get updated in the other tables as well?
<br>
<br>An updated ID still needs to be unique. Given that, IDs are often abstracted away and we rarely change them.
<br><br>
<br>A subquery is a query inside another query. These are also called nested queries.
<br>Consider this example for a one-to-many relationship. In the&nbsp;books&nbsp;table, we have an ID to indicate the publisher, which is a foreign key taken from the&nbsp;publishers&nbsp;table. To find out the books published by Fitzcarraldo Editions, we would need two queries — one to find out the&nbsp;publisher_id&nbsp;of Fitzcarraldo Editions from the&nbsp;publishers&nbsp;table and the second, to use this&nbsp;publisher_id&nbsp;to find all the books published by Fitzcarraldo Editions. These two queries can be combined into one using the idea of a subquery.
SELECT "title"
FROM "books"
WHERE "publisher_id" = (
    SELECT "id"
    FROM "publishers"
    WHERE "publisher" = 'Fitzcarraldo Editions'
);

  Notice that:

<br>The subquery is in parentheses. The query that is furthest inside parantheses will be run first, followed by outer queries.
<br>The inner query is indented. This is done as per style conventions for subqueries, to increase readability.


<br>To find all the ratings for the book In Memory of Memory
SELECT "rating"
FROM "ratings"
WHERE "book_id" = (
    SELECT "id"
    FROM "books"
    WHERE "title" = 'In Memory of Memory'
);


<br>To select just the average rating for this book
SELECT AVG("rating")
FROM "ratings"
WHERE "book_id" = (
    SELECT "id"
    FROM "books"
    WHERE "title" = 'In Memory of Memory'
);


<br>The next example is for many-to-many relationships. To find the author(s) who wrote the book Flights, three tables would need to be queried:&nbsp;books,&nbsp;authors&nbsp;and&nbsp;authored.
SELECT "name"
FROM "authors"
WHERE "id" = (
    SELECT "author_id"
    FROM "authored"
    WHERE "book_id" = (
      SELECT "id"
      FROM "books"
      WHERE "title" = 'Flights'
    )
);

  The first query that is run is the most deeply nested one — finding the ID of the book Flights. Then, the ID of the author(s) who wrote Flights is found. Last, this is used to retrieve the author name(s).<br>

<br><br>
<br>This keyword is used to check whether the desired value is&nbsp;in&nbsp;a given list or set of values.
<br>The relationship between authors and books is many-to-many. This means that it is possible a given author has written more than one book. To find the names of all books in the database written by Fernanda Melchor, we would use the&nbsp;IN&nbsp;keyword as follows.
SELECT "title"
FROM "books"
WHERE "id" IN (
    SELECT "book_id"
    FROM "authored"
    WHERE "author_id" = (
        SELECT "id"
        FROM "authors"
        WHERE "name" = 'Fernanda Melchor'
    )
);

  Note that the innermost query uses&nbsp;=&nbsp;and not the&nbsp;IN&nbsp;operator. This is because we expect to find just one author named Fernanda Melchor.<br>

<br><br>
What if the value of an inner query is not found?
<br>
<br>In this case, the inner query would return nothing, prompting the outer query to also return nothing. The outer query is thus dependent on the results of the inner query.
<br>
Is it necessary to use four spaces to indent a subquery?
<br>
<br>No. The number of spaces used to indent a subquery can vary, as can the length of each line in the query. But the central idea behind breaking up queries and indenting subqueries is to make them readable.
<br>
How can we implement a many-to-one relationship between tables?
<br>
<br>Consider the situation wherein a book is co-written by multiple authors. We would have an&nbsp;authored&nbsp;table with multiple entries for the same book ID. Each of these entries would have a different author ID. It is worth noting that foreign key values can be repeated within a table, but primary key values are always unique.
<br><br>
<br>This keyword allows us to combine two or more tables together.
<br>To understand how&nbsp;JOIN&nbsp;works, consider a database of sea lions and their migration patterns. Here is a snapshot of the database.
<br><img alt="&quot;Sea Lions database with tables: sea lions, migrations&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p69.jpg" referrerpolicy="no-referrer"><br>
<br>To find out how far the sea lion Spot travelled, or answer similar questions about each sea lion, we could use nested queries. Alternately, we could join the tables&nbsp;sea lions&nbsp;and&nbsp;migrations&nbsp;together such that each sea lion also has its corresponding information as an extension of the same row.
<br>We can join the tables on the sea lion ID (the common factor between the two tables) to ensure that the correct rows are lined up against each other.
<br>Before testing this out, make sure to exit&nbsp;longlist.db&nbsp;using the&nbsp;.quit&nbsp;SQLite command. Then, open up&nbsp;sea_lions.db.
<br>To join the tables
<br>SELECT *
FROM "sea_lions"
JOIN "migrations" ON "migrations"."id" = "sea_lions"."id";
<br>Notice that:<br>
- The&nbsp;ON&nbsp;keyword is used to specify which values match between the tables being joined. It is not possible to join tables without matching values.<br>
- If there are any IDs in one table not present in the other, this row will not be present in the joined table. This kind of join is called an&nbsp;INNER JOIN.<br>
<br>Some other ways of joining tables that allow us to retain certain unmatched IDs are&nbsp;LEFT JOIN,&nbsp;RIGHT JOIN&nbsp;and&nbsp;FULL JOIN. Each of these is a kind of&nbsp;OUTER JOIN.
<br>A&nbsp;LEFT JOIN&nbsp;prioritizes the data in the left (or first) table.
<br>先outer join，然后在根据left或者right<br>SELECT *
FROM "sea_lions"
LEFT JOIN "migrations" ON "migrations"."id" = "sea_lions"."id";
<br>This query would retain all sea lion data from the&nbsp;sea_lions&nbsp;table — the left one. Some rows in the joined table could be partially blank. This would happen if the right table didn’t have data for a particular ID.<br>
<br>Similarly, a&nbsp;RIGHT JOIN&nbsp;retains all the rows from the right (or second) table. A&nbsp;FULL JOIN&nbsp;allows us to see the entirety of all tables.
<br>As we can observe, an&nbsp;OUTER JOIN&nbsp;could lead to empty or&nbsp;NULL&nbsp;values in the joined table.
<br>Both tables in the sea lions database have the column&nbsp;id. Since the value on which we are joining the tables has the same column name in both tables, we can actually omit the&nbsp;ON&nbsp;section of the query while joining.
<br>SELECT *
FROM "sea_lions"
NATURAL JOIN "migrations";
<br>Notice that the result does not have a duplicate&nbsp;id&nbsp;column in this case. Also, this join works similarly to an&nbsp;INNER JOIN.<br><br>
In the sea lions database, how are the IDs created? Do they come from the&nbsp;sea_lions&nbsp;table or the&nbsp;migrations&nbsp;table?
<br>
<br>The ID of each sea lion likely came from researchers tracking the migration patterns of these sea lions. That is to say, the IDs were not generated in either of the tables, but were assigned at the source of the data itself.
<br>
If we are trying to join three tables, how can we know which the left or right tables are?
<br>
<br>For each&nbsp;JOIN&nbsp;statement, the first table before the keyword is the left one. The one that is involved in the&nbsp;JOIN&nbsp;keyword is the right table.
<br>
When we join tables, does the resulting joined table get saved? Can we reference it later without joining again?
<br>
<br>In the way that we are using&nbsp;JOIN, the result is a temporary table or a result set. It can be used for the duration of the query.
<br>
There’s many different kinds of&nbsp;JOIN. Is there a default one we should use?
<br>
<br>The simplest kind — just&nbsp;JOIN&nbsp;— is actually an&nbsp;INNER JOIN&nbsp;and that’s the default for SQL.
<br><br>
<br>Before diving into sets, we will need to exit the database of sea lions and switch to&nbsp;longlist.db.
<br>On running a query, the results we see are called a result set. This is a kind of set in SQL.
<br>Let’s take another example. In our database of books, we have authors and translators. A person could be either an author or a translator. If the two sets have an intersection, it is also a possible that a person could be both an author and a translator of books. We can use the&nbsp;INTERSECT&nbsp;operator to find this set.
  <img alt="&quot;Intersection Set of Authors and Translators&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p100.jpg" referrerpolicy="no-referrer">
SELECT "name" FROM "translators"
INTERSECT
SELECT "name" FROM "authors";


<br>If a person is either an author or a translator, or both, they belong to the union of the two sets. In other words, this set is formed by combining the author and translator sets.
  <img alt="&quot;Union Set of Authors and Translators&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p102.jpg" referrerpolicy="no-referrer">
SELECT "name" FROM "translators"
UNION
SELECT "name" FROM "authors";

  Notice that every author and every translator is included in this result set, but only once!<br>

<br>A minor adjustment to the previous query gives us the profession of the person in the result set, based on whether they are an author or a translator.
SELECT 'author' AS "profession", "name" 
FROM "authors"
UNION
SELECT 'translator' AS "profession", "name" 
FROM "translators";


<br>Everyone who is an author and&nbsp;only&nbsp;an author is included in the following set. The&nbsp;EXCEPT&nbsp;keyword can be used to find such a set. In other words, the set of translators is subtracted from the set of authors to form this one.
  <img alt="&quot;EXCEPT set including people who are only authors&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p104.jpg" referrerpolicy="no-referrer">
SELECT "name" FROM "authors"
EXCEPT
SELECT "name" FROM "translators";

  We can verify that no author-translator from the intersection set appears in this result set.<br>

<br>Similarly, it is possible to find a set of people who are only translators using&nbsp;EXCEPT.
<br>How can we find this set of people who are either authors or translators but not both?
  <img alt="&quot;Set — people who are either authors or translators but not both&quot;" src="https://cs50.harvard.edu/sql/2024/notes/1/images/p107.jpg" referrerpolicy="no-referrer"><br>

<br>These operators could be useful to answer many different questions. For example, we can find the books that Sophie Hughes and Margaret Jull Costa have translated together.
SELECT "book_id" FROM "translated"
WHERE "translator_id" = (
    SELECT "id" from "translators"
    WHERE "name" = 'Sophie Hughes'
)
INTERSECT
SELECT "book_id" FROM "translated"
WHERE "translator_id" = (
    SELECT "id" from "translators"
    WHERE "name" = 'Margaret Jull Costa'
);

  Each of the nested queries here finds the IDs of the books for one translator. The&nbsp;INTERSECT&nbsp;keyword is used to intersect the resulting sets and give us the books they have collaborated on.<br>

<br><br>
Could we use&nbsp;INTERSECT,&nbsp;UNION&nbsp;etc. to perform operations on 3-4 sets?
<br>
<br>Yes, absolutely. To intersect 3 sets, we would have to use the&nbsp;INTERSECT&nbsp;operator twice. An important note — we have to make sure to have the same number and same types of columns in the sets to be combined using&nbsp;INTERSECT,&nbsp;UNION&nbsp;etc.
<br><br>
<br>Consider the&nbsp;ratings&nbsp;table. For each book, we want to find the average rating of the book. To do this, we would first need to group ratings together by book and then average the ratings out for each book (each group).
SELECT "book_id", AVG("rating") AS "average rating"
FROM "ratings"
GROUP BY "book_id";

  In this query, the&nbsp;GROUP BY&nbsp;keyword was used to create groups for each book and then collapse the ratings of the group into an average rating!<br>

<br>Now, we only want to see the books that are well-rated, with an average rating of over 4.
SELECT "book_id", ROUND(AVG("rating"), 2) AS "average rating"
FROM "ratings"
GROUP BY "book_id"
HAVING "average rating" &gt; 4.0;

  Note that the&nbsp;HAVING&nbsp;keyword is used here to specify a condition for the groups, instead of&nbsp;WHERE&nbsp;(which can only be used to specify conditions for individual rows).<br>

<br><br>
Is it possible to see the number of ratings given to each book?
<br>
<br>Yes, this would require a slight modification with the use of the&nbsp;COUNT&nbsp;keyword.
SELECT "book_id", COUNT("rating")
FROM "ratings"
GROUP BY "book_id";


<br>
Is it also possible to sort the data obtained here?
<br>
<br>Yes, it is. Say we wanted to find the average ratings per well-rated book, ordered in descending order.
SELECT "book_id", ROUND(AVG("rating"), 2) AS "average rating"
FROM "ratings"
GROUP BY "book_id"
HAVING "average rating" &gt; 4.0
ORDER BY "average rating" DESC;


]]></description><link>https://congzhi.wiki/cs50-sql/lecture-1-relating-(nc).html</link><guid isPermaLink="false">CS50 SQL/Lecture 1 - Relating (NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 22:05:04 GMT</pubDate><enclosure url="https://cs50.harvard.edu/sql/2024/notes/1/images/p6.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cs50.harvard.edu/sql/2024/notes/1/images/p6.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Lecture 2 - Designing (NC)]]></title><description><![CDATA[ 
 <br><br>
<br>In this lecture, we will learn how to design our own database schemas.
<br>Thus far, we have primarily worked with a database of books that were longlisted for the International Booker Prize. Now, we will look underneath the hood and see what commands can be used to create such a database.
<br>First, let us open up the database&nbsp;longlist.db&nbsp;from Week 0 on our terminal. As a reminder, this database contained just one table, called&nbsp;longlist. To see a snapshot of the table, we can run
SELECT "author", "title"
FROM "longlist"
LIMIT 5;

  This gives us the authors and titles from the first 5 rows of the table&nbsp;longlist.<br>

<br>Here is a SQLite command (not an SQL keyword) that can shed more light on how this database was created.
.schema

  On running this, we see the SQL statement used to create the table&nbsp;longlist. This shows us the columns inside&nbsp;longlist&nbsp;and the types of data that each column is able to store.<br>

<br>Next, let’s open up the same database from Week 1 on our terminal. This version of&nbsp;longlist.db&nbsp;contained different tables related to each other.
<br>On running&nbsp;.schema&nbsp;again, we see many commands — one for each table in the database. There is a way to see the schema for a specified table:
.schema books

  Now we see the statement used to create the&nbsp;books&nbsp;table. We are also able to see the columns and data types for each column. For example, the&nbsp;"title"&nbsp;column takes text and the&nbsp;"publisher_id"&nbsp;column is an integer.<br>

<br><br>
<br>Now that we have seen the schema for an existing database, let us create our own! We are tasked with representing the subway system of the city of Boston through a database schema. This includes the subway stations, the different train lines, and the people who take the trains.
  <img alt="&quot;Boston Subway Map&quot;" src="https://cs50.harvard.edu/sql/2024/notes/2/images/subwaymap.jpg" referrerpolicy="no-referrer"><br>

<br>To break down the question further, we need to decide…

<br>what kinds of tables we will have in our Boston Subway database,
<br>what columns each of the tables will have, and
<br>what types of data we should put in each of those columns.


<br><br>
<br>Observe this initial attempt at creating a table to represent Boston Subway data. This table contains subway rider names, current stations the riders are at and the action performed at the station (like entering and exiting). It also records the fares paid and balance amounts on their subway cards. This table also contains an ID for each rider “transaction”, which serves as the primary key.
  <img alt="&quot;First attempt at table for Boston subway&quot;" src="https://cs50.harvard.edu/sql/2024/notes/2/images/table1.jpg" referrerpolicy="no-referrer"><br>

<br>What redundancies exist in this table?

<br>We may choose to separate out rider names into a table of its own, to avoid having to duplicate the names so many times. We would need to give each rider an ID that can be used to relate the new table to this one.
<br>We may similarly choose to move subway stations to a different table and give each subway station an ID to be used as a foreign key here.


<br>The process of separating our data in this manner is called&nbsp;normalizing. When normalizing, we put each entity in its own table—as we did with riders and subway stations. Any information about a specific entity, for example a rider’s address, goes into the entity’s own table.
<br><br>
<br>We now need to decide how our entities (riders and stations) are related. A rider will likely visit multiple stations, and a subway station is likely to have more than one rider. Given this, it will be a many-to-many relationship.
<br>We can also use an ER diagram to represent this relationship.
  <img alt="&quot;Many-to-many relationship between riders and stations&quot;" src="https://cs50.harvard.edu/sql/2024/notes/2/images/erdriders.jpg" referrerpolicy="no-referrer">
  Here, we see that every rider must visit at least one station to be considered a rider. A station, though, could have no riders visiting it, because perhaps it is out of order temporarily. However, it is likely that a station has multiple riders visiting it, indicated by the crow’s foot in the ER diagram.<br>

<br><br>
Does the relationship between riders and stations have to be exactly the way described here? For example, why is it okay for a station to have 0 riders?
<br>
<br>It is up to the person designing the database to make decisions about relationships between entities. It is possible to add a constraint that says a station must have at least one rider to be considered a station.
<br><br>
<br>Now that we have the schema for two of the tables, let’s go ahead and create the tables.
<br>Let us open up a new database called&nbsp;mbta.db&nbsp;— MBTA stands for Massachusetts Bay Transportation Authority and runs the Boston Subway.
<br>If we run&nbsp;.schema, we will see nothing because no table has been created in this database yet.
<br>In this database, we run the following command to create the first table for riders:
CREATE TABLE riders (
    "id",
    "name"
);

  On running this, no results appear on the terminal. But if we run&nbsp;.schema&nbsp;again, we will now see the schema for the table&nbsp;riders, as defined by us!<br>

<br>Similarly, let us create a table for stations as well.
CREATE TABLE stations (
    "id",
    "name",
    "line"
);

  Here, we add a column&nbsp;"line"&nbsp;to store the train line that the station is a part of.<br>

<br>.schema&nbsp;now shows us the schema for both&nbsp;riders&nbsp;and&nbsp;stations.
<br>Next, we will create a table to relate these two entities. These tables are often called junction tables, associative entities or join tables!
CREATE TABLE visits (
    "rider_id",
    "station_id"
);

  Each row of this table tells us the station visited by a particular rider.<br>

<br><br>
Is it necessary to indent the lines within the&nbsp;CREATE TABLE&nbsp;parantheses?

<br>No, not strictly. However, we indent the column names to adhere to style conventions as always!

<br><br>
<br>SQLite has five storage classes:

<br>Null: nothing, or empty value
<br>Integer: numbers without decimal points
<br>Real: decimal or floating point numbers
<br>Text: characters or strings
<br>Blob: Binary Large Object, for storing objects in binary (useful for images, audio etc.)


<br>A storage class can hold several data types.
<br>For example, these are the data types that fall under the umbrella of the Integer storage class.
  <img alt="&quot;Integer Storage Class and Data Types&quot;" src="https://cs50.harvard.edu/sql/2024/notes/2/images/integer.jpg" referrerpolicy="no-referrer">
  SQLite takes care of storing the input value under the right data type. In other words, we as programmers only need to choose a storage class and SQLite will do the rest!<br>

<br>Consider this question: what storage class would we use to store fares? Each choice comes with affordances and limitations.

<br>Integers: We can store a 10 cent fare as the number 10, but that doesn’t make it very clear whether the fare is 10 cents or 10 dollars.
<br>Text: We can store the fare in text, like “$0.10”. However, now it will be hard to perform mathematical operations like adding up a rider’s fares.
<br>Real: We can store the fare using a floating point number, like 0.10, but it is not possible to store floating point numbers in binary precisely and—depending on how precise we need to be—doing so may lead to miscalculations down the line.


<br><br>
<br>It is possible to specify the data type of a column while creating a table.
<br>However, columns in SQLite don’t always store one particular data type. They are said to have&nbsp;type affinities, meaning that they try to convert an input value into the type they have an affinity for.
<br>The five type affinities in SQLite are: Text, Numeric (either integer or real values based on what the input value best converts to), Integer, Real and Blob.
<br>Consider a column with a type affinity for Integers. If we try to insert “25” (the number 25 but stored as text) into this column, it will be converted into an integer data type.
<br>Similarly, inserting an integer 25 into a column with a type affinity for text will convert the number to its text equivalent, “25”.
<br><br>
<br>To create the tables in our database again, we will first need to drop (or delete) the existing tables.
<br>Let’s try the following commands
DROP TABLE "riders";

DROP TABLE "stations";

DROP TABLE "visits";

  Running these statements gives no output, but&nbsp;.schema&nbsp;shows us that the tables have now been dropped.<br>

<br>Next, let us create a schema file that can be run to create the tables from scratch. This is an improvement over what we previously did—typing out the&nbsp;CREATE TABLE&nbsp;command for each table—because it allows us to edit and view the entire schema easily.
<br>Create a file&nbsp;schema.sql. Notice the extension&nbsp;.sql&nbsp;that enables syntax highlighting for SQL keywords in our editor.
<br>Inside the file, let’s type out the schemas again, but with the affinity types this time.
CREATE TABLE riders (
    "id" INTEGER,
    "name" TEXT
);

CREATE TABLE stations (
    "id" INTEGER,
    "name" TEXT,
    "line" TEXT
);

CREATE TABLE visits (
    "rider_id" INTEGER,
    "station_id" INTEGER
);


<br>Now, we read this file within the database to actually create the tables. Here is an updated ER Diagram with the data types included.
  <img alt="&quot;Updated ER Diagram with Data Types&quot;" src="https://cs50.harvard.edu/sql/2024/notes/2/images/erdtypes.jpg" referrerpolicy="no-referrer"><br>

<br><br>
Previously, we were able to query the tables in our database and see the results in a table-like structure. How do we get the same kind of results to show up here?
<br>
<br>We haven’t yet added any data to the tables. In Lecture 3, we will see how to insert, update and delete rows in tables that we have created!
<br>
Do we have a type affinity for Boolean?
<br>
<br>We don’t in SQLite, but other DBMS’s might have this option. A workaround could be to use 0 or 1 integer values to represent booleans.
<br><br>
<br>We can use table constraints to impose restrictions on certain values in our tables.
<br>For example, a primary key column must have unique values. The table constraint we use for this is&nbsp;PRIMARY KEY.
<br>Similarly, a constraint on a foreign key value is that it must be found in the primary key column of the related table! This table constraint is called, predictably,&nbsp;FOREIGN KEY.
<br>Let’s add primary and foreign key constraints to our&nbsp;schema.sql&nbsp;file.
CREATE TABLE riders (
    "id" INTEGER,
    "name" TEXT,
    PRIMARY KEY("id")
);

CREATE TABLE stations (
    "id" INTEGER,
    "name" TEXT,
    "line" TEXT,
    PRIMARY KEY("id")
);

CREATE TABLE visits (
    "rider_id" INTEGER,
    "station_id" INTEGER,
    FOREIGN KEY("rider_id") REFERENCES "riders"("id"),
    FOREIGN KEY("station_id") REFERENCES "stations"("id")
);

  Notice that we created two primary key columns, the ID for both&nbsp;riders&nbsp;and&nbsp;stations&nbsp;and then referenced these primary keys as foreign keys in the&nbsp;visits&nbsp;table.<br>

<br>In the&nbsp;visits&nbsp;table, there is no primary key. However, SQLite gives every table a primary key by default, known as the row ID. Even though the row ID is implicit, it can be queried!
<br>It is also possible to create a primary key composed of two columns. For example, if we wanted to give&nbsp;visits&nbsp;a primary key composed of both the rider and stations IDs, we could use this syntax
CREATE TABLE visits (
    "rider_id" INTEGER,
    "station_id" INTEGER,
    PRIMARY KEY("rider_id", "station_id")
);

  In this case, we probably want to allow a rider to visit a station more than once, so we would not move ahead with this approach.<br>

<br><br>
Is it possible to include our own primary key for the&nbsp;visits&nbsp;table?
<br>
<br>Yes! If, for some reason, an explicit primary key was required for the&nbsp;visits&nbsp;table, we could create an ID column and make it the primary key.
<br><br>
<br>A column constraint is a type of constraint that applies to a specified column in the table.
<br>SQLite has four column constraints:

<br>CHECK: allows checking for a condition, like all values in the column must be greater than 0
<br>DEFAULT: uses a default value if none is supplied for a row
<br>NOT NULL: dictates that a null or empty value cannot be inserted into the column
<br>UNIQUE: dictates that every value in this column must be unique


<br>An updated schema with these contraints would look like the following:
CREATE TABLE riders (
    "id" INTEGER,
    "name" TEXT,
    PRIMARY KEY("id")
);

CREATE TABLE stations (
    "id" INTEGER,
    "name" TEXT NOT NULL UNIQUE,
    "line" TEXT NOT NULL,
    PRIMARY KEY("id")
);

CREATE TABLE visits (
    "rider_id" INTEGER,
    "station_id" INTEGER,
    FOREIGN KEY("rider_id") REFERENCES "riders"("id"),
    FOREIGN KEY("station_id") REFERENCES "stations"("id")
);

  The&nbsp;NOT NULL&nbsp;constraint ensures that a station name and line are specified. On the other hand, riders are not mandated to share their names, because there is no constraint applied to rider names. Similarly, each station must have a unique name, as dictated by the&nbsp;UNIQUE&nbsp;constraint.<br>

<br>Primary key columns and by extension, foreign key columns must always have unique values, so there is no need to explicitly specify the&nbsp;NOT NULL&nbsp;or&nbsp;UNIQUE&nbsp;column constraints. The table constraint&nbsp;PRIMARY KEY&nbsp;includes these column constraints.
<br><br>
<br>Consider the following updated ER diagram, where the entity “Rider” has been swapped out with a new entity “Card” used to represent CharlieCards. CharlieCards, in the Boston Subway, can be loaded with money and are used to swipe into and sometimes out of stations.
  <img alt="&quot;Updated ER Diagram with CharlieCards and columns&quot;" src="https://cs50.harvard.edu/sql/2024/notes/2/images/updatederd.jpg" referrerpolicy="no-referrer"><br>

<br>Notice that a card can be swiped many times in total, but only at one station at a given time.
<br>The “Card” entity has an ID, which is also its primary key.
<br>There is also now an entity “Swipe”, with an ID of its own and a type. “Swipe” also records the time at which a card was swiped and the amount that was subtracted (equivalent to the amount of money needed to ride the subway)!
<br>Now, to implement these changes in our database, we need to first drop the&nbsp;riders&nbsp;table.
DROP TABLE "riders";


<br>Running&nbsp;.schema&nbsp;shows us the updated schema without the&nbsp;riders&nbsp;table.
<br>Next, we need a&nbsp;swipes&nbsp;table to represent the “Swipe” entity from our updated ER diagram. We could alter the&nbsp;visits&nbsp;table in the following way.
ALTER TABLE "visits"
RENAME TO "swipes";


<br>On running&nbsp;.schema&nbsp;we can see that the table&nbsp;visits&nbsp;was renamed to&nbsp;swipes. However, this is not the only change needed. We also need to add some columns, like the type of swipe.
ALTER TABLE "swipes"
ADD COLUMN "swipetype" TEXT;

  Notice the type affinity&nbsp;TEXT&nbsp;is also mentioned while adding this column.<br>

<br>We also have the ability to rename a column in an&nbsp;ALTER TABLE&nbsp;command. If we wanted to rename the column&nbsp;"swipetype"&nbsp;to make it less wordy, perhaps, we could try the following.
ALTER TABLE "swipes"
RENAME COLUMN "swipetype" TO "type";


<br>Finally, we have the ability to drop (or remove) a column.
ALTER TABLE "swipes"
DROP COLUMN "type";

  On running&nbsp;.schema&nbsp;again, we can confirm that the column&nbsp;"type"&nbsp;was dropped from the table.<br>

<br>It is also possible to return to the schema file&nbsp;schema.sql&nbsp;that we had originally and simply make these changes there instead of altering tables. The following is an updated&nbsp;schema.sql.
CREATE TABLE "cards" (
    "id" INTEGER,
    PRIMARY KEY("id")
);

CREATE TABLE "stations" (
    "id" INTEGER,
    "name" TEXT NOT NULL UNIQUE,
    "line" TEXT NOT NULL,
    PRIMARY KEY("id")
);

CREATE TABLE "swipes" (
    "id" INTEGER,
    "card_id" INTEGER,
    "station_id" INTEGER,
    "type" TEXT NOT NULL CHECK("type" IN ('enter', 'exit', 'deposit')),
    "datetime" NUMERIC NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "amount" NUMERIC NOT NULL CHECK("amount" != 0),
    PRIMARY KEY("id"),
    FOREIGN KEY("station_id") REFERENCES "stations"("id"),
    FOREIGN KEY("card_id") REFERENCES "cards"("id")
);


<br>Let us take a couple of minutes to read through the updated schema and make a note of the things that seem to have changed!

<br>The tables&nbsp;cards&nbsp;and&nbsp;swipes&nbsp;are added and the&nbsp;NOT NULL&nbsp;column constraint is used to require some values in&nbsp;swipes.
<br>The&nbsp;"datetime"&nbsp;column is given the type affinity numeric — this is because numeric types can store and display date values.
<br>The foreign key mapping is adjusted as needed, such that&nbsp;"card_id"&nbsp;is a foreign key referring to the ID of the&nbsp;cards&nbsp;table.
<br>A default value is assigned to the&nbsp;"datetime"&nbsp;column so that it automatically picks up the current timestamp if none is supplied. Notice the use of the&nbsp;CURRENT_TIMESTAMP&nbsp;—&nbsp;it returns the year, month, day, hour, minute and second combined into one value.
<br>There is a check in place to ensure the amount on a swipe is not 0. This is implemented through the column constraint&nbsp;CHECK, which is used with an expression&nbsp;"amount" != 0&nbsp;to ensure the value is not 0.
<br>Similarly, there is a check on&nbsp;"type"&nbsp;to ensure its value is one of ‘enter’, ‘exit’ and ‘deposit’. This is done because when a CharlieCard is swiped, it is usually for one of these three purposes, so it makes sense to have&nbsp;"type"&nbsp;assume these values only. Notice the use of the&nbsp;IN&nbsp;keyword to carry out this check! Is there a way to implement this check using the&nbsp;OR&nbsp;operator instead?


<br><br>
On trying to drop the table&nbsp;riders, an error comes up because we’re using the ID of&nbsp;riders&nbsp;as a foreign key. How can the table be dropped in this case?
<br>
<br>Foreign key constraints within the database are checked when dropping a table. Before dropping&nbsp;riders, we would need to first drop the foreign key column&nbsp;"rider_id".
<br>
How different is the syntax for a different DBMS like MySQL or PostgreSQL?
<br>
<br>Most of the SQLite syntax definitely applies to other database management systems as well. However, if we tried porting our SQLite code, some minimal changes would be needed.
<br>
If we don’t specify a type affinity of a column in SQLite, what happens?
<br>
<br>The default type affinity is numeric, so the column would get assigned the numeric type affinity.
<br><br>
<br>This brings us to the conclusion of Lecture 2 about Designing in SQL! For an interesting story about the origin of the name CharlieCard, read&nbsp;<a data-tooltip-position="top" aria-label="http://www.celebrateboston.com/mbta/charlie-card-origin.htm" rel="noopener nofollow" class="external-link" href="http://www.celebrateboston.com/mbta/charlie-card-origin.htm" target="_blank">this</a>&nbsp;article from Celebrate Boston.
]]></description><link>https://congzhi.wiki/cs50-sql/lecture-2-designing-(nc).html</link><guid isPermaLink="false">CS50 SQL/Lecture 2 - Designing (NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 22:05:24 GMT</pubDate><enclosure url="https://cs50.harvard.edu/sql/2024/notes/2/images/subwaymap.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://cs50.harvard.edu/sql/2024/notes/2/images/subwaymap.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Lecture 3 - Writing (NC)]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/cs50-sql/lecture-3-writing-(nc).html</link><guid isPermaLink="false">CS50 SQL/Lecture 3 - Writing (NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 22:05:20 GMT</pubDate></item><item><title><![CDATA[Lecture 4 - Viewing (NC)]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/cs50-sql/lecture-4-viewing-(nc).html</link><guid isPermaLink="false">CS50 SQL/Lecture 4 - Viewing (NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 22:05:33 GMT</pubDate></item><item><title><![CDATA[Lecture 5 - Optimizing (NC)]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/cs50-sql/lecture-5-optimizing-(nc).html</link><guid isPermaLink="false">CS50 SQL/Lecture 5 - Optimizing (NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 22:05:29 GMT</pubDate></item><item><title><![CDATA[Lecture 6 - Scaling (NC)]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/cs50-sql/lecture-6-scaling-(nc).html</link><guid isPermaLink="false">CS50 SQL/Lecture 6 - Scaling (NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 22:05:37 GMT</pubDate></item><item><title><![CDATA[Transaction in Database (NC)]]></title><description><![CDATA[ 
 <br><br>ACID]]></description><link>https://congzhi.wiki/cs50-sql/transaction-in-database-(nc).html</link><guid isPermaLink="false">CS50 SQL/Transaction in Database (NC).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Mon, 24 Feb 2025 07:25:59 GMT</pubDate></item><item><title><![CDATA[Data Structure and Algorithm]]></title><description><![CDATA[ 
 <br><br><br>DSA 系列上会放一些数据结构（DS）、排序算法（SA）和 Leecode 算法题（L）。下面是本系列的目录：<br>Data Structure

<br><a data-href="DS. B Tree" href="https://congzhi.wiki/data-structure-and-algorithm/ds.-b-tree.html" class="internal-link" target="_self" rel="noopener nofollow">DS. B Tree</a>
<br><a data-href="DS. Red-Black Tree" href="https://congzhi.wiki/data-structure-and-algorithm/ds.-red-black-tree.html" class="internal-link" target="_self" rel="noopener nofollow">DS. Red-Black Tree</a>
<br><a data-href="DS. Heap (Priority Queue)" href="https://congzhi.wiki/data-structure-and-algorithm/ds.-heap-(priority-queue).html" class="internal-link" target="_self" rel="noopener nofollow">DS. Heap (Priority Queue)</a>

<br>Leecode Algo Questions

<br><a data-href="L1. Contains Duplicate" href="https://congzhi.wiki/data-structure-and-algorithm/l1.-contains-duplicate.html" class="internal-link" target="_self" rel="noopener nofollow">L1. Contains Duplicate</a>
<br><a data-href="L2. Valid Anagram" href="https://congzhi.wiki/data-structure-and-algorithm/l2.-valid-anagram.html" class="internal-link" target="_self" rel="noopener nofollow">L2. Valid Anagram</a>
<br><a data-href="L3. Two Sum" href="https://congzhi.wiki/data-structure-and-algorithm/l3.-two-sum.html" class="internal-link" target="_self" rel="noopener nofollow">L3. Two Sum</a>
<br><a data-href="L4. Group Anagrams (Star)" href="https://congzhi.wiki/data-structure-and-algorithm/l4.-group-anagrams-(star).html" class="internal-link" target="_self" rel="noopener nofollow">L4. Group Anagrams (Star)</a>
<br><a data-href="L5. Top K Frequent Elements (Star)" href="https://congzhi.wiki/data-structure-and-algorithm/l5.-top-k-frequent-elements-(star).html" class="internal-link" target="_self" rel="noopener nofollow">L5. Top K Frequent Elements (Star)</a>
<br><a data-href="L6. Product of Array Except Self (Star)" href="https://congzhi.wiki/data-structure-and-algorithm/l6.-product-of-array-except-self-(star).html" class="internal-link" target="_self" rel="noopener nofollow">L6. Product of Array Except Self (Star)</a>
<br><a data-href="L7. Valid Sudoku (Medium)" href="https://congzhi.wiki/data-structure-and-algorithm/l7.-valid-sudoku-(medium).html" class="internal-link" target="_self" rel="noopener nofollow">L7. Valid Sudoku (Medium)</a>
<br><a data-href="L8. Encode and Decode Strings (Midium)" href="https://congzhi.wiki/data-structure-and-algorithm/l8.-encode-and-decode-strings-(midium).html" class="internal-link" target="_self" rel="noopener nofollow">L8. Encode and Decode Strings (Midium)</a>

<br>Sorting Algorithms

<br><a data-href="SA. Bubble Sort" href="https://congzhi.wiki/data-structure-and-algorithm/sa.-bubble-sort.html" class="internal-link" target="_self" rel="noopener nofollow">SA. Bubble Sort</a>

<br><br><br>你可以通过 <a data-tooltip-position="top" aria-label="mailto:duzhi_02@qq.com" rel="noopener nofollow" class="external-link" href="https://congzhi.wiki/mailto:duzhi_02@qq.com" target="_blank">duzhi_02@qq.com</a> 联系我！]]></description><link>https://congzhi.wiki/data-structure-and-algorithm/data-structure-and-algorithm.html</link><guid isPermaLink="false">Data Structure and Algorithm/Data Structure and Algorithm.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 17:27:19 GMT</pubDate></item><item><title><![CDATA[DS. B Tree]]></title><description><![CDATA[ 
 ]]></description><link>https://congzhi.wiki/data-structure-and-algorithm/ds.-b-tree.html</link><guid isPermaLink="false">Data Structure and Algorithm/DS. B Tree.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 08:05:31 GMT</pubDate></item><item><title><![CDATA[DS. Heap (Priority Queue)]]></title><description><![CDATA[ 
 <br><br>如果你熟悉树数据结构，你该知道，树有一个 root 根节点，根节点又有多个子节点，子节点后又相连有许多子节点，这些不同的节点一般用指针相连。<br>二叉树是一种特殊的树，二叉树的每个节点最多只能有 2 个子节点。而完全二叉树(complete binary tree) 是一棵特殊的二叉树。除了最后一层外，完全二叉树其余每层的节点都必须是满的，最后一层的节点必须从左往右连续填充。而堆，是一棵特殊的完全二叉树。<br>一般树的实现都是用指针实现，而完全二叉树由于其性质，一般使用数组来实现，因为完全二叉树的节点可以通过数组的索引定位到。使用数组而不使用指针而用数组有很多好处，除了节省了指针所带来的开销外，你还可以通过索引直接找到任意节点，时间复杂度为  。<br>对于数组中的节点 i：<br>
<br>左子节点的索引是 2*i + 1 
<br>右子节点的索引是 2*i + 2
<br>父节点的索引是 (i - 1) / 2 （取整）
<br>我们说了，堆是一棵特别的完全二叉树，它有一些属性。我们通过堆的属性把堆分成最小堆和最大堆。最小堆的根节点总是包含最小值，因此查找最小值非常高效（时间复杂度为 ）。同样的，最大堆的根节点总是包含最大值。<br><br>常见的数据结构操作包括增加、删除、查找、修改。我们用最小堆举例子。<br><br>当在堆中插入新元素时，新元素将被插入到堆的末尾（数组的最后一个位置）。然后新元素会和父节点逐步比较并上浮（和冒泡排序很类似），直到最小堆的性质被满足。因为这一操作是在树的一个 branch 上完成的，因而，插入操作的时间复杂度为 ，这和堆的高度 是一样的。<br><br>删除操作通常发生在堆顶，因为堆顶是最小堆的最小值。删除堆顶后，将堆的最后一个元素放到堆顶位置，然后通过下沉操作恢复堆的性质。下沉的逻辑是：逐步与较小的子节点比较并交换，直到堆的性质得到满足。和插入操作一样，删除操作的时间复杂度也是 。<br><br>查找堆顶元素的操作，即访问最小值（最小堆）或最大值（最大堆）。由于堆顶元素始终存储在数组的第一个位置，这一操作的时间复杂度为 。<br><br>堆排序是一种基于堆的数据结构实现的排序算法。其逻辑是先将输入数据构建为最大堆，然后依次将堆顶元素（最大值）移除并存储到结果列表，同时调整剩余的堆。堆排序的时间复杂度为 ，空间复杂度为 ，因为它在原数组上进行排序，不需要额外的存储空间。<br><br>堆化是将一个普通的二叉树转换成堆结构的过程，通常通过 sift down 操作实现。对于每一个非叶子节点，从该节点开始逐步调整与子节点的关系，直到堆的性质得到满足。Heapify 的时间复杂度为 ，因为在堆化过程中，树的叶子节点已经满足堆的性质，无需调整。]]></description><link>https://congzhi.wiki/data-structure-and-algorithm/ds.-heap-(priority-queue).html</link><guid isPermaLink="false">Data Structure and Algorithm/DS. Heap (Priority Queue).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 07:07:52 GMT</pubDate></item><item><title><![CDATA[DS. Red-Black Tree]]></title><description><![CDATA[ 
 <br><br>红黑树是一颗自平衡的二叉搜索树，红黑树有 5 个属性，这五个属性都满足时，我们就说红黑树是平衡的。由于其属性，在每次增删改查时，红黑树都需要不断地进行调整，所以它是自平衡的。红黑树的属性是：<br>
<br>每个节点要么是红节点，要么是黑节点。（红黑树名字的由来）
<br>根节点总是黑节点。
<br>每个 NIL 节点（即叶子节点）都是黑节点。
<br>每个红节点的子节点必须都要是黑节点。
<br>从根节点到任意叶子节点之间的所有路径中，黑节点的数量总是一样的。
<br>为了满足 5 ，红黑树每次加入节点时，初始颜色总是红色的。
<br><br>当你在红黑树中插入一个节点时，插入的节点会被默认设定为红节点。为什么？因为上面的第五条规则，从根节点到任意 nil 节点之间黑节点的个数都应当是相同的。插入红节点不会造成影响。之后，如果两个红节点连在一起，我们就需要修正红黑树（颜色翻转、旋转），平衡红黑树。<br><br>插入一个子节点（红节点）。但是 uncle node 是红结点，这时候，切换 grandparent node 和 parent/uncle node 的颜色。（颜色翻转）<br>初始状态：
	 ...
	  /
   ● G(黑)
    /   \
 ○ P(红) ○ U(红)

插入N(红)后：
	 ...
	  /
   ● G(黑)
    /   \
 ○ P(红) ○ U(红)
  /
○ N(红) ← 冲突！

颜色翻转：
	 ...
	  /
   ○ G(红)
    /   \
 ● P(黑) ● U(黑)
  /
○ N(红)
<br><br>插入一个子节点（红节点）。Parent node 是红节点，而且 uncle node 是黑结点，这时候，旋转。<br>初始状态：
	 ...
	  /
   ● G(黑)
    /   \
 ○ P(红) ● U(黑)

插入N(红)后：
	 ...
	  /
   ● G(黑)
    /   \
 ○ P(红) ● U(黑)
    \
   ○ N(红) ← 冲突！

P节点左旋：转换成 Case 3
	 ...
	  /
   ● G(黑)
    /   \
 ○ N(红) ● U(黑)
  /
○ P(红)
<br><br>初始状态：
	 ...
	  /
   ● G(黑)
    /   \
 ○ P(红) ● U(黑)
  /
○ N(红)

旋转 grandparent node
	 ...
	  /
   ○ P(红)
    /   \
 ○ N(红) ● G(黑)
		  \
		  ● U(黑)

最终形态：
	 ...
	  /
   ● P(黑)
    /   \
 ○ N(红) ○ G(红)
		  \
		  ● U(黑)
<br><br>我们要插入 1, 2, 3, 4, 5, 6<br><br>○ 1(红)
/   \
NIL NIL

由于根节点必须是黑节点:

● 1(黑)
/   \
NIL NIL
<br><br>● 1(黑)
/   \
NIL ○ 2(红)
	/   \
   NIL  NIL
<br><br>● 1(黑)
/   \
NIL ○ 2(红)
	/   \
   NIL  ○ 3(红)
	    /   \
	   NIL  NIL

冲突发生，回到我们 Case 3, 翻转 grandparent node

	○ 2(红)
	/   \
● 1(黑) ○ 3(红)
/   \     /   \
NIL	NIL  NIL  NIL

翻转颜色：
	● 2(黑)
	/   \
○ 1(红) ○ 3(红)
/   \     /   \
NIL	NIL  NIL  NIL
<br><br>	● 2(黑)
	/   \
○ 1(红) ○ 3(红)
/   \     /   \
NIL	NIL  NIL  ○ 4(红)
			  /   \
             NIL  NIL

冲突发生，回到 Case 1 的情况：颜色翻转

	○ 2(红)
	/   \
● 1(黑) ● 3(黑)
/   \     /   \
NIL	NIL  NIL  ○ 4(红)
			  /   \
             NIL  NIL

根节点需要是黑节点：

	● 2(黑)
	/   \
● 1(黑) ● 3(黑)
/   \     /   \
NIL	NIL  NIL  ○ 4(红)
			  /   \
             NIL  NIL
<br><br>	● 2(黑)
	/   \
● 1(黑) ● 3(黑)
/   \     /   \
NIL	NIL  NIL  ○ 4(红)
			  /   \
             NIL  ○ 5(红)
	              /   \
	             NIL  NIL

回到 Case 3：

	● 2(黑)
	/    \
● 1(黑)  ○ 4(红)
/    \    /    \
NIL	NIL ● 3(黑) ○ 5(红)
		/    \   /    \
      NIL   NIL NIL  NIL

Recoloring:

	● 2(黑)
	/    \
● 1(黑)  ● 4(黑)
/    \    /    \
NIL	NIL ○ 3(红) ○ 5(红)
		/    \   /    \
      NIL   NIL NIL  NIL
<br><br>
	● 2(黑)
	/    \
● 1(黑)  ● 4(黑)
/    \    /    \
NIL	NIL ○ 3(红) ○ 5(红)
		/    \   /    \
      NIL   NIL NIL  ○ 6(红)
					/   \
				  NIL   NIL
回到 Case 1:

	● 2(黑)
	/    \
● 1(黑)  ○ 4(红)
/    \    /    \
NIL	NIL ● 3(黑) ● 5(黑)
		/    \   /    \
      NIL   NIL NIL  ○ 6(红)
				    /   \
				  NIL   NIL
]]></description><link>https://congzhi.wiki/data-structure-and-algorithm/ds.-red-black-tree.html</link><guid isPermaLink="false">Data Structure and Algorithm/DS. Red-Black Tree.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 07:52:07 GMT</pubDate></item><item><title><![CDATA[L1. Contains Duplicate]]></title><description><![CDATA[ 
 <br><br>Given an integer array nums, return true if any value appears at least twice in the array, and return false if every element is distinct.<br><br>为了检查数组中的元素是否存在重复，使用 std::unordered_set 看上去很不错。尽管 std::set 也可以完成此任务，并且红黑树能够提供  的增删查改时间复杂度，但在题目描述的情景下 std::unordered_set 通过平均  的插入和查找性能表现得更为优异。<br>如果检查的数据量极大（上亿）使用 std::set 会不会更好呢？<br>#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;unordered_set&gt;

class mySolution{
public:
    bool checkDuplication(const std::vector&lt;int&gt;&amp; v){
        std::unordered_set&lt;int&gt; set;
        for(int elem : v){
            if(set.count(elem)){ return true; }
            // if(set.contains(elem)){ return true; } // C++20
            set.insert(elem);
        }
        return false;
    }
};

int main(){
    std::vector&lt;int&gt; v1 = {1,2,3,4,9,7,2};
    std::vector&lt;int&gt; v2 = {1,2,4,5,10,59,66,100,15,20,5,10};
    std::vector&lt;int&gt; v3 = {1,2,3,4,5,6,7,8,9,10};
    mySolution solution;
    std::cout &lt;&lt; (solution.checkDuplication(v1) ? "Find!\n" : "Not Find!\n")
              &lt;&lt; (solution.checkDuplication(v2) ? "Find!\n" : "Not Find!\n")
              &lt;&lt; (solution.checkDuplication(v3) ? "Find!\n" : "Not Find!\n")
              &lt;&lt; std::endl;
    return 0;
}
]]></description><link>https://congzhi.wiki/data-structure-and-algorithm/l1.-contains-duplicate.html</link><guid isPermaLink="false">Data Structure and Algorithm/L1. Contains Duplicate.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 07:11:17 GMT</pubDate></item><item><title><![CDATA[L2. Valid Anagram]]></title><description><![CDATA[ 
 <br><br>Given two strings s and t, return true if t is an anagram of s, and false otherwise.<br><br>第一种解决方案：将 s1, 2s 两个字符串进行复制，然后用 std::sort 对他们进行排序。检查排序后的两个字符串。<br>#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;algorithm&gt;

class mySolution{
public:
    bool checkAnagram(const std::string&amp; s1, const std::string&amp; s2){
        if(s1.length() != s2.length()){ return false; }
        std::string sorted_s1 = s1, sorted_s2 = s2;
        std::sort(sorted_s1.begin(), sorted_s1.end());
        std::sort(sorted_s2.begin(), sorted_s2.end());
        return (sorted_s1 == sorted_s2);
    }
};

int main(){
	std::string s1{"listen"}, s2{"silent"};
    mySolution solution;
    std::cout &lt;&lt; (solution.checkAnagram(s1, s2) ? "Positive" : "Negative") &lt;&lt; std::endl;;
    return 0;
}
<br><br>字符计数的方法：<br>#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;vector&gt;

class mySolution {
public:
    bool checkAnagram(const std::string&amp; s1, const std::string&amp; s2) {
        if (s1.length() != s2.length()){ return false; }

        std::vector&lt;int&gt; charCount(26, 0);
        for (char c : s1) {
            charCount[c - 'a']++;
        }
        for (char c : s2) {
            charCount[c - 'a']--;
        }
        for (int count : charCount) {
            if (count != 0) return false;
        }
        return true;
    }
};
int main() {
    std::string s1{"listen"}, s2{"silent"};
    mySolution solution;
    std::cout &lt;&lt; (solution.checkAnagram(s1, s2) ? "Positive" : "Negative") &lt;&lt; std::endl;
}
]]></description><link>https://congzhi.wiki/data-structure-and-algorithm/l2.-valid-anagram.html</link><guid isPermaLink="false">Data Structure and Algorithm/L2. Valid Anagram.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Mon, 24 Mar 2025 18:20:24 GMT</pubDate></item><item><title><![CDATA[L3. Two Sum]]></title><description><![CDATA[ 
 <br><br>Given an array of integers num and an integer target, return indices of two numbers such that they add up to target.<br>You may assume that each input would have exactly one solution, and you may not use the same element twice.<br><br>暴力求解的方法，我们需要两个 for 循环遍历所有可能的数字对，因而其时间复杂度为 。思路是这样的：<br>#include &lt;iostream&gt;
#include &lt;vector&gt;

class mySolution{
public:
    std::vector&lt;int&gt; twoSum(const std::vector&lt;int&gt;&amp; nums, const int&amp; target){
        for( size_t i = 0; i &lt; nums.size(); i++){
            for( size_t j = i + 1; j &lt; nums.size(); j++){
                if(nums[i] + nums[j] == target){
                    return{static_cast&lt;int&gt;(i), static_cast&lt;int&gt;(j)};
                }
            }
        }
        return {};
    }
};

int main(){
    std::vector&lt;int&gt; nums = {1,2,4,8,16,32,64,128,256};
    int target = 96;
    mySolution solution;
    std::vector&lt;int&gt; res = solution.twoSum(nums, target);
    if(res.size()){
        for(auto elem : res){
            std::cout &lt;&lt; elem &lt;&lt; std::endl;
        }
    }
    else{
        std::cout &lt;&lt; "Negative" &lt;&lt; std::endl;
    }
    return 0;
}
<br><br>再好一点的方法就是使用哈希表，简单的思路如下：<br>#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;unordered_map&gt;

std::vector&lt;int&gt; twoSum(const std::vector&lt;int&gt;&amp; nums, int target) {
    std::unordered_map&lt;int, int&gt; numMap;
    for (int i = 0; i &lt; nums.size(); i++) {
        int complement = target - nums[i];
        if(numMap.find(complement) != numMap.end()){
            return {numMap[complement], i};
        }
        numMap.insert(std::make_pair(nums[i], i));
    }
    return {};
}

int main() {
    std::vector&lt;int&gt; nums = {2, 7, 11, 15};
    int target = 9;
    std::vector&lt;int&gt; result = twoSum(nums, target);
    for (int index : result) {
        std::cout &lt;&lt; index &lt;&lt; " ";
    }
    return 0;
}
]]></description><link>https://congzhi.wiki/data-structure-and-algorithm/l3.-two-sum.html</link><guid isPermaLink="false">Data Structure and Algorithm/L3. Two Sum.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Mon, 24 Mar 2025 18:00:22 GMT</pubDate></item><item><title><![CDATA[L4. Group Anagrams (Star)]]></title><description><![CDATA[ 
 <br><br>Given an array of strings strs, group the anagrams together. You can return the answer in any order.<br>An anagram is a word or phrase formed by rearranging the letters of a different word or phrase, typically using all the original letters exactly once.<br>Example 1:<br>
<br>Input: strs = ["eat", "tea", "tan", "ate", "nat", "bat"]
<br>Output: [["bat"], ["nat", "tan"], ["ate", "eat", "tea"]]
<br>Example 2:<br>
<br>Input: strs = [""]
<br>Output: [[""]]
<br><br>为了解决这道题，键值对肯定少不了。为了快速插入和查询，我选择使用 std::unordered_map。由于我们需要对字符串数组进行分类，并输出分组后的结果。和 <a data-href="L2. Valid Anagram#Solution - 1" href="https://congzhi.wiki/data-structure-and-algorithm/l2.-valid-anagram.html#Solution_-_1" class="internal-link" target="_self" rel="noopener nofollow">L2. Valid Anagram &gt; Solution - 1</a> 类似的思路，这里我们先对字符串数组中的每个字符串进行排序，将排序后的字符串作为键，排序前的字符串作为值。利用这种键值对关系，我们可以将所有键值对加入到 std::unordered_map 中。<br>这样，每一个键都会对应一组具有相同字符组合的字符串（share a same anagram）。通过遍历 std::unordered_map 中的值，即可输出分类后的字符串数组。<br>#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;string&gt;
#include &lt;unordered_map&gt;
#include &lt;algorithm&gt;

class mySolution{
public:
    std::vector&lt;std::vector&lt;std::string&gt;&gt; groupAnagrams(const std::vector&lt;std::string&gt;&amp; anagrams) {
        std::unordered_map&lt;std::string, std::vector&lt;std::string&gt;&gt; map;
        for(auto str : anagrams){
            std::string sorted_str = str;
            std::sort(sorted_str.begin(), sorted_str.end());
            map[sorted_str] .push_back(str);
        }
        std::vector&lt;std::vector&lt;std::string&gt;&gt; groupedAnagrams;
        for(auto entry : map){
            groupedAnagrams.push_back(entry.second);
        }
        return groupedAnagrams;
    }
};
int main() {
    std::vector&lt;std::string&gt; anagrams{"eat", "tea", "tan", "ate", "nat", "bat"};
    mySolution solution;
    std::vector&lt;std::vector&lt;std::string&gt;&gt; grouped_Anagrams =  solution.groupAnagrams(anagrams);
    for(auto group : grouped_Anagrams){
        for(auto str : group){
            std::cout&lt;&lt; str &lt;&lt; ", ";
        }
        std::cout &lt;&lt; std::endl;
    }
    return 0;
}
]]></description><link>https://congzhi.wiki/data-structure-and-algorithm/l4.-group-anagrams-(star).html</link><guid isPermaLink="false">Data Structure and Algorithm/L4. Group Anagrams (Star).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Mon, 24 Mar 2025 19:08:59 GMT</pubDate></item><item><title><![CDATA[L5. Top K Frequent Elements (Star)]]></title><description><![CDATA[ 
 <br><br>Given an integer array nums and an integer k, return the k most frequent elements. You may return the answer in any order.<br>Example:<br>
<br>Input: nums = [1, 1, 1, 2, 2, 3], k = 2
<br>Output: [1, 2]
<br><br>提示：哈希表和优先队列（也就是堆）。<br>我的思路是，把这些数字都存储到哈希表中，这里我们用 std::unordered_map ，因为它要存储一个键值对，我们将重叠的数字作为键，将其出现的频次作为值。每一次出现相同的键，就将他的值进行加一操作，也就得到了该键出现的频次。<br>之后，将这个 map 结构放到一个 std::pair&lt;int, int&gt; 的优先队列里面，由于我们想要让堆来反应其最大频次，而在 C++ 中默认的堆是最大堆，我们将键值对中的值（也就是频次）作为优先队列的。最后按需求弹出 k 个频次最高的元素。<br>#include &lt;iostream&gt;
#include &lt;unordered_map&gt;
#include &lt;vector&gt;
#include &lt;algorithm&gt;

class mySolution{
public:
    std::vector&lt;int&gt; topK(const std::vector&lt;int&gt;&amp; nums, const int&amp; k ){
        std::unordered_map&lt;int, int&gt; map;
        for(auto elem : nums){
            map[elem] += 1;
        }
        std::vector&lt;std::pair&lt;int, int&gt;&gt; heap;
        for(std::pair&lt;int, int&gt; elem : map){
            heap.push_back({elem.second, elem.first});
        }
        std::make_heap(heap.begin(), heap.end());
        std::vector&lt;int&gt; res;
        for (int i = 0; i &lt; k; i++) {
            std::pop_heap(heap.begin(), heap.end()); 
            res.push_back(heap.back().second);
            heap.pop_back();
        }
        return res;
    }
};

int main(){
    std::vector&lt;int&gt; nums = {1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 
                         6, 6, 6, 6, 6, 6, 7, 8, 9, 10, 10, 10, 11, 12};
    int k = 3;

    mySolution solution;
    std::vector&lt;int&gt; res = solution.topK(nums, k);
    for(auto elem : res){
        std::cout &lt;&lt; elem &lt;&lt; std::endl;
    }
    return 0;
}
]]></description><link>https://congzhi.wiki/data-structure-and-algorithm/l5.-top-k-frequent-elements-(star).html</link><guid isPermaLink="false">Data Structure and Algorithm/L5. Top K Frequent Elements (Star).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 10:23:20 GMT</pubDate></item><item><title><![CDATA[L6. Product of Array Except Self (Star)]]></title><description><![CDATA[ 
 <br><br>Given an integer array nums , return an array answer such that  answer[i] is equal to the product of all the elements of nums except nums[i].<br>The product of any prefix or suffix of nums is guaranteed to fit in a 32-bit integer.<br>You must write an algorithm that runs on  time and without using the division operation.<br>Example1:<br>
<br>Input: nums = [1, 2, 3, 4]
<br>Output: [24, 12, 8, 6]
<br>Example2:<br>
<br>Input: nums = [-1, 1, 0, -3, 3]
<br>Output: [0, 0, 9, 0, 0]
<br><br>暴力方法需要循环遍历数组，时间复杂度来到了  ，不符合要求。<br>前缀积 + 后缀积 时间复杂度空间复杂度都为  。<br>#include &lt;iostream&gt;
#include &lt;vector&gt;

class mySolution{
public:
    std::vector&lt;int&gt; productExceptSelf(const std::vector&lt;int&gt; nums){
        std::vector&lt;int&gt; answer(nums.size());
        int prefix = 1;
        for(int i = 0; i &lt; nums.size(); i++){
            answer[i] = prefix;
            prefix *= nums[i];
        }
        int suffix = 1;
        for(int i = nums.size() - 1; i &gt;=0; --i){
            answer[i] *= suffix;
            suffix *= nums[i];
        }
        return answer;
    }
};

int main(){
    std::vector&lt;int&gt; nums{1, 2, 3, 4};
    mySolution solution;
    std::vector&lt;int&gt; answer = solution.productExceptSelf(nums);
    for(auto elem : answer){
        std::cout &lt;&lt; elem &lt;&lt; std::endl;
    }
    return 0;
}
]]></description><link>https://congzhi.wiki/data-structure-and-algorithm/l6.-product-of-array-except-self-(star).html</link><guid isPermaLink="false">Data Structure and Algorithm/L6. Product of Array Except Self (Star).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 15:35:57 GMT</pubDate></item><item><title><![CDATA[L7. Valid Sudoku (Medium)]]></title><description><![CDATA[ 
 <br><br>Determine if a 9 x 9 Sudoku board is valid. Only the filled cells need to be validated according to the following rules:<br>
<br>Each row must contain the digits 1-9 without repetition.
<br>Each column must contain the digits 1-9 without repetition.
<br>Each of the nine 3 x 3 sub-boxes of the grid must contain the digits 1-9 without repetition.
<br>Note: <br>
<br>A Sudoku board (partially filled) could be valid but is not necessarily solvable.
<br>Only the filled cells need to be validated a according to the mentioned rules.
<br><br>没有思路，唯一能想到的办法就是 B.F. 。按行、列、子块分别遍历 3 遍。查看这些规则是否有被满足。如果有一次违规，直接返回 false。我们可能需要 27 个大小为 9 的哈希集合，即行、列和子块分别 9 个 std::unordered_set&lt;char&gt;。]]></description><link>https://congzhi.wiki/data-structure-and-algorithm/l7.-valid-sudoku-(medium).html</link><guid isPermaLink="false">Data Structure and Algorithm/L7. Valid Sudoku (Medium).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 16:38:54 GMT</pubDate></item><item><title><![CDATA[L8. Encode and Decode Strings (Midium)]]></title><description><![CDATA[ 
 <br><br>Design an algorithm to encode a list of strings to a string. The encoded string is then sent over the network and is decoded back to the original list of strings.<br>Sender has the function:<br>std::string encode(const std::vector&lt;std::string&gt;&amp; strs){
// ...
	return encoded_string;
}
<br>Receiver has the function:<br>std::vector&lt;std::string&gt; decode(const std::string&amp; encoded_string){
// ...
	return strs;
}
<br><br>看到描述，第一反应是在每一个字符串后面加入额外的特殊字符，如 HTTP 报文中的 CRLF 。但 CR+LF 本来就是回车和换行的意思，但如果这些字符出现在某个字符串中，就会导致解码错误。<br>一种可行的解决办法是在每个字符串的前面加上该字符串的长度元数据（和 glibc malloc 管理虚拟内存一样），在解码时通过解析长度来找到每个字符串的边界。<br>用 STL ，我们可以先将题目所给的类型转换成 std::vector&lt;std::pair&lt;int, std::string&gt;&gt; 来存储。]]></description><link>https://congzhi.wiki/data-structure-and-algorithm/l8.-encode-and-decode-strings-(midium).html</link><guid isPermaLink="false">Data Structure and Algorithm/L8. Encode and Decode Strings (Midium).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 17:23:58 GMT</pubDate></item><item><title><![CDATA[SA. Bubble Sort]]></title><description><![CDATA[ 
 <br>排序算法的作用是将一组元素按照指定顺序进行排列。常见的顺序包括数字从小到大的升序排列、字母从 A 到 Z 的字典序排列，也可以是其他任意顺序（如降序排列）。高效的排序算法对于系统至关重要，因为它在一定程度上会影响系统的整体性能，尤其是在需要频繁处理大规模数据时。<br><br>冒泡排序可以说是最简单的排序算法，它的核心思想是通过多次比较和交换，将较大的元素逐步“冒泡”到序列的末尾。]]></description><link>https://congzhi.wiki/data-structure-and-algorithm/sa.-bubble-sort.html</link><guid isPermaLink="false">Data Structure and Algorithm/SA. Bubble Sort.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 17:31:54 GMT</pubDate></item><item><title><![CDATA[存储器扩展技术]]></title><description><![CDATA[ 
 <br><br>在数字电路中，二进制译码器可以把  位二进制输入转换成  个输出。译码器的应用非常广泛，地址解码、数据选择等都是常用的译码器应用。<br>为了更清楚地理解 CPU 的  根地址线是如何产生多达  个连续的地址空间的，我们先用简单的3-8译码器来举例。74LS138是最为常见的3线-8线译码器，我们不去关注它的选通使能端，着重观察它的逻辑真值表。在如下表的逻辑真值表中，我们看到，虽然我们的输入位只有 3 位，但是却解码出了 8 种输出状态。即 3 根输入的”地址线“产生了  个连续的”地址空间“。<br><br>在74LS138译码器中，当输出端被选中后会变为低电平（0），其余输出端口保持高电平（1），在设计译码电路时，我们可以人为规定选中后呈现高电平或是低电平。现在，我们就应该理解为什么  根地址线，能过产生  个连续的地址空间了。当寻址方式是按字节寻址时，译码电路的一个输出端就能够对应 1byte 的数据。<br>当地址线条数有 12 根，且按照字节寻址，那么 CPU 直接寻址范围就等于:<br><br>
<br>记忆单元（存储基元/ 存储元/ 位元）(Cell)

<br>具有两种稳态的能够表示二进制数码0和1的物理器件 


<br>存储单元/ 编址单位（Addressing Unit）

<br>具有相同地址的位构成一个存储单元，也称为一个编址单位 


<br>存储体/ 存储矩阵/ 存储阵列（Bank） 

<br>所有存储单元构成一个存储阵列 


<br>编址方式（Addressing Mode）

<br>字节编址、按字编址 


<br><br>位平面(Bit plane) 是存储体的重要组成部分。而每个内存芯片(DRAM chip)中可以包含多个存储体。明晰了它们之间的关系，我们来看下面这张图，假如每个位平面都包含 64*64 的位元，也就是说每个位平面的寻址范围都是 0-4096，每一个可寻址位都包含 1bit 信息。这样，8 个位平面摞在一起就可以每次寻址 8bits（也就是1byte）的数据。<br><img alt="Pasted image 20240812173423.png" src="https://congzhi.wiki/some-notes/pics/pasted-image-20240812173423.png"><br><br><br>在上节中我们看到，寻址空间的范围是会随地址线条数的增加翻倍增长的。地址线每增加一根，可寻址空间增大一倍。这样会导致一个很直接的问题，那就是如果我们只采用一个译码器，译码器每增加一个输入端就会使得输出端翻倍！12 根地址线译码后可是能产生 4096 个输出端口。这样设计的译码电路会使得整个芯片奇长无比，但显然设计人员考虑到了这个问题。因而，我们现在的内存多采用的是二维地址译码方式。<br><br>我们将地址线划分成为不同行(Row)不同列(Column)，当某寻址单元行选中同时列选中时也可以选中这一单元。这样可以避免译码器过于庞大。而且现代计算机多采用地址线分时复用，也就是用 6 根地址线分时复用，由 RAS(Row Address Select) 和 CAS(Column Address Select) 控制分时的时序。这样，原先 12 根地址线就可以减少到 7 根（6根复用线，1根 RAS/CAS）。<br><img alt="Pasted image 20240812172331.png" src="https://congzhi.wiki/some-notes/pics/pasted-image-20240812172331.png"><br>
看上去好像分时复用要花上比原先多一倍的时间去访存。但实际上分时复用其实并不会浪费多少时间，因为行译码后会将这一整行的数据全部放到行缓冲中，这是用 SRAM 做的，速度要比主存快很多，当列选中信号到来的时候，CPU直接从行缓冲中读取数据。而且行缓冲技术遵循了 程序的局部性原理 当CPU后面再需要访存的时候，如果行译码后仍然在这一行，CPU就会直接从 SRAM 中读取数据。这样不但访存时间不会增加，反而因为局部性原理访存时间还减少了不少。<br><br><br>存储器也会出现和一维地址译码方式类似的问题。如果单方面扩大存储芯片的存储容量，就可能导致芯片越做越大，不但可能影响存储性能，也会对物理空间造成影响。因此，我们可以对存储芯片进行编址，这种增加芯片数量增大寻址范围的方式就是我们所说的字扩展。<br>举个例子，两片 4K * 8bits 的芯片可以通过字扩展形成 8K * 8bits 的”组合芯片“。通过字扩展，CPU 可以寻址的范围就从 0-4095 变为 0-8191。<br>芯片进行字扩展时，因为字长不需要改变，所以芯片的字线相连一模一样。片内的地址线也不需要改变，只需要译码芯片选中时将输出端连接响应的芯片片选引脚即可。我们使用3-8译码器，3位地址线可以编址选中 8 片芯片。<br><br>字扩展可以帮我们解决内存寻址大小的问题，但是随着16位机、32位机器甚至64位机的出现，我们还需要对内存芯片进行位扩展来使得我们一次性能读出符合机器的的位数。假如我们的机器是16位机，而恰好我们手头上只有位宽8位的芯片，不论寻址大小是多少，我们总需要两片这样的芯片才能位扩展成16位 I/O 的数据宽度要求。<br>当我们用芯片进行位扩展时，我们想要扩展芯片 I/O 的数据宽度。若 CPU 数据线有16根，我们用两个 4K*8bits 的芯片，片选和地址引脚连接完全相同，芯片1的8位数据线连接系统数据线 D0-D7，芯片2的8位数据线连接系统的 D8-D15即可完成芯片的位扩展。<br><br>字位同时扩展。]]></description><link>https://congzhi.wiki/some-notes/存储器扩展技术.html</link><guid isPermaLink="false">Some Notes/存储器扩展技术.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Mon, 24 Feb 2025 01:31:03 GMT</pubDate><enclosure url="https://congzhi.wiki/some-notes/pics/pasted-image-20240812173423.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/some-notes/pics/pasted-image-20240812173423.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[进程的一生——从出生到死亡 (Abandoned)]]></title><description><![CDATA[ 
 <br><br><br>存储程序的工作方式是现代计算机运行的根基之一，它由冯诺依曼在1946年提出。它的核心思想是将用于解决问题的程序和数据一起存储在计算机的存储器中。计算机通过读取和执行这些存储的指令自动地完成各种任务，在执行过程中不需要认为的干预。<br><br>
Any problem in computer science can be solved by another layer of indirection.
<br>当今的计算机是层层抽象的产物，我们已经不需要直接和逻辑进行交互，而将这些繁琐的程序交给操作系统这个”管家“（管理软硬件资源）。有了一层层的抽象，我们现在只需要把高级语言源程序交给操作系统，而不需要明白管家之后要做什么。<br>我们有了底层的门电路后能够将电路实现进行封装，创造出自己的存储元件、计算器、控制器等这些功能部件。之后，我们组合这些元件可以组成自己简易的计算机了，但是指令太乱、没有章法，咋办？<br>人们提出了一个个的指令集体系结构来应对指令混乱的问题，规约底层硬件的实现，为上层提供操作计算机的接口。最开始我们用开关、灯泡来作为计算机的输入和输出。后来，我们将这些工作交给操作系统代为我们完成，我们只用输入指令。这也是汇编诞生的节点，而直到这里都是机器级的代码，也就是对于不同的ISA，你需要使用不同的汇编。<br>再到后来，具有跨平台特性(portable)的高级语言诞生了。汇编指令和机器码是一一对应的，我们可以通过汇编器来直接转换，我们在一定程度上可以说汇编就是机器语言。而高级对于机器来说就相当于外国语，因为高级语言是人类读写的，是人类与机器交流的接口。通过编译器，我们就可以将高级语言翻译为机器能够理解的语言。所有相比于汇编器，编译器可就复杂多了。<br>从高级语言的诞生开始，你就可以用高级语言提供的抽象来操作计算机底层硬件为你做各种各样的操作。各种应用层出不穷，为人们的生活带来了极大的便利。<br><br>程序自动执行而不需要人为干预听起来可能有些不知所以然。到了后面，我们会慢慢发现，这些其实都是堆和栈的功劳。在进程的虚拟内存中，只有堆和栈是会一直变化的，栈中的创建栈帧、销毁栈帧更是时刻不停的发生。<br><br>栈是一种数据结构，遵循着先进后出(Last In First Out, LIFO) 的原则进行工作。在程序运行的过程中，我们往往需要一些函数帮助我们实现想要的功能，而栈的应用就是保存在程序执行过程中所需要保存的返回地址和局部变量，还负责保存和恢复现场信息。<br>如果你学过系统调用或中断，你一定对“栈”不陌生。栈非常重要，它保存的数据是程序近期会用到的数据。在硬件中断或软件中断发生时，操作系统为了响应这些中断，会将程序运行的现场信息保存到内核栈。等操作系统应付完差事，读取栈中数据并恢复现场状态。<br>如果执行用户程序呢？在x86-64架构下，当我们进入一段用户程序的函数中时，我们会：<br>
<br>保存参数 寄存器传递和压栈
<br>调用函数 call func
<br>压栈保存当前栈帧 push ebp
<br>设置新的栈顶 mov ebp, esp
<br>分配局部变量 push sub_args
<br>函数执行 add or sub and so on
<br>函数执行完毕要返回，这时我们会：<br>
<br>释放局部变量空间 mov esp, ebp
<br>恢复调用函数栈帧 pop ebp
<br>返回 ret
<br>其中，EBP和ESP分别是帧指针寄存器和栈指针寄存器，分别用来指 向当前栈帧的底部和顶部。其实也并不复杂，就是调用函数的栈底就是被调用函数的栈顶。我们后面会用具体的例子说明。<br><br>我们可能会知道，堆是容纳、存放动态内存分配的内存块。尽管使用上理解起来很简单，但是堆的实现比栈来得复杂。堆内存的分配有很多种实现方式，如bitmap，linked list等。在这个文档中，你只需要知道，堆是用于动态内存分配，程序在运行时可以请求和释放内存块。<br><br>x86汇编有三部分构成：1) 伪指令，2) 指令，3) 标号 所构成。<br><br><br><br>指令中需要给出的信息有：<br>
<br>操作性质（操作码）
<br>源操作数1 或/和 源操作数2（可能是立即数、寄存器、存储地址）
<br>目的操作数地址（寄存器、存储地址）
<br><br><br>入口参数的位置：从左到右的顺序入栈，即最右边的参数先入栈。<br><br><br><br><br>不同于传统32位机器将所有要传递的参数压到栈中保存的方式，在x86-64架构下的机器会先使用寄存器传递参数，通过通用寄存器传送参数，很多过程不用访问栈，缩短了代码的执行时间。在x86-64架构下的机器中，最多可有6个整型或指针型参数通过寄存器传递。当超过6个入口参数时，后面的通过栈来传递。<br>寄存器传递：在x86-64架构下，前六个整数参数依次存放在寄存器 %rdi、%rsi、%rdx、%rcx、%r8 和 %r9 中。如果有浮点参数，它们会依次存放在 %xmm0 到 %xmm7 中。<br>栈传递：如果参数数量超过了寄存器的数量限制，多余的参数会依次压入栈中，从右到左的顺序。在栈中传递的参数若是基本类型，则都被分配8个字节。<br>假设有一个函数 func，它有八个整型参数和两个浮点型参数：<br>
void func(int a, int b, int c, int d, int e, int f, int g, int h, float i, float j);<br>在调用 func 时，前六个参数 a 到 f 会存放在寄存器中，而参数 g 和 h 会被压入栈中：<br>整型数：
	a -&gt; %rdi
	b -&gt; %rsi
	c -&gt; %rdx
	d -&gt; %rcx
	e -&gt; %r8
	f -&gt; %r9
	g -&gt; 栈
	h -&gt; 栈
浮点数：
	i -&gt; %xmm0
	j -&gt; %xmm1
	...
	klmnop -&gt; %xmm2-%xmm7
	q -&gt; 栈
<br><br>在上面，我们知道当我们直接使用寄存器来传递参数后，能够免去一系列的微指令的开销。当我们每次调用过程中都只使用寄存器传递参数的话，我们就能保证系统的性能处在最佳状态。为了优化为了减少参数传递的开销，可以考虑以下优化方法：<br>
<br>使用结构体：将多个相关参数打包成一个结构体，传递结构体指针。
<br>减少参数数量：尽量减少函数参数的数量，保持在寄存器的限制范围内。
<br><br>从我们编写程序，到一个真正可以在机器上运行的二进制可执行目标程序ELF之间，我们需要执行许多步骤。C语言源程序的预处理、编译到汇编最后链接之后我们才能获得二进制的可执行文件。下面，我们会一步一步的说明每个阶段的作用是什么。<br>
<img alt="Pasted image 20240916212548.png" src="https://congzhi.wiki/some-notes/pics/pasted-image-20240916212548.png"><br><br><br>当你创建了一个 xxxx.c 的文件，一颗ELF的种子开始在此处生根。我们前面说过，高级语言源程序是给人类读的，机器没办法直接执行高级语言源程序。可能我们没有办法直接理解这句话，我们下面用最简单的 hello.c 源程序来说明一下。<br>#include &lt;stdio.h&gt;
int main(){
	printf("hello, world\n"); // This prints "hello, world\n"
}
<br>上面的代码在计算机看来就是一连串的ASCII字符，转换成ASCII就是：<br># i n c l u d e &lt;sp&gt; &lt; s t d i o . h &gt; \n \n i n t m a i n ( ) \n { \n  &lt;sp&gt; &lt;sp&gt; &lt;sp&gt; &lt;sp&gt; p r i n t f ( " h e l l o , w o r l d \ n " ) ; \n } 
<br>而计算机实际上只能存储0和1所组成的二进制数，将这些字符转换成对应的十进制数数字就是：<br>35 105 110 99 108 117 100 101 32 60 115 116 100 105 111 46 104 62 10 10 105 110 116 32 109 97 105 110 40 41 10 123 10 32 32 32 32 112 114 105 110 116 102 40 34 104 101 108 108 111 44 32 119 111 114 108 100 92 110 34 41 59 10 125
<br><br>在得到源程序后，我们可以用下面的命令对源程序进行预处理：<br>gcc -E hello.c -o hello.i
cpp hello.c &gt; hello.i
<br>预处理完毕后，我们就得到了 xxxx.i 的预处理后文本文件。在Linux中，文件的后缀并不重要，但我们这样规定，使得我们能够清楚 xxxx.i 是一个预处理文件。那么预处理阶段做了什么呢？<br>预处理文件处理源文件中以 '#' 开头的语句。如：<br>
<br>删除 #define 并展开其所定义的宏
<br>处理所有条件预编译指令，如 #if、#ifdef、#endif等
<br>插入头文件到#include处，可以递归方式进行处理（复制粘贴）
<br>删除注释（可选择保留）
<br>添加行号和文件名标识
<br>保留#pragma编译指令（编译用）
<br>完成这六步的源文件处理后，我们就得到了预处理文件，虽然预处理文件仍然可读，但是不包含任何头文件信息和宏定义。这时的种子褪去外壳。<br><br>编译非常重要，因为这是从 human readable 到 machine readable 的阶段。编译过程将预处理文件进行词法分析、语法分析、语义分析和优化后生成汇编代码文件。《编译原理》就是专门讨论编译阶段而诞生的学科。我们称进行编译处理的程序为编译器(Compiler) 。<br>我们用如下的命令可将程序编译为可读的汇编代码文件。虽然机器无法理解这些代码，但是汇编代码和二进制机器语言代码一一对应。<br>gcc -S hello.i -o hello.s
gcc -S hello.c -o hello.s
/user/lib/gcc/xxxx-linux-gnu/4.1/cc1 hello.c

<br>其中，cc1&nbsp;是 GCC 的内部编译器，它负责将预处理后的 C 语言文件转换为汇编代码。直接调用cc1可以跳过 GCC 的其他阶段，直接进行编译。gcc命令实际上是具体程序（如ccp、cc1、as等）的包装命令， 用户通过gcc命令来使用具体的预处理程序ccp、编译程序cc1和 汇编程序as等。<br>编译阶段的实现非常复杂，我们不介绍。<br><br>编译阶段完成后，生成ELF可执行文件的程序就依然走完了大半。在汇编阶段，汇编程序（汇编器）会将编译阶段所产生的汇编代码文件转换成机器指令序列。我们提到过汇编指令和机器指令是一一对应的，都属于机器级代码，只不过前者是后者的符号标识而已。我们可以用如下的指令汇编得到可重定位目标文件。<br>gcc –c hello.s –o hello.o
gcc –c hello.c –o hello.o
as hello.s -o hello.o
<br>汇编结果是一个可重定位目标文件（如，hello.o），其中包含着的是人不可读的二进制代码，必须用相应的工具软件来查看其内容。<br><br>预处理、编译和汇编三个阶段针对一个模块（一个.c文件）进行处理，得到对应的一个可重定位目标文件（一个.o文件）。而链接过程是将多个可重定位目标文件合并生成一个可执行文件。我们可以用下面的shell命令来生成一个可执行文件：<br>gcc –static –o myproc main.o test.o
ld –static –o myproc main.o test.o  # 需要C静态标准库
<br>其中，–static 表示静态链接，如果不指定-o选项，则可执行文件名 为“a.out”。<br><br>早期程序员是在纸带上编写程序的，当程序员修改了某行指令（增加/删除指令）时，纸带很可能作废。这是因为有些代码是位置相关的（如&nbsp;jmp，即跳转指令），当增加一行代码，jmp&nbsp;后面跟的绝对地址就需要跟着改变。<br>后来汇编语言出现了，汇编语言用符号表示跳转的位置，不需要修改&nbsp;jmp&nbsp;指令的跳转目标了。如：<br>0: 0101 0110       add B
1: 0010 0101       jmp L0
	...
5: 0110 0111    L0: sub C
<br>这样，我们开始编写的汇编指令都是位置无关的。随着程序越来越复杂，一个程序可能由多个子模块组成。子程序（函数）的起始地址和变量的起始地址我们也用符号来定义，调用子程序或对变量的使用就是顾好的引用(reference)。之后这些符号通过汇编、链接后才会确定符号的地址（符号解析和重定位）。<br><br>我们编写的C语言源程序通过预处理、编译、汇编之后终于得到一个二进制的目标文件了。之后我们还需要链接之后才能成为可执行目标文件。那为什么要链接，链接给我们带来什么好处了？简单来说，链接容许我们程序的模块化，当你要使用某个功能时，只需要加载对应功能的模块就好了。这种模块化加载还带来了另一个好处，即效率高，debug程序和更新程序也只需要修改某一个模块就好了。开发工作由此也可以并发进行，效率更高。<br>程序经过编译汇编之后能够生成下面的三类目标文件。<br><br>即未链接之前的目标文件，每个.o文件都由对应的.c文件生成。每个.o文件代码和数据的地址都从0开始。虽然这时的目标文件代码是机器能够识别的机器代码，但由于没有经过符号的解析和重定位，这种目标文件仍然是不可执行的。可重定位目标文件包含代码、数据和重定位的信息。<br>静态链接库文件可以又若干的可重定位目标文件构成。<br>要得到可执行目标文件，我们需要将可重定位目标文件和其他可重定位文件合并为可执行文件。<br><br>可执行目标文件包含的代码和数据可以被直接复制到内存中执行。这时的代码和数据的地址不再是从0开始，经过重定位之后，代码和数据的地址为虚拟地址空间中的地址。<br>**链接的本质就是合并多个可重定位目标文件的代码节、数据节等成代码段、数据段。**<br><img alt="Pasted image 20240926140732.png" src="https://congzhi.wiki/some-notes/pics/pasted-image-20240926140732.png"><br>
但是在合并这些可重定位目标文件的代码节、数据节等节之前，我们需要对这些符号（即全局变量和函数名） 进行解析并重定位这些符号。（局部变量不放入符号表）<br><br>共享库文件是特殊的可重定位目标文件，能够在程序装入内存或运行时自动地被装入内存并自动被链接。在Windows中称为动态链接库文件(Dynamic Link Libraries, DLL)。<br><br>目标代码(Object Code)：编译器和汇编器处理源代码后所生成的机器语言目标代码。<br>目标文件(Object File)：指包含目标代码的文件，最早的目标文件是自由格式，非标准的。标准的几种目标文件格式：<br>
<br>DOS操作系统：COM格式，文件中仅包含代码和数据， 且被加载到固定位置
<br>System V UNIX早期版本：COFF格式，文件中不仅包含代码和数据 ，还包含重定位信息、调试信息、符号表等其他信息，由一组严格定 义的数据结构序列组成
<br>Windows：PE格式（COFF的变种），称为可移植可执行（ Portable Executable，简称PE）
<br>Linux等类UNIX：ELF格式（COFF的变种），称为可执行可链接（ Executable and Linkable Format，简称ELF）
<br><br>可执行可链接目标文件有两种视图，我们说的三类目标文件都是是ELF。其中 .o 后缀的文件和 .so 后缀的文件其实并不是可执行文件，而是可重定位目标文件，这时*.o 文件并不具有可执行属性，是ELF的链接视图。当这些链接视图的文件链接后就会生成可执行目标文件（默认 a.out ），这时得到的目标文件具有可执行的属性，是ELF的执行视图。<br>我们现在可以将链接的概念拓展一下：链接的本质就是将多个可重定位目标文件的代码节、数据节等合并成可执行目标文件中的代码段和数据段。<br>本节课我们依旧使用下面的程序做例子：<br>#include &lt;stdio.h&gt;

int main(){
	printf("hello, world\n");
}
<br>开始之前，我们先用命令将C语言程序生成可重定位目标文件和可执行目标文件：<br>gcc -c hello.c -o hello.o
gcc hello.c -o hello
<br>需要用到的命令：<br># 显示 ELF 文件的所有信息
readelf -a objfile
# 显示 ELF 文件头信息
readelf -h objfile
# 显示 ELF 文件的节头信息
readelf -S objfile
# 显示 ELF 文件的符号表信息
readelf -s objfile
# 显示 ELF 文件的程序头信息
readelf -l objfile
# 反汇编 ELF 文件中的代码段
objdump -d objfile
# 以十六进制和 ASCII 格式显示文件内容
hexdump -C objfile
# 查看目标文件中的符号表信息
nm
<br><br>可重定位目标文件由ELF头、程序头表（可选）、节(Sections)、和节头表组成。节(section)是ELF文件中具有相同特征的最小可处理单位，链接时就是对相同的属性的节进行组合成段(segments)。<br>ELF头标识了文件的架构类型、数据的编码方式、文件类型、目标机器架构、入口点地址、节头表的位置和header的大小等信息。而节头表标识了每个节的属性信息，这两个部分是可重定位目标文件最重要的部分，搞清楚这两个部分，你就明白了ELF的链接视图是怎么样的。<br><br>ELF头位于ELF文件最开始的地方（偏移为0），包含了文件结构的说明信息。这些信息存放在一个数据结构中。<br>#include &lt;stdint.h&gt;

#define EI_NIDENT 16

typedef struct {
    unsigned char e_ident[EI_NIDENT]; // 魔数和其他标识信息，16字节
    uint16_t e_type;                  // 文件类型，2字节
    uint16_t e_machine;               // 目标机器架构（如 x86-64），2字节
    uint32_t e_version;               // ELF 版本号，4字节
    uint64_t e_entry;                 // 程序入口地址（可执行文件使用），8字节
    uint64_t e_phoff;                 // 程序头表在文件中的偏移量，8字节
    uint64_t e_shoff;                 // 节头表在文件中的偏移量，8字节
    uint32_t e_flags;                 // 特定于处理器的标志，4字节
    uint16_t e_ehsize;                // ELF 头部的大小，2字节
    uint16_t e_phentsize;             // 程序头表中每个条目的大小，2字节
    uint16_t e_phnum;                 // 程序头表中的条目数，2字节
    uint16_t e_shentsize;             // 节头表中每个条目的大小，2字节
    uint16_t e_shnum;                 // 节头表中的条目数，2字节
    uint16_t e_shstrndx;              // 节头字符串表的索引，2字节
} Elf64_Ehdr;                         // ELF头部总共64字节
<br>ELF64头信息在机器中的编码是01序列，我们可以通过 readelf 这种工具软件来查看ELF中包含的信息。这里我们需要读取文件的头信息，我们用 readelf -h hello.o 来获取ELF的头包含什么信息。<br>du@DVM:~/Desktop$ readelf -h hello.o
ELF Header:
  Magic:   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 
  Class:                             ELF64
  Data:                              2's complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0
  Type:                              REL (Relocatable file)
  Machine:                           Advanced Micro Devices X86-64
  Version:                           0x1
  Entry point address:               0x0
  Start of program headers:          0 (bytes into file)
  Start of section headers:          600 (bytes into file)
  Flags:                             0x0
  Size of this header:               64 (bytes)
  Size of program headers:           0 (bytes)
  Number of program headers:         0
  Size of section headers:           64 (bytes)
  Number of section headers:         14
  Section header string table index: 13
<br>从中，我们能够读取到很多信息，如果你好奇查看了 hello 可执行文件的ELF头，你就会发现有几项不一样。比如文件的类型、入口地址、程序头和节信息变了。其中入口地址是我们不得不关注的，hello.o 是可重定位的目标文件，给出的是ELF的链接视图，所以装入的入口地址是0x0。<br>我们再来读一下其他信息，在ELF头中，我们可以读到另一个重要表项——节头表的信息。我们在下面的注释中给出。<br># 节头表开始的位置，偏移量为600字节(0x258)
  Start of section headers:          600 (bytes into file)
# 节头表由多个节头的信息组成，这里节头表由14个大小为64个字节的节头构成。一共896Bytes
  Size of section headers:           64 (bytes)
  Number of section headers:         14

# 字符串表在节头表中的位置 .strtab
  Section header string table index: 13
<br>思考一下，为什么需要额外地指出 .strtab 在节头表中的位置？<br><br>我们前面在ELF头中其实都看到 hello.o 中有多少个节头了。这些节头给出每个节的相关信息，如节的名称、节的起始地址、节的偏移等等。每个节承担不同的功能，我们很快就能根据这些信息从文件的二进值信息这找到我们写进去的数据了（Hacker 101）。<br>在 ELF 文件中，节头表（Section Header Table）包含了每个节的信息。节头的结构体定义如下：<br>typedef struct {
    uint32_t sh_name;      // 节名称的索引
    uint32_t sh_type;      // 节的类型
    uint64_t sh_flags;     // 节的标志(在虚拟空间中的访问属性)
    uint64_t sh_addr;      // 节的虚拟内存地址(链接视图无意义)
    uint64_t sh_offset;    // 节在文件中的偏移
    uint64_t sh_size;      // 节的大小
    uint32_t sh_link;      // 节的链接信息
    uint32_t sh_info;      // 链接信息
    uint64_t sh_addralign; // 对齐要求信息
    uint64_t sh_entsize;   // 节中条目的大小
} Elf64_Shdr;
<br>节头的结构体中的数据都是01序列，不方便读懂，我们用 readelf -S 命令来获取节头表的信息：<br>du@DVM:~/Desktop$ readelf -S hello.o
There are 14 section headers, starting at offset 0x258:
Section Headers:
  [Nr] Name              Type             Address           Offset
       Size              EntSize          Flags  Link  Info  Align
       
  [ 0]                   NULL             0000000000000000  00000000
       0000000000000000  0000000000000000           0     0     0
  [ 1] .text             PROGBITS         0000000000000000  00000040
       000000000000001e  0000000000000000  AX       0     0     1
  [ 2] .rela.text        RELA             0000000000000000  00000198
       0000000000000030  0000000000000018   I      11     1     8
  [ 3] .data             PROGBITS         0000000000000000  0000005e
       0000000000000000  0000000000000000  WA       0     0     1
  [ 4] .bss              NOBITS           0000000000000000  0000005e
       0000000000000000  0000000000000000  WA       0     0     1
  [ 5] .rodata           PROGBITS         0000000000000000  0000005e
       000000000000000d  0000000000000000   A       0     0     1
  [ 6] .comment          PROGBITS         0000000000000000  0000006b
       000000000000002c  0000000000000001  MS       0     0     1
  [ 7] .note.GNU-stack   PROGBITS         0000000000000000  00000097
       0000000000000000  0000000000000000           0     0     1
  [ 8] .note.gnu.pr[...] NOTE             0000000000000000  00000098
       0000000000000020  0000000000000000   A       0     0     8
  [ 9] .eh_frame         PROGBITS         0000000000000000  000000b8
       0000000000000038  0000000000000000   A       0     0     8
  [10] .rela.eh_frame    RELA             0000000000000000  000001c8
       0000000000000018  0000000000000018   I      11     9     8
  [11] .symtab           SYMTAB           0000000000000000  000000f0
       0000000000000090  0000000000000018          12     4     8
  [12] .strtab           STRTAB           0000000000000000  00000180
       0000000000000013  0000000000000000           0     0     1
  [13] .shstrtab         STRTAB           0000000000000000  000001e0
       0000000000000074  0000000000000000           0     0     1
Key to Flags:
  W (write), A (alloc), X (execute), M (merge), S (strings), I (info),
  L (link order), O (extra OS processing required), G (group), T (TLS),
  C (compressed), x (unknown), o (OS specific), E (exclude),
  D (mbind), l (large), p (processor specific)
<br>属性信息的含义如下：<br>
<br>[Nr]：节的索引号，从 0 开始。
<br>Name：节的名称，如&nbsp;.text、.data&nbsp;等。
<br>Type：节的类型，表示节的内容和用途。

<br>NULL：空节。
<br>PROGBITS：程序数据。
<br>RELA：重定位条目，带附加信息。
<br>NOBITS：不占用文件空间的节（如 .bss）。
<br>NOTE：包含附加信息的节。
<br>SYMTAB：符号表。
<br>STRTAB：字符串表。


<br>Address：节在内存中的加载地址。
<br>Offset：节在文件中的偏移量。
<br>Size：节的大小（以字节为单位）。
<br>EntSize：节中每个条目的大小（如果节包含固定大小的条目）。
<br>Flags：节的标志，描述节的属性。
<br>Link：与该节相关联的其他节的索引。
<br>Info：额外的信息，通常与&nbsp;Link&nbsp;字段一起使用。
<br>Align：节的对齐要求。
<br>现在，我们就能准确地从中知道每个节相对 0 的确切位置。但仍然迷惑的是为何所有节的 address 字段都为 0000？这是因为当前 hello.o 并没有链接重定位生成可执行目标文件，所以对应的每个节的起始地址都为0（因为这时的节地址是毫无意义的）。<br>我们的例子中并没有使用任何变量，所以在 .data 节和 .bss 节中什么都没有，size 字段为0。而我们的 hello world 字符串属于 .rodata 节中的内容（只读数据、printf格式串、switch跳转表），一共13个字节（13 = 0xd），所以 .rodata 的 size 字段为 0xd。我们之后会在 hello.o 文件中查看我们 .rodata 中的内容。<br>如果你定义了初始化的全局变量和未初始化的全局变量，你就会发现 .data 节中是有数据的，而 .bss 节中无论你定义了多少未初始化的全局变量和局部静态变量都不会存放任何数据即 size 字段永远是0。这是因为 .data 节中存放具体的初始值，需要占磁盘空间。而 .bss 节用专门的节头表来说明应该为 .bss 节预留多大的空间，所以只要说明 .bss 中的每个变量将来在执行时占用几个字节即可，因此，.bss 节实际上不占用磁盘空间，提高了磁盘空间利用率。（C语言默认未初始化的全局和局部静态变量的值为0）<br>通过节头表中的信息和ELF头的信息，我们就能绘制出 hello.o 文件结构：<br>
+-------------------------+-------------------------+   0x000
| ELF Header              | 64 bytes (0x40)         |
+-------------------------+-------------------------+   0x040
| .text                   | 30 bytes (0x1e)         |
+-------------------------+-------------------------+   0x05e
| .data                   | 0 bytes                 |
+-------------------------+-------------------------+   0x05e
| .bss                    | 0 bytes                 |
+-------------------------+-------------------------+   0x05e
| .rodata                 | 13 bytes (0x0d)         |
+-------------------------+-------------------------+   0x06b
| .comment                | 44 bytes (0x2c)         |
+-------------------------+-------------------------+   0x097
| .note.GNU-stack         | 0 bytes                 |
+-------------------------+-------------------------+   0x097
+-------------------------+-------------------------+   0x098(0x97对齐)
| .note.gnu.property      | 32 bytes (0x20)         |
+-------------------------+-------------------------+   0x0b8
| .eh_frame               | 56 bytes (0x38)         |
+-------------------------+-------------------------+   0x0f0
| .symtab                 | 144 bytes (0x90)        |
+-------------------------+-------------------------+   0x180
| .strtab                 | 19 bytes (0x13)         |
+-------------------------+-------------------------+   0x193
+-------------------------+-------------------------+   0x198(0x193对齐)
| .rela.text              | 48 bytes (0x30)         |
+-------------------------+-------------------------+   0x1c8
| .rela.eh_frame          | 24 bytes (0x18)         |
+-------------------------+-------------------------+   0x1e0
| .shstrtab               | 116 bytes (0x74)        |
+-------------------------+-------------------------+   0x254(596 Bytes)
+-------------------------+-------------------------+   0x258(600 Bytes)
| Section Headers         | 896 bytes (14 * 64)     |
+-------------------------+-------------------------+   0x5d8(600+896 Bytes)
<br>通过结构信息，我们可以很清楚地看到文件从哪开始，从哪里结束。我们用 hexdump -C 以16进制和ASCII格式查看 hello.o 文件。我们看到，程序如我们预想的一样从 0x5d8 结束。查看 .rodata 节的位置，我们也如预料地看到了 hello,world. 这样12个字符。至此，关于 hello.o 的解读圆满结束！<br>du@DVM:~/Desktop$ hexdump -C hello.o
00000000  7f 45 4c 46 02 01 01 00  00 00 00 00 00 00 00 00  |.ELF............|
...
00000050  89 c7 e8 00 00 00 00 b8  00 00 00 00 5d c3 68 65  |............].he|
00000060  6c 6c 6f 2c 20 77 6f 72  6c 64 00 00 47 43 43 3a  |llo, world..GCC:|
...
000005d0  00 00 00 00 00 00 00 00                           |........|
000005d8
<br><br><br>可执行文件中包括代码、数据（已初始化的 .data 和未初始化的 .bss）。与可重定位的目标文件不同，我们定义的所有变量和函数在可执行目标文件中都明确了其地址（虚拟地址空间），符号的引用处也已被重定位，指向所引用的定义符号。<br>为了执行的方便，链接时还会将具有相同访问属性的节进行合并成段（如 .text 节和 .rodata 节合并为 .rodata 段，.data 和 .bss 节合并为 .data 段）。这些段的信息被存放在程序头表/段头表中。<br>在Linux中的可执行目标文件没有文件扩展名（默认为a.out），在Windows中，可执行文件的扩展名为 .exe。<br><br>我们先用命令 readelf -h 查看ELF头，看看与可重定位目标文件有什么不同。首先，最大的不同就是程序的入口地址不再是0了，还多了程序头表/段头表(Segment header table) 和 .init 节。然后我们发现，在链接（重定位）过后，我们少了带重定位信息的节（如.rela.text、.rela.data等）。<br>du@DVM:~/Desktop$ readelf -h hello
ELF Header:
  Magic:   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 
  Class:                             ELF64
  Data:                              2's complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0
  Type:                              DYN (Position-Independent Executable file)
  Machine:                           Advanced Micro Devices X86-64
  Version:                           0x1
  Entry point address:               0x1060
  Start of program headers:          64 (bytes into file)
  Start of section headers:          13976 (bytes into file)
  Flags:                             0x0
  Size of this header:               64 (bytes)
  Size of program headers:           56 (bytes)
  Number of program headers:         13
  Size of section headers:           64 (bytes)
  Number of section headers:         31
  Section header string table index: 30
<br>我们简单介绍 .init 节和段头表的作用。.init 节用于定义 _init函数，这个函数用于可执行目标文件开始时的初始化工作。和节头表一样，段头表也是一个结构体数组，段头表用于描述这些段的各种属性信息。从上面的ELF头信息中我们可以读出，程序有13个段头，每个段头有56个字节。<br><br>程序头表描述了可执行文件中的段的属性信息和虚拟空间中的存储段和节之间的映射关系（段由哪些节构成）。在我的系统上，每个段头有52字节，这52字节就说明虚拟地址空间中一个连续的段或特殊节的描述信息。<br>typedef struct {
    uint32_t p_type;   // 段的类型
    uint32_t p_flags;  // 段的权限标志
    uint64_t p_offset; // 段在文件中的偏移量
    uint64_t p_vaddr;  // 段在内存中的虚拟地址
    uint64_t p_paddr;  // 段在内存中的物理地址
    uint64_t p_filesz; // 段在文件中的大小
    uint64_t p_memsz;  // 段在内存中的大小
    uint64_t p_align;  // 段在内存中的对齐要求
} Elf64_Phdr;
<br>同样，我们用 readelf -l 读取段头表的信息：<br>du@DVM:~/Desktop$ readelf -l hello

Elf file type is DYN (Position-Independent Executable file)
Entry point 0x1060
There are 13 program headers, starting at offset 64

Program Headers:
  Type           Offset             VirtAddr           PhysAddr
                 FileSiz            MemSiz              Flags  Align
  PHDR           0x0000000000000040 0x0000000000000040 0x0000000000000040
                 0x00000000000002d8 0x00000000000002d8  R      0x8
  INTERP         0x0000000000000318 0x0000000000000318 0x0000000000000318
                 0x000000000000001c 0x000000000000001c  R      0x1
      [Requesting program interpreter: /lib64/ld-linux-x86-64.so.2]
  LOAD           0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000000628 0x0000000000000628  R      0x1000
  LOAD           0x0000000000001000 0x0000000000001000 0x0000000000001000
                 0x0000000000000175 0x0000000000000175  R E    0x1000
  LOAD           0x0000000000002000 0x0000000000002000 0x0000000000002000
                 0x00000000000000f4 0x00000000000000f4  R      0x1000
  LOAD           0x0000000000002db8 0x0000000000003db8 0x0000000000003db8
                 0x0000000000000258 0x0000000000000260  RW     0x1000
  DYNAMIC        0x0000000000002dc8 0x0000000000003dc8 0x0000000000003dc8
                 0x00000000000001f0 0x00000000000001f0  RW     0x8
  NOTE           0x0000000000000338 0x0000000000000338 0x0000000000000338
                 0x0000000000000030 0x0000000000000030  R      0x8
  NOTE           0x0000000000000368 0x0000000000000368 0x0000000000000368
                 0x0000000000000044 0x0000000000000044  R      0x4
  GNU_PROPERTY   0x0000000000000338 0x0000000000000338 0x0000000000000338
                 0x0000000000000030 0x0000000000000030  R      0x8
  GNU_EH_FRAME   0x0000000000002014 0x0000000000002014 0x0000000000002014
                 0x0000000000000034 0x0000000000000034  R      0x4
  GNU_STACK      0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000000000 0x0000000000000000  RW     0x10
  GNU_RELRO      0x0000000000002db8 0x0000000000003db8 0x0000000000003db8
                 0x0000000000000248 0x0000000000000248  R      0x1

 Section to Segment mapping:
  Segment Sections...
   00     
   01     .interp 
   02     .interp .note.gnu.property .note.gnu.build-id .note.ABI-tag .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rela.dyn .rela.plt 
   03     .init .plt .plt.got .plt.sec .text .fini 
   04     .rodata .eh_frame_hdr .eh_frame 
   05     .init_array .fini_array .dynamic .got .data .bss 
   06     .dynamic 
   07     .note.gnu.property 
   08     .note.gnu.build-id .note.ABI-tag 
   09     .note.gnu.property 
   10     .eh_frame_hdr 
   11     
   12     .init_array .fini_array .dynamic .got 
<br>段头的的属性信息含义入下：<br>
<br>Type: 段的类型，例如&nbsp;LOAD&nbsp;表示可加载段/可装入段，DYNAMIC&nbsp;表示动态链接信息段。
<br>Offset: 段在文件中的偏移量。
<br>VirtAddr: 段在内存中的虚拟地址。
<br>PhysAddr: 段在内存中的物理地址（通常在现代系统中未使用）。
<br>FileSiz: 段在文件中的大小。
<br>MemSiz: 段在内存中的大小。
<br>Flags: 段的权限标志，例如&nbsp;R&nbsp;表示可读，W&nbsp;表示可写，E&nbsp;表示可执行。
<br>Align: 段在内存中的对齐要求。
<br>通过Section to Segment mapping中的信息，我们能够知道各个段和其所包含的节之间的映射关系，哪个段由哪些节组成。并且通过段的类型能够知道哪些段是需要载入内存，与存储器进行映像的。通过这些段头的信息，和在上节课的操作一样，我们可以通过这些地址信息找到我们只读字符串的位置。<br>00002000  01 00 02 00 68 65 6c 6c  6f 2c 20 77 6f 72 6c 64  |....hello, world|
00002010  00 00 00 00 01 1b 03 3b  30 00 00 00 05 00 00 00  |.......;0.......|
<br><br>在 ELF 文件中，只有&nbsp;LOAD&nbsp;类型的段会被装入内存。这些段包含了程序的代码和数据，加载器会根据这些段的信息将它们映射到进程的地址空间中。其他类型的段，如&nbsp;PHDR、INTERP、DYNAMIC、NOTE&nbsp;等，虽然在 ELF 文件中有定义，但不会被直接装入内存，而是用于辅助加载和运行程序。<br><br>链接的操作实际上是合并多个可重定位目标文件，要合并这些可重定位目标文件，我们就需要先对这些符号进行符号解析。这是因为不同的可重定位目标文件中可能有其他文件中的符号引用。我们确定这些符号的引用关系的这一过程就是符号解析（将每个符号的引用都与一个确定的符号定义建立关联）。<br>符号解析后，我们就能够合并相关的.o文件了。具体一点的过程是：先确定每个符号的地址，然后在引用处填入符号的地址。<br>
<img alt="Pasted image 20240928003748.png" src="https://congzhi.wiki/some-notes/pics/pasted-image-20240928003748.png"><br>
在上面的例子中，P0.o中引用了符号P1（使用外部定义的函数），在P1.o中引用了P0.o中的符号A和B（外部数据）。而在编译阶段，符号的位置是未知的，因为它们可能在不同的目标文件中。链接器将可重定位目标文件中属性相同的节合并成段。链接器解析这些符号，确定它们的最终地址。在符号引用处将引用替换为解析后的地址，从而完成对符号的访问。<br><br><br>每个可重定位目标文件都有一个符号表，包含着在文件中定义和引用的符号。有三种连接器符号：<br>
<br>
模块内部定义的全局符号(global symbols)：<br>
由模块m定义并能被其他模块引用的符号。例如，非static的函数和非static的全局变量。<br>
如，my_func.c 中的全局变量名buf 。

<br>
外部定义的全局符号(external symbols)：<br>
由其他模块定义并被模块引用的全局符号。如在main.c中的函数名swap和add。 

<br>
本模块的局部符号(local symbols)：<br>
仅由模块m定义和引用的本地符号。在模块定义的带static的函数和全局变量。如，my_var.c中的static变量local。
需要注意的是链接的局部符号不是指程序中的局部变量（分配在栈中的临时性变量）。对于C语言中的局部变量，链接器并不关心。

<br>在符号解析的时候，当本模块内引用的是本地的局部符号，我们只要与本模块内唯一的定义符号关联即可。而全局符号的解析涉及多个模块（内部定义的、外部定义的），所以较复杂。<br><br>在程序中，我们需要先定义一个符号。之后对该符号的操作其实都是对符号的引用，例如我们定义了一个函数（符号的定义），之后使用函数的操作叫函数的引用（符号的引用）。变量也有相似的操作。例如：<br>void test(){}   // 定义符号 test
void test();    // 定义符号（弱符号）
test();         // 引用符号 test
int x;          // 全局变量x，定义符号x
int *xp = &amp;x;   // 全局变量xp，定义符号xp，引用符号x
<br>说明类型的符号都是一种定义，而其他的属于引用。局部变量会在栈中分配空间，不会被过程外的文件中引用，所以不属于符号，不会出现在符号表中。<br>我们举个例子：<br>我们将变量都放在 my_var.c 中（3个符号，没有引用）<br>int buf[3] = {1, 2, 0}; // 全局符号的定义
int var2 = 15;          // 全局符号的定义
static var1 = 5;        // 局部符号(static)的定义
<br>然后我们有 my_func.c（3个符号，7个 .rela.text 的引用（buf）,2个 .rela.eh_frame 的引用）<br>extern int buf[];       // 外部符号的定义

void swap(){            // 全局符号的定义
	int temp;
	temp = buf[0];      // buf引用
	buf[0] = buf[1];    // 2*buf的引用
	buf[1] = temp;      // 1*buf的引用
}
void add(){             // 全局符号的定义
	buf[2] = buf[0] + buf[1]; // 2*buf的引用
}
<br>之后所有的操作在 main.c 中完成（6个符号）<br>int buf[];   // 外部符号(弱符号)的定义
void add();  // 外部符号(弱符号)的定义
void swap(); // 外部符号(弱符号)的定义
void local(){}// 全局符号的定义
int main(){  // 全局符号的定义
	swap();  // 全局符号的引用
	add();   // 全局符号的引用
	local(); // 全局符号的引用
	return 0;
}
<br><br>编译器会将符号的定义存放到一个符号表(symbol table) 即我们之前看到的 .symtab 中。符号表是一个结构体数组，每个表项都包含着符号名、长度和位置等信息。在64位系统中，符号表的每一项有24字节大小。（32位系统位16字节）<br>typedef struct {
    Elf64_Word    st_name;  // 符号名(.strtab节中的偏移量)          4B
    unsigned char st_info;  // 符号类型(低四位)和绑定(高四位)        1B
    unsigned char st_other; // 符号可见性，通常为0                  1B
    Elf64_Half    st_shndx; // 符号对应目标所在的节，或其他情况       2B
    Elf64_Addr    st_value; // 在对应节中的偏移量，或虚拟地址         8B
    Elf64_Xword   st_size;  // 符号对应的字节数(函数大小或变量长度)    8B
} Elf64_Sym;
<br>绑定属性(Bind)：局部符号(0)、全局符号(1)、弱符号(2)<br>
符号类型(Type)：未指定类型(0)、数据(1)、函数或可执行代码(2)、节(3)、文件名(4)。其他情况下，ABS表示不该被重定位、UND表示未定义、COM表示未初始化数据（.bss），此时，value表示对齐要求，size给出最小大小。（x64 下未初始化数据一般用 .bss 节号指代未初始化符号的类型）<br>当我们查看符号表时，会发现我们的文件中额外多了两个符号。第一个符号（Num: 0）通常是占位符，之前我们查看节头表信息时也会发现第一个节头也是占位符。第二个符号（Num: 1）通常是源文件的名称。往后的符号表信息往往就是我们所定义或引用的符号了。<br>符号的重定位信息会被编译器放到重定位节中。当符号解析完成且没有错误时，链接器会进行符号的重定位，即将符号的引用与一个确定的符号定义相关联。这一过程涉及符号表和重定位节之间的关联。在重定位阶段，多个代码节和数据节会合并成单独的代码段和数据段。链接器会计算每个定义的符号在虚拟地址空间中的绝对地址，并将引用处的地址修改为重定位后的地址信息。<br>从符号对应的字节数我们能够看到，我们其实就是用符号来指代一段存储空间。当符号为变量名时，变量名指的就是其所占的静态数据区，当符号是函数名时，函数么指的其实就是代码所在的区域大小。<br><br><br>全局符号的强弱特性：<br>
<br>函数/初始化的全局变量是强符号
<br>未初始化的全局变量是弱符号（使用COMMON标记）
<br>符号解析规则：<br>
<br>不允许多个同名的强符号<br>
强符号只能定义一次，否则链接错误
<br>有一个强符号和弱符号同名时，链接选择强符号<br>
后面对弱符号的引用被解析为定义强定义符号
<br>如果多个弱符号同名，链接时任意选择一个<br>
符号解析时只能有一个确定的定义（即每个符号仅占一处存储空间）。
<br>gcc -c main.c -o main.o -fno-common    #禁止弱符号
<br>用上面的命令链接时，会告诉链接器在遇到多个弱定义的全局符号时输出一条警告信息。<br>static变量是弱符号且只能在当前文件中使用（限制符号的可见性），所以即使在不同文件中定义有相同变量名的static变量或函数也不会发生冲突。<br><br>多重定义全局变量会造成一些意想不到的错误，编译系统也可能不会发出警告。程序运行过程中可能就会发生意料之外的错误。随着软件不断做大，错误的根源也会变得愈发难找。<br>我们下面看一下这个例子。在编译的时候，模块各自进行编译，在main.c中的变量d是int类型的变量，运算时的命令是整型运算命令。而p1.c中的变量d虽然是未初始化的全局变量（弱符号）。但是编译的时候并不知晓这个符号是否外部定义了。所以执行d = 1.0;的时候会将d作为浮点类型变量进行运算。<br>链接的时候强弱符号的定义非常清晰，并不会发生冲突。<br># include &lt;stdio.h&gt;
int d = 100;
int x = 200;
d += 10;
void p1(void);
int main(){
	p1();
	printf("d = %d, x = %d\n", d, x);
	return 0;
}
<br>main.c<br>double d;
void p1(){
/*
	d = 1.0;会被汇编成浮点运算指令
	FLD1
	FSTPI &amp;d
*/
	d = 1.0;
}
<br>p1.c<br>由于浮点数是8Bytes，int型变量只有4Bytes。当在main()函数中对p1()进行调用之后，写回结果时就会出现意想不到的结果。我们得到的变量d和变量x都不是我们想要的结果。<br>要避免多重定义全局符号的问题。<br>
<br>
尽量避免使用全局变量 

<br>
一定需要用的话，请按照以下规则使用：

<br>尽量使用static本地变量
<br>全局变量要赋初值
<br>外部全局变量要使用extern


<br><br>我们前面链接不同文件生成可执行文件时，使用的链接命令就是把多个可重定位目标文件静态链接成一个可执行目标文件的过程。在这个过程中，静态链接的对象是多个可重定位目标文件和标准静态库。静态库文件就是 .a 文件，包含有多个 .o 模块。<br><br>为了增加代码的可重用，我们可以将一些函数进行分类并将分类好的函数存放在多个源文件中，编译后将这些 .o 可重定位目标文件进行归档。这样生成的文件就是静态库文件，也叫做归档文件(archive file)。常见的库函数模块有 libc.a(C标准库) 和 libm.a(C数学库)。<br>当我们自定义静态库时，我们应当注意避免下面的两种极端：<br>
<br>将所有的函数都放在一个源文件中

<br>这样会导致每次修改，都需要重新编译整个源文件（时间浪费）
<br>每次链接都会为可执行文件引入不必要的模块（空间上的浪费）


<br>每个源文件只分配一个函数

<br>虽然效率提高了，但是模块太多，链接时会很繁琐


<br>在构建可执行文件时，只需指定库文件名，链接器会自动到库中寻找那些应用程序所用到的目标模块，并且只把用到的模块从库中拷贝出来。在GCC命令行中无需明显指定 libc.a，涉及到文件路径的查找问题。<br><br>我们可以用归档器 ar 将 .o 目标文件模块进行归档为 .a 文件。归档器允许程序进行增量更新，如果我们重新编写了某一源程序或者想为静态库增加新的功能，我们只需要编译那一个文件并将其归档即可。<br><img alt="Pasted image 20240930154026.png" src="https://congzhi.wiki/some-notes/pics/pasted-image-20240930154026.png"><br>
常用的标准库有：<br>
<br>libc.a ：C标准库，包含I/O、存储分配、信号处理、字符串处理、时间和日期、随机数生成、定点整数算术运算实现等的目标文件。约有8MB。
<br>libm.a ：C数学库，浮点数算术运算(如sin, cos, tan, log, exp, sqrt, …)，约1MB。
<br><br>我们新创建两个模块（module1.c 和 module2.c），将这两个文件编译后归档成我们自己的静态库。<br>// module1.c
#include &lt;stdio.h&gt;

void print_hello(){
	printf("hello\n");
}
// module2.c
#include &lt;stdio.h&gt;

void print_world(){
	printf("world\n");
}
<br>编译后我们用归档程序将这两个模块( .o )文件归档成一个归档文件( .a )文件。<br>ar rcs mylib.a module1.o module2.o
<br>我们可以用下面的命令来查看存档文件中有哪些目标文件：<br># 查看xxxx.a中目标文件成员表，-t 表示table listing
ar t xxxx.a | sort 
<br><br>用我们创建的静态库，与一个main.o链接，最后会发生什么？<br>int main(){
    print_hello();
	return 0;
}
<br>函数之间的调用关系很清楚，main()调用print_hello()，然后print_hello()调用C库中的printf()函数。如果链接后查看可执行文件的符号表，你会发现虽然我们链接的是整个 mylib.a ，但是符号表中确没有print_world。也就是说 module2.o 并没有走到“节的合并”这一步。这里面发生了什么就是我们符号解析要关注的。<br><br>在符号解析开始之前，我们先给出三个符号解析需要用到的集合：<br>
<br>E：指的是将被合并组成可执行文件的所有目标文件的集合
<br>U：指的是当前所有未解析的引用符号的集合
<br>D：当前所有已定义符号的集合
<br>当执行下面的命令时，链接器会先对所要链接的模块进行符号解析。从上面的字符说明不难明白，符号解析完成后U应当为空，否则就会链接失败。<br>$ gcc –o proc main.o mylib.a 
<br>具体一点的符号解析过程如下：<br>
<br>最开始的时候E、U、D集合为空，然后扫描 main.o，发现定义的符号 main 和未定义的引用符号 print_hello 。随后将 main 加入D中、将 print_hello 加入U中并将main.o加入E中。
<br>接下来扫描mylib.a中的 .o 文件，发现 print_hello 的定义在 module.o 中，随后将符号 print_hello 从U转移到D中并将 module1.o 加入到E中。之后 print_hello 引入了一个未定义的符号 printf 到U里面。
<br>如果使用静态链接，链接器会扫描module2.o查找 printf 的符号定义，最后会从 libc.a 中一个一个查找 printf 的符号定义，过程和上面的相同。（这里我并没有使用静态标准库）
<br>最后，U为空，符号解析完毕。之后重定位的时候就只需要合并E中的文件就好了。
<br><br>由于符号解析是顺序进行的，这就为我们带来了一个问题，那就是链接时的顺序问题。如果我们把静态库文件放在前头会怎么样？<br>du@DVM:~/Desktop$ gcc -o proc mylib.a main.o
<br>结果出错了，链接器告诉我们在main.o中引用的符号 print_hello 没有找到定义。还记得我们的函数调用顺序么？是这样的：main -&gt; print_hello -&gt; printf。由于 main 是程序的入口，其他文件在先于 main 链接时由于集合U为空，所以扫描这些文件无一会被加入集合E里。等到扫描main.o时就会出现找不到定义的问题。（因为后面没有能扫描的模块了）<br>/usr/bin/ld: main.o: in function `main':
main.c:(.text+0xe): undefined reference to `print_hello'
collect2: error: ld returned 1 exit status
<br>除了使用正确的顺序外，我们可以用下面亡羊补牢的命令简单的解决这种问题：<br>du@DVM:~/Desktop$ gcc -o proc mylib.a main.o mylib.a
<br>事实上，如果两个模块互相引用对方模块中定义的符号，我们就可以用上面这种形式解决符号的互相调用问题。假设调用关系如下：func.o → libx.a 和 liby.a 中的函数 libx.a → liby.a 同时 liby.a → libx.a 则以下命令行可行：<br>gcc -static –o myfunc func.o libx.a liby.a libx.a
<br><br>链接由下面的四部分构成：符号解析、同节合并、确定地址 和 修改引用。我们上面已经做完了第一步，也就是符号解析过程，后面三步就属于重定位所关系的。<br>符号解析完成之后，我们得到了E集合和D集合。之后在重定位的时候我们就会将E集合中所有的.o文件进行同节合并。然后再确定D集合中所有符号的虚拟空间地址，最后将合并的文件中所有引用处的符号替换为符号定义处的地址就完成了重定位。<br><br>同节合并看起来很简单，合并之后确定符号定义的地址也不复杂，现在我们可能仍然困惑于引用处是如何替换地址的。在学习节头表时，我们看到重定位信息会被放到 .rela 的重定位节中（x64）。<br>当汇编器进行汇编时，它一旦遇到符号的引用，就会初始化引用地址并生成一个重定位条目用于链接时的重定位。在IA32中，将对数据引用的重定位条目在 .rel_data 节中，对指令的重定位条目在 .rel_text 节中。<br>IA-32中有两种最基本的重定位类型：<br>
<br>R_386_32：绝对地址（一般多用于数据引用条目的重定位）
<br>R_386_PC32：PC相对地址（多用于指令引用条目的重定位）
<br>在x64中重定位类型被分为：<br>
<br>R_X86_64_PLT32：32位相对地址，用于调用外部函数，通过过程链接表（PLT）进行间接调用。
<br>R_X86_64_PC32：32位的相对地址，用于相对当前指令位置的偏移。
<br>ELF中重定位条目的格式如下：<br>typedef struct{
	int offset;
	int symbol:24, type:8;
} ELF32_Rel;
<br>我们用readelf读重定位条目信息：<br>readelf -r xxxx.o
<br><br>这里我们先编写两个模块的程序，最后链接时将两个模块链接为一个可执行文件，这里我们对符号解析的过程不再赘述，我们两个单独的模块如下：<br>// module1.c
int i = 50;         // Symbol 'i' is defined in the module
static s_i = 100;   // Local defined symbol
extern int j;       // Symbol 'j' and 'k' is defined outside of the module
extern double k;

void test(){
    i = j + k;      // In case global variables won't be optimized.
}
int main(){
    externFunc();   // ref to an extern function
    test();         // ref to an internal defined function
    return 0;
}

<br>// module2.c
int j = 100;
double k = 300;

externFunc(){
    j = 4;
    k = 5;
}
<br>编译汇编为可重定位目标文件后，我们先读取符号表：<br>du@DVM:~/Desktop$ readelf -s module1.o

Symbol table '.symtab' contains 10 entries:
   Num:    Value          Size Type    Bind   Vis      Ndx Name
     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND 
     1: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS module1.c
     2: 0000000000000000     0 SECTION LOCAL  DEFAULT    1 .text
     3: 0000000000000004     4 OBJECT  LOCAL  DEFAULT    3 s_i
     4: 0000000000000000     4 OBJECT  GLOBAL DEFAULT    3 i
     5: 0000000000000000    47 FUNC    GLOBAL DEFAULT    1 test
     6: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND j
     7: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND k
     8: 000000000000002f    35 FUNC    GLOBAL DEFAULT    1 main
     9: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND externFunc

du@DVM:~/Desktop$ readelf -s module2.o

Symbol table '.symtab' contains 7 entries:
   Num:    Value          Size Type    Bind   Vis      Ndx Name
     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND 
     1: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS module2.c
     2: 0000000000000000     0 SECTION LOCAL  DEFAULT    1 .text
     3: 0000000000000000     0 SECTION LOCAL  DEFAULT    5 .rodata
     4: 0000000000000000     4 OBJECT  GLOBAL DEFAULT    3 j
     5: 0000000000000008     8 OBJECT  GLOBAL DEFAULT    3 k
     6: 0000000000000000    37 FUNC    GLOBAL DEFAULT    1 externFunc
<br>读重定位条目。我们先看module1.o的重定位条目信息：<br>du@DVM:~/Desktop$ readelf -r module1.o

Relocation section '.rela.text' at offset 0x240 contains 5 entries:
  Offset          Info           Type           Sym. Value    Sym. Name + Addend
00000000000a  000500000002 R_X86_64_PC32     0000000000000000 j - 4
00000000001a  000600000002 R_X86_64_PC32     0000000000000000 k - 4
000000000028  000300000002 R_X86_64_PC32     0000000000000000 i - 4
00000000003d  000800000004 R_X86_64_PLT32    0000000000000000 externFunc - 4
000000000047  000400000004 R_X86_64_PLT32    0000000000000000 test - 4

Relocation section '.rela.eh_frame' at offset 0x2b8 contains 2 entries:
  Offset          Info           Type           Sym. Value    Sym. Name + Addend
000000000020  000200000002 R_X86_64_PC32     0000000000000000 .text + 0
000000000040  000200000002 R_X86_64_PC32     0000000000000000 .text + 2f
<br>下面是module2.o的重定位条目信息：<br>du@DVM:~/Desktop$ readelf -r module2.o

Relocation section '.rela.text' at offset 0x1d0 contains 3 entries:
  Offset          Info           Type           Sym. Value    Sym. Name + Addend
00000000000a  000400000002 R_X86_64_PC32     0000000000000000 j - 8
000000000016  000300000002 R_X86_64_PC32     0000000000000000 .rodata - 4
00000000001e  000500000002 R_X86_64_PC32     0000000000000008 k - 4

Relocation section '.rela.eh_frame' at offset 0x218 contains 1 entry:
  Offset          Info           Type           Sym. Value    Sym. Name + Addend
000000000020  000200000002 R_X86_64_PC32     0000000000000000 .text + 0

<br>反汇编后的代码如下：<br>du@DVM:~/Desktop$ objdump -d module1.o

module1.o:     file format elf64-x86-64


Disassembly of section .text:

0000000000000000 &lt;test&gt;:
   0:	f3 0f 1e fa          	endbr64 
   4:	55                   	push   %rbp
   5:	48 89 e5             	mov    %rsp,%rbp
   8:	8b 05 00 00 00 00    	mov    0x0(%rip),%eax        # e &lt;test+0xe&gt;
   e:	66 0f ef c9          	pxor   %xmm1,%xmm1
  12:	f2 0f 2a c8          	cvtsi2sd %eax,%xmm1
  16:	f2 0f 10 05 00 00 00 	movsd  0x0(%rip),%xmm0        # 1e &lt;test+0x1e&gt;
  1d:	00 
  1e:	f2 0f 58 c1          	addsd  %xmm1,%xmm0
  22:	f2 0f 2c c0          	cvttsd2si %xmm0,%eax
  26:	89 05 00 00 00 00    	mov    %eax,0x0(%rip)        # 2c &lt;test+0x2c&gt;
  2c:	90                   	nop
  2d:	5d                   	pop    %rbp
  2e:	c3                   	ret    

000000000000002f &lt;main&gt;:
  2f:	f3 0f 1e fa          	endbr64 
  33:	55                   	push   %rbp
  34:	48 89 e5             	mov    %rsp,%rbp
  37:	b8 00 00 00 00       	mov    $0x0,%eax
  3c:	e8 00 00 00 00       	call   41 &lt;main+0x12&gt;
  41:	b8 00 00 00 00       	mov    $0x0,%eax
  46:	e8 00 00 00 00       	call   4b &lt;main+0x1c&gt;
  4b:	b8 00 00 00 00       	mov    $0x0,%eax
  50:	5d                   	pop    %rbp
  51:	c3                   	ret    
du@DVM:~/Desktop$ objdump -d module2.o

module2.o:     file format elf64-x86-64


Disassembly of section .text:

0000000000000000 &lt;externFunc&gt;:
   0:	f3 0f 1e fa          	endbr64 
   4:	55                   	push   %rbp
   5:	48 89 e5             	mov    %rsp,%rbp
   8:	c7 05 00 00 00 00 04 	movl   $0x4,0x0(%rip)        # 12 &lt;externFunc+0x12&gt;
   f:	00 00 00 
  12:	f2 0f 10 05 00 00 00 	movsd  0x0(%rip),%xmm0        # 1a &lt;externFunc+0x1a&gt;
  19:	00 
  1a:	f2 0f 11 05 00 00 00 	movsd  %xmm0,0x0(%rip)        # 22 &lt;externFunc+0x22&gt;
  21:	00 
  22:	90                   	nop
  23:	5d                   	pop    %rbp
  24:	c3                   	ret    
<br><br>在同节合并后，所有的数据节、代码节都会合并成数据段、代码段。我们在.rela.eh_frame中看到很多如下的重定位项，其实当同节合并后这些不同的&nbsp;.text&nbsp;节的虚存地址也就能够得到确认了。这时只要将节合并后的&nbsp;.text&nbsp;节首地址同后面的偏移量相加即可。<br>Relocation section '.rela.eh_frame' at offset 0x2b8 contains 2 entries:
  Offset          Info           Type           Sym. Value    Sym. Name + Addend
000000000020  000200000002 R_X86_64_PC32     0000000000000000 .text + 0
000000000040  000200000002 R_X86_64_PC32     0000000000000000 .text + 2f
<br>一般PC相对地址的重定位多用于函数符号的重定位上。因为函数都是作为代码段映射到虚拟内存上的。如果引用符号在本模块里定义了，我们就只需要像上面那样计算出偏移量即可知道函数符号的定义在哪里了。<br><br>同样，在所有的同节合并后，当我们定义和引用数据符号时，由于它们不在同一个段内，我们往往直接将数据的绝对地址填入数据符号的引用处。在符号引用时，能够直接在数据段读取数据。这时，相对地址的方式就显得繁琐。<br><br><br><br><br><br>在不考虑内核区内存布局的情况下，一般而言用户区的进程内存布局从低地址到高地址分别是代码段、数据段、堆和栈。它们具体的作用如下：<br>
<br>代码段(Text Segment)：存放二进制机器代码程序的执行代码（只读/执行）
<br>数据段(Data Segment)：初始化的全局变量和静态变量（读写）
<br>BSS段(Block Started by Symbol)：未初始化的全局和静态变量（读写）
<br>只读数据段(Read-Only Data Segment, rodata)：不可修改的数据（只读）字符串常量如：char* local_d = "hi,world";
<br>堆(Heap)：动态内存分配的区域（使用malloc）
<br>栈(Stack)：由于存放函数的局部变量、调用返回地址等<br>
<img alt="Pasted image 20240916181307.png" src="https://congzhi.wiki/some-notes/pics/pasted-image-20240916181307.png">
<br>]]></description><link>https://congzhi.wiki/some-notes/进程的一生——从出生到死亡-(abandoned).html</link><guid isPermaLink="false">Some Notes/进程的一生——从出生到死亡 (Abandoned).md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Mar 2025 17:28:33 GMT</pubDate><enclosure url="https://congzhi.wiki/some-notes/pics/pasted-image-20240916212548.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/some-notes/pics/pasted-image-20240916212548.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[CS50's Introduction to Python]]></title><description><![CDATA[ 
 <br><br><br><br><br>我们将Hello world!输出到console作为我们的第一个python程序。下面就是我们的第一个python程序。如果你使用过C，你就会发现，在python中，一切来的如此简单自然。<br>print("Hello world!")  # Literally prints out "Hello world!"
# or in this way
print('Hello world!')  # Same as above, Python does not distinguish between '' and ""

# But be aware to match them, the following examples would be incorrect:

# print('Hello world!")
# print("Hello world!')
# print("Hello "world")

# This would be fine with back slash:

print("Hello \"world")
<br>print()函数的功能类似于C语言中的printf()，但不同于C语言，我们在使用input()的时候并不需要包含任何头文件等等。这是因为print()函数是一个内置函数(build-in function)，这些内置函数作为python语言的一部分存在。要使用这些内置函数，我们并不需要import任何的python标准库或其他的库。<br>如果注意力惊人。当你运行了程序，你就会发现虽然我们程序中并没有换行的需求，print() 函数还是默认在输出的字符串后添加一个换行符。这和print()函数的原型有关。<br>在<a data-tooltip-position="top" aria-label="https://docs.python.org/3/library/functions.html" rel="noopener nofollow" class="external-link" href="https://docs.python.org/3/library/functions.html" target="_blank">这里</a>你可以找到所有的python内置函数。print()的函数原型如下：<br>def print(*objects, sep=' ', end='\n', file=None, flush=False):
"""
Prints the given objects to the standard output or to the specified file.

Parameters:
    1. *objects: Any number of objects to be printed.
    2. sep: A string inserted between the objects, default is a space.
    3. end: A string appended after the last object, default is a newline.
    4. file: A file-like object (stream); defaults to the current sys.stdout.
    5. flush: Whether to forcibly flush the stream.
Return value: No return values.
"""
<br>当你没有指定第二个参数end时，end参数默认会在字符串最后追加一个换行符，也就是'\n'。如果你不想在输出时换行，你只需要：<br>print("Hello world!", end = '')
<br><br>学习过了如何用print()在console中打印一个字符串。这小节我们来编写一个简单的交互式程序吧。我们将学到另一个内置函数——input()。它的作用是从用户哪里读取一行输入，并将其作为一串字符串返回给一个变量。下面是input()的函数原型。<br>def input(prompt):
"""
Reads a line from input, converts it to a string (stripping a trailing newline), and returns that.

Parameters:
    1. prompt: A string, representing a message to display before the input (optional).

Return value: The input from the user as a string.
"""
<br>input()函数会等待用户按下回车并将用户输入作为str类型的返回值返回。所以我们使用input()时往往需要一个变量来存储我们输入的字符串信息。在python中，我们不需要在变量前面指明string类型。一个简单的“你是？我是xxx。”的交互式程序如下：<br>print("Who are you?")
s = input() # Input your name.
print("I am", end = ' ')
print(s)
<br>由于input()有一个参数prompt用来标识一个可选择性输入的提示信息。所以我们可以直接用input()输出一些提示信息：<br>s = input("Who are you?") # Input your name.
print("I am", end = ' ')
print(s)
<br>此外，我们还可以用以下的方法来打印我是xxx的信息：<br>print("I am " + name)
print("I am", name)

# format string
print(f"I am {name}")
<br><br><a data-tooltip-position="top" aria-label="https://docs.python.org/3/library/stdtypes.html#string-methods" rel="noopener nofollow" class="external-link" href="https://docs.python.org/3/library/stdtypes.html#string-methods" target="_blank">这里</a><br>round and formatted string<br><br>变量是用于存储数据的命名位置，即我们用变量来标识一个地址。在上面的程序中我们看到，要储存一个信息（不仅仅是字符串），我们需要定义一个变量。当我们用赋值运算符=，信息就会被储存到变量所在的位置。<br>Python解释器为我们内置了很多类型，这些内置类型是python语言中预定义的数据类型。当你将一个值赋给变量时，变量会自动采用该值的类型。常见的内置类型有：<br>
<br>整数(int)
<br>浮点数(float)
<br>浮点数(bool)
<br>字符串(str)
<br>列表(list)
<br>字典(dict)
<br>......
<br>趁热打铁，我们来用input()输入两个数字实现一下我们第一个python的加法程序：<br>n = input("Enter a interger number:") # Enter 5
m = input("Enter a float number:") # Enter 0.5
print(f"The result is {n + m}") # Print out 50.5
<br>我们运行了上面的程序，但是我们发现输出完全是错误的。这是因为在之前我们使用s = input()时，由于input()会返回一个str类型的值。为了实现加法程序，我们需要将输入的数据进行转换，具体步骤如下：<br>n = input("Enter a interger number:") # Enter 5
n = int(n)
m = input("Enter a float number:") # Enter 0.5
m = float(m)
print(f"The result is {n + m}") # Print out 5.5
<br>再简化一下，我们让里面input()函数的返回值作为外面函数的参数：<br>n = int(input("Enter a interger number:")) # Enter 5
m = float(input("Enter a float number:")) # Enter 0.5
print(f"The result is {n + m}") # Print out 5.5
<br>甚至，你可以将输入放到print()函数中。那么一行代码可能会变得很长，可读性就会下降。<br>上面，我们用input() 函数获取用户输入并返回一个字符串。然后，我们使用内置函数 int() 和 float() 函数将字符串转换为整数（默认10进制）或浮点数。如果用户输入的内容不能转换为数字，就会引发 ValueError 异常。<br>和上面的string build-in methods一样，其他build-in类型也有相应的build-in methods。<br>row = line.rstrip().split(",")
row[0],row[1]

name, house = line.rstrip().split(",")
<br><br>在Python中，函数的定义确实非常简单。我们使用def关键字来引入函数的定义。Python并不像C或其他语言那样用分号表示一个语句的结束，而是用换行符来表示语句的结束。此外，Python使用缩进来表示代码块的层次结构和逻辑关系，而不是像C语言那样使用大括号{}。<br>下面是一个简答的python函数示例：<br>def greet(name):
    print(f"Hello, {name}!")

greet("David")
<br>Python中并没有C语言里面的函数声明等的东西。而且函数引入了变量的作用域(scope)。在函数里面出现的变量就是局部变量，相比之下C语言中我们称大括号里面的变量为局部变量。<br><br>&gt;、&gt;=、&lt;、&lt;=、==、!=<br>to many if<br>enif(else if) and else<br>or and and<br>pythonic code:<br>def is_even(n):
	return (n % 2 == 0) else False
<br>match case<br><br>try:
    x = int(input("what's x:"))
    print(f"x = {x}")
except ValueError:
    print("x is not a integer")

<br>try:
    x = int(input("what's x:"))
except ValueError:
    print("x is not a integer")
print(f"x = {x}")
<br>try:

except Error:
	pass
else:

<br>raise
<br><br>def main():
    print("This is the main function.")

if __name__ == "__main__":
    main()
<br>modules<br>command pip install module<br><br>unit means function<br>assert<br>pytest<br>with<br>test a folder<br>
once the testor find a __init__.py in the folder, it would treat this folder into a package<br>my_project/
    ├── my_package/
    │   ├── __init__.py
    │   ├── module1.py
    │   └── module2.py
    └── test/
        ├── __init__.py
        └── test_module1.py

<br><br>file = open()<br>with with statement, you can automatically close the file<br>]]></description><link>https://congzhi.wiki/some-notes/cs50&apos;s-introduction-to-python.html</link><guid isPermaLink="false">Some Notes/CS50&apos;s Introduction to Python.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 22:06:28 GMT</pubDate></item><item><title><![CDATA[Endianness]]></title><description><![CDATA[ 
 <br>在不同的计算机体系结构中，对于数据的存储可能是不一样的。当下各种不同的体系结构提供了两种字节存储机制：大端和小端。在计算机的硬件实现上，采用这两种不统一的实现方式可能会为我们带来很多麻烦，比方说两台计算机的交流问题。所以我们规定了网络字节序为大端序。<br><br>大端序和小端序最大的区别就是 MSB(Most Significant Bit/Byte) 和 LSB(Least Significant Bit/Byte) 的所在位置。比方说我们有十六进制整数0x12345678，这里面 MSB（byte） 就是0x12，LSB 就是0x78。这很好理解，因为0x12是对结果影响最大的（即Most significant），而0x78是对结果影响最小的（Least significant）。<br>再往深了看，在0x12字节中，它的二进制形式为 0001 0010 最左边的 1 就是 MSB（bit）。而在0x78字节中，它的二进制形式为 0111 1000 最右边的 0 就是 LSB（bit）。<br><img alt="bit-endian-1.gif" src="https://congzhi.wiki/some-notes/pics/bit-endian-1.gif"><br>理解了这个概念，我们回头来看大小端分别都是什么。大端序规定 MSB 存储在低地址，传输数据时先传输 MSB 。小端序呢？我们往下看。<br><br>理解了 MSB、LSB 和大端序，理解小端序就易如反掌了。我们可以假设小端序将 MSB 存储在高地址，并在传输数据时先传输 LSB。事实也确实是这样的。<br><br>大小端各有其优缺点，有些人认为大端序方便阅读，因为符合人类书写的习惯。而我觉得大端序很反人类，反而随着地址的增加、位权也随之增加的小端序更易被我理解。在数据的处理上，由于计算机处理数据常常从低地址走向高地址。所以在比较大小（位数相同）、符号位的判断上面，大端序占优。而检查奇偶、比较大小（位数不同）、类型转换等计算密集型操作上小端序则更占优势。<br><br>怎么才能判断系统的大小端？<br>#include &lt;stdio.h&gt;
int main() {
    int num = 1;
    if (*(char *)&amp;num == 1) {
        printf("Little-endian\n");
    } else {
        printf("Big-endian\n");
    }
    return 0;
}
]]></description><link>https://congzhi.wiki/some-notes/endianness.html</link><guid isPermaLink="false">Some Notes/Endianness.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sat, 22 Mar 2025 16:18:14 GMT</pubDate><enclosure url="https://congzhi.wiki/some-notes/pics/bit-endian-1.gif" length="0" type="image/gif"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/some-notes/pics/bit-endian-1.gif&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Flask]]></title><description><![CDATA[ 
 <br><br>创建一个 Flask 文件夹作为 work directory。在 VS Code 中打开这个目录并在目录下添加 app.py 和 requirements.txt。<br>在 app.py 中键入：<br>from flask import Flask
app = Flask(__name__)

@app.route("/")
def index():
	return "hello, world"
]]></description><link>https://congzhi.wiki/some-notes/flask.html</link><guid isPermaLink="false">Some Notes/Flask.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 18 Mar 2025 06:48:07 GMT</pubDate></item><item><title><![CDATA[Intro to Algorithm]]></title><description><![CDATA[ 
 <br><br><br>对于一段好的程序，算法至关重要。算法是解决问题的一系列步骤或规则，是抽象的。而程序则更加具体，当你将算法变为程序时，你需要在特定的环境下用特定的编程语言来进行实现。<br>下面是算法和程序的比较：<br><br>算法是实现前的程序设计，需要领域内的知识，算法可以用任何语言来描述而且通常上无关系硬件和系统。而程序是算法思想的实现，由程序员完成，按照要求用特定的编程语言在特定的硬件设备和系统环境下进行。<br>在算法阶段，我们衡量一个算法好坏的评判标准是分析其时间复杂度和空间复杂度，这通常作为先验分析。在程序实现完成后，我们需要通过实际的运行来评估其性能，这被叫做后验测试。<br><br>算法的特征或properties用以下五方面来表示：<br>
<br>Input: 一个算法应当有0个或多个输入；
<br>Output: 一个算法应当有至少一个输出，不然算法就没有意义了；
<br>Definiteness: 确定性是指算法的每一步操作都应当有明确的定义和说明，确保算法是清晰的、无歧义的。避免出现不确定性。
<br>Finiteness: 要让算法起作用，最起码要保证算法在某些时刻必须终止。这就是有穷性。
<br>Effectiveness: 有效性是指算法的每一步操作都应当是基本的，不应当掺杂多余的部分。
<br><br><br>写一个算法很简单，你可以不需要任何的编程语言知识来描述算法的思想。但是，算法的实现需要你将算法思想转换成一些编程语言。假如我有一个交换A和B值的算法，我可以这样实现：<br>SWAP(A, B):
Begin
	temp = A
	A = B
	B = Temp
End
<br>也可以这样：<br>int SWAP(A, B)
{
	temp := A;
	A := B;
	B := temp;
}
<br>尽管细节可能有所不同，但它们传达的主题思想都是一样的。<br><br>传统上，我们通常使用时间复杂度和空间复杂度来衡量一个算法的好坏。此外，我们还有其他的一些标准来衡量一个算法，如：<br>
<br>Network consumption
<br>Power consumption
<br>CPU registers consumption
<br><br>对于时间复杂度的计算，我们简单地将高级语言程序中的一行代码作为一个基本操作。在上面的SWAP算法中，我们的算法的时间复杂度就为3，因为有三行高级语言代码。虽然高级语言程序最终会变成二进制的机器语言，但我们不用关心对时间复杂度的影响。（对能耗和寄存器的确有影响）<br>由于我们算法的时间复杂度的最高阶是一个常数，因此我们称其为常数时间复杂度，记作&nbsp;。<br><br>同样上述的算法，当我们计算空间复杂度时，我们将一个变量看作一个基本单位。通过分析程序中基本单位的数量和它们的使用频率，我们可以确定整个算法的空间复杂度。在SWAP算法中，我们有三个变量，但由于我们的空间复杂度最高阶是常数阶，我们也可以将其记作&nbsp;。<br><br>     - Constant<br>
 - Logarithmic<br>
  - Square&nbsp;Root<br>
     - Linear<br>
    - Quadratic<br>
    - Cubic<br>
     - Exponential<br>Big-O describes&nbsp;the&nbsp;worst-case&nbsp;scenario,&nbsp;providing&nbsp;an&nbsp;upper&nbsp;bound&nbsp;on&nbsp;the&nbsp;time&nbsp;complexity.<br>Big-Ω describes&nbsp;the&nbsp;best-case&nbsp;scenario,&nbsp;providing&nbsp;a&nbsp;lower&nbsp;bound&nbsp;on&nbsp;the&nbsp;time&nbsp;complexity.<br>Big-Θ describes&nbsp;the&nbsp;average case&nbsp;scenario.]]></description><link>https://congzhi.wiki/some-notes/intro-to-algorithm.html</link><guid isPermaLink="false">Some Notes/Intro to Algorithm.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 16:13:34 GMT</pubDate></item><item><title><![CDATA[ISA, Instructions and CPU]]></title><description><![CDATA[ 
 <br><br>我们都明白，计算机系统可以分成两类功能上的实体——计算机硬件、计算机软件。但是软件和硬件是两个很宽泛的概念，继续划分，我们可以将整个计算机系统划分成 7 层结构：<br>
<br>应用（问题）
<br>算法
<br>编程（语言）
<br>指令集体系结构(Instruction Set Architecture, ISA)
<br>微体系结构
<br>功能部件的电路设计
<br>器件<br>
在这 7 层结构中软件层面包括应用、算法、编程和ISA，硬件层面包含有ISA、微体系结构、电路设计和器件。你发现了么？软件层面包含ISA，硬件层面也包括了ISA，那ISA到底是何方神圣，脚踏两条船？
<br>在我们学习操作系统的时候，可能会听老师说：“操作系统是介于软件和硬件之间最接近硬件的软件，为软件间接提供操作硬件的接口“。通过上面对ISA极其模糊的介绍之后，你会不会有很多关于ISA和操作系统的疑惑？我们下面来看看ISA究竟是什么东西。<br><br>ISA是指令集体系结构，它对于硬件而言是一种设计上的规约，而对于操作系统而言ISA提供API的接口。我们常听说ARM、MIPS、x86等这些就对应着不同的ISA。既然叫指令集体系结构，那它肯定和指令有着密不可分的关系，对于硬件来说，ISA是一种规约，它规定了CPU需要为哪些指令提供接口（例如：加减乘除与或非），而至于具体的实现？那完全是微体系结构的事情。（ISA关心的是有没有乘法器、乘法指令的事情，微体系结构关心的是乘法器如何实现的事情。）<br>我们举例子直观来感受一下ISA对上层操作系统提供的指令集接口，我们用ARM和x86举例子：<br>
<br>
加载寄存器

<br>ARM:&nbsp;LDR R0, [R1]

<br>二进制表示:&nbsp;1110 0101 1000 0000 0000 0000 0000 0000


<br>x86:&nbsp;MOV EAX, [EBX]

<br>二进制表示:&nbsp;1000 1011 0000 0000




<br>
加法操作

<br>ARM:&nbsp;ADD R0, R1, R2

<br>二进制表示:&nbsp;1110 0000 1000 0001 0000 0000 0000 0010


<br>x86:&nbsp;ADD EAX, EBX

<br>二进制表示:&nbsp;0000 0001 1100 0011




<br>
存储寄存器
- **ARM**:&nbsp;`STR R0, [R1]`
    - 二进制表示:&nbsp;`1110 0101 0000 0000 0000 0000 0000 0000`
- **x86**:&nbsp;`MOV [EBX], EAX`
    - 二进制表示:&nbsp;`1000 1001 0000 0000`

发现了么？ISA不同，实现相同功能的指令就是不一样的。这也就是为什么你写的程序不能在其他平台上运行，这里的平台指的就是ISA。

<br><br>如果我们的只有定长的8位指令，我们如何设计自己的ISA？我们下面给出规约：<br><br>系统应当有6个寄存器（REG0-REG5），一个输入端，一个输出端。<br><br>用高两位用来表示指令的类型:<br>
<br>
00表示立即数指令，我们规定立即数指令总是将立即数送给REG0;

<br>
01表示计算指令，这部分指令由ALU实现，我们进行如下规定：

<br>01 000 000表示OR指令
<br>01 000 001表示NAND指令
<br>01 000 010表示NOR指令
<br>01 000 011表示AND指令
<br>01 000 100表示ADD指令
<br>01 000 101表示SUB指令

我们可以向立即数指令一样，设置某个特定的寄存器用于特定的作用，如：算数操作永远是将REG1和REG2中读取数值作为输入的操作数，并将结果写入REG3中。

<br>
10表示复制指令，将源的数据送到目的，我们进行如下规定：

<br>10 000(SRC) 000(DEST)高两位表示类型，中间三位表示源，后三位表示目的。
<br>000-101表示从REG0-REG5的寄存器，中间三位为110时表示从输入端读数据，后三位为110时表示将源数据送到输出端。


<br>
11表示条件判断指令，只有满足条件才会将数据输出，我们给出如下规定：

<br>11 000 000表示永不输出
<br>11 000 001表示输入=0时输出
<br>11 000 010表示输入&lt;0时输出
<br>11 000 011表示输入≤0时输出
<br>11 000 100表示永远输出
<br>11 000 101表示输入≠0时输出
<br>11 000 111表示输入&gt;0时输出


<br><br>汇编，我们可以理解为机器码的别名，每一条汇编指令都可以对于某一个特定的指令。依此，我们可以将机器码通过添加汇编别名方便地为人类理解，如：<br>add ;01 000 100
sub ;01 000 101

mov_reg0_reg5 ;10 000 101
mov_in_out ;10 110 110
<br>等等。看到了么？在我们的指令系统中，操作系统可以用add指令来与底层的裸机进行交互，告诉机器我现在要让你把REG1和REG2的数据相加放到REG3中。<br><br>根据上面我们的指令集体系结构的规约，我们就可以设计自己的CPU了。<br><br>首先，我们需要译码器帮助我们用高两位将不同功能的指令给筛选出来，这里，我们简单用分线器将 8 位指令分成 8 个输入端，取高两位用2-4译码器来完成译码的工作。当高两位为00就使能立即数操作的工作逻辑，为01就使能ALU，以此类推。]]></description><link>https://congzhi.wiki/some-notes/isa,-instructions-and-cpu.html</link><guid isPermaLink="false">Some Notes/ISA, Instructions and CPU.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Feb 2025 22:06:08 GMT</pubDate></item><item><title><![CDATA[Real-Basic Algorithm Concepts]]></title><description><![CDATA[ 
 <br><br>递归是一种通过将重复的问题分解为子问题来解决的算法。比方说求从 1 加到 n 的值，我们就可以用递归来解决。递归的特征就是自身调用和存在终止条件。下面是一个简单的例子：<br>int sum(int n){
	if(n &lt;= 0){
		return -1;
	}
	if(n = 1){
		return 1;
	}
	return sum(n - 1) + n;
}
<br>由于每次的函数调用都会创建出一个栈帧用于存储局部变量和临时变量，所以递归程序应尽量简洁，并避免递归调用层次，避免栈溢出。<br><br>使用穷举解决问题的方法<br>def solveNQueens(N):
    def isValid(board, row, col):
        for i in range(row):
            if board[i] == col or \
               board[i] - i == col - row or \
               board[i] + i == col + row:
                return False
        return True

    def solve(board, row):
        if row == N:
            result.append(board[:])
            return
        for col in range(N):
            if isValid(board, row, col):
                board[row] = col
                solve(board, row + 1)
                board[row] = -1  # 回溯

    result = []
    solve([-1] * N, 0)
    return result

<br><br><br>处理问题的思路<br>归并]]></description><link>https://congzhi.wiki/some-notes/real-basic-algorithm-concepts.html</link><guid isPermaLink="false">Some Notes/Real-Basic Algorithm Concepts.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Sun, 23 Feb 2025 12:58:08 GMT</pubDate></item><item><title><![CDATA[Some Notes]]></title><description><![CDATA[ 
 <br><br><br><a data-href="Some Notes" href="https://congzhi.wiki/some-notes/some-notes.html" class="internal-link" target="_self" rel="noopener nofollow">Some Notes</a> 用于保存记录零碎的小笔记，或是暂时未开工的新计划。<a data-href="Some Notes" href="https://congzhi.wiki/some-notes/some-notes.html" class="internal-link" target="_self" rel="noopener nofollow">Some Notes</a> 下的笔记有：<br>Some Notes:

<br><a data-href="Three Steps to Have Your Own Obsidian Site" href="https://congzhi.wiki/some-notes/three-steps-to-have-your-own-obsidian-site.html" class="internal-link" target="_self" rel="noopener nofollow">Three Steps to Have Your Own Obsidian Site</a>
<br><a data-href="进程的一生——从出生到死亡 (Abandoned)" href="https://congzhi.wiki/some-notes/进程的一生——从出生到死亡-(abandoned).html" class="internal-link" target="_self" rel="noopener nofollow">进程的一生——从出生到死亡 (Abandoned)</a> --&gt; <a data-href="Building and Version Control" href="https://congzhi.wiki/building-and-version-control/building-and-version-control.html" class="internal-link" target="_self" rel="noopener nofollow">Building and Version Control</a>
<br><a data-href="存储器扩展技术" href="https://congzhi.wiki/some-notes/存储器扩展技术.html" class="internal-link" target="_self" rel="noopener nofollow">存储器扩展技术</a>
<br><a data-href="Endianness" href="https://congzhi.wiki/some-notes/endianness.html" class="internal-link" target="_self" rel="noopener nofollow">Endianness</a>
<br><a data-href="Flask" href="https://congzhi.wiki/some-notes/flask.html" class="internal-link" target="_self" rel="noopener nofollow">Flask</a>
<br><a data-href="ISA, Instructions and CPU" href="https://congzhi.wiki/some-notes/isa,-instructions-and-cpu.html" class="internal-link" target="_self" rel="noopener nofollow">ISA, Instructions and CPU</a>
<br><a data-href="CS50's Introduction to Python" href="https://congzhi.wiki/some-notes/cs50's-introduction-to-python.html" class="internal-link" target="_self" rel="noopener nofollow">CS50's Introduction to Python</a>
<br><a data-href="Real-Basic Algorithm Concepts" href="https://congzhi.wiki/some-notes/real-basic-algorithm-concepts.html" class="internal-link" target="_self" rel="noopener nofollow">Real-Basic Algorithm Concepts</a>
<br><a data-href="Intro to Algorithm" href="https://congzhi.wiki/some-notes/intro-to-algorithm.html" class="internal-link" target="_self" rel="noopener nofollow">Intro to Algorithm</a>
<br><a data-href="YOLO Env Config" href="https://congzhi.wiki/some-notes/yolo-env-config.html" class="internal-link" target="_self" rel="noopener nofollow">YOLO Env Config</a>

<br><br><br>任何疑问都欢迎通过 <a data-tooltip-position="top" aria-label="mailto:duzhi_02@qq.com" rel="noopener nofollow" class="external-link" href="https://congzhi.wiki/mailto:duzhi_02@qq.com" target="_blank">duzhi_02@qq.com</a> 联系我。]]></description><link>https://congzhi.wiki/some-notes/some-notes.html</link><guid isPermaLink="false">Some Notes/Some Notes.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 16:14:26 GMT</pubDate></item><item><title><![CDATA[Three Steps to Have Your Own Obsidian Site]]></title><description><![CDATA[ 
 <br><br>你需要先完成你的笔记。<br><br>Obsidian 社区中有很多有趣实用的插件。你可以用下面的插件将你的 markdown 格式的笔记转换成 HTML ：obsidian://show-plugin?id=webpage-html-export 。<br>记得把导出模式（export mode）改为 Online-Web-Server，然后把你的 vault 中的所有笔记导出到一个文件夹中，便于后面上传到一个托管平台上。<br>请你注意，你需要一个 index.html 文件用于默认的主页。你可以把 index.html 作为你的主页直接使用。也可以讲这个 index.html 用作重定向到其他的页面。<br><br>第二步，你需要一个 Github 账户来进行博客笔记的托管。简单来说，就相当于 Github 给你了一个免费的服务器。在创建好你的账号之后，你需要：<br>
<br>创建一个后缀名为 github.io 的公开仓库（比如 username.github.io ，你需要把 username 换为你的用户名），这相当于一个文件夹，后续用作笔记的托管；
<br>随后打开刚才创建的仓库。点击 "settings"（设置）选项卡。在左侧栏中找到并点击 "pages" 选项。你可以在这里进行笔记的托管。
<br>在“Source”部分选择“Branch: main”，然后点击“Save”按钮。
<br> 完成后，你的笔记将被托管在 GitHub Pages 上，你可以通过 username.github.io 访问你的仓库。你应当看到左上角的 Hello world。<br>至此一切顺利的话，你就可以把你的笔记上传到你创建好的仓库中。等待片刻，再次打开 username.github.io 你应该可以看到你的笔记了。<br><br>你可以在任何域名注册商购买你心仪的域名。购买完成后，你需要找到 DNS 设置，添加一条 DNS 记录。在如果你在阿里云购买域名，你需要搜索 DNS 云解析，然后点击你的域名并添加域名解析记录。这里，你只需要添加一条 CNAME 类型的记录，即 Canonical hostNAME。其作用就是将该域名的访问指向 Github pages 的域名。<br>Type: CNAME
Name: www
TTL : 10 min for default in aliyun
<br>全部都配置好后，你需要再打开你的 Github pages 页面。在下面的 "Custom domain" 部分输入你自己的域名并保存。最后你可能需要等待几分钟让 DNS 更改生效。完成后，你就可以从 www.yourdomain.com来访问你的网站了。<br>如果你想直接使用你的域名来访问，你可以配置根域名。通过配置根域名（如 yourdomain.com），可以帮你更方便地使用你的网站。这时，你需要复制你的 Github pages 的域名到域名查询网站，查找对应的 IPv4/IPv6 地址，然后逐一添加解析记录。<br><br>GitHub Pages 的服务器在美国，所以难免会有延迟。但是你可以使用 CDN 的内容分发网络服务，可以让网站的访问速度倍增。简单地说，CDN 会将你网页上的内容缓存到更近的 CDN 服务器上，访问时直接从 CDN 服务器上获取网页内容，就不需要等待源站（GitHub Pages）将内容传输过来。<br>不过你要注意，在大陆使用 CDN 需要进行备案。而且你的网站内容需要符合法律规定，确保合规运营。但备案前，你一般还需要购买租用一定时间的服务器。有人说在赛博活佛 Cloudflare 那里你可以获取到免费的 CDN 服务，但是加速区域不覆盖中国大陆。这里我选择的是阿里云，1 GB 的 CDN 内容加速只需要 0.8 人民币，对于访问量极低的我来说还算可以（而且 HTML 网页一般都很小）。]]></description><link>https://congzhi.wiki/some-notes/three-steps-to-have-your-own-obsidian-site.html</link><guid isPermaLink="false">Some Notes/Three Steps to Have Your Own Obsidian Site.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Fri, 14 Mar 2025 14:54:40 GMT</pubDate></item><item><title><![CDATA[YOLO Env Config]]></title><description><![CDATA[ 
 <br><br>安装conda(运行环境隔离)<br>[Verifying - USTC Mirrors](https://mirrors.ustc.edu.cn/anaconda/miniconda/Miniconda3-py310_24.9.2-0-Windows-x86_64.exe)
<br>输入 conda create -n yolov8 python=3.10 新建环境<br>(base) C:\Users\Chi&gt;conda create -n yolov8 python=3.10
Channels:
 - defaults
Platform: win-64
Collecting package metadata (repodata.json): done
Solving environment: done

## Package Plan ##

  environment location: C:\Users\Chi\miniconda3\envs\yolov8

  added / updated specs:
    - python=3.10


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    ca-certificates-2025.2.25  |       haa95532_0         130 KB
    openssl-3.0.16             |       h3f729d1_0         7.8 MB
    pip-25.0                   |  py310haa95532_0         2.5 MB
    python-3.10.16             |       h4607a30_1        16.3 MB
    setuptools-75.8.0          |  py310haa95532_0         1.7 MB
    tzdata-2025a               |       h04d1e81_0         117 KB
    vc-14.42                   |       haa95532_4          11 KB
    vs2015_runtime-14.42.34433 |       he0abc0d_4         1.2 MB
    wheel-0.45.1               |  py310haa95532_0         145 KB
    xz-5.6.4                   |       h4754444_1         280 KB
    ------------------------------------------------------------
                                           Total:        30.1 MB

The following NEW packages will be INSTALLED:

  bzip2              pkgs/main/win-64::bzip2-1.0.8-h2bbff1b_6
  ca-certificates    pkgs/main/win-64::ca-certificates-2025.2.25-haa95532_0
  libffi             pkgs/main/win-64::libffi-3.4.4-hd77b12b_1
  openssl            pkgs/main/win-64::openssl-3.0.16-h3f729d1_0
  pip                pkgs/main/win-64::pip-25.0-py310haa95532_0
  python             pkgs/main/win-64::python-3.10.16-h4607a30_1
  setuptools         pkgs/main/win-64::setuptools-75.8.0-py310haa95532_0
  sqlite             pkgs/main/win-64::sqlite-3.45.3-h2bbff1b_0
  tk                 pkgs/main/win-64::tk-8.6.14-h0416ee5_0
  tzdata             pkgs/main/noarch::tzdata-2025a-h04d1e81_0
  vc                 pkgs/main/win-64::vc-14.42-haa95532_4
  vs2015_runtime     pkgs/main/win-64::vs2015_runtime-14.42.34433-he0abc0d_4
  wheel              pkgs/main/win-64::wheel-0.45.1-py310haa95532_0
  xz                 pkgs/main/win-64::xz-5.6.4-h4754444_1
  zlib               pkgs/main/win-64::zlib-1.2.13-h8cc25b3_1


Proceed ([y]/n)?
<br>输入 y<br>Downloading and Extracting Packages:

Preparing transaction: done
Verifying transaction: done
Executing transaction: done
#
# To activate this environment, use
#
#     $ conda activate yolov8
#
# To deactivate an active environment, use
#
#     $ conda deactivate
<br>用 conda env list 查看现有环境<br>(base) C:\Users\Chi&gt;conda env list
# conda environments:
#
base                  *  C:\Users\Chi\miniconda3
yolov8                   C:\Users\Chi\miniconda3\envs\yolov8
<br>然后用 conda activate yolov8 激活环境，我们现在在 yolov8 的环境下<br>(base) C:\Users\Chi&gt;conda activate yolov8

(yolov8) C:\Users\Chi&gt;conda env list
# conda environments:
#
base                     C:\Users\Chi\miniconda3
yolov8                *  C:\Users\Chi\miniconda3\envs\yolov8
<br>配置清华源<br>(yolov8) C:\Users\Chi&gt;pip config set global.index-url https://mirror.tuna.tsinghua.edu.cn/pypi/web/simple
Writing to C:\Users\Chi\AppData\Roaming\pip\pip.ini
<br>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --set show_channel_urls yes
<br>在 cmd 中激活环境：<br>conda init cmd.exe
<br>关闭再打开<br>conda activate yolov8
<br><br>查看显卡支持的 CUDA 版本：12.3<br><img alt="cuda_version.png" src="https://congzhi.wiki/some-notes/pics/cuda_version.png"><br>30系显卡需要安装 CUDA 111 以上的版本<br>conda install pytorch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1  pytorch-cuda=11.8 -c pytorch -c nvidia
<br>测试一切是否正确：<br>(yolov8) C:\Users\Chi&gt;python
Python 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)] on win32
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; import torch
&gt;&gt;&gt; torch.ones(3).cuda()
tensor([1., 1., 1.], device='cuda:0')
&gt;&gt;&gt; exit()
<br><br><a data-tooltip-position="top" aria-label="https://github.com/ultralytics/ultralytics/releases?page=17" rel="noopener nofollow" class="external-link" href="https://github.com/ultralytics/ultralytics/releases?page=17" target="_blank">Releases · ultralytics/ultralytics</a><br>
下载版本 8.1.0<br>    目录: D:\gesture_recog\ultralytics-8.1.0


Mode                 LastWriteTime         Length Name
----                 -------------         ------ ----
d-----         2025/3/16     22:09                .github
d-----         2025/3/16     22:09                docker
d-----         2025/3/16     22:09                docs
d-----         2025/3/16     22:09                examples
d-----         2025/3/16     22:09                tests
d-----         2025/3/16     22:09                ultralytics
-a----         2025/3/16     22:09           2295 .gitignore
-a----         2025/3/16     22:09           2408 .pre-commit-config.yaml
-a----         2025/3/16     22:09            612 CITATION.cff
-a----         2025/3/16     22:09           5585 CONTRIBUTING.md
-a----         2025/3/16     22:09          34523 LICENSE
-a----         2025/3/16     22:09           6728 pyproject.toml
-a----         2025/3/16     22:09          35898 README.md
-a----         2025/3/16     22:09          34774 README.zh-CN.md


(yolov8) PS D:\gesture_recog\ultralytics-8.1.0&gt; pip install -e .
<br>下载<br>pip install jupyterlab tensorboard
<br>环境配置错误<br>pip uninstall pillow # 删除原先的 9.3.0 版本
pip install pillow==9.3.0 # 重新下载一遍，好了
<br>好了<br>(yolov8) PS D:\gesture_recog\ultralytics-8.1.0&gt; yolo
C:\Users\Chi\miniconda3\envs\yolov8\lib\site-packages\torchvision\io\image.py:14: UserWarning: Failed to load image Python extension: '[WinError 127] 找不到指定的程序。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

    Arguments received: ['yolo']. Ultralytics 'yolo' commands use the following syntax:

        yolo TASK MODE ARGS

        Where   TASK (optional) is one of ('detect', 'segment', 'classify', 'pose', 'obb')
                MODE (required) is one of ('train', 'val', 'predict', 'export', 'track', 'benchmark')
                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.
                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'

    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01
        yolo train data=coco128.yaml model=yolov8n.pt epochs=10 lr0=0.01

    2. Predict a YouTube video using a pretrained segmentation model at image size 320:
        yolo predict model=yolov8n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320

    3. Val a pretrained detection model at batch-size 1 and image size 640:
        yolo val model=yolov8n.pt data=coco128.yaml batch=1 imgsz=640

    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)
        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128

    5. Explore your datasets using semantic search and SQL with a simple GUI powered by Ultralytics Explorer API
        yolo explorer

    7. Run special commands:
        yolo help
        yolo checks
        yolo version
        yolo settings
        yolo copy-cfg
        yolo cfg

    Docs: https://docs.ultralytics.com
    Community: https://community.ultralytics.com
    GitHub: https://github.com/ultralytics/ultralytics
<br>至此，环境配置完成。<br><br>选择下载的 ultralytics 8.1.0 的文件夹。<br>配置终端和解释器。<br>下载 YOLO 模型<br>有警告：<br>(yolov8) D:\gesture_recog\ultralytics-8.1.0&gt;yolo mode='predict' task='detect' model='yolov8m.pt' source='00001.jpeg'
C:\Users\Chi\miniconda3\envs\yolov8\lib\site-packages\torchvision\io\image.py:14: UserWarning: Failed to load image Python extension: '[WinError 127] 找不到指定的程序。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
D:\gesture_recog\ultralytics-8.1.0\ultralytics\nn\tasks.py:634: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(file, map_location="cpu"), file  # load

image 1/1 D:\gesture_recog\ultralytics-8.1.0\00001.jpeg: 384x640 19 cars, 4 buss, 70.9ms
Speed: 7.6ms preprocess, 70.9ms inference, 148.1ms postprocess per image at shape (1, 3, 384, 640)
💡 Learn more at https://docs.ultralytics.com/modes/predict
<br>之后重新安装了 TorchVision<br>(yolov8) D:\gesture_recog\ultralytics-8.1.0&gt;conda install torchvision -c pytorch
<br>完成之后测试：发现 Pillow 的 _imaging 模块加载失败<br>(yolov8) D:\gesture_recog\ultralytics-8.1.0&gt;yolo mode='predict' task='detect' model='yolov8m.pt' source='00001.jpeg'
Traceback (most recent call last):
  File "C:\Users\Chi\miniconda3\envs\yolov8\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "C:\Users\Chi\miniconda3\envs\yolov8\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "C:\Users\Chi\miniconda3\envs\yolov8\Scripts\yolo.exe\__main__.py", line 4, in &lt;module&gt;
  File "D:\gesture_recog\ultralytics-8.1.0\ultralytics\__init__.py", line 5, in &lt;module&gt;
    from ultralytics.data.explorer.explorer import Explorer
  File "D:\gesture_recog\ultralytics-8.1.0\ultralytics\data\__init__.py", line 3, in &lt;module&gt;
    from .base import BaseDataset
  File "D:\gesture_recog\ultralytics-8.1.0\ultralytics\data\base.py", line 17, in &lt;module&gt;
    from ultralytics.utils import DEFAULT_CFG, LOCAL_RANK, LOGGER, NUM_THREADS, TQDM
  File "D:\gesture_recog\ultralytics-8.1.0\ultralytics\utils\__init__.py", line 19, in &lt;module&gt;
    import matplotlib.pyplot as plt
  File "C:\Users\Chi\miniconda3\envs\yolov8\lib\site-packages\matplotlib\__init__.py", line 161, in &lt;module&gt;
    from . import _api, _version, cbook, _docstring, rcsetup
  File "C:\Users\Chi\miniconda3\envs\yolov8\lib\site-packages\matplotlib\rcsetup.py", line 28, in &lt;module&gt;
    from matplotlib.colors import Colormap, is_color_like
  File "C:\Users\Chi\miniconda3\envs\yolov8\lib\site-packages\matplotlib\colors.py", line 52, in &lt;module&gt;
    from PIL import Image
  File "C:\Users\Chi\miniconda3\envs\yolov8\lib\site-packages\PIL\Image.py", line 100, in &lt;module&gt;
    from . import _imaging as core
ImportError: DLL load failed while importing _imaging: 找不到指定的模块。
<br>随后重装 pillow 测试还是不行<br>然后通过 conda 包管理器从 conda-forge 中安装 pillow 包。<br>conda install -c conda-forge pillow
<br>好了。<br>from ultralytics import YOLO

yolo = YOLO(model='..\Models\yolov8m.pt', task='detect')

result=yolo(source=0, save=True)
<br><br>ultralytics\cfg\default.yaml # 存放参数和一些默认参数形式
<br><br>查看Pytorch是否能检查到GPU<br>import torch
print(torch.cuda.is_available())
<br>yolo task=detect mode=train model=..\Model\yolov8n.pt data=D:/gesture_recog/ASL/data.yaml epochs=50 imgsz=640 batch=4 device=0

<br># 验证模型
yolo task=detect mode=val model=runs/detect/train/weights/best.pt data=D:/gesture_recog/ASL/data.yaml
<br>人脸识别测试：<br>(yolov8) D:\facial_recog\ultralytics-8.1.0&gt;yolo task=detect mode=val model=runs/detect/train3/weights/best.pt data=D:\facial_recog\Faces\data.yaml     
<br>(yolov8) D:\gesture_recog\ultralytics-8.1.0&gt;yolo task=detect mode=val model=runs/detect/train/weights/best.pt data=D:/gesture_recog/ASL/data.yaml
D:\gesture_recog\ultralytics-8.1.0\ultralytics\nn\tasks.py:634: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(file, map_location="cpu"), file  # load
Ultralytics YOLOv8.1.0 🚀 Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)
Model summary (fused): 168 layers, 3010718 parameters, 0 gradients, 8.1 GFLOPs
val: Scanning D:\gesture_recog\ASL\valid\labels.cache... 1320 images, 60 backgrounds, 0 corrupt: 100%|██████████| 1320/1320 [00:00&lt;?, ?it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 83/83 [00:13&lt;00:00,  6.27it/s]
                   all       1320       1270      0.921      0.889      0.945      0.785
                     A       1320         41      0.989      0.927      0.963      0.812
                     B       1320         53      0.877          1      0.989      0.839
                     C       1320         51      0.944      0.922       0.98      0.777
                     D       1320         44      0.906      0.876      0.949      0.761
                     E       1320         46          1      0.909      0.949      0.862
                     F       1320         49      0.981      0.898      0.983      0.895
                     G       1320         51      0.843      0.841      0.897      0.761
                     H       1320         46      0.903      0.957      0.956      0.773
                     I       1320         48      0.721      0.729      0.782      0.536
                     J       1320         48      0.954      0.861      0.938      0.697
                     K       1320         51      0.899      0.804      0.893      0.726
                     L       1320         56          1      0.905      0.984      0.826
                     M       1320         50      0.934       0.92      0.982      0.845
                     N       1320         29      0.891       0.85      0.968       0.83
                     O       1320         54      0.958      0.836      0.947      0.701
                     P       1320         44      0.943      0.886      0.939      0.687
                     Q       1320         44      0.831      0.818      0.858      0.744
                     R       1320         52      0.909      0.957      0.974      0.875
                     S       1320         67      0.962      0.881      0.965      0.851
                     T       1320         45      0.926      0.911      0.959       0.89
                     U       1320         53      0.938      0.943      0.977      0.852
                     V       1320         48      0.937      0.929      0.961      0.798
                     W       1320         46      0.977      0.942      0.984      0.842
                     X       1320         57      0.981      0.895       0.96      0.723
                     Y       1320         55      0.928      0.938       0.97      0.802
                     Z       1320         42      0.824      0.786      0.867      0.716
Speed: 0.4ms preprocess, 4.3ms inference, 0.0ms loss, 1.3ms postprocess per image
Results saved to runs\detect\val2
💡 Learn more at https://docs.ultralytics.com/modes/val
<br># 使用模型预测
yolo task=detect mode=predict model=runs/detect/train/weights/best.pt source=path/to/images_or_video
<br><img alt="Pasted image 20250318224527.png" src="https://congzhi.wiki/some-notes/pics/pasted-image-20250318224527.png"><br>安装 Flask 库：<br>(yolov8) D:\gesture_recog\Flask&gt;pip install flask
<br><br><br><br><br>]]></description><link>https://congzhi.wiki/some-notes/yolo-env-config.html</link><guid isPermaLink="false">Some Notes/YOLO Env Config.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Thu, 20 Mar 2025 17:13:12 GMT</pubDate><enclosure url="https://congzhi.wiki/some-notes/pics/cuda_version.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://congzhi.wiki/some-notes/pics/cuda_version.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[index]]></title><description><![CDATA[ 
 <br><br><br>
<br><a data-tooltip-position="top" aria-label="Congrats on Finding Here!" data-href="#Congrats on Finding Here!" href="https://congzhi.wiki/about:blank#Congrats_on_Finding_Here!" class="internal-link" target="_self" rel="noopener nofollow">Congrats on Finding Here!</a>
<br><a data-tooltip-position="top" aria-label="Everything You Could Learn Right Now" data-href="#Everything You Could Learn Right Now" href="https://congzhi.wiki/about:blank#Everything_You_Could_Learn_Right_Now" class="internal-link" target="_self" rel="noopener nofollow">Everything You Could Learn Right Now</a>
<br><a data-tooltip-position="top" aria-label="All About Me" data-href="#All About Me" href="https://congzhi.wiki/about:blank#All_About_Me" class="internal-link" target="_self" rel="noopener nofollow">All About Me</a>
<br><a data-tooltip-position="top" aria-label="Contact Me" data-href="#Contact Me" href="https://congzhi.wiki/about:blank#Contact_Me" class="internal-link" target="_self" rel="noopener nofollow">Contact Me</a>
<br><br><br>Hi there! Welcome to my home site. This site will be my zone of the internet. I will be sharing everything here, including some computer science notes I have made myself, some life stuff, and on and on and on...<br>From this page, you might assume this site is English-friendly. However, the majority of the note content is written in Chinese. For those who don't know Chinese, I feel real-sorry for you, but you can find some C++ notes written in English. Come on, go take an adventure!<br><br><br>Currently, there's five series I have are listed below. In the future, this list will grow longer.<br>Congzhi's CS Note Series

<br><a data-href="Building and Version Control" href="https://congzhi.wiki/building-and-version-control/building-and-version-control.html" class="internal-link" target="_self" rel="noopener nofollow">Building and Version Control</a>
<br><a data-href="Congzhi's OS Series" href="https://congzhi.wiki/congzhi's-os-series/congzhi's-os-series.html" class="internal-link" target="_self" rel="noopener nofollow">Congzhi's OS Series</a>
<br><a data-href="C Plus Plus" href="https://congzhi.wiki/c-plus-plus/c-plus-plus.html" class="internal-link" target="_self" rel="noopener nofollow">C Plus Plus</a> &lt;--- English Notes here!
<br><a data-href="CS50 SQL" href="https://congzhi.wiki/cs50-sql/cs50-sql.html" class="internal-link" target="_self" rel="noopener nofollow">CS50 SQL</a>
<br><a data-href="Data Structure and Algorithm" href="https://congzhi.wiki/data-structure-and-algorithm/data-structure-and-algorithm.html" class="internal-link" target="_self" rel="noopener nofollow">Data Structure and Algorithm</a>
<br><a data-href="Some Notes" href="https://congzhi.wiki/some-notes/some-notes.html" class="internal-link" target="_self" rel="noopener nofollow">Some Notes</a>

<br>Sadly, projects or series have been abandoned for some reasons. But you might strike gold there!<br>Abandoned Projects

<br><a data-tooltip-position="top" aria-label="Computer Networking A Top-Down Approach" data-href="Computer Networking A Top-Down Approach" href="https://congzhi.wiki/computer-networking-a-top-down-approach/computer-networking-a-top-down-approach.html" class="internal-link" target="_self" rel="noopener nofollow">Computer Networking</a>

<br><br><br>This section will be released when it's appropriate:<br>All About Me

<br><a data-href="生记" href="https://congzhi.wiki/生记/生记.html" class="internal-link" target="_self" rel="noopener nofollow">生记</a>
<br><a data-href="游记" href="https://congzhi.wiki/游记/游记.html" class="internal-link" target="_self" rel="noopener nofollow">游记</a>
<br><a data-href="业记" href="https://congzhi.wiki/业记/业记.html" class="internal-link" target="_self" rel="noopener nofollow">业记</a>

<br><br><br>You are welcomed to contact me at <a data-tooltip-position="top" aria-label="mailto:duzhi_02@qq.com" rel="noopener nofollow" class="external-link" href="https://congzhi.wiki/mailto:duzhi_02@qq.com" target="_blank">duzhi_02@qq.com</a>!<br>
你可以通过邮箱 <a data-tooltip-position="top" aria-label="mailto:duzhi_02@qq.com" rel="noopener nofollow" class="external-link" href="https://congzhi.wiki/mailto:duzhi_02@qq.com" target="_blank">duzhi_02@qq.com</a> 联系我。欢迎任何类型的留言！]]></description><link>https://congzhi.wiki/index.html</link><guid isPermaLink="false">index.md</guid><dc:creator><![CDATA[Congzhi]]></dc:creator><pubDate>Tue, 25 Mar 2025 09:05:53 GMT</pubDate></item></channel></rss>